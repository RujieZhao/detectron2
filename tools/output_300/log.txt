[10/27 18:12:10] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:12:11] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.113.01
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/27 18:12:11] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[10/27 18:12:11] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[10/27 18:12:11] detectron2 INFO: Full config saved to ./output_300/config.yaml
[10/27 18:12:11] d2.utils.env INFO: Using a generated random seed 14555235
[10/27 18:12:27] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.59 seconds.
[10/27 18:12:28] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[10/27 18:12:36] d2.data.build INFO: Removed 0 images with no usable annotations. 301 images left.
[10/27 18:12:36] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 656          |   bicycle    | 18           |      car      | 133          |
|  motorcycle   | 38           |   airplane   | 5            |      bus      | 26           |
|     train     | 13           |    truck     | 33           |     boat      | 29           |
| traffic light | 28           | fire hydrant | 7            |   stop sign   | 2            |
| parking meter | 5            |    bench     | 15           |     bird      | 19           |
|      cat      | 12           |     dog      | 13           |     horse     | 13           |
|     sheep     | 3            |     cow      | 39           |   elephant    | 13           |
|     bear      | 5            |    zebra     | 25           |    giraffe    | 9            |
|   backpack    | 26           |   umbrella   | 32           |    handbag    | 44           |
|      tie      | 25           |   suitcase   | 9            |    frisbee    | 5            |
|     skis      | 15           |  snowboard   | 5            |  sports ball  | 26           |
|     kite      | 19           | baseball bat | 9            | baseball gl.. | 17           |
|  skateboard   | 18           |  surfboard   | 8            | tennis racket | 12           |
|    bottle     | 65           |  wine glass  | 5            |      cup      | 27           |
|     fork      | 8            |    knife     | 13           |     spoon     | 26           |
|     bowl      | 43           |    banana    | 28           |     apple     | 24           |
|   sandwich    | 8            |    orange    | 26           |   broccoli    | 13           |
|    carrot     | 12           |   hot dog    | 8            |     pizza     | 5            |
|     donut     | 31           |     cake     | 15           |     chair     | 84           |
|     couch     | 25           | potted plant | 25           |      bed      | 11           |
| dining table  | 31           |    toilet    | 5            |      tv       | 22           |
|    laptop     | 12           |    mouse     | 5            |    remote     | 27           |
|   keyboard    | 8            |  cell phone  | 12           |   microwave   | 7            |
|     oven      | 11           |   toaster    | 1            |     sink      | 17           |
| refrigerator  | 5            |     book     | 49           |     clock     | 22           |
|     vase      | 15           |   scissors   | 2            |  teddy bear   | 8            |
|  hair drier   | 1            |  toothbrush  | 5            |               |              |
|     total     | 2196         |              |              |               |              |[0m
[10/27 18:12:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[10/27 18:12:38] d2.data.build INFO: Using training sampler TrainingSampler
[10/27 18:12:38] d2.data.common INFO: Serializing 301 elements to byte tensors and concatenating them all ...
[10/27 18:12:38] d2.data.common INFO: Serialized dataset takes 1.19 MiB
[10/27 18:12:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl ...
[10/27 18:12:38] fvcore.common.checkpoint INFO: Reading a file from 'Detectron2 Model Zoo'
[10/27 18:12:38] d2.engine.train_loop INFO: Starting training from iteration 0
[10/27 18:12:47] d2.utils.events INFO:  eta: 9:35:18  iter: 19  total_loss: 0.773  loss_cls: 0.1738  loss_box_reg: 0.2129  loss_mask: 0.2554  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.06385  time: 0.3811  data_time: 0.0169  lr: 4.9952e-05  max_mem: 4724M
[10/27 18:12:54] d2.utils.events INFO:  eta: 9:31:20  iter: 39  total_loss: 0.6972  loss_cls: 0.1626  loss_box_reg: 0.1844  loss_mask: 0.2597  loss_rpn_cls: 0.03027  loss_rpn_loc: 0.04767  time: 0.3746  data_time: 0.0071  lr: 9.9902e-05  max_mem: 4900M
[10/27 18:13:02] d2.utils.events INFO:  eta: 9:26:57  iter: 59  total_loss: 0.6563  loss_cls: 0.1628  loss_box_reg: 0.2109  loss_mask: 0.2452  loss_rpn_cls: 0.0344  loss_rpn_loc: 0.0482  time: 0.3756  data_time: 0.0074  lr: 0.00014985  max_mem: 4903M
[10/27 18:13:09] d2.utils.events INFO:  eta: 9:24:27  iter: 79  total_loss: 0.7372  loss_cls: 0.188  loss_box_reg: 0.2219  loss_mask: 0.2314  loss_rpn_cls: 0.03749  loss_rpn_loc: 0.06594  time: 0.3765  data_time: 0.0075  lr: 0.0001998  max_mem: 4903M
[10/27 18:13:17] d2.utils.events INFO:  eta: 9:24:20  iter: 99  total_loss: 0.82  loss_cls: 0.2133  loss_box_reg: 0.2421  loss_mask: 0.2508  loss_rpn_cls: 0.02923  loss_rpn_loc: 0.07989  time: 0.3759  data_time: 0.0070  lr: 0.00024975  max_mem: 4903M
[10/27 18:13:24] d2.utils.events INFO:  eta: 9:24:12  iter: 119  total_loss: 0.7438  loss_cls: 0.1791  loss_box_reg: 0.2011  loss_mask: 0.2535  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.05601  time: 0.3762  data_time: 0.0069  lr: 0.0002997  max_mem: 4903M
[10/27 18:13:32] d2.utils.events INFO:  eta: 9:26:29  iter: 139  total_loss: 0.7278  loss_cls: 0.1861  loss_box_reg: 0.2101  loss_mask: 0.2698  loss_rpn_cls: 0.02442  loss_rpn_loc: 0.04994  time: 0.3777  data_time: 0.0069  lr: 0.00034965  max_mem: 4903M
[10/27 18:13:40] d2.utils.events INFO:  eta: 9:24:16  iter: 159  total_loss: 0.6961  loss_cls: 0.1604  loss_box_reg: 0.2153  loss_mask: 0.2422  loss_rpn_cls: 0.02411  loss_rpn_loc: 0.03389  time: 0.3772  data_time: 0.0077  lr: 0.0003996  max_mem: 4903M
[10/27 18:13:47] d2.utils.events INFO:  eta: 9:23:48  iter: 179  total_loss: 0.6642  loss_cls: 0.1563  loss_box_reg: 0.1956  loss_mask: 0.243  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.05453  time: 0.3771  data_time: 0.0071  lr: 0.00044955  max_mem: 4903M
[10/27 18:13:55] d2.utils.events INFO:  eta: 9:25:56  iter: 199  total_loss: 0.8097  loss_cls: 0.1892  loss_box_reg: 0.2427  loss_mask: 0.2593  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.05757  time: 0.3788  data_time: 0.0069  lr: 0.0004995  max_mem: 4906M
[10/27 18:14:03] d2.utils.events INFO:  eta: 9:25:18  iter: 219  total_loss: 0.7622  loss_cls: 0.1853  loss_box_reg: 0.2303  loss_mask: 0.2491  loss_rpn_cls: 0.0327  loss_rpn_loc: 0.0608  time: 0.3785  data_time: 0.0069  lr: 0.00054945  max_mem: 4906M
[10/27 18:14:10] d2.utils.events INFO:  eta: 9:25:53  iter: 239  total_loss: 0.6738  loss_cls: 0.1615  loss_box_reg: 0.2046  loss_mask: 0.244  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.04715  time: 0.3794  data_time: 0.0068  lr: 0.0005994  max_mem: 4906M
[10/27 18:14:18] d2.utils.events INFO:  eta: 9:24:41  iter: 259  total_loss: 0.7317  loss_cls: 0.1738  loss_box_reg: 0.2104  loss_mask: 0.241  loss_rpn_cls: 0.03291  loss_rpn_loc: 0.06347  time: 0.3792  data_time: 0.0074  lr: 0.00064935  max_mem: 4906M
[10/27 18:14:25] d2.utils.events INFO:  eta: 9:23:35  iter: 279  total_loss: 0.5911  loss_cls: 0.1483  loss_box_reg: 0.1893  loss_mask: 0.2182  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.0344  time: 0.3782  data_time: 0.0073  lr: 0.0006993  max_mem: 4906M
[10/27 18:14:33] d2.utils.events INFO:  eta: 9:23:28  iter: 299  total_loss: 0.777  loss_cls: 0.1877  loss_box_reg: 0.2172  loss_mask: 0.2464  loss_rpn_cls: 0.03076  loss_rpn_loc: 0.09264  time: 0.3780  data_time: 0.0076  lr: 0.00074925  max_mem: 4906M
[10/27 18:14:40] d2.utils.events INFO:  eta: 9:23:40  iter: 319  total_loss: 0.7037  loss_cls: 0.1731  loss_box_reg: 0.2077  loss_mask: 0.2422  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.06172  time: 0.3781  data_time: 0.0070  lr: 0.0007992  max_mem: 4906M
[10/27 18:14:48] d2.utils.events INFO:  eta: 9:23:13  iter: 339  total_loss: 0.7095  loss_cls: 0.1747  loss_box_reg: 0.192  loss_mask: 0.2432  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.03973  time: 0.3778  data_time: 0.0078  lr: 0.00084915  max_mem: 4906M
[10/27 18:14:55] d2.utils.events INFO:  eta: 9:23:47  iter: 359  total_loss: 0.6689  loss_cls: 0.1521  loss_box_reg: 0.2104  loss_mask: 0.2258  loss_rpn_cls: 0.02261  loss_rpn_loc: 0.04649  time: 0.3779  data_time: 0.0073  lr: 0.0008991  max_mem: 4906M
[10/27 18:15:03] d2.utils.events INFO:  eta: 9:24:17  iter: 379  total_loss: 0.6498  loss_cls: 0.1519  loss_box_reg: 0.1968  loss_mask: 0.2237  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.05028  time: 0.3781  data_time: 0.0073  lr: 0.00094905  max_mem: 4906M
[10/27 18:15:11] d2.utils.events INFO:  eta: 9:25:17  iter: 399  total_loss: 0.7365  loss_cls: 0.1849  loss_box_reg: 0.2176  loss_mask: 0.2315  loss_rpn_cls: 0.02862  loss_rpn_loc: 0.05269  time: 0.3784  data_time: 0.0078  lr: 0.000999  max_mem: 4906M
[10/27 18:15:18] d2.utils.events INFO:  eta: 9:26:31  iter: 419  total_loss: 0.6596  loss_cls: 0.1628  loss_box_reg: 0.2005  loss_mask: 0.2494  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.06258  time: 0.3787  data_time: 0.0082  lr: 0.001049  max_mem: 4906M
[10/27 18:15:26] d2.utils.events INFO:  eta: 9:25:42  iter: 439  total_loss: 0.6018  loss_cls: 0.1421  loss_box_reg: 0.1915  loss_mask: 0.2144  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.04212  time: 0.3779  data_time: 0.0065  lr: 0.0010989  max_mem: 4906M
[10/27 18:15:33] d2.utils.events INFO:  eta: 9:25:35  iter: 459  total_loss: 0.625  loss_cls: 0.1493  loss_box_reg: 0.1792  loss_mask: 0.2319  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.03073  time: 0.3781  data_time: 0.0068  lr: 0.0011489  max_mem: 4906M
[10/27 18:15:41] d2.utils.events INFO:  eta: 9:26:30  iter: 479  total_loss: 0.5607  loss_cls: 0.1309  loss_box_reg: 0.1602  loss_mask: 0.2021  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.03542  time: 0.3783  data_time: 0.0075  lr: 0.0011988  max_mem: 4906M
[10/27 18:15:48] d2.utils.events INFO:  eta: 9:24:56  iter: 499  total_loss: 0.6369  loss_cls: 0.14  loss_box_reg: 0.1798  loss_mask: 0.2214  loss_rpn_cls: 0.02288  loss_rpn_loc: 0.05189  time: 0.3781  data_time: 0.0074  lr: 0.0012488  max_mem: 4906M
[10/27 18:15:56] d2.utils.events INFO:  eta: 9:25:33  iter: 519  total_loss: 0.7361  loss_cls: 0.1727  loss_box_reg: 0.2146  loss_mask: 0.2398  loss_rpn_cls: 0.03053  loss_rpn_loc: 0.0753  time: 0.3786  data_time: 0.0074  lr: 0.0012987  max_mem: 4906M
[10/27 18:16:04] d2.utils.events INFO:  eta: 9:25:52  iter: 539  total_loss: 0.6519  loss_cls: 0.1378  loss_box_reg: 0.2037  loss_mask: 0.2301  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.03861  time: 0.3788  data_time: 0.0078  lr: 0.0013487  max_mem: 4906M
[10/27 18:16:12] d2.utils.events INFO:  eta: 9:25:46  iter: 559  total_loss: 0.6947  loss_cls: 0.1558  loss_box_reg: 0.2031  loss_mask: 0.2258  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.08249  time: 0.3790  data_time: 0.0082  lr: 0.0013986  max_mem: 4914M
[10/27 18:16:19] d2.utils.events INFO:  eta: 9:26:07  iter: 579  total_loss: 0.5888  loss_cls: 0.1552  loss_box_reg: 0.1757  loss_mask: 0.2446  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.048  time: 0.3792  data_time: 0.0070  lr: 0.0014486  max_mem: 4914M
[10/27 18:16:27] d2.utils.events INFO:  eta: 9:26:28  iter: 599  total_loss: 0.679  loss_cls: 0.1517  loss_box_reg: 0.2134  loss_mask: 0.2455  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.05256  time: 0.3796  data_time: 0.0083  lr: 0.0014985  max_mem: 4914M
[10/27 18:16:35] d2.utils.events INFO:  eta: 9:27:03  iter: 619  total_loss: 0.6226  loss_cls: 0.134  loss_box_reg: 0.204  loss_mask: 0.2278  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.04415  time: 0.3801  data_time: 0.0081  lr: 0.0015485  max_mem: 4914M
[10/27 18:16:43] d2.utils.events INFO:  eta: 9:27:13  iter: 639  total_loss: 0.6566  loss_cls: 0.1536  loss_box_reg: 0.1925  loss_mask: 0.2302  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.04853  time: 0.3803  data_time: 0.0076  lr: 0.0015984  max_mem: 4914M
[10/27 18:16:50] d2.utils.events INFO:  eta: 9:27:05  iter: 659  total_loss: 0.6229  loss_cls: 0.1315  loss_box_reg: 0.1726  loss_mask: 0.221  loss_rpn_cls: 0.02322  loss_rpn_loc: 0.07117  time: 0.3803  data_time: 0.0073  lr: 0.0016484  max_mem: 4914M
[10/27 18:16:58] d2.utils.events INFO:  eta: 9:26:58  iter: 679  total_loss: 0.5912  loss_cls: 0.1234  loss_box_reg: 0.1855  loss_mask: 0.2179  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.0419  time: 0.3802  data_time: 0.0073  lr: 0.0016983  max_mem: 4914M
[10/27 18:17:05] d2.utils.events INFO:  eta: 9:26:32  iter: 699  total_loss: 0.6492  loss_cls: 0.1415  loss_box_reg: 0.204  loss_mask: 0.233  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.04685  time: 0.3800  data_time: 0.0069  lr: 0.0017483  max_mem: 4914M
[10/27 18:17:13] d2.utils.events INFO:  eta: 9:26:04  iter: 719  total_loss: 0.4518  loss_cls: 0.08957  loss_box_reg: 0.1204  loss_mask: 0.1913  loss_rpn_cls: 0.01112  loss_rpn_loc: 0.03509  time: 0.3797  data_time: 0.0072  lr: 0.0017982  max_mem: 4914M
[10/27 18:17:21] d2.utils.events INFO:  eta: 9:25:56  iter: 739  total_loss: 0.626  loss_cls: 0.1463  loss_box_reg: 0.2118  loss_mask: 0.2318  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.05382  time: 0.3797  data_time: 0.0070  lr: 0.0018482  max_mem: 4914M
[10/27 18:17:28] d2.utils.events INFO:  eta: 9:26:27  iter: 759  total_loss: 0.666  loss_cls: 0.1444  loss_box_reg: 0.224  loss_mask: 0.2241  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.05466  time: 0.3799  data_time: 0.0076  lr: 0.0018981  max_mem: 4914M
[10/27 18:17:36] d2.utils.events INFO:  eta: 9:26:20  iter: 779  total_loss: 0.5768  loss_cls: 0.1207  loss_box_reg: 0.1924  loss_mask: 0.2126  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.04138  time: 0.3798  data_time: 0.0071  lr: 0.0019481  max_mem: 4914M
[10/27 18:17:43] d2.utils.events INFO:  eta: 9:26:25  iter: 799  total_loss: 0.6233  loss_cls: 0.1333  loss_box_reg: 0.1887  loss_mask: 0.2128  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.06095  time: 0.3800  data_time: 0.0067  lr: 0.001998  max_mem: 4914M
[10/27 18:17:51] d2.utils.events INFO:  eta: 9:26:24  iter: 819  total_loss: 0.5698  loss_cls: 0.1082  loss_box_reg: 0.1813  loss_mask: 0.1977  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.04107  time: 0.3801  data_time: 0.0073  lr: 0.002048  max_mem: 4914M
[10/27 18:17:59] d2.utils.events INFO:  eta: 9:26:09  iter: 839  total_loss: 0.6637  loss_cls: 0.128  loss_box_reg: 0.2017  loss_mask: 0.2239  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.06714  time: 0.3801  data_time: 0.0069  lr: 0.0020979  max_mem: 4914M
[10/27 18:18:06] d2.utils.events INFO:  eta: 9:26:02  iter: 859  total_loss: 0.6136  loss_cls: 0.1215  loss_box_reg: 0.1969  loss_mask: 0.2053  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.0499  time: 0.3800  data_time: 0.0074  lr: 0.0021479  max_mem: 4914M
[10/27 18:18:14] d2.utils.events INFO:  eta: 9:25:54  iter: 879  total_loss: 0.6792  loss_cls: 0.1335  loss_box_reg: 0.1968  loss_mask: 0.2324  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.05451  time: 0.3800  data_time: 0.0073  lr: 0.0021978  max_mem: 4914M
[10/27 18:18:22] d2.utils.events INFO:  eta: 9:25:56  iter: 899  total_loss: 0.5573  loss_cls: 0.09645  loss_box_reg: 0.1746  loss_mask: 0.1965  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.04853  time: 0.3802  data_time: 0.0072  lr: 0.0022478  max_mem: 4914M
[10/27 18:18:29] d2.utils.events INFO:  eta: 9:25:48  iter: 919  total_loss: 0.5924  loss_cls: 0.1119  loss_box_reg: 0.1869  loss_mask: 0.2085  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.04776  time: 0.3803  data_time: 0.0074  lr: 0.0022977  max_mem: 4914M
[10/27 18:18:38] d2.utils.events INFO:  eta: 9:26:15  iter: 939  total_loss: 0.6145  loss_cls: 0.134  loss_box_reg: 0.2132  loss_mask: 0.2214  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.04651  time: 0.3808  data_time: 0.0071  lr: 0.0023477  max_mem: 4914M
[10/27 18:18:45] d2.utils.events INFO:  eta: 9:26:10  iter: 959  total_loss: 0.4546  loss_cls: 0.08641  loss_box_reg: 0.1391  loss_mask: 0.1669  loss_rpn_cls: 0.006191  loss_rpn_loc: 0.02354  time: 0.3808  data_time: 0.0065  lr: 0.0023976  max_mem: 4914M
[10/27 18:18:53] d2.utils.events INFO:  eta: 9:26:04  iter: 979  total_loss: 0.5917  loss_cls: 0.1135  loss_box_reg: 0.1727  loss_mask: 0.2218  loss_rpn_cls: 0.009549  loss_rpn_loc: 0.04599  time: 0.3809  data_time: 0.0068  lr: 0.0024476  max_mem: 4914M
[10/27 18:19:00] d2.utils.events INFO:  eta: 9:25:55  iter: 999  total_loss: 0.6043  loss_cls: 0.1196  loss_box_reg: 0.1999  loss_mask: 0.2244  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.04737  time: 0.3808  data_time: 0.0075  lr: 0.0024975  max_mem: 4914M
[10/27 18:19:08] d2.utils.events INFO:  eta: 9:25:50  iter: 1019  total_loss: 0.5788  loss_cls: 0.09418  loss_box_reg: 0.1871  loss_mask: 0.2011  loss_rpn_cls: 0.006777  loss_rpn_loc: 0.04821  time: 0.3810  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:19:16] d2.utils.events INFO:  eta: 9:25:42  iter: 1039  total_loss: 0.5956  loss_cls: 0.1341  loss_box_reg: 0.1811  loss_mask: 0.2145  loss_rpn_cls: 0.007648  loss_rpn_loc: 0.05169  time: 0.3809  data_time: 0.0068  lr: 0.0025  max_mem: 4914M
[10/27 18:19:24] d2.utils.events INFO:  eta: 9:26:08  iter: 1059  total_loss: 0.5512  loss_cls: 0.1031  loss_box_reg: 0.1603  loss_mask: 0.2061  loss_rpn_cls: 0.009171  loss_rpn_loc: 0.05355  time: 0.3811  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:19:31] d2.utils.events INFO:  eta: 9:26:05  iter: 1079  total_loss: 0.5975  loss_cls: 0.1104  loss_box_reg: 0.1785  loss_mask: 0.2219  loss_rpn_cls: 0.00898  loss_rpn_loc: 0.03766  time: 0.3811  data_time: 0.0067  lr: 0.0025  max_mem: 4914M
[10/27 18:19:39] d2.utils.events INFO:  eta: 9:26:02  iter: 1099  total_loss: 0.5758  loss_cls: 0.1147  loss_box_reg: 0.1838  loss_mask: 0.2117  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.05526  time: 0.3812  data_time: 0.0066  lr: 0.0025  max_mem: 4914M
[10/27 18:19:47] d2.utils.events INFO:  eta: 9:26:11  iter: 1119  total_loss: 0.4694  loss_cls: 0.08109  loss_box_reg: 0.1574  loss_mask: 0.1953  loss_rpn_cls: 0.008636  loss_rpn_loc: 0.04033  time: 0.3812  data_time: 0.0068  lr: 0.0025  max_mem: 4914M
[10/27 18:19:54] d2.utils.events INFO:  eta: 9:25:54  iter: 1139  total_loss: 0.4649  loss_cls: 0.0732  loss_box_reg: 0.1434  loss_mask: 0.1903  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.04926  time: 0.3813  data_time: 0.0067  lr: 0.0025  max_mem: 4914M
[10/27 18:20:02] d2.utils.events INFO:  eta: 9:26:02  iter: 1159  total_loss: 0.5084  loss_cls: 0.09379  loss_box_reg: 0.1674  loss_mask: 0.193  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.03521  time: 0.3813  data_time: 0.0071  lr: 0.0025  max_mem: 4914M
[10/27 18:20:10] d2.utils.events INFO:  eta: 9:26:20  iter: 1179  total_loss: 0.5224  loss_cls: 0.1012  loss_box_reg: 0.1921  loss_mask: 0.2081  loss_rpn_cls: 0.008764  loss_rpn_loc: 0.04258  time: 0.3813  data_time: 0.0071  lr: 0.0025  max_mem: 4914M
[10/27 18:20:17] d2.utils.events INFO:  eta: 9:25:56  iter: 1199  total_loss: 0.5009  loss_cls: 0.1052  loss_box_reg: 0.1606  loss_mask: 0.1793  loss_rpn_cls: 0.005652  loss_rpn_loc: 0.03588  time: 0.3814  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:20:25] d2.utils.events INFO:  eta: 9:26:44  iter: 1219  total_loss: 0.5761  loss_cls: 0.1141  loss_box_reg: 0.2059  loss_mask: 0.2001  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.06615  time: 0.3817  data_time: 0.0071  lr: 0.0025  max_mem: 4914M
[10/27 18:20:33] d2.utils.events INFO:  eta: 9:26:36  iter: 1239  total_loss: 0.527  loss_cls: 0.1012  loss_box_reg: 0.1751  loss_mask: 0.2123  loss_rpn_cls: 0.00888  loss_rpn_loc: 0.04094  time: 0.3816  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:20:40] d2.utils.events INFO:  eta: 9:26:28  iter: 1259  total_loss: 0.5453  loss_cls: 0.1018  loss_box_reg: 0.1724  loss_mask: 0.1895  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.03515  time: 0.3815  data_time: 0.0071  lr: 0.0025  max_mem: 4914M
[10/27 18:20:48] d2.utils.events INFO:  eta: 9:27:00  iter: 1279  total_loss: 0.4815  loss_cls: 0.08423  loss_box_reg: 0.1568  loss_mask: 0.1999  loss_rpn_cls: 0.007733  loss_rpn_loc: 0.03673  time: 0.3815  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:20:56] d2.utils.events INFO:  eta: 9:27:34  iter: 1299  total_loss: 0.4872  loss_cls: 0.08639  loss_box_reg: 0.1604  loss_mask: 0.1875  loss_rpn_cls: 0.009214  loss_rpn_loc: 0.04552  time: 0.3816  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:21:04] d2.utils.events INFO:  eta: 9:28:04  iter: 1319  total_loss: 0.6188  loss_cls: 0.122  loss_box_reg: 0.2041  loss_mask: 0.2209  loss_rpn_cls: 0.007112  loss_rpn_loc: 0.04023  time: 0.3818  data_time: 0.0074  lr: 0.0025  max_mem: 4914M
[10/27 18:21:11] d2.utils.events INFO:  eta: 9:28:17  iter: 1339  total_loss: 0.4379  loss_cls: 0.07535  loss_box_reg: 0.138  loss_mask: 0.1833  loss_rpn_cls: 0.008216  loss_rpn_loc: 0.03537  time: 0.3818  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:21:19] d2.utils.events INFO:  eta: 9:28:21  iter: 1359  total_loss: 0.5164  loss_cls: 0.09198  loss_box_reg: 0.1469  loss_mask: 0.1624  loss_rpn_cls: 0.006067  loss_rpn_loc: 0.03898  time: 0.3818  data_time: 0.0078  lr: 0.0025  max_mem: 4914M
[10/27 18:21:27] d2.utils.events INFO:  eta: 9:28:33  iter: 1379  total_loss: 0.5004  loss_cls: 0.08538  loss_box_reg: 0.1611  loss_mask: 0.1891  loss_rpn_cls: 0.008186  loss_rpn_loc: 0.04811  time: 0.3818  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:21:34] d2.utils.events INFO:  eta: 9:28:42  iter: 1399  total_loss: 0.5155  loss_cls: 0.09691  loss_box_reg: 0.1516  loss_mask: 0.2075  loss_rpn_cls: 0.006137  loss_rpn_loc: 0.05631  time: 0.3819  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:21:42] d2.utils.events INFO:  eta: 9:28:08  iter: 1419  total_loss: 0.4249  loss_cls: 0.08164  loss_box_reg: 0.1571  loss_mask: 0.1627  loss_rpn_cls: 0.00528  loss_rpn_loc: 0.03088  time: 0.3820  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:21:50] d2.utils.events INFO:  eta: 9:28:34  iter: 1439  total_loss: 0.5447  loss_cls: 0.08753  loss_box_reg: 0.1929  loss_mask: 0.1955  loss_rpn_cls: 0.009324  loss_rpn_loc: 0.03923  time: 0.3821  data_time: 0.0072  lr: 0.0025  max_mem: 4914M
[10/27 18:21:58] d2.utils.events INFO:  eta: 9:29:16  iter: 1459  total_loss: 0.5919  loss_cls: 0.1013  loss_box_reg: 0.1724  loss_mask: 0.203  loss_rpn_cls: 0.009447  loss_rpn_loc: 0.04583  time: 0.3823  data_time: 0.0076  lr: 0.0025  max_mem: 4914M
[10/27 18:22:06] d2.utils.events INFO:  eta: 9:28:32  iter: 1479  total_loss: 0.5314  loss_cls: 0.09216  loss_box_reg: 0.1785  loss_mask: 0.19  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.06451  time: 0.3823  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:22:14] d2.utils.events INFO:  eta: 9:29:10  iter: 1499  total_loss: 0.5591  loss_cls: 0.1028  loss_box_reg: 0.1864  loss_mask: 0.1962  loss_rpn_cls: 0.008273  loss_rpn_loc: 0.04169  time: 0.3825  data_time: 0.0072  lr: 0.0025  max_mem: 4914M
[10/27 18:22:21] d2.utils.events INFO:  eta: 9:29:04  iter: 1519  total_loss: 0.4973  loss_cls: 0.0892  loss_box_reg: 0.1615  loss_mask: 0.1909  loss_rpn_cls: 0.006499  loss_rpn_loc: 0.03221  time: 0.3826  data_time: 0.0068  lr: 0.0025  max_mem: 4914M
[10/27 18:22:29] d2.utils.events INFO:  eta: 9:29:16  iter: 1539  total_loss: 0.5138  loss_cls: 0.08582  loss_box_reg: 0.1584  loss_mask: 0.1778  loss_rpn_cls: 0.008085  loss_rpn_loc: 0.05351  time: 0.3828  data_time: 0.0072  lr: 0.0025  max_mem: 4914M
[10/27 18:22:37] d2.utils.events INFO:  eta: 9:29:55  iter: 1559  total_loss: 0.5013  loss_cls: 0.09421  loss_box_reg: 0.1734  loss_mask: 0.1802  loss_rpn_cls: 0.007441  loss_rpn_loc: 0.04173  time: 0.3829  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:22:45] d2.utils.events INFO:  eta: 9:29:01  iter: 1579  total_loss: 0.4322  loss_cls: 0.07117  loss_box_reg: 0.1516  loss_mask: 0.1855  loss_rpn_cls: 0.007058  loss_rpn_loc: 0.03782  time: 0.3828  data_time: 0.0077  lr: 0.0025  max_mem: 4914M
[10/27 18:22:52] d2.utils.events INFO:  eta: 9:29:05  iter: 1599  total_loss: 0.5177  loss_cls: 0.09013  loss_box_reg: 0.1719  loss_mask: 0.1927  loss_rpn_cls: 0.009046  loss_rpn_loc: 0.04399  time: 0.3829  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:23:00] d2.utils.events INFO:  eta: 9:28:33  iter: 1619  total_loss: 0.5509  loss_cls: 0.09808  loss_box_reg: 0.1902  loss_mask: 0.1989  loss_rpn_cls: 0.008081  loss_rpn_loc: 0.03747  time: 0.3829  data_time: 0.0072  lr: 0.0025  max_mem: 4914M
[10/27 18:23:08] d2.utils.events INFO:  eta: 9:28:38  iter: 1639  total_loss: 0.5523  loss_cls: 0.1052  loss_box_reg: 0.1829  loss_mask: 0.1945  loss_rpn_cls: 0.00889  loss_rpn_loc: 0.04894  time: 0.3830  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:23:16] d2.utils.events INFO:  eta: 9:28:34  iter: 1659  total_loss: 0.4953  loss_cls: 0.08577  loss_box_reg: 0.1577  loss_mask: 0.1963  loss_rpn_cls: 0.007386  loss_rpn_loc: 0.03647  time: 0.3829  data_time: 0.0072  lr: 0.0025  max_mem: 4914M
[10/27 18:23:23] d2.utils.events INFO:  eta: 9:28:17  iter: 1679  total_loss: 0.367  loss_cls: 0.06688  loss_box_reg: 0.1283  loss_mask: 0.1399  loss_rpn_cls: 0.004559  loss_rpn_loc: 0.03035  time: 0.3828  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:23:31] d2.utils.events INFO:  eta: 9:28:50  iter: 1699  total_loss: 0.5158  loss_cls: 0.09271  loss_box_reg: 0.1858  loss_mask: 0.193  loss_rpn_cls: 0.008963  loss_rpn_loc: 0.04158  time: 0.3829  data_time: 0.0077  lr: 0.0025  max_mem: 4914M
[10/27 18:23:39] d2.utils.events INFO:  eta: 9:29:04  iter: 1719  total_loss: 0.5167  loss_cls: 0.09129  loss_box_reg: 0.1748  loss_mask: 0.1831  loss_rpn_cls: 0.007595  loss_rpn_loc: 0.04657  time: 0.3830  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:23:47] d2.utils.events INFO:  eta: 9:29:18  iter: 1739  total_loss: 0.5299  loss_cls: 0.08685  loss_box_reg: 0.1554  loss_mask: 0.1871  loss_rpn_cls: 0.005946  loss_rpn_loc: 0.05651  time: 0.3831  data_time: 0.0068  lr: 0.0025  max_mem: 4914M
[10/27 18:23:54] d2.utils.events INFO:  eta: 9:28:27  iter: 1759  total_loss: 0.4279  loss_cls: 0.07583  loss_box_reg: 0.1436  loss_mask: 0.1716  loss_rpn_cls: 0.004376  loss_rpn_loc: 0.02683  time: 0.3830  data_time: 0.0074  lr: 0.0025  max_mem: 4914M
[10/27 18:24:02] d2.utils.events INFO:  eta: 9:28:55  iter: 1779  total_loss: 0.5211  loss_cls: 0.09607  loss_box_reg: 0.1737  loss_mask: 0.1999  loss_rpn_cls: 0.007267  loss_rpn_loc: 0.06449  time: 0.3832  data_time: 0.0067  lr: 0.0025  max_mem: 4914M
[10/27 18:24:10] d2.utils.events INFO:  eta: 9:28:43  iter: 1799  total_loss: 0.405  loss_cls: 0.06831  loss_box_reg: 0.1391  loss_mask: 0.1725  loss_rpn_cls: 0.003576  loss_rpn_loc: 0.02245  time: 0.3831  data_time: 0.0071  lr: 0.0025  max_mem: 4914M
[10/27 18:24:17] d2.utils.events INFO:  eta: 9:28:47  iter: 1819  total_loss: 0.4888  loss_cls: 0.08912  loss_box_reg: 0.1692  loss_mask: 0.1838  loss_rpn_cls: 0.008745  loss_rpn_loc: 0.04252  time: 0.3831  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:24:25] d2.utils.events INFO:  eta: 9:29:02  iter: 1839  total_loss: 0.3838  loss_cls: 0.06557  loss_box_reg: 0.1268  loss_mask: 0.1637  loss_rpn_cls: 0.003871  loss_rpn_loc: 0.02789  time: 0.3831  data_time: 0.0066  lr: 0.0025  max_mem: 4914M
[10/27 18:24:33] d2.utils.events INFO:  eta: 9:28:54  iter: 1859  total_loss: 0.4645  loss_cls: 0.07294  loss_box_reg: 0.1461  loss_mask: 0.1689  loss_rpn_cls: 0.005489  loss_rpn_loc: 0.05242  time: 0.3832  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:24:40] d2.utils.events INFO:  eta: 9:29:11  iter: 1879  total_loss: 0.4843  loss_cls: 0.08505  loss_box_reg: 0.1622  loss_mask: 0.1803  loss_rpn_cls: 0.005966  loss_rpn_loc: 0.03019  time: 0.3831  data_time: 0.0068  lr: 0.0025  max_mem: 4914M
[10/27 18:24:48] d2.utils.events INFO:  eta: 9:29:06  iter: 1899  total_loss: 0.4917  loss_cls: 0.08132  loss_box_reg: 0.1598  loss_mask: 0.1803  loss_rpn_cls: 0.004476  loss_rpn_loc: 0.04495  time: 0.3833  data_time: 0.0075  lr: 0.0025  max_mem: 4914M
[10/27 18:24:56] d2.utils.events INFO:  eta: 9:29:17  iter: 1919  total_loss: 0.5209  loss_cls: 0.08851  loss_box_reg: 0.1778  loss_mask: 0.1966  loss_rpn_cls: 0.005178  loss_rpn_loc: 0.05012  time: 0.3833  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:25:04] d2.utils.events INFO:  eta: 9:28:30  iter: 1939  total_loss: 0.4436  loss_cls: 0.07953  loss_box_reg: 0.1495  loss_mask: 0.1612  loss_rpn_cls: 0.008168  loss_rpn_loc: 0.03231  time: 0.3833  data_time: 0.0074  lr: 0.0025  max_mem: 4914M
[10/27 18:25:11] d2.utils.events INFO:  eta: 9:28:43  iter: 1959  total_loss: 0.435  loss_cls: 0.06396  loss_box_reg: 0.1471  loss_mask: 0.1779  loss_rpn_cls: 0.005263  loss_rpn_loc: 0.03834  time: 0.3834  data_time: 0.0073  lr: 0.0025  max_mem: 4914M
[10/27 18:25:19] d2.utils.events INFO:  eta: 9:29:04  iter: 1979  total_loss: 0.408  loss_cls: 0.06674  loss_box_reg: 0.1444  loss_mask: 0.164  loss_rpn_cls: 0.005941  loss_rpn_loc: 0.02909  time: 0.3835  data_time: 0.0066  lr: 0.0025  max_mem: 4914M
[10/27 18:25:27] d2.utils.events INFO:  eta: 9:29:30  iter: 1999  total_loss: 0.4301  loss_cls: 0.07392  loss_box_reg: 0.148  loss_mask: 0.1689  loss_rpn_cls: 0.004049  loss_rpn_loc: 0.0342  time: 0.3835  data_time: 0.0069  lr: 0.0025  max_mem: 4914M
[10/27 18:25:35] d2.utils.events INFO:  eta: 9:29:22  iter: 2019  total_loss: 0.5324  loss_cls: 0.08831  loss_box_reg: 0.1869  loss_mask: 0.1844  loss_rpn_cls: 0.008056  loss_rpn_loc: 0.06341  time: 0.3835  data_time: 0.0070  lr: 0.0025  max_mem: 4914M
[10/27 18:25:42] d2.utils.events INFO:  eta: 9:29:05  iter: 2039  total_loss: 0.4171  loss_cls: 0.06144  loss_box_reg: 0.1287  loss_mask: 0.1717  loss_rpn_cls: 0.003821  loss_rpn_loc: 0.04052  time: 0.3835  data_time: 0.0074  lr: 0.0025  max_mem: 4914M
[10/27 18:25:51] d2.utils.events INFO:  eta: 9:29:14  iter: 2059  total_loss: 0.4515  loss_cls: 0.08532  loss_box_reg: 0.1539  loss_mask: 0.184  loss_rpn_cls: 0.007907  loss_rpn_loc: 0.04398  time: 0.3837  data_time: 0.0080  lr: 0.0025  max_mem: 4914M
[10/27 18:25:59] d2.utils.events INFO:  eta: 9:29:29  iter: 2079  total_loss: 0.4122  loss_cls: 0.06727  loss_box_reg: 0.1272  loss_mask: 0.1595  loss_rpn_cls: 0.004172  loss_rpn_loc: 0.02839  time: 0.3838  data_time: 0.0068  lr: 0.0025  max_mem: 4937M
[10/27 18:26:06] d2.utils.events INFO:  eta: 9:29:14  iter: 2099  total_loss: 0.464  loss_cls: 0.07536  loss_box_reg: 0.1589  loss_mask: 0.1774  loss_rpn_cls: 0.005875  loss_rpn_loc: 0.04651  time: 0.3839  data_time: 0.0070  lr: 0.0025  max_mem: 4937M
[10/27 18:26:14] d2.utils.events INFO:  eta: 9:29:13  iter: 2119  total_loss: 0.3956  loss_cls: 0.05702  loss_box_reg: 0.1442  loss_mask: 0.168  loss_rpn_cls: 0.00417  loss_rpn_loc: 0.03169  time: 0.3839  data_time: 0.0069  lr: 0.0025  max_mem: 4937M
[10/27 18:26:22] d2.utils.events INFO:  eta: 9:28:59  iter: 2139  total_loss: 0.4185  loss_cls: 0.07006  loss_box_reg: 0.1316  loss_mask: 0.1589  loss_rpn_cls: 0.004354  loss_rpn_loc: 0.03584  time: 0.3840  data_time: 0.0064  lr: 0.0025  max_mem: 4937M
[10/27 18:26:30] d2.utils.events INFO:  eta: 9:28:58  iter: 2159  total_loss: 0.4257  loss_cls: 0.07502  loss_box_reg: 0.1457  loss_mask: 0.1696  loss_rpn_cls: 0.005561  loss_rpn_loc: 0.03772  time: 0.3841  data_time: 0.0078  lr: 0.0025  max_mem: 4937M
[10/27 18:26:38] d2.utils.events INFO:  eta: 9:29:05  iter: 2179  total_loss: 0.4006  loss_cls: 0.07104  loss_box_reg: 0.1346  loss_mask: 0.1606  loss_rpn_cls: 0.005681  loss_rpn_loc: 0.03679  time: 0.3841  data_time: 0.0084  lr: 0.0025  max_mem: 4937M
[10/27 18:26:45] d2.utils.events INFO:  eta: 9:29:06  iter: 2199  total_loss: 0.5189  loss_cls: 0.09906  loss_box_reg: 0.188  loss_mask: 0.1755  loss_rpn_cls: 0.006719  loss_rpn_loc: 0.04682  time: 0.3842  data_time: 0.0075  lr: 0.0025  max_mem: 4937M
[10/27 18:26:53] d2.utils.events INFO:  eta: 9:28:58  iter: 2219  total_loss: 0.3891  loss_cls: 0.0645  loss_box_reg: 0.1281  loss_mask: 0.171  loss_rpn_cls: 0.005256  loss_rpn_loc: 0.02916  time: 0.3843  data_time: 0.0076  lr: 0.0025  max_mem: 4937M
[10/27 18:27:01] d2.utils.events INFO:  eta: 9:28:50  iter: 2239  total_loss: 0.4248  loss_cls: 0.07331  loss_box_reg: 0.1462  loss_mask: 0.1739  loss_rpn_cls: 0.004948  loss_rpn_loc: 0.04388  time: 0.3843  data_time: 0.0072  lr: 0.0025  max_mem: 4937M
[10/27 18:27:09] d2.utils.events INFO:  eta: 9:29:03  iter: 2259  total_loss: 0.4473  loss_cls: 0.07323  loss_box_reg: 0.1556  loss_mask: 0.1625  loss_rpn_cls: 0.005052  loss_rpn_loc: 0.05575  time: 0.3844  data_time: 0.0071  lr: 0.0025  max_mem: 4984M
[10/27 18:27:15] d2.engine.hooks INFO: Overall training speed: 2273 iterations in 0:14:34 (0.3846 s / it)
[10/27 18:27:15] d2.engine.hooks INFO: Total training time: 0:14:35 (0:00:01 on hooks)
[10/27 18:27:15] d2.utils.events INFO:  eta: 9:29:38  iter: 2275  total_loss: 0.429  loss_cls: 0.064  loss_box_reg: 0.1426  loss_mask: 0.1707  loss_rpn_cls: 0.005876  loss_rpn_loc: 0.04476  time: 0.3845  data_time: 0.0079  lr: 0.0025  max_mem: 4984M
[10/27 18:27:24] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 18:27:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.113.01
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/27 18:27:25] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[10/27 18:27:25] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[10/27 18:27:25] detectron2 INFO: Full config saved to ./output_300/config.yaml
[10/27 18:27:25] d2.utils.env INFO: Using a generated random seed 27934861
[10/27 18:27:40] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.70 seconds.
[10/27 18:27:41] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[10/27 18:27:49] d2.data.build INFO: Removed 0 images with no usable annotations. 301 images left.
[10/27 18:27:50] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 656          |   bicycle    | 18           |      car      | 133          |
|  motorcycle   | 38           |   airplane   | 5            |      bus      | 26           |
|     train     | 13           |    truck     | 33           |     boat      | 29           |
| traffic light | 28           | fire hydrant | 7            |   stop sign   | 2            |
| parking meter | 5            |    bench     | 15           |     bird      | 19           |
|      cat      | 12           |     dog      | 13           |     horse     | 13           |
|     sheep     | 3            |     cow      | 39           |   elephant    | 13           |
|     bear      | 5            |    zebra     | 25           |    giraffe    | 9            |
|   backpack    | 26           |   umbrella   | 32           |    handbag    | 44           |
|      tie      | 25           |   suitcase   | 9            |    frisbee    | 5            |
|     skis      | 15           |  snowboard   | 5            |  sports ball  | 26           |
|     kite      | 19           | baseball bat | 9            | baseball gl.. | 17           |
|  skateboard   | 18           |  surfboard   | 8            | tennis racket | 12           |
|    bottle     | 65           |  wine glass  | 5            |      cup      | 27           |
|     fork      | 8            |    knife     | 13           |     spoon     | 26           |
|     bowl      | 43           |    banana    | 28           |     apple     | 24           |
|   sandwich    | 8            |    orange    | 26           |   broccoli    | 13           |
|    carrot     | 12           |   hot dog    | 8            |     pizza     | 5            |
|     donut     | 31           |     cake     | 15           |     chair     | 84           |
|     couch     | 25           | potted plant | 25           |      bed      | 11           |
| dining table  | 31           |    toilet    | 5            |      tv       | 22           |
|    laptop     | 12           |    mouse     | 5            |    remote     | 27           |
|   keyboard    | 8            |  cell phone  | 12           |   microwave   | 7            |
|     oven      | 11           |   toaster    | 1            |     sink      | 17           |
| refrigerator  | 5            |     book     | 49           |     clock     | 22           |
|     vase      | 15           |   scissors   | 2            |  teddy bear   | 8            |
|  hair drier   | 1            |  toothbrush  | 5            |               |              |
|     total     | 2196         |              |              |               |              |[0m
[10/27 18:27:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[10/27 18:27:51] d2.data.build INFO: Using training sampler TrainingSampler
[10/27 18:27:51] d2.data.common INFO: Serializing 301 elements to byte tensors and concatenating them all ...
[10/27 18:27:51] d2.data.common INFO: Serialized dataset takes 1.19 MiB
[10/27 18:27:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl ...
[10/27 18:27:52] fvcore.common.checkpoint INFO: Reading a file from 'Detectron2 Model Zoo'
[10/27 18:27:52] d2.engine.train_loop INFO: Starting training from iteration 0
[10/27 18:27:55] d2.utils.events INFO:  eta: 3:30:00  iter: 19  total_loss: 0.8311  loss_cls: 0.2382  loss_box_reg: 0.2361  loss_mask: 0.267  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.03845  time: 0.1384  data_time: 0.0104  lr: 4.9952e-05  max_mem: 1601M
[10/27 18:27:58] d2.utils.events INFO:  eta: 3:27:14  iter: 39  total_loss: 0.4405  loss_cls: 0.1078  loss_box_reg: 0.1029  loss_mask: 0.1715  loss_rpn_cls: 0.02915  loss_rpn_loc: 0.02501  time: 0.1310  data_time: 0.0022  lr: 9.9902e-05  max_mem: 1601M
[10/27 18:28:00] d2.utils.events INFO:  eta: 3:24:31  iter: 59  total_loss: 0.5211  loss_cls: 0.1477  loss_box_reg: 0.2134  loss_mask: 0.2139  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.02202  time: 0.1263  data_time: 0.0022  lr: 0.00014985  max_mem: 1601M
[10/27 18:28:02] d2.utils.events INFO:  eta: 3:03:45  iter: 79  total_loss: 0.536  loss_cls: 0.1503  loss_box_reg: 0.1681  loss_mask: 0.215  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.01779  time: 0.1232  data_time: 0.0024  lr: 0.0001998  max_mem: 1601M
[10/27 18:28:04] d2.utils.events INFO:  eta: 2:58:57  iter: 99  total_loss: 0.5996  loss_cls: 0.1556  loss_box_reg: 0.2426  loss_mask: 0.2411  loss_rpn_cls: 0.02301  loss_rpn_loc: 0.03297  time: 0.1203  data_time: 0.0022  lr: 0.00024975  max_mem: 1601M
[10/27 18:28:07] d2.utils.events INFO:  eta: 2:53:13  iter: 119  total_loss: 0.9024  loss_cls: 0.2306  loss_box_reg: 0.3424  loss_mask: 0.2182  loss_rpn_cls: 0.03497  loss_rpn_loc: 0.05102  time: 0.1193  data_time: 0.0026  lr: 0.0002997  max_mem: 1601M
[10/27 18:28:09] d2.utils.events INFO:  eta: 2:51:35  iter: 139  total_loss: 0.5219  loss_cls: 0.1383  loss_box_reg: 0.1156  loss_mask: 0.2094  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.0242  time: 0.1178  data_time: 0.0026  lr: 0.00034965  max_mem: 1601M
[10/27 18:28:11] d2.utils.events INFO:  eta: 2:47:40  iter: 159  total_loss: 0.8364  loss_cls: 0.2636  loss_box_reg: 0.2384  loss_mask: 0.2278  loss_rpn_cls: 0.03432  loss_rpn_loc: 0.0235  time: 0.1166  data_time: 0.0026  lr: 0.0003996  max_mem: 1601M
[10/27 18:28:13] d2.utils.events INFO:  eta: 2:43:56  iter: 179  total_loss: 0.4852  loss_cls: 0.1108  loss_box_reg: 0.1134  loss_mask: 0.1941  loss_rpn_cls: 0.005051  loss_rpn_loc: 0.01508  time: 0.1152  data_time: 0.0028  lr: 0.00044955  max_mem: 1601M
[10/27 18:28:15] d2.utils.events INFO:  eta: 2:42:03  iter: 199  total_loss: 0.5477  loss_cls: 0.09938  loss_box_reg: 0.1045  loss_mask: 0.2191  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.02776  time: 0.1145  data_time: 0.0027  lr: 0.0004995  max_mem: 1601M
[10/27 18:28:17] d2.utils.events INFO:  eta: 2:41:16  iter: 219  total_loss: 0.4853  loss_cls: 0.1208  loss_box_reg: 0.1066  loss_mask: 0.1882  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.0172  time: 0.1133  data_time: 0.0027  lr: 0.00054945  max_mem: 1601M
[10/27 18:28:19] d2.utils.events INFO:  eta: 2:39:38  iter: 239  total_loss: 0.6198  loss_cls: 0.1009  loss_box_reg: 0.1429  loss_mask: 0.2676  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.05123  time: 0.1128  data_time: 0.0024  lr: 0.0005994  max_mem: 1601M
[10/27 18:28:22] d2.utils.events INFO:  eta: 2:39:08  iter: 259  total_loss: 0.7372  loss_cls: 0.1896  loss_box_reg: 0.2192  loss_mask: 0.2222  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.03962  time: 0.1120  data_time: 0.0026  lr: 0.00064935  max_mem: 1601M
[10/27 18:28:24] d2.utils.events INFO:  eta: 2:38:51  iter: 279  total_loss: 0.735  loss_cls: 0.2058  loss_box_reg: 0.2387  loss_mask: 0.1945  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.02886  time: 0.1116  data_time: 0.0026  lr: 0.0006993  max_mem: 1601M
[10/27 18:28:26] d2.utils.events INFO:  eta: 2:38:38  iter: 299  total_loss: 0.747  loss_cls: 0.2547  loss_box_reg: 0.207  loss_mask: 0.2991  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.03286  time: 0.1114  data_time: 0.0029  lr: 0.00074925  max_mem: 1601M
[10/27 18:28:28] d2.utils.events INFO:  eta: 2:37:41  iter: 319  total_loss: 0.4801  loss_cls: 0.1092  loss_box_reg: 0.1321  loss_mask: 0.1932  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.02489  time: 0.1110  data_time: 0.0024  lr: 0.0007992  max_mem: 1601M
[10/27 18:28:30] d2.utils.events INFO:  eta: 2:36:32  iter: 339  total_loss: 0.6513  loss_cls: 0.1676  loss_box_reg: 0.1978  loss_mask: 0.1984  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.04764  time: 0.1103  data_time: 0.0026  lr: 0.00084915  max_mem: 1601M
[10/27 18:28:32] d2.utils.events INFO:  eta: 2:36:23  iter: 359  total_loss: 0.4625  loss_cls: 0.09624  loss_box_reg: 0.1293  loss_mask: 0.2371  loss_rpn_cls: 0.009571  loss_rpn_loc: 0.01901  time: 0.1100  data_time: 0.0025  lr: 0.0008991  max_mem: 1603M
[10/27 18:28:34] d2.utils.events INFO:  eta: 2:36:00  iter: 379  total_loss: 0.5692  loss_cls: 0.1295  loss_box_reg: 0.2268  loss_mask: 0.2127  loss_rpn_cls: 0.02272  loss_rpn_loc: 0.03086  time: 0.1097  data_time: 0.0024  lr: 0.00094905  max_mem: 1603M
[10/27 18:28:36] d2.utils.events INFO:  eta: 2:35:38  iter: 399  total_loss: 0.6412  loss_cls: 0.1329  loss_box_reg: 0.1999  loss_mask: 0.2034  loss_rpn_cls: 0.007686  loss_rpn_loc: 0.02611  time: 0.1092  data_time: 0.0023  lr: 0.000999  max_mem: 1603M
[10/27 18:28:38] d2.utils.events INFO:  eta: 2:35:02  iter: 419  total_loss: 0.6362  loss_cls: 0.1645  loss_box_reg: 0.2067  loss_mask: 0.1925  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.0259  time: 0.1089  data_time: 0.0026  lr: 0.001049  max_mem: 1603M
[10/27 18:28:40] d2.utils.events INFO:  eta: 2:34:13  iter: 439  total_loss: 0.8067  loss_cls: 0.1885  loss_box_reg: 0.1811  loss_mask: 0.2532  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.03337  time: 0.1083  data_time: 0.0024  lr: 0.0010989  max_mem: 1603M
[10/27 18:28:42] d2.utils.events INFO:  eta: 2:33:51  iter: 459  total_loss: 0.7754  loss_cls: 0.2167  loss_box_reg: 0.2435  loss_mask: 0.2248  loss_rpn_cls: 0.03811  loss_rpn_loc: 0.04226  time: 0.1080  data_time: 0.0024  lr: 0.0011489  max_mem: 1603M
[10/27 18:28:44] d2.utils.events INFO:  eta: 2:33:02  iter: 479  total_loss: 0.5609  loss_cls: 0.1055  loss_box_reg: 0.1605  loss_mask: 0.2026  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.03091  time: 0.1075  data_time: 0.0028  lr: 0.0011988  max_mem: 1603M
[10/27 18:28:46] d2.utils.events INFO:  eta: 2:32:41  iter: 499  total_loss: 0.4695  loss_cls: 0.1319  loss_box_reg: 0.1321  loss_mask: 0.2002  loss_rpn_cls: 0.009018  loss_rpn_loc: 0.01025  time: 0.1071  data_time: 0.0026  lr: 0.0012488  max_mem: 1603M
[10/27 18:28:48] d2.utils.events INFO:  eta: 2:32:39  iter: 519  total_loss: 1.024  loss_cls: 0.2061  loss_box_reg: 0.2234  loss_mask: 0.2531  loss_rpn_cls: 0.04059  loss_rpn_loc: 0.06769  time: 0.1069  data_time: 0.0025  lr: 0.0012987  max_mem: 1603M
[10/27 18:28:50] d2.utils.events INFO:  eta: 2:32:39  iter: 539  total_loss: 0.6337  loss_cls: 0.153  loss_box_reg: 0.2282  loss_mask: 0.1965  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.04624  time: 0.1070  data_time: 0.0022  lr: 0.0013487  max_mem: 1603M
[10/27 18:28:52] d2.utils.events INFO:  eta: 2:32:33  iter: 559  total_loss: 0.6468  loss_cls: 0.1864  loss_box_reg: 0.1521  loss_mask: 0.2438  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.02057  time: 0.1066  data_time: 0.0019  lr: 0.0013986  max_mem: 1603M
[10/27 18:28:54] d2.utils.events INFO:  eta: 2:32:31  iter: 579  total_loss: 0.7304  loss_cls: 0.2508  loss_box_reg: 0.1968  loss_mask: 0.2453  loss_rpn_cls: 0.02675  loss_rpn_loc: 0.03411  time: 0.1065  data_time: 0.0025  lr: 0.0014486  max_mem: 1603M
[10/27 18:28:56] d2.utils.events INFO:  eta: 2:31:51  iter: 599  total_loss: 0.4726  loss_cls: 0.1055  loss_box_reg: 0.1285  loss_mask: 0.1794  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.0242  time: 0.1063  data_time: 0.0023  lr: 0.0014985  max_mem: 1603M
[10/27 18:28:58] d2.utils.events INFO:  eta: 2:31:49  iter: 619  total_loss: 0.628  loss_cls: 0.1221  loss_box_reg: 0.1897  loss_mask: 0.2184  loss_rpn_cls: 0.01844  loss_rpn_loc: 0.04484  time: 0.1061  data_time: 0.0027  lr: 0.0015485  max_mem: 1603M
[10/27 18:29:01] d2.utils.events INFO:  eta: 2:31:53  iter: 639  total_loss: 0.5678  loss_cls: 0.1266  loss_box_reg: 0.1513  loss_mask: 0.1867  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.02107  time: 0.1061  data_time: 0.0023  lr: 0.0015984  max_mem: 1603M
[10/27 18:29:03] d2.utils.events INFO:  eta: 2:31:45  iter: 659  total_loss: 0.6477  loss_cls: 0.185  loss_box_reg: 0.1753  loss_mask: 0.2118  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.02457  time: 0.1059  data_time: 0.0024  lr: 0.0016484  max_mem: 1603M
[10/27 18:29:05] d2.utils.events INFO:  eta: 2:31:38  iter: 679  total_loss: 0.4679  loss_cls: 0.09056  loss_box_reg: 0.1025  loss_mask: 0.2123  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.0319  time: 0.1056  data_time: 0.0027  lr: 0.0016983  max_mem: 1603M
[10/27 18:29:07] d2.utils.events INFO:  eta: 2:31:32  iter: 699  total_loss: 0.6348  loss_cls: 0.1522  loss_box_reg: 0.228  loss_mask: 0.2262  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.0402  time: 0.1055  data_time: 0.0025  lr: 0.0017483  max_mem: 1603M
[10/27 18:29:08] d2.utils.events INFO:  eta: 2:31:22  iter: 719  total_loss: 0.694  loss_cls: 0.1679  loss_box_reg: 0.1757  loss_mask: 0.2454  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.03394  time: 0.1053  data_time: 0.0025  lr: 0.0017982  max_mem: 1603M
[10/27 18:29:11] d2.utils.events INFO:  eta: 2:31:23  iter: 739  total_loss: 0.5181  loss_cls: 0.1176  loss_box_reg: 0.1642  loss_mask: 0.2004  loss_rpn_cls: 0.008031  loss_rpn_loc: 0.03317  time: 0.1053  data_time: 0.0026  lr: 0.0018482  max_mem: 1603M
[10/27 18:29:13] d2.utils.events INFO:  eta: 2:31:25  iter: 759  total_loss: 0.5031  loss_cls: 0.09182  loss_box_reg: 0.1323  loss_mask: 0.2262  loss_rpn_cls: 0.00953  loss_rpn_loc: 0.01581  time: 0.1052  data_time: 0.0026  lr: 0.0018981  max_mem: 1603M
[10/27 18:29:15] d2.utils.events INFO:  eta: 2:31:23  iter: 779  total_loss: 0.9731  loss_cls: 0.2131  loss_box_reg: 0.2834  loss_mask: 0.2339  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.07411  time: 0.1051  data_time: 0.0028  lr: 0.0019481  max_mem: 1603M
[10/27 18:29:17] d2.utils.events INFO:  eta: 2:31:20  iter: 799  total_loss: 0.6591  loss_cls: 0.1815  loss_box_reg: 0.1678  loss_mask: 0.2316  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.04265  time: 0.1050  data_time: 0.0027  lr: 0.001998  max_mem: 1603M
[10/27 18:29:19] d2.utils.events INFO:  eta: 2:31:15  iter: 819  total_loss: 0.5387  loss_cls: 0.1287  loss_box_reg: 0.1598  loss_mask: 0.2178  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.03099  time: 0.1049  data_time: 0.0028  lr: 0.002048  max_mem: 1603M
[10/27 18:29:21] d2.utils.events INFO:  eta: 2:31:01  iter: 839  total_loss: 0.7378  loss_cls: 0.2435  loss_box_reg: 0.2331  loss_mask: 0.2674  loss_rpn_cls: 0.02971  loss_rpn_loc: 0.03554  time: 0.1048  data_time: 0.0028  lr: 0.0020979  max_mem: 1603M
[10/27 18:29:23] d2.utils.events INFO:  eta: 2:31:11  iter: 859  total_loss: 1.077  loss_cls: 0.2536  loss_box_reg: 0.3014  loss_mask: 0.3089  loss_rpn_cls: 0.05387  loss_rpn_loc: 0.08148  time: 0.1048  data_time: 0.0025  lr: 0.0021479  max_mem: 1603M
[10/27 18:29:25] d2.utils.events INFO:  eta: 2:31:13  iter: 879  total_loss: 0.9318  loss_cls: 0.2865  loss_box_reg: 0.2743  loss_mask: 0.2729  loss_rpn_cls: 0.05583  loss_rpn_loc: 0.04561  time: 0.1050  data_time: 0.0028  lr: 0.0021978  max_mem: 1603M
[10/27 18:29:27] d2.utils.events INFO:  eta: 2:31:10  iter: 899  total_loss: 0.6453  loss_cls: 0.1689  loss_box_reg: 0.2023  loss_mask: 0.2098  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.02846  time: 0.1049  data_time: 0.0026  lr: 0.0022478  max_mem: 1603M
[10/27 18:29:29] d2.utils.events INFO:  eta: 2:31:01  iter: 919  total_loss: 0.6823  loss_cls: 0.1465  loss_box_reg: 0.1867  loss_mask: 0.2219  loss_rpn_cls: 0.02378  loss_rpn_loc: 0.03262  time: 0.1047  data_time: 0.0027  lr: 0.0022977  max_mem: 1603M
[10/27 18:29:31] d2.utils.events INFO:  eta: 2:30:51  iter: 939  total_loss: 0.5889  loss_cls: 0.1544  loss_box_reg: 0.1773  loss_mask: 0.2243  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.02617  time: 0.1047  data_time: 0.0023  lr: 0.0023477  max_mem: 1603M
[10/27 18:29:33] d2.utils.events INFO:  eta: 2:30:49  iter: 959  total_loss: 0.9514  loss_cls: 0.2226  loss_box_reg: 0.271  loss_mask: 0.2783  loss_rpn_cls: 0.0321  loss_rpn_loc: 0.03094  time: 0.1046  data_time: 0.0019  lr: 0.0023976  max_mem: 1603M
[10/27 18:29:35] d2.utils.events INFO:  eta: 2:30:40  iter: 979  total_loss: 0.6248  loss_cls: 0.1617  loss_box_reg: 0.2334  loss_mask: 0.2273  loss_rpn_cls: 0.007431  loss_rpn_loc: 0.02993  time: 0.1045  data_time: 0.0021  lr: 0.0024476  max_mem: 1603M
[10/27 18:29:37] d2.utils.events INFO:  eta: 2:30:38  iter: 999  total_loss: 0.7018  loss_cls: 0.1381  loss_box_reg: 0.2025  loss_mask: 0.2029  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.02948  time: 0.1045  data_time: 0.0022  lr: 0.0024975  max_mem: 1603M
[10/27 18:29:39] d2.utils.events INFO:  eta: 2:30:03  iter: 1019  total_loss: 0.6613  loss_cls: 0.1659  loss_box_reg: 0.2213  loss_mask: 0.2108  loss_rpn_cls: 0.03515  loss_rpn_loc: 0.05207  time: 0.1044  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:29:41] d2.utils.events INFO:  eta: 2:29:36  iter: 1039  total_loss: 0.5685  loss_cls: 0.1471  loss_box_reg: 0.161  loss_mask: 0.1782  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.02923  time: 0.1043  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:29:43] d2.utils.events INFO:  eta: 2:29:23  iter: 1059  total_loss: 0.9317  loss_cls: 0.181  loss_box_reg: 0.2462  loss_mask: 0.2369  loss_rpn_cls: 0.03466  loss_rpn_loc: 0.0542  time: 0.1043  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:29:45] d2.utils.events INFO:  eta: 2:28:54  iter: 1079  total_loss: 0.652  loss_cls: 0.1837  loss_box_reg: 0.1584  loss_mask: 0.2368  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01846  time: 0.1042  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:29:47] d2.utils.events INFO:  eta: 2:28:37  iter: 1099  total_loss: 0.5997  loss_cls: 0.1449  loss_box_reg: 0.1094  loss_mask: 0.1815  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.03225  time: 0.1041  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:29:49] d2.utils.events INFO:  eta: 2:28:27  iter: 1119  total_loss: 0.616  loss_cls: 0.1227  loss_box_reg: 0.1489  loss_mask: 0.2073  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.02019  time: 0.1041  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:29:51] d2.utils.events INFO:  eta: 2:28:18  iter: 1139  total_loss: 0.6365  loss_cls: 0.1699  loss_box_reg: 0.2009  loss_mask: 0.1881  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.04406  time: 0.1040  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:29:53] d2.utils.events INFO:  eta: 2:27:51  iter: 1159  total_loss: 0.4976  loss_cls: 0.1243  loss_box_reg: 0.1803  loss_mask: 0.2138  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.01851  time: 0.1039  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:29:55] d2.utils.events INFO:  eta: 2:27:56  iter: 1179  total_loss: 0.6727  loss_cls: 0.1715  loss_box_reg: 0.197  loss_mask: 0.2168  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.02923  time: 0.1038  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:29:57] d2.utils.events INFO:  eta: 2:27:47  iter: 1199  total_loss: 0.7033  loss_cls: 0.1754  loss_box_reg: 0.1768  loss_mask: 0.215  loss_rpn_cls: 0.01825  loss_rpn_loc: 0.03038  time: 0.1037  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:29:59] d2.utils.events INFO:  eta: 2:27:32  iter: 1219  total_loss: 0.6821  loss_cls: 0.1946  loss_box_reg: 0.1788  loss_mask: 0.2511  loss_rpn_cls: 0.02516  loss_rpn_loc: 0.04127  time: 0.1036  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:30:01] d2.utils.events INFO:  eta: 2:27:34  iter: 1239  total_loss: 0.6008  loss_cls: 0.1523  loss_box_reg: 0.1878  loss_mask: 0.1844  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.04446  time: 0.1035  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:03] d2.utils.events INFO:  eta: 2:27:23  iter: 1259  total_loss: 0.648  loss_cls: 0.1391  loss_box_reg: 0.1587  loss_mask: 0.2049  loss_rpn_cls: 0.006779  loss_rpn_loc: 0.01848  time: 0.1035  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:05] d2.utils.events INFO:  eta: 2:27:05  iter: 1279  total_loss: 0.5658  loss_cls: 0.143  loss_box_reg: 0.1613  loss_mask: 0.2026  loss_rpn_cls: 0.024  loss_rpn_loc: 0.02896  time: 0.1034  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:30:07] d2.utils.events INFO:  eta: 2:26:50  iter: 1299  total_loss: 0.5833  loss_cls: 0.1902  loss_box_reg: 0.2  loss_mask: 0.1891  loss_rpn_cls: 0.0202  loss_rpn_loc: 0.0529  time: 0.1033  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:30:09] d2.utils.events INFO:  eta: 2:26:42  iter: 1319  total_loss: 0.7405  loss_cls: 0.165  loss_box_reg: 0.238  loss_mask: 0.1982  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.03111  time: 0.1033  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:11] d2.utils.events INFO:  eta: 2:26:50  iter: 1339  total_loss: 0.7715  loss_cls: 0.166  loss_box_reg: 0.2422  loss_mask: 0.2307  loss_rpn_cls: 0.02042  loss_rpn_loc: 0.05175  time: 0.1032  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:30:14] d2.utils.events INFO:  eta: 2:26:54  iter: 1359  total_loss: 1.041  loss_cls: 0.269  loss_box_reg: 0.3244  loss_mask: 0.2178  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.05756  time: 0.1033  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:16] d2.utils.events INFO:  eta: 2:27:06  iter: 1379  total_loss: 0.6195  loss_cls: 0.1473  loss_box_reg: 0.1854  loss_mask: 0.2466  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.04275  time: 0.1033  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:18] d2.utils.events INFO:  eta: 2:27:15  iter: 1399  total_loss: 0.5407  loss_cls: 0.145  loss_box_reg: 0.1594  loss_mask: 0.1902  loss_rpn_cls: 0.00867  loss_rpn_loc: 0.02382  time: 0.1032  data_time: 0.0029  lr: 0.0025  max_mem: 1603M
[10/27 18:30:20] d2.utils.events INFO:  eta: 2:26:53  iter: 1419  total_loss: 0.6425  loss_cls: 0.1525  loss_box_reg: 0.2083  loss_mask: 0.1994  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.01959  time: 0.1032  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:30:22] d2.utils.events INFO:  eta: 2:27:25  iter: 1439  total_loss: 0.6366  loss_cls: 0.1385  loss_box_reg: 0.2187  loss_mask: 0.2067  loss_rpn_cls: 0.005715  loss_rpn_loc: 0.02599  time: 0.1032  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:24] d2.utils.events INFO:  eta: 2:27:17  iter: 1459  total_loss: 0.6809  loss_cls: 0.1698  loss_box_reg: 0.2253  loss_mask: 0.1897  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.04398  time: 0.1031  data_time: 0.0024  lr: 0.0025  max_mem: 1603M
[10/27 18:30:26] d2.utils.events INFO:  eta: 2:27:24  iter: 1479  total_loss: 0.5555  loss_cls: 0.1486  loss_box_reg: 0.168  loss_mask: 0.2001  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.02691  time: 0.1031  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:28] d2.utils.events INFO:  eta: 2:27:19  iter: 1499  total_loss: 0.52  loss_cls: 0.1163  loss_box_reg: 0.1846  loss_mask: 0.189  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.04402  time: 0.1031  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:30:30] d2.utils.events INFO:  eta: 2:27:17  iter: 1519  total_loss: 0.5427  loss_cls: 0.1313  loss_box_reg: 0.1891  loss_mask: 0.1712  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.03085  time: 0.1030  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:32] d2.utils.events INFO:  eta: 2:27:04  iter: 1539  total_loss: 0.5032  loss_cls: 0.1202  loss_box_reg: 0.1703  loss_mask: 0.1752  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.03602  time: 0.1029  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:34] d2.utils.events INFO:  eta: 2:26:53  iter: 1559  total_loss: 0.685  loss_cls: 0.1929  loss_box_reg: 0.2089  loss_mask: 0.1888  loss_rpn_cls: 0.00912  loss_rpn_loc: 0.02194  time: 0.1028  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:35] d2.utils.events INFO:  eta: 2:26:34  iter: 1579  total_loss: 0.5626  loss_cls: 0.1436  loss_box_reg: 0.1905  loss_mask: 0.2222  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.03041  time: 0.1027  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:37] d2.utils.events INFO:  eta: 2:26:24  iter: 1599  total_loss: 0.4268  loss_cls: 0.08901  loss_box_reg: 0.1456  loss_mask: 0.1614  loss_rpn_cls: 0.004678  loss_rpn_loc: 0.01531  time: 0.1027  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:30:40] d2.utils.events INFO:  eta: 2:26:18  iter: 1619  total_loss: 0.6534  loss_cls: 0.1684  loss_box_reg: 0.2823  loss_mask: 0.2005  loss_rpn_cls: 0.006162  loss_rpn_loc: 0.01891  time: 0.1027  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:42] d2.utils.events INFO:  eta: 2:26:07  iter: 1639  total_loss: 0.5025  loss_cls: 0.1005  loss_box_reg: 0.1625  loss_mask: 0.1978  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.05766  time: 0.1026  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:44] d2.utils.events INFO:  eta: 2:26:14  iter: 1659  total_loss: 0.5787  loss_cls: 0.1259  loss_box_reg: 0.2174  loss_mask: 0.1865  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.04562  time: 0.1026  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:46] d2.utils.events INFO:  eta: 2:26:32  iter: 1679  total_loss: 0.5431  loss_cls: 0.08172  loss_box_reg: 0.1215  loss_mask: 0.1899  loss_rpn_cls: 0.008424  loss_rpn_loc: 0.03217  time: 0.1026  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:30:48] d2.utils.events INFO:  eta: 2:26:33  iter: 1699  total_loss: 0.6102  loss_cls: 0.1434  loss_box_reg: 0.2419  loss_mask: 0.1799  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.04071  time: 0.1026  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:50] d2.utils.events INFO:  eta: 2:26:42  iter: 1719  total_loss: 0.9502  loss_cls: 0.2154  loss_box_reg: 0.3456  loss_mask: 0.2604  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.05506  time: 0.1026  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:30:52] d2.utils.events INFO:  eta: 2:26:18  iter: 1739  total_loss: 0.4896  loss_cls: 0.1022  loss_box_reg: 0.1634  loss_mask: 0.1616  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.03208  time: 0.1025  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:30:54] d2.utils.events INFO:  eta: 2:26:04  iter: 1759  total_loss: 0.6446  loss_cls: 0.1538  loss_box_reg: 0.2231  loss_mask: 0.1808  loss_rpn_cls: 0.01623  loss_rpn_loc: 0.03143  time: 0.1025  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:56] d2.utils.events INFO:  eta: 2:26:06  iter: 1779  total_loss: 0.5034  loss_cls: 0.1006  loss_box_reg: 0.1903  loss_mask: 0.1743  loss_rpn_cls: 0.008167  loss_rpn_loc: 0.02241  time: 0.1025  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:30:58] d2.utils.events INFO:  eta: 2:25:51  iter: 1799  total_loss: 0.8035  loss_cls: 0.1982  loss_box_reg: 0.2403  loss_mask: 0.2167  loss_rpn_cls: 0.02403  loss_rpn_loc: 0.05186  time: 0.1025  data_time: 0.0028  lr: 0.0025  max_mem: 1603M
[10/27 18:31:00] d2.utils.events INFO:  eta: 2:25:41  iter: 1819  total_loss: 0.4419  loss_cls: 0.07008  loss_box_reg: 0.119  loss_mask: 0.1722  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.02406  time: 0.1024  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:31:02] d2.utils.events INFO:  eta: 2:25:43  iter: 1839  total_loss: 0.4889  loss_cls: 0.119  loss_box_reg: 0.1414  loss_mask: 0.1844  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01767  time: 0.1024  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:31:04] d2.utils.events INFO:  eta: 2:25:26  iter: 1859  total_loss: 0.6165  loss_cls: 0.0858  loss_box_reg: 0.2298  loss_mask: 0.1991  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.04255  time: 0.1024  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:31:06] d2.utils.events INFO:  eta: 2:25:13  iter: 1879  total_loss: 0.5386  loss_cls: 0.1248  loss_box_reg: 0.1831  loss_mask: 0.1795  loss_rpn_cls: 0.009922  loss_rpn_loc: 0.03156  time: 0.1024  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:31:08] d2.utils.events INFO:  eta: 2:25:04  iter: 1899  total_loss: 0.3785  loss_cls: 0.07196  loss_box_reg: 0.1244  loss_mask: 0.1611  loss_rpn_cls: 0.007054  loss_rpn_loc: 0.02098  time: 0.1024  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:31:10] d2.utils.events INFO:  eta: 2:25:02  iter: 1919  total_loss: 0.6262  loss_cls: 0.1317  loss_box_reg: 0.2368  loss_mask: 0.17  loss_rpn_cls: 0.009915  loss_rpn_loc: 0.04573  time: 0.1023  data_time: 0.0025  lr: 0.0025  max_mem: 1603M
[10/27 18:31:12] d2.utils.events INFO:  eta: 2:25:07  iter: 1939  total_loss: 0.6515  loss_cls: 0.1186  loss_box_reg: 0.2605  loss_mask: 0.2141  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.04449  time: 0.1023  data_time: 0.0026  lr: 0.0025  max_mem: 1603M
[10/27 18:31:14] d2.utils.events INFO:  eta: 2:25:07  iter: 1959  total_loss: 0.532  loss_cls: 0.1006  loss_box_reg: 0.1823  loss_mask: 0.2176  loss_rpn_cls: 0.005882  loss_rpn_loc: 0.021  time: 0.1023  data_time: 0.0024  lr: 0.0025  max_mem: 1603M
[10/27 18:31:16] d2.utils.events INFO:  eta: 2:25:17  iter: 1979  total_loss: 0.791  loss_cls: 0.1244  loss_box_reg: 0.2687  loss_mask: 0.2192  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.05912  time: 0.1023  data_time: 0.0027  lr: 0.0025  max_mem: 1603M
[10/27 18:31:18] d2.utils.events INFO:  eta: 2:25:09  iter: 1999  total_loss: 0.595  loss_cls: 0.1184  loss_box_reg: 0.2557  loss_mask: 0.1767  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.05464  time: 0.1023  data_time: 0.0024  lr: 0.0025  max_mem: 1603M
[10/27 18:31:20] d2.utils.events INFO:  eta: 2:25:25  iter: 2019  total_loss: 0.6043  loss_cls: 0.1235  loss_box_reg: 0.2091  loss_mask: 0.179  loss_rpn_cls: 0.008339  loss_rpn_loc: 0.03005  time: 0.1023  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:22] d2.utils.events INFO:  eta: 2:25:27  iter: 2039  total_loss: 0.6504  loss_cls: 0.1374  loss_box_reg: 0.195  loss_mask: 0.2071  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.03256  time: 0.1023  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:31:24] d2.utils.events INFO:  eta: 2:25:21  iter: 2059  total_loss: 0.6623  loss_cls: 0.1525  loss_box_reg: 0.2038  loss_mask: 0.1412  loss_rpn_cls: 0.009349  loss_rpn_loc: 0.04028  time: 0.1023  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:26] d2.utils.events INFO:  eta: 2:25:01  iter: 2079  total_loss: 0.5362  loss_cls: 0.09637  loss_box_reg: 0.1321  loss_mask: 0.1604  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.0267  time: 0.1022  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:28] d2.utils.events INFO:  eta: 2:25:15  iter: 2099  total_loss: 0.471  loss_cls: 0.09212  loss_box_reg: 0.1381  loss_mask: 0.1606  loss_rpn_cls: 0.009865  loss_rpn_loc: 0.0357  time: 0.1022  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:31:30] d2.utils.events INFO:  eta: 2:25:16  iter: 2119  total_loss: 0.6195  loss_cls: 0.1598  loss_box_reg: 0.2275  loss_mask: 0.1881  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.03761  time: 0.1022  data_time: 0.0027  lr: 0.0025  max_mem: 1628M
[10/27 18:31:32] d2.utils.events INFO:  eta: 2:25:14  iter: 2139  total_loss: 0.6385  loss_cls: 0.1551  loss_box_reg: 0.2378  loss_mask: 0.2254  loss_rpn_cls: 0.01825  loss_rpn_loc: 0.05485  time: 0.1022  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:31:34] d2.utils.events INFO:  eta: 2:25:20  iter: 2159  total_loss: 0.4125  loss_cls: 0.08029  loss_box_reg: 0.1182  loss_mask: 0.1519  loss_rpn_cls: 0.003117  loss_rpn_loc: 0.02598  time: 0.1021  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:36] d2.utils.events INFO:  eta: 2:25:35  iter: 2179  total_loss: 0.4188  loss_cls: 0.06683  loss_box_reg: 0.1276  loss_mask: 0.1673  loss_rpn_cls: 0.008603  loss_rpn_loc: 0.05017  time: 0.1021  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:38] d2.utils.events INFO:  eta: 2:25:33  iter: 2199  total_loss: 0.2899  loss_cls: 0.05818  loss_box_reg: 0.1216  loss_mask: 0.114  loss_rpn_cls: 0.003527  loss_rpn_loc: 0.01631  time: 0.1021  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:40] d2.utils.events INFO:  eta: 2:25:40  iter: 2219  total_loss: 0.5919  loss_cls: 0.1304  loss_box_reg: 0.2282  loss_mask: 0.185  loss_rpn_cls: 0.008694  loss_rpn_loc: 0.03663  time: 0.1021  data_time: 0.0024  lr: 0.0025  max_mem: 1628M
[10/27 18:31:42] d2.utils.events INFO:  eta: 2:25:35  iter: 2239  total_loss: 0.5598  loss_cls: 0.1187  loss_box_reg: 0.2284  loss_mask: 0.1523  loss_rpn_cls: 0.009179  loss_rpn_loc: 0.04957  time: 0.1021  data_time: 0.0024  lr: 0.0025  max_mem: 1628M
[10/27 18:31:44] d2.utils.events INFO:  eta: 2:25:41  iter: 2259  total_loss: 0.4767  loss_cls: 0.09848  loss_box_reg: 0.159  loss_mask: 0.122  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.03605  time: 0.1021  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:46] d2.utils.events INFO:  eta: 2:25:47  iter: 2279  total_loss: 0.7083  loss_cls: 0.1312  loss_box_reg: 0.2445  loss_mask: 0.2565  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.03241  time: 0.1021  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:48] d2.utils.events INFO:  eta: 2:25:45  iter: 2299  total_loss: 0.8011  loss_cls: 0.1595  loss_box_reg: 0.2896  loss_mask: 0.2147  loss_rpn_cls: 0.02411  loss_rpn_loc: 0.07263  time: 0.1021  data_time: 0.0027  lr: 0.0025  max_mem: 1628M
[10/27 18:31:50] d2.utils.events INFO:  eta: 2:25:43  iter: 2319  total_loss: 0.4851  loss_cls: 0.09557  loss_box_reg: 0.1748  loss_mask: 0.1799  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.02065  time: 0.1020  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:31:52] d2.utils.events INFO:  eta: 2:25:40  iter: 2339  total_loss: 0.5897  loss_cls: 0.1276  loss_box_reg: 0.2245  loss_mask: 0.2077  loss_rpn_cls: 0.00932  loss_rpn_loc: 0.03804  time: 0.1020  data_time: 0.0024  lr: 0.0025  max_mem: 1628M
[10/27 18:31:54] d2.utils.events INFO:  eta: 2:25:26  iter: 2359  total_loss: 0.5378  loss_cls: 0.1257  loss_box_reg: 0.1577  loss_mask: 0.1741  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.01724  time: 0.1020  data_time: 0.0028  lr: 0.0025  max_mem: 1628M
[10/27 18:31:56] d2.utils.events INFO:  eta: 2:25:05  iter: 2379  total_loss: 0.45  loss_cls: 0.09608  loss_box_reg: 0.179  loss_mask: 0.1618  loss_rpn_cls: 0.004982  loss_rpn_loc: 0.02968  time: 0.1020  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:31:58] d2.utils.events INFO:  eta: 2:24:54  iter: 2399  total_loss: 0.6093  loss_cls: 0.126  loss_box_reg: 0.1925  loss_mask: 0.1834  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.04281  time: 0.1020  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:32:00] d2.utils.events INFO:  eta: 2:24:54  iter: 2419  total_loss: 0.5308  loss_cls: 0.1009  loss_box_reg: 0.2119  loss_mask: 0.1888  loss_rpn_cls: 0.006928  loss_rpn_loc: 0.02345  time: 0.1020  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:32:02] d2.utils.events INFO:  eta: 2:24:59  iter: 2439  total_loss: 0.4216  loss_cls: 0.06529  loss_box_reg: 0.1406  loss_mask: 0.1578  loss_rpn_cls: 0.003325  loss_rpn_loc: 0.016  time: 0.1020  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:32:05] d2.utils.events INFO:  eta: 2:25:03  iter: 2459  total_loss: 0.4856  loss_cls: 0.09252  loss_box_reg: 0.1742  loss_mask: 0.155  loss_rpn_cls: 0.005373  loss_rpn_loc: 0.02821  time: 0.1020  data_time: 0.0025  lr: 0.0025  max_mem: 1628M
[10/27 18:32:07] d2.utils.events INFO:  eta: 2:25:11  iter: 2479  total_loss: 0.5841  loss_cls: 0.1549  loss_box_reg: 0.2357  loss_mask: 0.1714  loss_rpn_cls: 0.006687  loss_rpn_loc: 0.02869  time: 0.1020  data_time: 0.0024  lr: 0.0025  max_mem: 1628M
[10/27 18:32:09] d2.utils.events INFO:  eta: 2:25:10  iter: 2499  total_loss: 0.577  loss_cls: 0.1143  loss_box_reg: 0.2594  loss_mask: 0.1881  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.03632  time: 0.1020  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:32:11] d2.utils.events INFO:  eta: 2:25:15  iter: 2519  total_loss: 0.6144  loss_cls: 0.1029  loss_box_reg: 0.212  loss_mask: 0.1958  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.05557  time: 0.1020  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:32:13] d2.utils.events INFO:  eta: 2:25:32  iter: 2539  total_loss: 0.8013  loss_cls: 0.1509  loss_box_reg: 0.2596  loss_mask: 0.2387  loss_rpn_cls: 0.01843  loss_rpn_loc: 0.08263  time: 0.1020  data_time: 0.0027  lr: 0.0025  max_mem: 1628M
[10/27 18:32:15] d2.utils.events INFO:  eta: 2:25:33  iter: 2559  total_loss: 0.3603  loss_cls: 0.04321  loss_box_reg: 0.1072  loss_mask: 0.1268  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.01049  time: 0.1019  data_time: 0.0027  lr: 0.0025  max_mem: 1628M
[10/27 18:32:17] d2.utils.events INFO:  eta: 2:25:31  iter: 2579  total_loss: 0.5544  loss_cls: 0.1062  loss_box_reg: 0.2137  loss_mask: 0.1927  loss_rpn_cls: 0.005538  loss_rpn_loc: 0.03584  time: 0.1019  data_time: 0.0024  lr: 0.0025  max_mem: 1628M
[10/27 18:32:19] d2.utils.events INFO:  eta: 2:25:29  iter: 2599  total_loss: 0.3654  loss_cls: 0.06946  loss_box_reg: 0.1174  loss_mask: 0.1519  loss_rpn_cls: 0.007431  loss_rpn_loc: 0.03056  time: 0.1019  data_time: 0.0026  lr: 0.0025  max_mem: 1628M
[10/27 18:32:21] d2.utils.events INFO:  eta: 2:25:31  iter: 2619  total_loss: 0.5493  loss_cls: 0.09912  loss_box_reg: 0.2198  loss_mask: 0.1628  loss_rpn_cls: 0.013  loss_rpn_loc: 0.03829  time: 0.1019  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:32:23] d2.utils.events INFO:  eta: 2:25:33  iter: 2639  total_loss: 0.507  loss_cls: 0.1116  loss_box_reg: 0.2002  loss_mask: 0.1522  loss_rpn_cls: 0.008359  loss_rpn_loc: 0.0453  time: 0.1019  data_time: 0.0027  lr: 0.0025  max_mem: 1629M
[10/27 18:32:25] d2.utils.events INFO:  eta: 2:25:23  iter: 2659  total_loss: 0.6066  loss_cls: 0.1026  loss_box_reg: 0.2093  loss_mask: 0.2014  loss_rpn_cls: 0.007664  loss_rpn_loc: 0.0452  time: 0.1019  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:32:27] d2.utils.events INFO:  eta: 2:24:56  iter: 2679  total_loss: 0.6198  loss_cls: 0.1289  loss_box_reg: 0.1736  loss_mask: 0.2099  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01818  time: 0.1018  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:29] d2.utils.events INFO:  eta: 2:24:53  iter: 2699  total_loss: 0.2935  loss_cls: 0.07249  loss_box_reg: 0.1036  loss_mask: 0.1402  loss_rpn_cls: 0.007055  loss_rpn_loc: 0.01914  time: 0.1018  data_time: 0.0026  lr: 0.0025  max_mem: 1629M
[10/27 18:32:31] d2.utils.events INFO:  eta: 2:24:40  iter: 2719  total_loss: 0.55  loss_cls: 0.1093  loss_box_reg: 0.1621  loss_mask: 0.2157  loss_rpn_cls: 0.004156  loss_rpn_loc: 0.03033  time: 0.1018  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:32:33] d2.utils.events INFO:  eta: 2:24:45  iter: 2739  total_loss: 0.7073  loss_cls: 0.1277  loss_box_reg: 0.2313  loss_mask: 0.2269  loss_rpn_cls: 0.006603  loss_rpn_loc: 0.05192  time: 0.1018  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:32:35] d2.utils.events INFO:  eta: 2:24:44  iter: 2759  total_loss: 0.509  loss_cls: 0.08477  loss_box_reg: 0.162  loss_mask: 0.1708  loss_rpn_cls: 0.005189  loss_rpn_loc: 0.03557  time: 0.1018  data_time: 0.0029  lr: 0.0025  max_mem: 1629M
[10/27 18:32:37] d2.utils.events INFO:  eta: 2:24:52  iter: 2779  total_loss: 0.8909  loss_cls: 0.1802  loss_box_reg: 0.3236  loss_mask: 0.2399  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.07709  time: 0.1018  data_time: 0.0028  lr: 0.0025  max_mem: 1629M
[10/27 18:32:39] d2.utils.events INFO:  eta: 2:25:13  iter: 2799  total_loss: 0.5336  loss_cls: 0.1199  loss_box_reg: 0.1933  loss_mask: 0.145  loss_rpn_cls: 0.005624  loss_rpn_loc: 0.02241  time: 0.1018  data_time: 0.0029  lr: 0.0025  max_mem: 1629M
[10/27 18:32:41] d2.utils.events INFO:  eta: 2:25:22  iter: 2819  total_loss: 0.4517  loss_cls: 0.08304  loss_box_reg: 0.1674  loss_mask: 0.1659  loss_rpn_cls: 0.004996  loss_rpn_loc: 0.04291  time: 0.1018  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:32:43] d2.utils.events INFO:  eta: 2:25:18  iter: 2839  total_loss: 0.4532  loss_cls: 0.07698  loss_box_reg: 0.1729  loss_mask: 0.1339  loss_rpn_cls: 0.005027  loss_rpn_loc: 0.03105  time: 0.1018  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:32:45] d2.utils.events INFO:  eta: 2:25:15  iter: 2859  total_loss: 0.3696  loss_cls: 0.06379  loss_box_reg: 0.1193  loss_mask: 0.14  loss_rpn_cls: 0.004565  loss_rpn_loc: 0.02852  time: 0.1018  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:47] d2.utils.events INFO:  eta: 2:25:06  iter: 2879  total_loss: 0.435  loss_cls: 0.07381  loss_box_reg: 0.1656  loss_mask: 0.1642  loss_rpn_cls: 0.003483  loss_rpn_loc: 0.01593  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:49] d2.utils.events INFO:  eta: 2:25:11  iter: 2899  total_loss: 0.4593  loss_cls: 0.1092  loss_box_reg: 0.1858  loss_mask: 0.16  loss_rpn_cls: 0.006401  loss_rpn_loc: 0.03647  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:51] d2.utils.events INFO:  eta: 2:25:12  iter: 2919  total_loss: 0.453  loss_cls: 0.08352  loss_box_reg: 0.2096  loss_mask: 0.1276  loss_rpn_cls: 0.007122  loss_rpn_loc: 0.02213  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:53] d2.utils.events INFO:  eta: 2:25:07  iter: 2939  total_loss: 0.5061  loss_cls: 0.09065  loss_box_reg: 0.2102  loss_mask: 0.1775  loss_rpn_cls: 0.006743  loss_rpn_loc: 0.0405  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:32:55] d2.utils.events INFO:  eta: 2:24:58  iter: 2959  total_loss: 0.4798  loss_cls: 0.1068  loss_box_reg: 0.1545  loss_mask: 0.1735  loss_rpn_cls: 0.007595  loss_rpn_loc: 0.04077  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:32:57] d2.utils.events INFO:  eta: 2:24:55  iter: 2979  total_loss: 0.5025  loss_cls: 0.1056  loss_box_reg: 0.137  loss_mask: 0.1716  loss_rpn_cls: 0.007948  loss_rpn_loc: 0.03234  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:32:59] d2.utils.events INFO:  eta: 2:24:54  iter: 2999  total_loss: 0.4319  loss_cls: 0.07983  loss_box_reg: 0.1898  loss_mask: 0.1234  loss_rpn_cls: 0.004332  loss_rpn_loc: 0.02388  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1629M
[10/27 18:33:01] d2.utils.events INFO:  eta: 2:24:22  iter: 3019  total_loss: 0.3884  loss_cls: 0.06043  loss_box_reg: 0.1237  loss_mask: 0.1287  loss_rpn_cls: 0.004426  loss_rpn_loc: 0.02778  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:03] d2.utils.events INFO:  eta: 2:24:37  iter: 3039  total_loss: 0.432  loss_cls: 0.09751  loss_box_reg: 0.1789  loss_mask: 0.1417  loss_rpn_cls: 0.008443  loss_rpn_loc: 0.03248  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1629M
[10/27 18:33:05] d2.utils.events INFO:  eta: 2:24:35  iter: 3059  total_loss: 0.3289  loss_cls: 0.0671  loss_box_reg: 0.1033  loss_mask: 0.1484  loss_rpn_cls: 0.008281  loss_rpn_loc: 0.02904  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:07] d2.utils.events INFO:  eta: 2:24:46  iter: 3079  total_loss: 0.527  loss_cls: 0.09078  loss_box_reg: 0.209  loss_mask: 0.1806  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.03852  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:33:09] d2.utils.events INFO:  eta: 2:24:21  iter: 3099  total_loss: 0.4975  loss_cls: 0.1056  loss_box_reg: 0.1641  loss_mask: 0.1323  loss_rpn_cls: 0.008803  loss_rpn_loc: 0.02672  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:11] d2.utils.events INFO:  eta: 2:24:10  iter: 3119  total_loss: 0.4838  loss_cls: 0.1013  loss_box_reg: 0.1686  loss_mask: 0.1548  loss_rpn_cls: 0.008349  loss_rpn_loc: 0.02589  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:13] d2.utils.events INFO:  eta: 2:24:05  iter: 3139  total_loss: 0.6645  loss_cls: 0.1186  loss_box_reg: 0.2323  loss_mask: 0.1815  loss_rpn_cls: 0.009761  loss_rpn_loc: 0.06022  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:15] d2.utils.events INFO:  eta: 2:24:03  iter: 3159  total_loss: 0.4355  loss_cls: 0.0807  loss_box_reg: 0.1659  loss_mask: 0.1718  loss_rpn_cls: 0.003158  loss_rpn_loc: 0.01346  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:17] d2.utils.events INFO:  eta: 2:23:50  iter: 3179  total_loss: 0.5209  loss_cls: 0.0949  loss_box_reg: 0.2141  loss_mask: 0.1584  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.02541  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:19] d2.utils.events INFO:  eta: 2:23:56  iter: 3199  total_loss: 0.4542  loss_cls: 0.08804  loss_box_reg: 0.1562  loss_mask: 0.1801  loss_rpn_cls: 0.004969  loss_rpn_loc: 0.02416  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:21] d2.utils.events INFO:  eta: 2:23:59  iter: 3219  total_loss: 0.6216  loss_cls: 0.1412  loss_box_reg: 0.248  loss_mask: 0.2041  loss_rpn_cls: 0.007939  loss_rpn_loc: 0.05299  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:23] d2.utils.events INFO:  eta: 2:23:57  iter: 3239  total_loss: 0.5456  loss_cls: 0.1114  loss_box_reg: 0.2139  loss_mask: 0.1789  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.04178  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1629M
[10/27 18:33:25] d2.utils.events INFO:  eta: 2:23:45  iter: 3259  total_loss: 0.446  loss_cls: 0.06854  loss_box_reg: 0.1377  loss_mask: 0.1531  loss_rpn_cls: 0.009223  loss_rpn_loc: 0.02669  time: 0.1015  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:33:27] d2.utils.events INFO:  eta: 2:23:50  iter: 3279  total_loss: 0.553  loss_cls: 0.1101  loss_box_reg: 0.1854  loss_mask: 0.1391  loss_rpn_cls: 0.005926  loss_rpn_loc: 0.02381  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:29] d2.utils.events INFO:  eta: 2:23:48  iter: 3299  total_loss: 0.3861  loss_cls: 0.07468  loss_box_reg: 0.1552  loss_mask: 0.1739  loss_rpn_cls: 0.006115  loss_rpn_loc: 0.02197  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:31] d2.utils.events INFO:  eta: 2:23:54  iter: 3319  total_loss: 0.5616  loss_cls: 0.09307  loss_box_reg: 0.2178  loss_mask: 0.1718  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.07046  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:33] d2.utils.events INFO:  eta: 2:23:53  iter: 3339  total_loss: 0.5369  loss_cls: 0.1089  loss_box_reg: 0.1817  loss_mask: 0.2121  loss_rpn_cls: 0.003306  loss_rpn_loc: 0.02733  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:35] d2.utils.events INFO:  eta: 2:23:55  iter: 3359  total_loss: 0.5939  loss_cls: 0.09321  loss_box_reg: 0.2178  loss_mask: 0.2027  loss_rpn_cls: 0.007953  loss_rpn_loc: 0.05127  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1629M
[10/27 18:33:37] d2.utils.events INFO:  eta: 2:24:16  iter: 3379  total_loss: 0.371  loss_cls: 0.05486  loss_box_reg: 0.146  loss_mask: 0.1449  loss_rpn_cls: 0.004665  loss_rpn_loc: 0.02785  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:39] d2.utils.events INFO:  eta: 2:24:14  iter: 3399  total_loss: 0.4202  loss_cls: 0.1091  loss_box_reg: 0.1723  loss_mask: 0.1666  loss_rpn_cls: 0.003864  loss_rpn_loc: 0.02802  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:41] d2.utils.events INFO:  eta: 2:24:12  iter: 3419  total_loss: 0.3177  loss_cls: 0.04686  loss_box_reg: 0.1015  loss_mask: 0.1322  loss_rpn_cls: 0.00518  loss_rpn_loc: 0.02947  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:43] d2.utils.events INFO:  eta: 2:24:06  iter: 3439  total_loss: 0.3937  loss_cls: 0.08706  loss_box_reg: 0.1675  loss_mask: 0.1235  loss_rpn_cls: 0.004758  loss_rpn_loc: 0.02702  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:45] d2.utils.events INFO:  eta: 2:23:45  iter: 3459  total_loss: 0.4328  loss_cls: 0.06974  loss_box_reg: 0.146  loss_mask: 0.1546  loss_rpn_cls: 0.008502  loss_rpn_loc: 0.02044  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:47] d2.utils.events INFO:  eta: 2:23:39  iter: 3479  total_loss: 0.4442  loss_cls: 0.0844  loss_box_reg: 0.168  loss_mask: 0.1595  loss_rpn_cls: 0.006705  loss_rpn_loc: 0.02534  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:49] d2.utils.events INFO:  eta: 2:23:57  iter: 3499  total_loss: 0.5536  loss_cls: 0.1155  loss_box_reg: 0.2254  loss_mask: 0.186  loss_rpn_cls: 0.00755  loss_rpn_loc: 0.03595  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1629M
[10/27 18:33:51] d2.utils.events INFO:  eta: 2:23:34  iter: 3519  total_loss: 0.5515  loss_cls: 0.08821  loss_box_reg: 0.2322  loss_mask: 0.1838  loss_rpn_cls: 0.004386  loss_rpn_loc: 0.02856  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:33:53] d2.utils.events INFO:  eta: 2:23:18  iter: 3539  total_loss: 0.5986  loss_cls: 0.1498  loss_box_reg: 0.2691  loss_mask: 0.2045  loss_rpn_cls: 0.008876  loss_rpn_loc: 0.02948  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1629M
[10/27 18:33:55] d2.utils.events INFO:  eta: 2:23:07  iter: 3559  total_loss: 0.3393  loss_cls: 0.06894  loss_box_reg: 0.1415  loss_mask: 0.1255  loss_rpn_cls: 0.0055  loss_rpn_loc: 0.02153  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:33:57] d2.utils.events INFO:  eta: 2:23:23  iter: 3579  total_loss: 0.6187  loss_cls: 0.1268  loss_box_reg: 0.2555  loss_mask: 0.1886  loss_rpn_cls: 0.007079  loss_rpn_loc: 0.04885  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:33:59] d2.utils.events INFO:  eta: 2:23:28  iter: 3599  total_loss: 0.3589  loss_cls: 0.06587  loss_box_reg: 0.1458  loss_mask: 0.1393  loss_rpn_cls: 0.00277  loss_rpn_loc: 0.01864  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:01] d2.utils.events INFO:  eta: 2:23:26  iter: 3619  total_loss: 0.5165  loss_cls: 0.09449  loss_box_reg: 0.2248  loss_mask: 0.1518  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.03224  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:34:03] d2.utils.events INFO:  eta: 2:23:22  iter: 3639  total_loss: 0.4047  loss_cls: 0.072  loss_box_reg: 0.1383  loss_mask: 0.1452  loss_rpn_cls: 0.001822  loss_rpn_loc: 0.02384  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:05] d2.utils.events INFO:  eta: 2:23:25  iter: 3659  total_loss: 0.5057  loss_cls: 0.1038  loss_box_reg: 0.2048  loss_mask: 0.1601  loss_rpn_cls: 0.005151  loss_rpn_loc: 0.03416  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:07] d2.utils.events INFO:  eta: 2:23:46  iter: 3679  total_loss: 0.5292  loss_cls: 0.1057  loss_box_reg: 0.205  loss_mask: 0.1865  loss_rpn_cls: 0.005061  loss_rpn_loc: 0.03726  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1629M
[10/27 18:34:09] d2.utils.events INFO:  eta: 2:23:34  iter: 3699  total_loss: 0.4241  loss_cls: 0.08009  loss_box_reg: 0.159  loss_mask: 0.1551  loss_rpn_cls: 0.005745  loss_rpn_loc: 0.04178  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:34:11] d2.utils.events INFO:  eta: 2:23:42  iter: 3719  total_loss: 0.3814  loss_cls: 0.06544  loss_box_reg: 0.1257  loss_mask: 0.1355  loss_rpn_cls: 0.00437  loss_rpn_loc: 0.02735  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:34:13] d2.utils.events INFO:  eta: 2:23:34  iter: 3739  total_loss: 0.4487  loss_cls: 0.08626  loss_box_reg: 0.1871  loss_mask: 0.1077  loss_rpn_cls: 0.005497  loss_rpn_loc: 0.02845  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1629M
[10/27 18:34:15] d2.utils.events INFO:  eta: 2:23:38  iter: 3759  total_loss: 0.632  loss_cls: 0.09778  loss_box_reg: 0.2648  loss_mask: 0.2229  loss_rpn_cls: 0.005554  loss_rpn_loc: 0.03564  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:18] d2.utils.events INFO:  eta: 2:23:26  iter: 3779  total_loss: 0.5628  loss_cls: 0.0975  loss_box_reg: 0.2561  loss_mask: 0.1702  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.03369  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:20] d2.utils.events INFO:  eta: 2:23:08  iter: 3799  total_loss: 0.3812  loss_cls: 0.05567  loss_box_reg: 0.1346  loss_mask: 0.1335  loss_rpn_cls: 0.00298  loss_rpn_loc: 0.02191  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:22] d2.utils.events INFO:  eta: 2:22:59  iter: 3819  total_loss: 0.3527  loss_cls: 0.0541  loss_box_reg: 0.1285  loss_mask: 0.1356  loss_rpn_cls: 0.003669  loss_rpn_loc: 0.03136  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:23] d2.utils.events INFO:  eta: 2:22:40  iter: 3839  total_loss: 0.4137  loss_cls: 0.08628  loss_box_reg: 0.1547  loss_mask: 0.1371  loss_rpn_cls: 0.007902  loss_rpn_loc: 0.02848  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1629M
[10/27 18:34:25] d2.utils.events INFO:  eta: 2:22:38  iter: 3859  total_loss: 0.4084  loss_cls: 0.07616  loss_box_reg: 0.1564  loss_mask: 0.1593  loss_rpn_cls: 0.008446  loss_rpn_loc: 0.03449  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1629M
[10/27 18:34:28] d2.utils.events INFO:  eta: 2:22:41  iter: 3879  total_loss: 0.6223  loss_cls: 0.1128  loss_box_reg: 0.2566  loss_mask: 0.1825  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.03372  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:30] d2.utils.events INFO:  eta: 2:22:44  iter: 3899  total_loss: 0.3639  loss_cls: 0.06022  loss_box_reg: 0.1347  loss_mask: 0.1216  loss_rpn_cls: 0.001762  loss_rpn_loc: 0.01493  time: 0.1013  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:34:32] d2.utils.events INFO:  eta: 2:23:02  iter: 3919  total_loss: 0.7467  loss_cls: 0.1622  loss_box_reg: 0.2857  loss_mask: 0.2125  loss_rpn_cls: 0.007041  loss_rpn_loc: 0.04439  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:34:34] d2.utils.events INFO:  eta: 2:22:47  iter: 3939  total_loss: 0.5613  loss_cls: 0.107  loss_box_reg: 0.2408  loss_mask: 0.1594  loss_rpn_cls: 0.005077  loss_rpn_loc: 0.01895  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:36] d2.utils.events INFO:  eta: 2:22:50  iter: 3959  total_loss: 0.4846  loss_cls: 0.08674  loss_box_reg: 0.1822  loss_mask: 0.1857  loss_rpn_cls: 0.008354  loss_rpn_loc: 0.02805  time: 0.1013  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:34:38] d2.utils.events INFO:  eta: 2:22:52  iter: 3979  total_loss: 0.4482  loss_cls: 0.1033  loss_box_reg: 0.2143  loss_mask: 0.1352  loss_rpn_cls: 0.00397  loss_rpn_loc: 0.02295  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:34:40] d2.utils.events INFO:  eta: 2:22:34  iter: 3999  total_loss: 0.365  loss_cls: 0.08302  loss_box_reg: 0.1352  loss_mask: 0.1382  loss_rpn_cls: 0.003263  loss_rpn_loc: 0.01626  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:34:42] d2.utils.events INFO:  eta: 2:22:48  iter: 4019  total_loss: 0.4703  loss_cls: 0.09321  loss_box_reg: 0.2032  loss_mask: 0.1362  loss_rpn_cls: 0.004045  loss_rpn_loc: 0.02707  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:44] d2.utils.events INFO:  eta: 2:22:24  iter: 4039  total_loss: 0.3983  loss_cls: 0.06891  loss_box_reg: 0.1618  loss_mask: 0.1445  loss_rpn_cls: 0.003439  loss_rpn_loc: 0.0282  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:34:46] d2.utils.events INFO:  eta: 2:22:28  iter: 4059  total_loss: 0.5134  loss_cls: 0.08174  loss_box_reg: 0.1901  loss_mask: 0.176  loss_rpn_cls: 0.007831  loss_rpn_loc: 0.04458  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:34:48] d2.utils.events INFO:  eta: 2:22:26  iter: 4079  total_loss: 0.6424  loss_cls: 0.1346  loss_box_reg: 0.2551  loss_mask: 0.141  loss_rpn_cls: 0.005867  loss_rpn_loc: 0.04094  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:50] d2.utils.events INFO:  eta: 2:23:02  iter: 4099  total_loss: 0.5614  loss_cls: 0.1096  loss_box_reg: 0.2269  loss_mask: 0.1463  loss_rpn_cls: 0.003788  loss_rpn_loc: 0.05494  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:52] d2.utils.events INFO:  eta: 2:23:04  iter: 4119  total_loss: 0.4312  loss_cls: 0.06577  loss_box_reg: 0.1971  loss_mask: 0.129  loss_rpn_cls: 0.002715  loss_rpn_loc: 0.02656  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:34:54] d2.utils.events INFO:  eta: 2:23:06  iter: 4139  total_loss: 0.7267  loss_cls: 0.1276  loss_box_reg: 0.2605  loss_mask: 0.1849  loss_rpn_cls: 0.008352  loss_rpn_loc: 0.05956  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:34:56] d2.utils.events INFO:  eta: 2:23:10  iter: 4159  total_loss: 0.2982  loss_cls: 0.06156  loss_box_reg: 0.1096  loss_mask: 0.1019  loss_rpn_cls: 0.002153  loss_rpn_loc: 0.01469  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:34:58] d2.utils.events INFO:  eta: 2:22:54  iter: 4179  total_loss: 0.4635  loss_cls: 0.06673  loss_box_reg: 0.1774  loss_mask: 0.1888  loss_rpn_cls: 0.005146  loss_rpn_loc: 0.01678  time: 0.1012  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:35:00] d2.utils.events INFO:  eta: 2:22:49  iter: 4199  total_loss: 0.3711  loss_cls: 0.05871  loss_box_reg: 0.1448  loss_mask: 0.1578  loss_rpn_cls: 0.002633  loss_rpn_loc: 0.02305  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:02] d2.utils.events INFO:  eta: 2:22:38  iter: 4219  total_loss: 0.399  loss_cls: 0.06417  loss_box_reg: 0.152  loss_mask: 0.1464  loss_rpn_cls: 0.006048  loss_rpn_loc: 0.02511  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:04] d2.utils.events INFO:  eta: 2:22:42  iter: 4239  total_loss: 0.537  loss_cls: 0.08633  loss_box_reg: 0.2175  loss_mask: 0.1481  loss_rpn_cls: 0.00612  loss_rpn_loc: 0.03818  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:06] d2.utils.events INFO:  eta: 2:22:40  iter: 4259  total_loss: 0.3856  loss_cls: 0.07215  loss_box_reg: 0.1584  loss_mask: 0.1346  loss_rpn_cls: 0.003194  loss_rpn_loc: 0.02658  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:08] d2.utils.events INFO:  eta: 2:22:22  iter: 4279  total_loss: 0.4006  loss_cls: 0.07254  loss_box_reg: 0.1317  loss_mask: 0.1432  loss_rpn_cls: 0.002395  loss_rpn_loc: 0.01862  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:10] d2.utils.events INFO:  eta: 2:22:16  iter: 4299  total_loss: 0.3754  loss_cls: 0.07758  loss_box_reg: 0.1497  loss_mask: 0.1293  loss_rpn_cls: 0.00517  loss_rpn_loc: 0.0259  time: 0.1012  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:35:12] d2.utils.events INFO:  eta: 2:21:59  iter: 4319  total_loss: 0.3116  loss_cls: 0.04794  loss_box_reg: 0.08698  loss_mask: 0.1319  loss_rpn_cls: 0.003559  loss_rpn_loc: 0.01985  time: 0.1012  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:35:14] d2.utils.events INFO:  eta: 2:22:00  iter: 4339  total_loss: 0.4687  loss_cls: 0.08285  loss_box_reg: 0.1961  loss_mask: 0.1553  loss_rpn_cls: 0.003927  loss_rpn_loc: 0.02494  time: 0.1012  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:35:16] d2.utils.events INFO:  eta: 2:21:58  iter: 4359  total_loss: 0.4288  loss_cls: 0.09498  loss_box_reg: 0.1743  loss_mask: 0.1308  loss_rpn_cls: 0.006538  loss_rpn_loc: 0.04141  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:18] d2.utils.events INFO:  eta: 2:22:03  iter: 4379  total_loss: 0.4971  loss_cls: 0.07985  loss_box_reg: 0.2455  loss_mask: 0.1222  loss_rpn_cls: 0.004563  loss_rpn_loc: 0.0167  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:20] d2.utils.events INFO:  eta: 2:22:06  iter: 4399  total_loss: 0.356  loss_cls: 0.06833  loss_box_reg: 0.1298  loss_mask: 0.1582  loss_rpn_cls: 0.003612  loss_rpn_loc: 0.02721  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:22] d2.utils.events INFO:  eta: 2:22:05  iter: 4419  total_loss: 0.4677  loss_cls: 0.08116  loss_box_reg: 0.1454  loss_mask: 0.1538  loss_rpn_cls: 0.006907  loss_rpn_loc: 0.04441  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:24] d2.utils.events INFO:  eta: 2:21:50  iter: 4439  total_loss: 0.435  loss_cls: 0.06929  loss_box_reg: 0.1554  loss_mask: 0.1389  loss_rpn_cls: 0.004281  loss_rpn_loc: 0.02449  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:26] d2.utils.events INFO:  eta: 2:22:01  iter: 4459  total_loss: 0.539  loss_cls: 0.09393  loss_box_reg: 0.22  loss_mask: 0.206  loss_rpn_cls: 0.005504  loss_rpn_loc: 0.04337  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:28] d2.utils.events INFO:  eta: 2:21:43  iter: 4479  total_loss: 0.4423  loss_cls: 0.1101  loss_box_reg: 0.1866  loss_mask: 0.1469  loss_rpn_cls: 0.005464  loss_rpn_loc: 0.02633  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:30] d2.utils.events INFO:  eta: 2:21:39  iter: 4499  total_loss: 0.4055  loss_cls: 0.08333  loss_box_reg: 0.1798  loss_mask: 0.1213  loss_rpn_cls: 0.005612  loss_rpn_loc: 0.02977  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:35:32] d2.utils.events INFO:  eta: 2:21:39  iter: 4519  total_loss: 0.3917  loss_cls: 0.0725  loss_box_reg: 0.1357  loss_mask: 0.1507  loss_rpn_cls: 0.003685  loss_rpn_loc: 0.03793  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:34] d2.utils.events INFO:  eta: 2:21:35  iter: 4539  total_loss: 0.5344  loss_cls: 0.07843  loss_box_reg: 0.1882  loss_mask: 0.1434  loss_rpn_cls: 0.00588  loss_rpn_loc: 0.04024  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:35:36] d2.utils.events INFO:  eta: 2:21:50  iter: 4559  total_loss: 0.5137  loss_cls: 0.09308  loss_box_reg: 0.2199  loss_mask: 0.1503  loss_rpn_cls: 0.006009  loss_rpn_loc: 0.0521  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:38] d2.utils.events INFO:  eta: 2:21:46  iter: 4579  total_loss: 0.4119  loss_cls: 0.05232  loss_box_reg: 0.1334  loss_mask: 0.1545  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.01997  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:40] d2.utils.events INFO:  eta: 2:21:43  iter: 4599  total_loss: 0.3821  loss_cls: 0.06587  loss_box_reg: 0.1364  loss_mask: 0.1338  loss_rpn_cls: 0.003214  loss_rpn_loc: 0.0252  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:42] d2.utils.events INFO:  eta: 2:21:26  iter: 4619  total_loss: 0.5097  loss_cls: 0.09265  loss_box_reg: 0.1934  loss_mask: 0.1691  loss_rpn_cls: 0.007766  loss_rpn_loc: 0.03627  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:44] d2.utils.events INFO:  eta: 2:21:24  iter: 4639  total_loss: 0.549  loss_cls: 0.1094  loss_box_reg: 0.2317  loss_mask: 0.2037  loss_rpn_cls: 0.006878  loss_rpn_loc: 0.02919  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:46] d2.utils.events INFO:  eta: 2:21:25  iter: 4659  total_loss: 0.3647  loss_cls: 0.06558  loss_box_reg: 0.1441  loss_mask: 0.1091  loss_rpn_cls: 0.003072  loss_rpn_loc: 0.02345  time: 0.1011  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:35:48] d2.utils.events INFO:  eta: 2:21:20  iter: 4679  total_loss: 0.4524  loss_cls: 0.06685  loss_box_reg: 0.1554  loss_mask: 0.1324  loss_rpn_cls: 0.005834  loss_rpn_loc: 0.02371  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:35:50] d2.utils.events INFO:  eta: 2:21:30  iter: 4699  total_loss: 0.5014  loss_cls: 0.08195  loss_box_reg: 0.1951  loss_mask: 0.1618  loss_rpn_cls: 0.008646  loss_rpn_loc: 0.04918  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:52] d2.utils.events INFO:  eta: 2:21:31  iter: 4719  total_loss: 0.5511  loss_cls: 0.08348  loss_box_reg: 0.1835  loss_mask: 0.1631  loss_rpn_cls: 0.00774  loss_rpn_loc: 0.04277  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:35:54] d2.utils.events INFO:  eta: 2:21:21  iter: 4739  total_loss: 0.3757  loss_cls: 0.07036  loss_box_reg: 0.169  loss_mask: 0.105  loss_rpn_cls: 0.003208  loss_rpn_loc: 0.02903  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:35:56] d2.utils.events INFO:  eta: 2:21:07  iter: 4759  total_loss: 0.4799  loss_cls: 0.05576  loss_box_reg: 0.1649  loss_mask: 0.1493  loss_rpn_cls: 0.006212  loss_rpn_loc: 0.02587  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:35:58] d2.utils.events INFO:  eta: 2:21:00  iter: 4779  total_loss: 0.4879  loss_cls: 0.08839  loss_box_reg: 0.2021  loss_mask: 0.1516  loss_rpn_cls: 0.00294  loss_rpn_loc: 0.03267  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:00] d2.utils.events INFO:  eta: 2:21:03  iter: 4799  total_loss: 0.4289  loss_cls: 0.08399  loss_box_reg: 0.1697  loss_mask: 0.1274  loss_rpn_cls: 0.003546  loss_rpn_loc: 0.02171  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:02] d2.utils.events INFO:  eta: 2:20:55  iter: 4819  total_loss: 0.3749  loss_cls: 0.06275  loss_box_reg: 0.1271  loss_mask: 0.1292  loss_rpn_cls: 0.002394  loss_rpn_loc: 0.01778  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:04] d2.utils.events INFO:  eta: 2:21:04  iter: 4839  total_loss: 0.4232  loss_cls: 0.07476  loss_box_reg: 0.2153  loss_mask: 0.1309  loss_rpn_cls: 0.0064  loss_rpn_loc: 0.02465  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:06] d2.utils.events INFO:  eta: 2:21:17  iter: 4859  total_loss: 0.556  loss_cls: 0.09991  loss_box_reg: 0.2577  loss_mask: 0.1392  loss_rpn_cls: 0.004365  loss_rpn_loc: 0.03184  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:36:08] d2.utils.events INFO:  eta: 2:21:05  iter: 4879  total_loss: 0.4507  loss_cls: 0.07717  loss_box_reg: 0.1999  loss_mask: 0.1519  loss_rpn_cls: 0.005393  loss_rpn_loc: 0.0233  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:36:10] d2.utils.events INFO:  eta: 2:20:58  iter: 4899  total_loss: 0.4656  loss_cls: 0.08042  loss_box_reg: 0.1697  loss_mask: 0.1252  loss_rpn_cls: 0.008167  loss_rpn_loc: 0.05004  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:12] d2.utils.events INFO:  eta: 2:20:42  iter: 4919  total_loss: 0.2906  loss_cls: 0.06211  loss_box_reg: 0.1216  loss_mask: 0.08764  loss_rpn_cls: 0.002043  loss_rpn_loc: 0.01722  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:14] d2.utils.events INFO:  eta: 2:20:50  iter: 4939  total_loss: 0.6242  loss_cls: 0.1065  loss_box_reg: 0.2086  loss_mask: 0.1719  loss_rpn_cls: 0.004381  loss_rpn_loc: 0.03843  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:36:16] d2.utils.events INFO:  eta: 2:20:52  iter: 4959  total_loss: 0.4686  loss_cls: 0.1083  loss_box_reg: 0.1994  loss_mask: 0.1299  loss_rpn_cls: 0.00608  loss_rpn_loc: 0.03913  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:18] d2.utils.events INFO:  eta: 2:20:49  iter: 4979  total_loss: 0.5191  loss_cls: 0.08683  loss_box_reg: 0.1951  loss_mask: 0.1893  loss_rpn_cls: 0.004533  loss_rpn_loc: 0.02812  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:20] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0004999.pth
[10/27 18:36:21] d2.utils.events INFO:  eta: 2:21:00  iter: 4999  total_loss: 0.4211  loss_cls: 0.07875  loss_box_reg: 0.1844  loss_mask: 0.1249  loss_rpn_cls: 0.003218  loss_rpn_loc: 0.01698  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:23] d2.utils.events INFO:  eta: 2:21:05  iter: 5019  total_loss: 0.4852  loss_cls: 0.08189  loss_box_reg: 0.1838  loss_mask: 0.1524  loss_rpn_cls: 0.005022  loss_rpn_loc: 0.03066  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:36:25] d2.utils.events INFO:  eta: 2:21:20  iter: 5039  total_loss: 0.3999  loss_cls: 0.0731  loss_box_reg: 0.1484  loss_mask: 0.1213  loss_rpn_cls: 0.002848  loss_rpn_loc: 0.02458  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:27] d2.utils.events INFO:  eta: 2:21:12  iter: 5059  total_loss: 0.363  loss_cls: 0.07003  loss_box_reg: 0.166  loss_mask: 0.1154  loss_rpn_cls: 0.004759  loss_rpn_loc: 0.03876  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:29] d2.utils.events INFO:  eta: 2:21:09  iter: 5079  total_loss: 0.344  loss_cls: 0.06708  loss_box_reg: 0.1481  loss_mask: 0.1348  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.0131  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:31] d2.utils.events INFO:  eta: 2:20:50  iter: 5099  total_loss: 0.4013  loss_cls: 0.06503  loss_box_reg: 0.1764  loss_mask: 0.1492  loss_rpn_cls: 0.003159  loss_rpn_loc: 0.02944  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:33] d2.utils.events INFO:  eta: 2:20:36  iter: 5119  total_loss: 0.4688  loss_cls: 0.08395  loss_box_reg: 0.1743  loss_mask: 0.1788  loss_rpn_cls: 0.003081  loss_rpn_loc: 0.02016  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:35] d2.utils.events INFO:  eta: 2:20:33  iter: 5139  total_loss: 0.3816  loss_cls: 0.06258  loss_box_reg: 0.1602  loss_mask: 0.1308  loss_rpn_cls: 0.002245  loss_rpn_loc: 0.02251  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:37] d2.utils.events INFO:  eta: 2:20:44  iter: 5159  total_loss: 0.4591  loss_cls: 0.07946  loss_box_reg: 0.171  loss_mask: 0.1271  loss_rpn_cls: 0.005312  loss_rpn_loc: 0.01527  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:39] d2.utils.events INFO:  eta: 2:20:59  iter: 5179  total_loss: 0.5089  loss_cls: 0.08817  loss_box_reg: 0.2236  loss_mask: 0.1345  loss_rpn_cls: 0.004891  loss_rpn_loc: 0.04085  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:41] d2.utils.events INFO:  eta: 2:20:51  iter: 5199  total_loss: 0.303  loss_cls: 0.05534  loss_box_reg: 0.1272  loss_mask: 0.1053  loss_rpn_cls: 0.004396  loss_rpn_loc: 0.01465  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:43] d2.utils.events INFO:  eta: 2:20:53  iter: 5219  total_loss: 0.3401  loss_cls: 0.05008  loss_box_reg: 0.1226  loss_mask: 0.1423  loss_rpn_cls: 0.006146  loss_rpn_loc: 0.04779  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:45] d2.utils.events INFO:  eta: 2:20:23  iter: 5239  total_loss: 0.3009  loss_cls: 0.04979  loss_box_reg: 0.1028  loss_mask: 0.1121  loss_rpn_cls: 0.001559  loss_rpn_loc: 0.01113  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:47] d2.utils.events INFO:  eta: 2:20:18  iter: 5259  total_loss: 0.3302  loss_cls: 0.05119  loss_box_reg: 0.1349  loss_mask: 0.1398  loss_rpn_cls: 0.0007411  loss_rpn_loc: 0.0153  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:49] d2.utils.events INFO:  eta: 2:20:48  iter: 5279  total_loss: 0.6428  loss_cls: 0.09872  loss_box_reg: 0.2451  loss_mask: 0.1849  loss_rpn_cls: 0.004109  loss_rpn_loc: 0.04945  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:51] d2.utils.events INFO:  eta: 2:20:54  iter: 5299  total_loss: 0.4654  loss_cls: 0.07352  loss_box_reg: 0.1894  loss_mask: 0.1478  loss_rpn_cls: 0.003368  loss_rpn_loc: 0.02332  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:36:53] d2.utils.events INFO:  eta: 2:21:06  iter: 5319  total_loss: 0.5118  loss_cls: 0.08459  loss_box_reg: 0.2082  loss_mask: 0.1336  loss_rpn_cls: 0.004576  loss_rpn_loc: 0.03487  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:36:55] d2.utils.events INFO:  eta: 2:20:56  iter: 5339  total_loss: 0.3206  loss_cls: 0.04111  loss_box_reg: 0.1028  loss_mask: 0.1393  loss_rpn_cls: 0.003766  loss_rpn_loc: 0.01625  time: 0.1010  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:36:57] d2.utils.events INFO:  eta: 2:21:05  iter: 5359  total_loss: 0.5725  loss_cls: 0.07195  loss_box_reg: 0.2282  loss_mask: 0.1721  loss_rpn_cls: 0.008299  loss_rpn_loc: 0.04282  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:36:59] d2.utils.events INFO:  eta: 2:21:03  iter: 5379  total_loss: 0.311  loss_cls: 0.04916  loss_box_reg: 0.1223  loss_mask: 0.1109  loss_rpn_cls: 0.006161  loss_rpn_loc: 0.02509  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:37:01] d2.utils.events INFO:  eta: 2:21:11  iter: 5399  total_loss: 0.4661  loss_cls: 0.09454  loss_box_reg: 0.1885  loss_mask: 0.1669  loss_rpn_cls: 0.002285  loss_rpn_loc: 0.02681  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:03] d2.utils.events INFO:  eta: 2:21:27  iter: 5419  total_loss: 0.5873  loss_cls: 0.1289  loss_box_reg: 0.2474  loss_mask: 0.1793  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.03715  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:05] d2.utils.events INFO:  eta: 2:21:31  iter: 5439  total_loss: 0.3175  loss_cls: 0.0579  loss_box_reg: 0.1027  loss_mask: 0.1145  loss_rpn_cls: 0.00145  loss_rpn_loc: 0.02213  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:07] d2.utils.events INFO:  eta: 2:21:19  iter: 5459  total_loss: 0.4848  loss_cls: 0.07824  loss_box_reg: 0.1842  loss_mask: 0.1331  loss_rpn_cls: 0.004996  loss_rpn_loc: 0.05077  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:09] d2.utils.events INFO:  eta: 2:21:25  iter: 5479  total_loss: 0.4748  loss_cls: 0.09372  loss_box_reg: 0.2039  loss_mask: 0.1506  loss_rpn_cls: 0.006784  loss_rpn_loc: 0.031  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:11] d2.utils.events INFO:  eta: 2:21:25  iter: 5499  total_loss: 0.4658  loss_cls: 0.08487  loss_box_reg: 0.1977  loss_mask: 0.154  loss_rpn_cls: 0.004015  loss_rpn_loc: 0.02385  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:13] d2.utils.events INFO:  eta: 2:21:23  iter: 5519  total_loss: 0.3769  loss_cls: 0.06004  loss_box_reg: 0.1508  loss_mask: 0.1248  loss_rpn_cls: 0.002219  loss_rpn_loc: 0.02628  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:15] d2.utils.events INFO:  eta: 2:21:26  iter: 5539  total_loss: 0.4381  loss_cls: 0.07125  loss_box_reg: 0.2115  loss_mask: 0.1387  loss_rpn_cls: 0.002571  loss_rpn_loc: 0.02134  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:17] d2.utils.events INFO:  eta: 2:21:35  iter: 5559  total_loss: 0.5439  loss_cls: 0.115  loss_box_reg: 0.2524  loss_mask: 0.1648  loss_rpn_cls: 0.00463  loss_rpn_loc: 0.03373  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:20] d2.utils.events INFO:  eta: 2:21:37  iter: 5579  total_loss: 0.5465  loss_cls: 0.1134  loss_box_reg: 0.2253  loss_mask: 0.151  loss_rpn_cls: 0.002334  loss_rpn_loc: 0.03009  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:22] d2.utils.events INFO:  eta: 2:21:38  iter: 5599  total_loss: 0.6369  loss_cls: 0.1038  loss_box_reg: 0.1989  loss_mask: 0.181  loss_rpn_cls: 0.007238  loss_rpn_loc: 0.05607  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:24] d2.utils.events INFO:  eta: 2:21:40  iter: 5619  total_loss: 0.7266  loss_cls: 0.1501  loss_box_reg: 0.2697  loss_mask: 0.1948  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.09064  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:26] d2.utils.events INFO:  eta: 2:21:38  iter: 5639  total_loss: 0.3976  loss_cls: 0.06078  loss_box_reg: 0.1504  loss_mask: 0.1397  loss_rpn_cls: 0.002732  loss_rpn_loc: 0.0273  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:28] d2.utils.events INFO:  eta: 2:21:27  iter: 5659  total_loss: 0.3278  loss_cls: 0.05469  loss_box_reg: 0.1513  loss_mask: 0.1227  loss_rpn_cls: 0.002221  loss_rpn_loc: 0.01472  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:30] d2.utils.events INFO:  eta: 2:21:30  iter: 5679  total_loss: 0.3289  loss_cls: 0.05135  loss_box_reg: 0.1453  loss_mask: 0.1016  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.01087  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:32] d2.utils.events INFO:  eta: 2:21:22  iter: 5699  total_loss: 0.395  loss_cls: 0.06372  loss_box_reg: 0.1585  loss_mask: 0.1362  loss_rpn_cls: 0.002675  loss_rpn_loc: 0.01674  time: 0.1010  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:37:34] d2.utils.events INFO:  eta: 2:21:20  iter: 5719  total_loss: 0.4442  loss_cls: 0.05901  loss_box_reg: 0.1785  loss_mask: 0.1255  loss_rpn_cls: 0.003265  loss_rpn_loc: 0.0358  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:36] d2.utils.events INFO:  eta: 2:21:18  iter: 5739  total_loss: 0.5274  loss_cls: 0.06149  loss_box_reg: 0.1617  loss_mask: 0.1592  loss_rpn_cls: 0.004106  loss_rpn_loc: 0.0249  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:38] d2.utils.events INFO:  eta: 2:21:19  iter: 5759  total_loss: 0.6079  loss_cls: 0.1267  loss_box_reg: 0.2389  loss_mask: 0.2155  loss_rpn_cls: 0.009084  loss_rpn_loc: 0.0517  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:40] d2.utils.events INFO:  eta: 2:21:15  iter: 5779  total_loss: 0.4096  loss_cls: 0.06458  loss_box_reg: 0.1746  loss_mask: 0.1339  loss_rpn_cls: 0.003373  loss_rpn_loc: 0.03653  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:42] d2.utils.events INFO:  eta: 2:21:13  iter: 5799  total_loss: 0.3459  loss_cls: 0.0534  loss_box_reg: 0.1232  loss_mask: 0.1401  loss_rpn_cls: 0.00208  loss_rpn_loc: 0.01629  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:37:44] d2.utils.events INFO:  eta: 2:21:05  iter: 5819  total_loss: 0.5654  loss_cls: 0.09563  loss_box_reg: 0.2128  loss_mask: 0.1395  loss_rpn_cls: 0.004682  loss_rpn_loc: 0.05011  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:46] d2.utils.events INFO:  eta: 2:20:55  iter: 5839  total_loss: 0.3087  loss_cls: 0.04417  loss_box_reg: 0.1109  loss_mask: 0.1384  loss_rpn_cls: 0.003995  loss_rpn_loc: 0.01518  time: 0.1010  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:37:48] d2.utils.events INFO:  eta: 2:20:49  iter: 5859  total_loss: 0.4593  loss_cls: 0.08934  loss_box_reg: 0.2078  loss_mask: 0.1239  loss_rpn_cls: 0.004089  loss_rpn_loc: 0.02073  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:50] d2.utils.events INFO:  eta: 2:20:43  iter: 5879  total_loss: 0.3902  loss_cls: 0.06024  loss_box_reg: 0.1722  loss_mask: 0.1259  loss_rpn_cls: 0.004892  loss_rpn_loc: 0.03994  time: 0.1010  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:37:51] d2.utils.events INFO:  eta: 2:20:37  iter: 5899  total_loss: 0.2587  loss_cls: 0.03353  loss_box_reg: 0.06778  loss_mask: 0.1254  loss_rpn_cls: 0.003672  loss_rpn_loc: 0.02809  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:54] d2.utils.events INFO:  eta: 2:20:59  iter: 5919  total_loss: 0.4621  loss_cls: 0.07939  loss_box_reg: 0.2022  loss_mask: 0.1447  loss_rpn_cls: 0.009015  loss_rpn_loc: 0.059  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:37:56] d2.utils.events INFO:  eta: 2:20:41  iter: 5939  total_loss: 0.3128  loss_cls: 0.04749  loss_box_reg: 0.1046  loss_mask: 0.1056  loss_rpn_cls: 0.003049  loss_rpn_loc: 0.02211  time: 0.1009  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:37:58] d2.utils.events INFO:  eta: 2:20:43  iter: 5959  total_loss: 0.431  loss_cls: 0.08936  loss_box_reg: 0.2142  loss_mask: 0.1294  loss_rpn_cls: 0.002795  loss_rpn_loc: 0.01645  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:38:00] d2.utils.events INFO:  eta: 2:20:44  iter: 5979  total_loss: 0.4639  loss_cls: 0.08057  loss_box_reg: 0.1987  loss_mask: 0.1659  loss_rpn_cls: 0.005853  loss_rpn_loc: 0.02097  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:02] d2.utils.events INFO:  eta: 2:20:47  iter: 5999  total_loss: 0.359  loss_cls: 0.05381  loss_box_reg: 0.1527  loss_mask: 0.1256  loss_rpn_cls: 0.00296  loss_rpn_loc: 0.023  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:04] d2.utils.events INFO:  eta: 2:20:40  iter: 6019  total_loss: 0.6541  loss_cls: 0.1198  loss_box_reg: 0.282  loss_mask: 0.1907  loss_rpn_cls: 0.004708  loss_rpn_loc: 0.04254  time: 0.1009  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:38:06] d2.utils.events INFO:  eta: 2:20:28  iter: 6039  total_loss: 0.3092  loss_cls: 0.03729  loss_box_reg: 0.104  loss_mask: 0.136  loss_rpn_cls: 0.0007913  loss_rpn_loc: 0.009722  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:08] d2.utils.events INFO:  eta: 2:20:26  iter: 6059  total_loss: 0.4186  loss_cls: 0.07294  loss_box_reg: 0.1897  loss_mask: 0.1309  loss_rpn_cls: 0.00256  loss_rpn_loc: 0.028  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:10] d2.utils.events INFO:  eta: 2:20:31  iter: 6079  total_loss: 0.3029  loss_cls: 0.05328  loss_box_reg: 0.1134  loss_mask: 0.1122  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.02001  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:12] d2.utils.events INFO:  eta: 2:20:43  iter: 6099  total_loss: 0.5132  loss_cls: 0.09913  loss_box_reg: 0.2144  loss_mask: 0.1682  loss_rpn_cls: 0.005552  loss_rpn_loc: 0.03546  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:14] d2.utils.events INFO:  eta: 2:20:58  iter: 6119  total_loss: 0.4351  loss_cls: 0.07173  loss_box_reg: 0.2118  loss_mask: 0.1456  loss_rpn_cls: 0.002985  loss_rpn_loc: 0.02578  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:16] d2.utils.events INFO:  eta: 2:20:58  iter: 6139  total_loss: 0.4092  loss_cls: 0.06327  loss_box_reg: 0.1767  loss_mask: 0.1125  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.01642  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:18] d2.utils.events INFO:  eta: 2:20:56  iter: 6159  total_loss: 0.579  loss_cls: 0.08337  loss_box_reg: 0.1685  loss_mask: 0.1654  loss_rpn_cls: 0.003111  loss_rpn_loc: 0.06047  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:20] d2.utils.events INFO:  eta: 2:20:54  iter: 6179  total_loss: 0.3937  loss_cls: 0.06632  loss_box_reg: 0.1539  loss_mask: 0.1409  loss_rpn_cls: 0.004197  loss_rpn_loc: 0.01262  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:22] d2.utils.events INFO:  eta: 2:20:52  iter: 6199  total_loss: 0.3018  loss_cls: 0.03961  loss_box_reg: 0.09057  loss_mask: 0.1164  loss_rpn_cls: 0.004158  loss_rpn_loc: 0.02696  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:24] d2.utils.events INFO:  eta: 2:20:50  iter: 6219  total_loss: 0.338  loss_cls: 0.05281  loss_box_reg: 0.1131  loss_mask: 0.1459  loss_rpn_cls: 0.004646  loss_rpn_loc: 0.0203  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:38:26] d2.utils.events INFO:  eta: 2:20:55  iter: 6239  total_loss: 0.3935  loss_cls: 0.06295  loss_box_reg: 0.183  loss_mask: 0.1683  loss_rpn_cls: 0.003028  loss_rpn_loc: 0.03544  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:38:28] d2.utils.events INFO:  eta: 2:20:58  iter: 6259  total_loss: 0.347  loss_cls: 0.05888  loss_box_reg: 0.1519  loss_mask: 0.1122  loss_rpn_cls: 0.005689  loss_rpn_loc: 0.04825  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:30] d2.utils.events INFO:  eta: 2:20:46  iter: 6279  total_loss: 0.3048  loss_cls: 0.05936  loss_box_reg: 0.1004  loss_mask: 0.1187  loss_rpn_cls: 0.00147  loss_rpn_loc: 0.01791  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:32] d2.utils.events INFO:  eta: 2:20:31  iter: 6299  total_loss: 0.4001  loss_cls: 0.05778  loss_box_reg: 0.1861  loss_mask: 0.1299  loss_rpn_cls: 0.001926  loss_rpn_loc: 0.02455  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:38:34] d2.utils.events INFO:  eta: 2:20:23  iter: 6319  total_loss: 0.4036  loss_cls: 0.07444  loss_box_reg: 0.1899  loss_mask: 0.1173  loss_rpn_cls: 0.002903  loss_rpn_loc: 0.03224  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:38:36] d2.utils.events INFO:  eta: 2:20:21  iter: 6339  total_loss: 0.3611  loss_cls: 0.06543  loss_box_reg: 0.1348  loss_mask: 0.1327  loss_rpn_cls: 0.0005887  loss_rpn_loc: 0.01603  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:38] d2.utils.events INFO:  eta: 2:20:21  iter: 6359  total_loss: 0.5475  loss_cls: 0.1109  loss_box_reg: 0.2369  loss_mask: 0.1707  loss_rpn_cls: 0.005968  loss_rpn_loc: 0.0402  time: 0.1009  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:38:40] d2.utils.events INFO:  eta: 2:20:17  iter: 6379  total_loss: 0.3701  loss_cls: 0.06903  loss_box_reg: 0.1509  loss_mask: 0.1386  loss_rpn_cls: 0.001231  loss_rpn_loc: 0.01967  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:42] d2.utils.events INFO:  eta: 2:20:10  iter: 6399  total_loss: 0.376  loss_cls: 0.05716  loss_box_reg: 0.1589  loss_mask: 0.1158  loss_rpn_cls: 0.002556  loss_rpn_loc: 0.02049  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:44] d2.utils.events INFO:  eta: 2:20:08  iter: 6419  total_loss: 0.5253  loss_cls: 0.08069  loss_box_reg: 0.2259  loss_mask: 0.1735  loss_rpn_cls: 0.005541  loss_rpn_loc: 0.0338  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:46] d2.utils.events INFO:  eta: 2:20:02  iter: 6439  total_loss: 0.2478  loss_cls: 0.03953  loss_box_reg: 0.09044  loss_mask: 0.1005  loss_rpn_cls: 0.001326  loss_rpn_loc: 0.009412  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:48] d2.utils.events INFO:  eta: 2:20:11  iter: 6459  total_loss: 0.3773  loss_cls: 0.04933  loss_box_reg: 0.1466  loss_mask: 0.1356  loss_rpn_cls: 0.003901  loss_rpn_loc: 0.02611  time: 0.1009  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:38:50] d2.utils.events INFO:  eta: 2:20:02  iter: 6479  total_loss: 0.4419  loss_cls: 0.07135  loss_box_reg: 0.1991  loss_mask: 0.116  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.03947  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:52] d2.utils.events INFO:  eta: 2:19:54  iter: 6499  total_loss: 0.4478  loss_cls: 0.06521  loss_box_reg: 0.1532  loss_mask: 0.1558  loss_rpn_cls: 0.003446  loss_rpn_loc: 0.02564  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:54] d2.utils.events INFO:  eta: 2:19:56  iter: 6519  total_loss: 0.3695  loss_cls: 0.06986  loss_box_reg: 0.1527  loss_mask: 0.1446  loss_rpn_cls: 0.00374  loss_rpn_loc: 0.02483  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:38:56] d2.utils.events INFO:  eta: 2:19:50  iter: 6539  total_loss: 0.3861  loss_cls: 0.06112  loss_box_reg: 0.1452  loss_mask: 0.1296  loss_rpn_cls: 0.002824  loss_rpn_loc: 0.03422  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:38:58] d2.utils.events INFO:  eta: 2:19:29  iter: 6559  total_loss: 0.2853  loss_cls: 0.03207  loss_box_reg: 0.08137  loss_mask: 0.1173  loss_rpn_cls: 0.002069  loss_rpn_loc: 0.01526  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:00] d2.utils.events INFO:  eta: 2:19:11  iter: 6579  total_loss: 0.302  loss_cls: 0.05497  loss_box_reg: 0.1274  loss_mask: 0.1123  loss_rpn_cls: 0.003272  loss_rpn_loc: 0.02718  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:03] d2.utils.events INFO:  eta: 2:19:15  iter: 6599  total_loss: 0.4512  loss_cls: 0.07792  loss_box_reg: 0.2046  loss_mask: 0.1279  loss_rpn_cls: 0.008234  loss_rpn_loc: 0.05709  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:05] d2.utils.events INFO:  eta: 2:19:15  iter: 6619  total_loss: 0.3617  loss_cls: 0.04159  loss_box_reg: 0.1359  loss_mask: 0.1231  loss_rpn_cls: 0.004939  loss_rpn_loc: 0.01821  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:07] d2.utils.events INFO:  eta: 2:19:17  iter: 6639  total_loss: 0.3819  loss_cls: 0.05352  loss_box_reg: 0.1264  loss_mask: 0.1384  loss_rpn_cls: 0.003149  loss_rpn_loc: 0.01947  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:08] d2.utils.events INFO:  eta: 2:19:09  iter: 6659  total_loss: 0.3152  loss_cls: 0.05717  loss_box_reg: 0.1193  loss_mask: 0.1289  loss_rpn_cls: 0.005562  loss_rpn_loc: 0.03941  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:10] d2.utils.events INFO:  eta: 2:18:55  iter: 6679  total_loss: 0.2692  loss_cls: 0.05968  loss_box_reg: 0.1124  loss_mask: 0.09855  loss_rpn_cls: 0.00415  loss_rpn_loc: 0.02893  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:13] d2.utils.events INFO:  eta: 2:18:55  iter: 6699  total_loss: 0.3615  loss_cls: 0.06351  loss_box_reg: 0.174  loss_mask: 0.1122  loss_rpn_cls: 0.0007518  loss_rpn_loc: 0.0195  time: 0.1009  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:39:15] d2.utils.events INFO:  eta: 2:19:03  iter: 6719  total_loss: 0.4127  loss_cls: 0.07277  loss_box_reg: 0.1697  loss_mask: 0.147  loss_rpn_cls: 0.003166  loss_rpn_loc: 0.03529  time: 0.1009  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:39:17] d2.utils.events INFO:  eta: 2:19:11  iter: 6739  total_loss: 0.406  loss_cls: 0.07083  loss_box_reg: 0.1642  loss_mask: 0.1323  loss_rpn_cls: 0.003608  loss_rpn_loc: 0.01843  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:19] d2.utils.events INFO:  eta: 2:19:12  iter: 6759  total_loss: 0.3424  loss_cls: 0.05447  loss_box_reg: 0.1527  loss_mask: 0.1141  loss_rpn_cls: 0.003385  loss_rpn_loc: 0.02165  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:21] d2.utils.events INFO:  eta: 2:19:11  iter: 6779  total_loss: 0.3689  loss_cls: 0.07051  loss_box_reg: 0.1592  loss_mask: 0.1312  loss_rpn_cls: 0.002769  loss_rpn_loc: 0.03307  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:23] d2.utils.events INFO:  eta: 2:19:07  iter: 6799  total_loss: 0.3755  loss_cls: 0.06164  loss_box_reg: 0.1635  loss_mask: 0.1088  loss_rpn_cls: 0.002488  loss_rpn_loc: 0.01827  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:25] d2.utils.events INFO:  eta: 2:19:26  iter: 6819  total_loss: 0.4524  loss_cls: 0.08979  loss_box_reg: 0.1999  loss_mask: 0.1377  loss_rpn_cls: 0.001818  loss_rpn_loc: 0.02432  time: 0.1009  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:27] d2.utils.events INFO:  eta: 2:19:21  iter: 6839  total_loss: 0.4201  loss_cls: 0.06982  loss_box_reg: 0.1615  loss_mask: 0.1346  loss_rpn_cls: 0.003229  loss_rpn_loc: 0.02199  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:29] d2.utils.events INFO:  eta: 2:19:07  iter: 6859  total_loss: 0.3474  loss_cls: 0.05064  loss_box_reg: 0.1401  loss_mask: 0.1152  loss_rpn_cls: 0.001926  loss_rpn_loc: 0.02445  time: 0.1009  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:39:31] d2.utils.events INFO:  eta: 2:19:21  iter: 6879  total_loss: 0.4054  loss_cls: 0.06625  loss_box_reg: 0.1865  loss_mask: 0.133  loss_rpn_cls: 0.003686  loss_rpn_loc: 0.0262  time: 0.1009  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:39:33] d2.utils.events INFO:  eta: 2:19:40  iter: 6899  total_loss: 0.3165  loss_cls: 0.04378  loss_box_reg: 0.09382  loss_mask: 0.108  loss_rpn_cls: 0.002123  loss_rpn_loc: 0.01836  time: 0.1009  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:39:35] d2.utils.events INFO:  eta: 2:19:37  iter: 6919  total_loss: 0.4335  loss_cls: 0.07974  loss_box_reg: 0.2147  loss_mask: 0.1334  loss_rpn_cls: 0.002195  loss_rpn_loc: 0.02934  time: 0.1009  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:39:37] d2.utils.events INFO:  eta: 2:19:32  iter: 6939  total_loss: 0.3623  loss_cls: 0.06388  loss_box_reg: 0.1504  loss_mask: 0.1251  loss_rpn_cls: 0.0007217  loss_rpn_loc: 0.01875  time: 0.1009  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:39:39] d2.utils.events INFO:  eta: 2:19:24  iter: 6959  total_loss: 0.4026  loss_cls: 0.07643  loss_box_reg: 0.2148  loss_mask: 0.1509  loss_rpn_cls: 0.004724  loss_rpn_loc: 0.03566  time: 0.1009  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:39:41] d2.utils.events INFO:  eta: 2:19:19  iter: 6979  total_loss: 0.4343  loss_cls: 0.07486  loss_box_reg: 0.1659  loss_mask: 0.1193  loss_rpn_cls: 0.003726  loss_rpn_loc: 0.02544  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:43] d2.utils.events INFO:  eta: 2:19:20  iter: 6999  total_loss: 0.3728  loss_cls: 0.05987  loss_box_reg: 0.1344  loss_mask: 0.1473  loss_rpn_cls: 0.002182  loss_rpn_loc: 0.0418  time: 0.1009  data_time: 0.0030  lr: 0.0025  max_mem: 1630M
[10/27 18:39:45] d2.utils.events INFO:  eta: 2:19:23  iter: 7019  total_loss: 0.3725  loss_cls: 0.06904  loss_box_reg: 0.1772  loss_mask: 0.1135  loss_rpn_cls: 0.002005  loss_rpn_loc: 0.02264  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:39:47] d2.utils.events INFO:  eta: 2:19:41  iter: 7039  total_loss: 0.2966  loss_cls: 0.0445  loss_box_reg: 0.1207  loss_mask: 0.1222  loss_rpn_cls: 0.002079  loss_rpn_loc: 0.01888  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:49] d2.utils.events INFO:  eta: 2:19:41  iter: 7059  total_loss: 0.2969  loss_cls: 0.04875  loss_box_reg: 0.09783  loss_mask: 0.1272  loss_rpn_cls: 0.001647  loss_rpn_loc: 0.02155  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:39:52] d2.utils.events INFO:  eta: 2:19:41  iter: 7079  total_loss: 0.6555  loss_cls: 0.1211  loss_box_reg: 0.2542  loss_mask: 0.1827  loss_rpn_cls: 0.002379  loss_rpn_loc: 0.03817  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:39:54] d2.utils.events INFO:  eta: 2:19:27  iter: 7099  total_loss: 0.4443  loss_cls: 0.06551  loss_box_reg: 0.1944  loss_mask: 0.1309  loss_rpn_cls: 0.003084  loss_rpn_loc: 0.02135  time: 0.1010  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:39:56] d2.utils.events INFO:  eta: 2:19:37  iter: 7119  total_loss: 0.4653  loss_cls: 0.08351  loss_box_reg: 0.2195  loss_mask: 0.1634  loss_rpn_cls: 0.003005  loss_rpn_loc: 0.02282  time: 0.1010  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:39:58] d2.utils.events INFO:  eta: 2:19:33  iter: 7139  total_loss: 0.2713  loss_cls: 0.04604  loss_box_reg: 0.1032  loss_mask: 0.09627  loss_rpn_cls: 0.0006857  loss_rpn_loc: 0.01494  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:00] d2.utils.events INFO:  eta: 2:19:33  iter: 7159  total_loss: 0.5258  loss_cls: 0.08016  loss_box_reg: 0.1632  loss_mask: 0.1665  loss_rpn_cls: 0.00312  loss_rpn_loc: 0.04496  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:02] d2.utils.events INFO:  eta: 2:19:37  iter: 7179  total_loss: 0.3325  loss_cls: 0.04369  loss_box_reg: 0.1457  loss_mask: 0.1017  loss_rpn_cls: 0.003341  loss_rpn_loc: 0.02247  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:04] d2.utils.events INFO:  eta: 2:19:40  iter: 7199  total_loss: 0.2667  loss_cls: 0.04123  loss_box_reg: 0.1008  loss_mask: 0.09865  loss_rpn_cls: 0.001001  loss_rpn_loc: 0.01019  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:06] d2.utils.events INFO:  eta: 2:19:38  iter: 7219  total_loss: 0.3766  loss_cls: 0.05349  loss_box_reg: 0.1548  loss_mask: 0.1343  loss_rpn_cls: 0.00237  loss_rpn_loc: 0.01833  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:08] d2.utils.events INFO:  eta: 2:19:43  iter: 7239  total_loss: 0.6722  loss_cls: 0.08476  loss_box_reg: 0.2311  loss_mask: 0.1965  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.09435  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:10] d2.utils.events INFO:  eta: 2:19:43  iter: 7259  total_loss: 0.413  loss_cls: 0.06675  loss_box_reg: 0.1786  loss_mask: 0.125  loss_rpn_cls: 0.004255  loss_rpn_loc: 0.0328  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:12] d2.utils.events INFO:  eta: 2:19:44  iter: 7279  total_loss: 0.4793  loss_cls: 0.07796  loss_box_reg: 0.195  loss_mask: 0.1466  loss_rpn_cls: 0.003176  loss_rpn_loc: 0.02596  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:14] d2.utils.events INFO:  eta: 2:19:54  iter: 7299  total_loss: 0.4087  loss_cls: 0.06297  loss_box_reg: 0.1575  loss_mask: 0.1387  loss_rpn_cls: 0.002956  loss_rpn_loc: 0.02443  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:16] d2.utils.events INFO:  eta: 2:19:58  iter: 7319  total_loss: 0.5297  loss_cls: 0.09898  loss_box_reg: 0.2258  loss_mask: 0.161  loss_rpn_cls: 0.003017  loss_rpn_loc: 0.05098  time: 0.1010  data_time: 0.0030  lr: 0.0025  max_mem: 1630M
[10/27 18:40:18] d2.utils.events INFO:  eta: 2:20:05  iter: 7339  total_loss: 0.3754  loss_cls: 0.06921  loss_box_reg: 0.1794  loss_mask: 0.1528  loss_rpn_cls: 0.008986  loss_rpn_loc: 0.02185  time: 0.1010  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:40:20] d2.utils.events INFO:  eta: 2:19:48  iter: 7359  total_loss: 0.3732  loss_cls: 0.04909  loss_box_reg: 0.1035  loss_mask: 0.1501  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.03785  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:22] d2.utils.events INFO:  eta: 2:19:52  iter: 7379  total_loss: 0.3562  loss_cls: 0.04195  loss_box_reg: 0.07815  loss_mask: 0.1415  loss_rpn_cls: 0.004834  loss_rpn_loc: 0.02708  time: 0.1010  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:40:24] d2.utils.events INFO:  eta: 2:19:54  iter: 7399  total_loss: 0.344  loss_cls: 0.05456  loss_box_reg: 0.1523  loss_mask: 0.1202  loss_rpn_cls: 0.002821  loss_rpn_loc: 0.01999  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:27] d2.utils.events INFO:  eta: 2:19:51  iter: 7419  total_loss: 0.277  loss_cls: 0.03794  loss_box_reg: 0.09287  loss_mask: 0.1141  loss_rpn_cls: 0.003653  loss_rpn_loc: 0.01736  time: 0.1010  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:29] d2.utils.events INFO:  eta: 2:19:58  iter: 7439  total_loss: 0.4459  loss_cls: 0.06498  loss_box_reg: 0.1398  loss_mask: 0.1206  loss_rpn_cls: 0.003835  loss_rpn_loc: 0.02589  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:31] d2.utils.events INFO:  eta: 2:19:56  iter: 7459  total_loss: 0.3207  loss_cls: 0.04533  loss_box_reg: 0.1265  loss_mask: 0.1228  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.01864  time: 0.1010  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:33] d2.utils.events INFO:  eta: 2:20:06  iter: 7479  total_loss: 0.3663  loss_cls: 0.05084  loss_box_reg: 0.1573  loss_mask: 0.1233  loss_rpn_cls: 0.003014  loss_rpn_loc: 0.01952  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:35] d2.utils.events INFO:  eta: 2:19:57  iter: 7499  total_loss: 0.3681  loss_cls: 0.05323  loss_box_reg: 0.1613  loss_mask: 0.1234  loss_rpn_cls: 0.003245  loss_rpn_loc: 0.0235  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:37] d2.utils.events INFO:  eta: 2:19:52  iter: 7519  total_loss: 0.3051  loss_cls: 0.04472  loss_box_reg: 0.1089  loss_mask: 0.1392  loss_rpn_cls: 0.001607  loss_rpn_loc: 0.009539  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:39] d2.utils.events INFO:  eta: 2:20:02  iter: 7539  total_loss: 0.2897  loss_cls: 0.0337  loss_box_reg: 0.1038  loss_mask: 0.116  loss_rpn_cls: 0.003364  loss_rpn_loc: 0.01441  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:41] d2.utils.events INFO:  eta: 2:20:00  iter: 7559  total_loss: 0.3261  loss_cls: 0.03245  loss_box_reg: 0.1049  loss_mask: 0.113  loss_rpn_cls: 0.004462  loss_rpn_loc: 0.03324  time: 0.1010  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:43] d2.utils.events INFO:  eta: 2:20:03  iter: 7579  total_loss: 0.3883  loss_cls: 0.04892  loss_box_reg: 0.1558  loss_mask: 0.1362  loss_rpn_cls: 0.004252  loss_rpn_loc: 0.04244  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:45] d2.utils.events INFO:  eta: 2:20:01  iter: 7599  total_loss: 0.4362  loss_cls: 0.06993  loss_box_reg: 0.1696  loss_mask: 0.152  loss_rpn_cls: 0.003476  loss_rpn_loc: 0.02514  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:47] d2.utils.events INFO:  eta: 2:20:13  iter: 7619  total_loss: 0.4261  loss_cls: 0.07317  loss_box_reg: 0.1833  loss_mask: 0.1339  loss_rpn_cls: 0.008823  loss_rpn_loc: 0.03886  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:49] d2.utils.events INFO:  eta: 2:20:11  iter: 7639  total_loss: 0.2504  loss_cls: 0.03281  loss_box_reg: 0.1004  loss_mask: 0.107  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.01797  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:51] d2.utils.events INFO:  eta: 2:20:15  iter: 7659  total_loss: 0.4422  loss_cls: 0.06139  loss_box_reg: 0.1699  loss_mask: 0.1645  loss_rpn_cls: 0.002442  loss_rpn_loc: 0.03056  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:40:53] d2.utils.events INFO:  eta: 2:20:14  iter: 7679  total_loss: 0.4101  loss_cls: 0.06113  loss_box_reg: 0.1706  loss_mask: 0.1183  loss_rpn_cls: 0.004096  loss_rpn_loc: 0.02704  time: 0.1011  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:40:55] d2.utils.events INFO:  eta: 2:20:11  iter: 7699  total_loss: 0.3785  loss_cls: 0.05573  loss_box_reg: 0.1465  loss_mask: 0.1207  loss_rpn_cls: 0.004091  loss_rpn_loc: 0.02126  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:40:57] d2.utils.events INFO:  eta: 2:20:00  iter: 7719  total_loss: 0.3383  loss_cls: 0.04844  loss_box_reg: 0.1396  loss_mask: 0.1274  loss_rpn_cls: 0.002473  loss_rpn_loc: 0.01417  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:40:59] d2.utils.events INFO:  eta: 2:19:56  iter: 7739  total_loss: 0.4277  loss_cls: 0.07445  loss_box_reg: 0.1702  loss_mask: 0.1518  loss_rpn_cls: 0.003659  loss_rpn_loc: 0.03091  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:01] d2.utils.events INFO:  eta: 2:19:47  iter: 7759  total_loss: 0.393  loss_cls: 0.05396  loss_box_reg: 0.1392  loss_mask: 0.1108  loss_rpn_cls: 0.00217  loss_rpn_loc: 0.01335  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:41:03] d2.utils.events INFO:  eta: 2:19:37  iter: 7779  total_loss: 0.3324  loss_cls: 0.05336  loss_box_reg: 0.1311  loss_mask: 0.1273  loss_rpn_cls: 0.002926  loss_rpn_loc: 0.01518  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:41:05] d2.utils.events INFO:  eta: 2:19:49  iter: 7799  total_loss: 0.3301  loss_cls: 0.05852  loss_box_reg: 0.09298  loss_mask: 0.1156  loss_rpn_cls: 0.002119  loss_rpn_loc: 0.02743  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:08] d2.utils.events INFO:  eta: 2:19:48  iter: 7819  total_loss: 0.5221  loss_cls: 0.07798  loss_box_reg: 0.2167  loss_mask: 0.1551  loss_rpn_cls: 0.007154  loss_rpn_loc: 0.04573  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:10] d2.utils.events INFO:  eta: 2:19:50  iter: 7839  total_loss: 0.3123  loss_cls: 0.05877  loss_box_reg: 0.1173  loss_mask: 0.1053  loss_rpn_cls: 0.001202  loss_rpn_loc: 0.0269  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:12] d2.utils.events INFO:  eta: 2:19:44  iter: 7859  total_loss: 0.2012  loss_cls: 0.02975  loss_box_reg: 0.06835  loss_mask: 0.09575  loss_rpn_cls: 0.002869  loss_rpn_loc: 0.0153  time: 0.1011  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:41:14] d2.utils.events INFO:  eta: 2:19:42  iter: 7879  total_loss: 0.2909  loss_cls: 0.04898  loss_box_reg: 0.09994  loss_mask: 0.1076  loss_rpn_cls: 0.00188  loss_rpn_loc: 0.01281  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:16] d2.utils.events INFO:  eta: 2:19:39  iter: 7899  total_loss: 0.4415  loss_cls: 0.05424  loss_box_reg: 0.1778  loss_mask: 0.1429  loss_rpn_cls: 0.004909  loss_rpn_loc: 0.04269  time: 0.1011  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:41:18] d2.utils.events INFO:  eta: 2:19:30  iter: 7919  total_loss: 0.362  loss_cls: 0.06091  loss_box_reg: 0.1442  loss_mask: 0.1297  loss_rpn_cls: 0.00266  loss_rpn_loc: 0.02831  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:20] d2.utils.events INFO:  eta: 2:19:42  iter: 7939  total_loss: 0.3527  loss_cls: 0.05247  loss_box_reg: 0.1438  loss_mask: 0.1262  loss_rpn_cls: 0.003249  loss_rpn_loc: 0.02  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:22] d2.utils.events INFO:  eta: 2:19:44  iter: 7959  total_loss: 0.3906  loss_cls: 0.05925  loss_box_reg: 0.1595  loss_mask: 0.1445  loss_rpn_cls: 0.00219  loss_rpn_loc: 0.02399  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:24] d2.utils.events INFO:  eta: 2:19:43  iter: 7979  total_loss: 0.4814  loss_cls: 0.08007  loss_box_reg: 0.2197  loss_mask: 0.1535  loss_rpn_cls: 0.003673  loss_rpn_loc: 0.03098  time: 0.1011  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:41:26] d2.utils.events INFO:  eta: 2:19:57  iter: 7999  total_loss: 0.412  loss_cls: 0.06977  loss_box_reg: 0.1648  loss_mask: 0.1055  loss_rpn_cls: 0.003674  loss_rpn_loc: 0.03386  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:28] d2.utils.events INFO:  eta: 2:19:58  iter: 8019  total_loss: 0.3031  loss_cls: 0.04444  loss_box_reg: 0.107  loss_mask: 0.1281  loss_rpn_cls: 0.001465  loss_rpn_loc: 0.02206  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:30] d2.utils.events INFO:  eta: 2:19:57  iter: 8039  total_loss: 0.4405  loss_cls: 0.07106  loss_box_reg: 0.1995  loss_mask: 0.1423  loss_rpn_cls: 0.007734  loss_rpn_loc: 0.04668  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:32] d2.utils.events INFO:  eta: 2:19:54  iter: 8059  total_loss: 0.2362  loss_cls: 0.02549  loss_box_reg: 0.06578  loss_mask: 0.0853  loss_rpn_cls: 0.001473  loss_rpn_loc: 0.01244  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:34] d2.utils.events INFO:  eta: 2:19:45  iter: 8079  total_loss: 0.284  loss_cls: 0.03947  loss_box_reg: 0.09661  loss_mask: 0.1091  loss_rpn_cls: 0.001057  loss_rpn_loc: 0.01555  time: 0.1011  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:41:36] d2.utils.events INFO:  eta: 2:19:31  iter: 8099  total_loss: 0.4662  loss_cls: 0.07495  loss_box_reg: 0.1932  loss_mask: 0.1567  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.02956  time: 0.1011  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:41:38] d2.utils.events INFO:  eta: 2:19:18  iter: 8119  total_loss: 0.3938  loss_cls: 0.06829  loss_box_reg: 0.1691  loss_mask: 0.12  loss_rpn_cls: 0.004043  loss_rpn_loc: 0.03648  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:40] d2.utils.events INFO:  eta: 2:19:22  iter: 8139  total_loss: 0.4601  loss_cls: 0.08874  loss_box_reg: 0.1741  loss_mask: 0.1552  loss_rpn_cls: 0.003082  loss_rpn_loc: 0.03496  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:43] d2.utils.events INFO:  eta: 2:19:24  iter: 8159  total_loss: 0.5226  loss_cls: 0.07585  loss_box_reg: 0.1962  loss_mask: 0.1751  loss_rpn_cls: 0.003248  loss_rpn_loc: 0.08096  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:45] d2.utils.events INFO:  eta: 2:19:36  iter: 8179  total_loss: 0.3213  loss_cls: 0.04864  loss_box_reg: 0.114  loss_mask: 0.1123  loss_rpn_cls: 0.00178  loss_rpn_loc: 0.03716  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:47] d2.utils.events INFO:  eta: 2:19:23  iter: 8199  total_loss: 0.2423  loss_cls: 0.04653  loss_box_reg: 0.08806  loss_mask: 0.08566  loss_rpn_cls: 0.0009145  loss_rpn_loc: 0.01235  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:49] d2.utils.events INFO:  eta: 2:19:25  iter: 8219  total_loss: 0.3785  loss_cls: 0.06144  loss_box_reg: 0.1615  loss_mask: 0.1159  loss_rpn_cls: 0.0031  loss_rpn_loc: 0.01621  time: 0.1011  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:51] d2.utils.events INFO:  eta: 2:19:23  iter: 8239  total_loss: 0.5182  loss_cls: 0.09791  loss_box_reg: 0.2214  loss_mask: 0.1419  loss_rpn_cls: 0.005465  loss_rpn_loc: 0.02861  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:53] d2.utils.events INFO:  eta: 2:19:21  iter: 8259  total_loss: 0.3338  loss_cls: 0.05635  loss_box_reg: 0.1321  loss_mask: 0.1285  loss_rpn_cls: 0.003725  loss_rpn_loc: 0.02013  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:55] d2.utils.events INFO:  eta: 2:19:12  iter: 8279  total_loss: 0.4251  loss_cls: 0.06952  loss_box_reg: 0.1974  loss_mask: 0.147  loss_rpn_cls: 0.003383  loss_rpn_loc: 0.02732  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:57] d2.utils.events INFO:  eta: 2:19:09  iter: 8299  total_loss: 0.3191  loss_cls: 0.05556  loss_box_reg: 0.1085  loss_mask: 0.1117  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.01679  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:41:59] d2.utils.events INFO:  eta: 2:19:07  iter: 8319  total_loss: 0.3592  loss_cls: 0.06323  loss_box_reg: 0.1587  loss_mask: 0.09933  loss_rpn_cls: 0.001547  loss_rpn_loc: 0.01662  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:01] d2.utils.events INFO:  eta: 2:18:58  iter: 8339  total_loss: 0.4651  loss_cls: 0.07985  loss_box_reg: 0.209  loss_mask: 0.1494  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.02851  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:03] d2.utils.events INFO:  eta: 2:19:01  iter: 8359  total_loss: 0.3483  loss_cls: 0.0603  loss_box_reg: 0.1672  loss_mask: 0.1158  loss_rpn_cls: 0.002201  loss_rpn_loc: 0.03295  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:05] d2.utils.events INFO:  eta: 2:19:01  iter: 8379  total_loss: 0.5157  loss_cls: 0.0774  loss_box_reg: 0.192  loss_mask: 0.1405  loss_rpn_cls: 0.004171  loss_rpn_loc: 0.04506  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:07] d2.utils.events INFO:  eta: 2:18:55  iter: 8399  total_loss: 0.2919  loss_cls: 0.04405  loss_box_reg: 0.1003  loss_mask: 0.09602  loss_rpn_cls: 0.001406  loss_rpn_loc: 0.01728  time: 0.1012  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:42:09] d2.utils.events INFO:  eta: 2:18:48  iter: 8419  total_loss: 0.2967  loss_cls: 0.04794  loss_box_reg: 0.1187  loss_mask: 0.1252  loss_rpn_cls: 0.002521  loss_rpn_loc: 0.02391  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:11] d2.utils.events INFO:  eta: 2:18:48  iter: 8439  total_loss: 0.2847  loss_cls: 0.04955  loss_box_reg: 0.1093  loss_mask: 0.09644  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.02391  time: 0.1012  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:42:13] d2.utils.events INFO:  eta: 2:18:33  iter: 8459  total_loss: 0.3054  loss_cls: 0.05037  loss_box_reg: 0.1369  loss_mask: 0.1015  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.01987  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:15] d2.utils.events INFO:  eta: 2:18:24  iter: 8479  total_loss: 0.3892  loss_cls: 0.04835  loss_box_reg: 0.1404  loss_mask: 0.1357  loss_rpn_cls: 0.002297  loss_rpn_loc: 0.0124  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:17] d2.utils.events INFO:  eta: 2:18:24  iter: 8499  total_loss: 0.4163  loss_cls: 0.05991  loss_box_reg: 0.1877  loss_mask: 0.1126  loss_rpn_cls: 0.002436  loss_rpn_loc: 0.02625  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:20] d2.utils.events INFO:  eta: 2:18:35  iter: 8519  total_loss: 0.4256  loss_cls: 0.07737  loss_box_reg: 0.1964  loss_mask: 0.1745  loss_rpn_cls: 0.007036  loss_rpn_loc: 0.01955  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:22] d2.utils.events INFO:  eta: 2:18:34  iter: 8539  total_loss: 0.4264  loss_cls: 0.08048  loss_box_reg: 0.1751  loss_mask: 0.157  loss_rpn_cls: 0.002688  loss_rpn_loc: 0.03513  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:24] d2.utils.events INFO:  eta: 2:18:48  iter: 8559  total_loss: 0.3402  loss_cls: 0.05735  loss_box_reg: 0.118  loss_mask: 0.1117  loss_rpn_cls: 0.001594  loss_rpn_loc: 0.0163  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:26] d2.utils.events INFO:  eta: 2:18:51  iter: 8579  total_loss: 0.4195  loss_cls: 0.07264  loss_box_reg: 0.1566  loss_mask: 0.1325  loss_rpn_cls: 0.003045  loss_rpn_loc: 0.0391  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:28] d2.utils.events INFO:  eta: 2:18:45  iter: 8599  total_loss: 0.4171  loss_cls: 0.08653  loss_box_reg: 0.1932  loss_mask: 0.1134  loss_rpn_cls: 0.003537  loss_rpn_loc: 0.01983  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:30] d2.utils.events INFO:  eta: 2:18:24  iter: 8619  total_loss: 0.3364  loss_cls: 0.04755  loss_box_reg: 0.09815  loss_mask: 0.1157  loss_rpn_cls: 0.001582  loss_rpn_loc: 0.01135  time: 0.1012  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:42:32] d2.utils.events INFO:  eta: 2:18:32  iter: 8639  total_loss: 0.4078  loss_cls: 0.06444  loss_box_reg: 0.1993  loss_mask: 0.1252  loss_rpn_cls: 0.003428  loss_rpn_loc: 0.0233  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:34] d2.utils.events INFO:  eta: 2:18:26  iter: 8659  total_loss: 0.3739  loss_cls: 0.06196  loss_box_reg: 0.1401  loss_mask: 0.1248  loss_rpn_cls: 0.001046  loss_rpn_loc: 0.01701  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:36] d2.utils.events INFO:  eta: 2:18:37  iter: 8679  total_loss: 0.3579  loss_cls: 0.05887  loss_box_reg: 0.1396  loss_mask: 0.1338  loss_rpn_cls: 0.001694  loss_rpn_loc: 0.03699  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:38] d2.utils.events INFO:  eta: 2:18:36  iter: 8699  total_loss: 0.2862  loss_cls: 0.04201  loss_box_reg: 0.1178  loss_mask: 0.1235  loss_rpn_cls: 0.000705  loss_rpn_loc: 0.01387  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:40] d2.utils.events INFO:  eta: 2:18:49  iter: 8719  total_loss: 0.3801  loss_cls: 0.05574  loss_box_reg: 0.1395  loss_mask: 0.1238  loss_rpn_cls: 0.001865  loss_rpn_loc: 0.0332  time: 0.1012  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:42:42] d2.utils.events INFO:  eta: 2:18:56  iter: 8739  total_loss: 0.5557  loss_cls: 0.09711  loss_box_reg: 0.2385  loss_mask: 0.1829  loss_rpn_cls: 0.006101  loss_rpn_loc: 0.04039  time: 0.1012  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:42:44] d2.utils.events INFO:  eta: 2:18:45  iter: 8759  total_loss: 0.2454  loss_cls: 0.03653  loss_box_reg: 0.09002  loss_mask: 0.1119  loss_rpn_cls: 0.00189  loss_rpn_loc: 0.01125  time: 0.1012  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:42:47] d2.utils.events INFO:  eta: 2:18:58  iter: 8779  total_loss: 0.5321  loss_cls: 0.0832  loss_box_reg: 0.2116  loss_mask: 0.1672  loss_rpn_cls: 0.00424  loss_rpn_loc: 0.03587  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:49] d2.utils.events INFO:  eta: 2:18:50  iter: 8799  total_loss: 0.2292  loss_cls: 0.03849  loss_box_reg: 0.08567  loss_mask: 0.09389  loss_rpn_cls: 0.0005245  loss_rpn_loc: 0.009637  time: 0.1012  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:42:51] d2.utils.events INFO:  eta: 2:18:30  iter: 8819  total_loss: 0.2737  loss_cls: 0.04603  loss_box_reg: 0.1233  loss_mask: 0.07858  loss_rpn_cls: 0.0008981  loss_rpn_loc: 0.01839  time: 0.1012  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:42:53] d2.utils.events INFO:  eta: 2:18:36  iter: 8839  total_loss: 0.3208  loss_cls: 0.05551  loss_box_reg: 0.1309  loss_mask: 0.1366  loss_rpn_cls: 0.004062  loss_rpn_loc: 0.02387  time: 0.1012  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:42:55] d2.utils.events INFO:  eta: 2:18:53  iter: 8859  total_loss: 0.3986  loss_cls: 0.06345  loss_box_reg: 0.149  loss_mask: 0.1153  loss_rpn_cls: 0.003963  loss_rpn_loc: 0.03261  time: 0.1013  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:42:57] d2.utils.events INFO:  eta: 2:18:42  iter: 8879  total_loss: 0.2993  loss_cls: 0.04033  loss_box_reg: 0.1034  loss_mask: 0.1004  loss_rpn_cls: 0.002142  loss_rpn_loc: 0.02399  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:42:59] d2.utils.events INFO:  eta: 2:18:39  iter: 8899  total_loss: 0.3309  loss_cls: 0.05806  loss_box_reg: 0.1488  loss_mask: 0.1083  loss_rpn_cls: 0.001531  loss_rpn_loc: 0.02199  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:43:01] d2.utils.events INFO:  eta: 2:18:37  iter: 8919  total_loss: 0.3613  loss_cls: 0.05729  loss_box_reg: 0.1345  loss_mask: 0.1266  loss_rpn_cls: 0.00156  loss_rpn_loc: 0.02226  time: 0.1012  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:43:03] d2.utils.events INFO:  eta: 2:18:45  iter: 8939  total_loss: 0.4829  loss_cls: 0.07334  loss_box_reg: 0.2045  loss_mask: 0.1482  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.02758  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:43:05] d2.utils.events INFO:  eta: 2:18:40  iter: 8959  total_loss: 0.4797  loss_cls: 0.07222  loss_box_reg: 0.2139  loss_mask: 0.1708  loss_rpn_cls: 0.003719  loss_rpn_loc: 0.03952  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:07] d2.utils.events INFO:  eta: 2:18:31  iter: 8979  total_loss: 0.3287  loss_cls: 0.05204  loss_box_reg: 0.1349  loss_mask: 0.1389  loss_rpn_cls: 0.001864  loss_rpn_loc: 0.02381  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:43:09] d2.utils.events INFO:  eta: 2:18:07  iter: 8999  total_loss: 0.4309  loss_cls: 0.05542  loss_box_reg: 0.1028  loss_mask: 0.1474  loss_rpn_cls: 0.005544  loss_rpn_loc: 0.02841  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:11] d2.utils.events INFO:  eta: 2:18:03  iter: 9019  total_loss: 0.4077  loss_cls: 0.06756  loss_box_reg: 0.1549  loss_mask: 0.1296  loss_rpn_cls: 0.006998  loss_rpn_loc: 0.03027  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:43:13] d2.utils.events INFO:  eta: 2:18:03  iter: 9039  total_loss: 0.509  loss_cls: 0.0699  loss_box_reg: 0.2019  loss_mask: 0.1718  loss_rpn_cls: 0.009546  loss_rpn_loc: 0.0481  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:15] d2.utils.events INFO:  eta: 2:18:19  iter: 9059  total_loss: 0.4021  loss_cls: 0.05699  loss_box_reg: 0.1683  loss_mask: 0.1497  loss_rpn_cls: 0.009045  loss_rpn_loc: 0.0275  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:17] d2.utils.events INFO:  eta: 2:18:14  iter: 9079  total_loss: 0.4035  loss_cls: 0.05771  loss_box_reg: 0.144  loss_mask: 0.1397  loss_rpn_cls: 0.004281  loss_rpn_loc: 0.0391  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:19] d2.utils.events INFO:  eta: 2:18:15  iter: 9099  total_loss: 0.299  loss_cls: 0.03494  loss_box_reg: 0.08828  loss_mask: 0.1199  loss_rpn_cls: 0.003082  loss_rpn_loc: 0.0142  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:21] d2.utils.events INFO:  eta: 2:18:16  iter: 9119  total_loss: 0.2565  loss_cls: 0.04426  loss_box_reg: 0.1125  loss_mask: 0.1137  loss_rpn_cls: 0.001006  loss_rpn_loc: 0.01247  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:23] d2.utils.events INFO:  eta: 2:17:50  iter: 9139  total_loss: 0.3438  loss_cls: 0.04016  loss_box_reg: 0.1441  loss_mask: 0.1388  loss_rpn_cls: 0.004897  loss_rpn_loc: 0.01537  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:25] d2.utils.events INFO:  eta: 2:17:38  iter: 9159  total_loss: 0.3247  loss_cls: 0.05525  loss_box_reg: 0.1164  loss_mask: 0.1364  loss_rpn_cls: 0.00426  loss_rpn_loc: 0.02312  time: 0.1013  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:43:28] d2.utils.events INFO:  eta: 2:17:23  iter: 9179  total_loss: 0.2964  loss_cls: 0.05363  loss_box_reg: 0.1006  loss_mask: 0.134  loss_rpn_cls: 0.00124  loss_rpn_loc: 0.0157  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:30] d2.utils.events INFO:  eta: 2:17:25  iter: 9199  total_loss: 0.2316  loss_cls: 0.03138  loss_box_reg: 0.09142  loss_mask: 0.09063  loss_rpn_cls: 0.001293  loss_rpn_loc: 0.01525  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:32] d2.utils.events INFO:  eta: 2:17:23  iter: 9219  total_loss: 0.4637  loss_cls: 0.05146  loss_box_reg: 0.1767  loss_mask: 0.1291  loss_rpn_cls: 0.003119  loss_rpn_loc: 0.03212  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:43:34] d2.utils.events INFO:  eta: 2:17:34  iter: 9239  total_loss: 0.364  loss_cls: 0.06782  loss_box_reg: 0.1554  loss_mask: 0.1087  loss_rpn_cls: 0.004222  loss_rpn_loc: 0.03355  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:36] d2.utils.events INFO:  eta: 2:17:36  iter: 9259  total_loss: 0.3582  loss_cls: 0.06291  loss_box_reg: 0.1636  loss_mask: 0.1353  loss_rpn_cls: 0.00549  loss_rpn_loc: 0.04591  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:43:38] d2.utils.events INFO:  eta: 2:17:30  iter: 9279  total_loss: 0.4037  loss_cls: 0.05631  loss_box_reg: 0.1527  loss_mask: 0.119  loss_rpn_cls: 0.002802  loss_rpn_loc: 0.02196  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:40] d2.utils.events INFO:  eta: 2:17:32  iter: 9299  total_loss: 0.3618  loss_cls: 0.06188  loss_box_reg: 0.1643  loss_mask: 0.1291  loss_rpn_cls: 0.003706  loss_rpn_loc: 0.03952  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:42] d2.utils.events INFO:  eta: 2:17:26  iter: 9319  total_loss: 0.4259  loss_cls: 0.0649  loss_box_reg: 0.1719  loss_mask: 0.1304  loss_rpn_cls: 0.00408  loss_rpn_loc: 0.0236  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:44] d2.utils.events INFO:  eta: 2:17:29  iter: 9339  total_loss: 0.3316  loss_cls: 0.05823  loss_box_reg: 0.1382  loss_mask: 0.1382  loss_rpn_cls: 0.0008207  loss_rpn_loc: 0.01235  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:46] d2.utils.events INFO:  eta: 2:17:27  iter: 9359  total_loss: 0.2876  loss_cls: 0.04175  loss_box_reg: 0.1293  loss_mask: 0.08683  loss_rpn_cls: 0.002288  loss_rpn_loc: 0.02241  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:48] d2.utils.events INFO:  eta: 2:17:24  iter: 9379  total_loss: 0.346  loss_cls: 0.05592  loss_box_reg: 0.1515  loss_mask: 0.1024  loss_rpn_cls: 0.00173  loss_rpn_loc: 0.01468  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:43:50] d2.utils.events INFO:  eta: 2:17:22  iter: 9399  total_loss: 0.3333  loss_cls: 0.0556  loss_box_reg: 0.1442  loss_mask: 0.1108  loss_rpn_cls: 0.004005  loss_rpn_loc: 0.0209  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:43:52] d2.utils.events INFO:  eta: 2:17:12  iter: 9419  total_loss: 0.3313  loss_cls: 0.0449  loss_box_reg: 0.1421  loss_mask: 0.1072  loss_rpn_cls: 0.003374  loss_rpn_loc: 0.02167  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:43:54] d2.utils.events INFO:  eta: 2:16:55  iter: 9439  total_loss: 0.3097  loss_cls: 0.05293  loss_box_reg: 0.1293  loss_mask: 0.1201  loss_rpn_cls: 0.003969  loss_rpn_loc: 0.04101  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:56] d2.utils.events INFO:  eta: 2:16:55  iter: 9459  total_loss: 0.4352  loss_cls: 0.06797  loss_box_reg: 0.1661  loss_mask: 0.106  loss_rpn_cls: 0.001465  loss_rpn_loc: 0.01699  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:43:58] d2.utils.events INFO:  eta: 2:17:10  iter: 9479  total_loss: 0.39  loss_cls: 0.07525  loss_box_reg: 0.1679  loss_mask: 0.124  loss_rpn_cls: 0.002578  loss_rpn_loc: 0.02406  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:44:00] d2.utils.events INFO:  eta: 2:17:04  iter: 9499  total_loss: 0.3608  loss_cls: 0.04989  loss_box_reg: 0.1361  loss_mask: 0.1369  loss_rpn_cls: 0.001904  loss_rpn_loc: 0.01964  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:02] d2.utils.events INFO:  eta: 2:16:47  iter: 9519  total_loss: 0.2783  loss_cls: 0.03292  loss_box_reg: 0.1135  loss_mask: 0.1186  loss_rpn_cls: 0.003791  loss_rpn_loc: 0.03115  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:04] d2.utils.events INFO:  eta: 2:16:43  iter: 9539  total_loss: 0.4024  loss_cls: 0.0673  loss_box_reg: 0.181  loss_mask: 0.1003  loss_rpn_cls: 0.004065  loss_rpn_loc: 0.01732  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:06] d2.utils.events INFO:  eta: 2:16:41  iter: 9559  total_loss: 0.3241  loss_cls: 0.05208  loss_box_reg: 0.1471  loss_mask: 0.1254  loss_rpn_cls: 0.003844  loss_rpn_loc: 0.02526  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:09] d2.utils.events INFO:  eta: 2:16:43  iter: 9579  total_loss: 0.3059  loss_cls: 0.06921  loss_box_reg: 0.1314  loss_mask: 0.09227  loss_rpn_cls: 0.001576  loss_rpn_loc: 0.02508  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:11] d2.utils.events INFO:  eta: 2:16:54  iter: 9599  total_loss: 0.6399  loss_cls: 0.104  loss_box_reg: 0.2651  loss_mask: 0.1821  loss_rpn_cls: 0.004467  loss_rpn_loc: 0.05777  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:44:13] d2.utils.events INFO:  eta: 2:17:18  iter: 9619  total_loss: 0.4287  loss_cls: 0.06143  loss_box_reg: 0.174  loss_mask: 0.1406  loss_rpn_cls: 0.002182  loss_rpn_loc: 0.03505  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:15] d2.utils.events INFO:  eta: 2:17:04  iter: 9639  total_loss: 0.2793  loss_cls: 0.03517  loss_box_reg: 0.08552  loss_mask: 0.1071  loss_rpn_cls: 0.002853  loss_rpn_loc: 0.01268  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:17] d2.utils.events INFO:  eta: 2:17:07  iter: 9659  total_loss: 0.3002  loss_cls: 0.04945  loss_box_reg: 0.08999  loss_mask: 0.1208  loss_rpn_cls: 0.004967  loss_rpn_loc: 0.03659  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:19] d2.utils.events INFO:  eta: 2:17:05  iter: 9679  total_loss: 0.3602  loss_cls: 0.05698  loss_box_reg: 0.1811  loss_mask: 0.1272  loss_rpn_cls: 0.002575  loss_rpn_loc: 0.02298  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:21] d2.utils.events INFO:  eta: 2:17:00  iter: 9699  total_loss: 0.5501  loss_cls: 0.08486  loss_box_reg: 0.2055  loss_mask: 0.1497  loss_rpn_cls: 0.003907  loss_rpn_loc: 0.04235  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:44:23] d2.utils.events INFO:  eta: 2:17:00  iter: 9719  total_loss: 0.3919  loss_cls: 0.06939  loss_box_reg: 0.1686  loss_mask: 0.1375  loss_rpn_cls: 0.003559  loss_rpn_loc: 0.03254  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:25] d2.utils.events INFO:  eta: 2:16:53  iter: 9739  total_loss: 0.4361  loss_cls: 0.07134  loss_box_reg: 0.1801  loss_mask: 0.1179  loss_rpn_cls: 0.003745  loss_rpn_loc: 0.03141  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:27] d2.utils.events INFO:  eta: 2:17:03  iter: 9759  total_loss: 0.3568  loss_cls: 0.05759  loss_box_reg: 0.1626  loss_mask: 0.1233  loss_rpn_cls: 0.002571  loss_rpn_loc: 0.02876  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:29] d2.utils.events INFO:  eta: 2:16:57  iter: 9779  total_loss: 0.3548  loss_cls: 0.05534  loss_box_reg: 0.159  loss_mask: 0.1216  loss_rpn_cls: 0.002837  loss_rpn_loc: 0.01841  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:31] d2.utils.events INFO:  eta: 2:17:01  iter: 9799  total_loss: 0.2511  loss_cls: 0.04118  loss_box_reg: 0.09244  loss_mask: 0.09597  loss_rpn_cls: 0.001672  loss_rpn_loc: 0.01376  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:33] d2.utils.events INFO:  eta: 2:16:59  iter: 9819  total_loss: 0.3637  loss_cls: 0.04547  loss_box_reg: 0.1174  loss_mask: 0.1088  loss_rpn_cls: 0.001995  loss_rpn_loc: 0.01714  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:44:36] d2.utils.events INFO:  eta: 2:17:02  iter: 9839  total_loss: 0.3759  loss_cls: 0.05671  loss_box_reg: 0.1586  loss_mask: 0.1225  loss_rpn_cls: 0.006497  loss_rpn_loc: 0.02592  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:44:38] d2.utils.events INFO:  eta: 2:16:53  iter: 9859  total_loss: 0.3759  loss_cls: 0.06043  loss_box_reg: 0.1533  loss_mask: 0.1106  loss_rpn_cls: 0.003651  loss_rpn_loc: 0.01633  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:44:40] d2.utils.events INFO:  eta: 2:16:58  iter: 9879  total_loss: 0.3158  loss_cls: 0.05048  loss_box_reg: 0.1328  loss_mask: 0.1026  loss_rpn_cls: 0.002683  loss_rpn_loc: 0.03187  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:42] d2.utils.events INFO:  eta: 2:17:04  iter: 9899  total_loss: 0.3723  loss_cls: 0.05881  loss_box_reg: 0.1649  loss_mask: 0.1327  loss_rpn_cls: 0.004377  loss_rpn_loc: 0.02016  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:44] d2.utils.events INFO:  eta: 2:16:54  iter: 9919  total_loss: 0.2933  loss_cls: 0.04189  loss_box_reg: 0.1075  loss_mask: 0.09767  loss_rpn_cls: 0.001505  loss_rpn_loc: 0.01428  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:44:46] d2.utils.events INFO:  eta: 2:16:45  iter: 9939  total_loss: 0.5523  loss_cls: 0.07886  loss_box_reg: 0.2548  loss_mask: 0.1472  loss_rpn_cls: 0.002532  loss_rpn_loc: 0.03813  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:44:48] d2.utils.events INFO:  eta: 2:16:44  iter: 9959  total_loss: 0.43  loss_cls: 0.07092  loss_box_reg: 0.1964  loss_mask: 0.1203  loss_rpn_cls: 0.002095  loss_rpn_loc: 0.0371  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:44:50] d2.utils.events INFO:  eta: 2:16:33  iter: 9979  total_loss: 0.3118  loss_cls: 0.04377  loss_box_reg: 0.1177  loss_mask: 0.1241  loss_rpn_cls: 0.001051  loss_rpn_loc: 0.01497  time: 0.1014  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:44:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0009999.pth
[10/27 18:44:53] d2.utils.events INFO:  eta: 2:16:39  iter: 9999  total_loss: 0.4418  loss_cls: 0.05914  loss_box_reg: 0.2124  loss_mask: 0.111  loss_rpn_cls: 0.002521  loss_rpn_loc: 0.0299  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:44:54] d2.utils.events INFO:  eta: 2:16:10  iter: 10019  total_loss: 0.2493  loss_cls: 0.03534  loss_box_reg: 0.09241  loss_mask: 0.09257  loss_rpn_cls: 0.0008037  loss_rpn_loc: 0.01747  time: 0.1014  data_time: 0.0021  lr: 0.0025  max_mem: 1630M
[10/27 18:44:56] d2.utils.events INFO:  eta: 2:16:00  iter: 10039  total_loss: 0.3835  loss_cls: 0.06566  loss_box_reg: 0.151  loss_mask: 0.1092  loss_rpn_cls: 0.003371  loss_rpn_loc: 0.02726  time: 0.1014  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:44:58] d2.utils.events INFO:  eta: 2:15:47  iter: 10059  total_loss: 0.3066  loss_cls: 0.04704  loss_box_reg: 0.1181  loss_mask: 0.09975  loss_rpn_cls: 0.001214  loss_rpn_loc: 0.01175  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:45:00] d2.utils.events INFO:  eta: 2:15:41  iter: 10079  total_loss: 0.3466  loss_cls: 0.05291  loss_box_reg: 0.1348  loss_mask: 0.1528  loss_rpn_cls: 0.003139  loss_rpn_loc: 0.01793  time: 0.1014  data_time: 0.0021  lr: 0.0025  max_mem: 1630M
[10/27 18:45:03] d2.utils.events INFO:  eta: 2:16:02  iter: 10099  total_loss: 0.3846  loss_cls: 0.06636  loss_box_reg: 0.1761  loss_mask: 0.1082  loss_rpn_cls: 0.002387  loss_rpn_loc: 0.04091  time: 0.1014  data_time: 0.0021  lr: 0.0025  max_mem: 1630M
[10/27 18:45:05] d2.utils.events INFO:  eta: 2:16:18  iter: 10119  total_loss: 0.504  loss_cls: 0.08385  loss_box_reg: 0.2327  loss_mask: 0.165  loss_rpn_cls: 0.005009  loss_rpn_loc: 0.03206  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:07] d2.utils.events INFO:  eta: 2:16:25  iter: 10139  total_loss: 0.3743  loss_cls: 0.04495  loss_box_reg: 0.1665  loss_mask: 0.1345  loss_rpn_cls: 0.0007718  loss_rpn_loc: 0.01775  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:09] d2.utils.events INFO:  eta: 2:16:21  iter: 10159  total_loss: 0.4062  loss_cls: 0.0638  loss_box_reg: 0.1748  loss_mask: 0.1148  loss_rpn_cls: 0.002447  loss_rpn_loc: 0.02426  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:45:11] d2.utils.events INFO:  eta: 2:16:20  iter: 10179  total_loss: 0.5223  loss_cls: 0.07032  loss_box_reg: 0.2093  loss_mask: 0.1477  loss_rpn_cls: 0.003439  loss_rpn_loc: 0.04788  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:45:13] d2.utils.events INFO:  eta: 2:16:31  iter: 10199  total_loss: 0.2696  loss_cls: 0.0517  loss_box_reg: 0.1135  loss_mask: 0.1091  loss_rpn_cls: 0.001188  loss_rpn_loc: 0.01655  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:15] d2.utils.events INFO:  eta: 2:16:34  iter: 10219  total_loss: 0.349  loss_cls: 0.06117  loss_box_reg: 0.1408  loss_mask: 0.1211  loss_rpn_cls: 0.001598  loss_rpn_loc: 0.02155  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:17] d2.utils.events INFO:  eta: 2:16:14  iter: 10239  total_loss: 0.2545  loss_cls: 0.03242  loss_box_reg: 0.08586  loss_mask: 0.1292  loss_rpn_cls: 0.0008855  loss_rpn_loc: 0.01424  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:45:19] d2.utils.events INFO:  eta: 2:16:08  iter: 10259  total_loss: 0.3059  loss_cls: 0.04707  loss_box_reg: 0.101  loss_mask: 0.1238  loss_rpn_cls: 0.0007078  loss_rpn_loc: 0.02573  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:21] d2.utils.events INFO:  eta: 2:16:17  iter: 10279  total_loss: 0.3674  loss_cls: 0.05968  loss_box_reg: 0.1807  loss_mask: 0.1136  loss_rpn_cls: 0.001289  loss_rpn_loc: 0.01429  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:23] d2.utils.events INFO:  eta: 2:16:17  iter: 10299  total_loss: 0.4612  loss_cls: 0.0977  loss_box_reg: 0.1965  loss_mask: 0.1351  loss_rpn_cls: 0.001886  loss_rpn_loc: 0.02189  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:45:25] d2.utils.events INFO:  eta: 2:16:02  iter: 10319  total_loss: 0.2743  loss_cls: 0.04483  loss_box_reg: 0.1156  loss_mask: 0.1044  loss_rpn_cls: 0.001391  loss_rpn_loc: 0.01327  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:45:27] d2.utils.events INFO:  eta: 2:15:54  iter: 10339  total_loss: 0.4012  loss_cls: 0.05982  loss_box_reg: 0.1843  loss_mask: 0.1213  loss_rpn_cls: 0.003067  loss_rpn_loc: 0.03831  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:45:29] d2.utils.events INFO:  eta: 2:15:53  iter: 10359  total_loss: 0.2943  loss_cls: 0.04593  loss_box_reg: 0.1186  loss_mask: 0.1062  loss_rpn_cls: 0.0008186  loss_rpn_loc: 0.02118  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:31] d2.utils.events INFO:  eta: 2:15:55  iter: 10379  total_loss: 0.4006  loss_cls: 0.07727  loss_box_reg: 0.1849  loss_mask: 0.1145  loss_rpn_cls: 0.003852  loss_rpn_loc: 0.02031  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:33] d2.utils.events INFO:  eta: 2:16:01  iter: 10399  total_loss: 0.2701  loss_cls: 0.04266  loss_box_reg: 0.1065  loss_mask: 0.09769  loss_rpn_cls: 0.0009183  loss_rpn_loc: 0.01205  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:35] d2.utils.events INFO:  eta: 2:15:59  iter: 10419  total_loss: 0.384  loss_cls: 0.06414  loss_box_reg: 0.1734  loss_mask: 0.1252  loss_rpn_cls: 0.004305  loss_rpn_loc: 0.02957  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:37] d2.utils.events INFO:  eta: 2:15:49  iter: 10439  total_loss: 0.2409  loss_cls: 0.03303  loss_box_reg: 0.08174  loss_mask: 0.09273  loss_rpn_cls: 0.002134  loss_rpn_loc: 0.01674  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:45:39] d2.utils.events INFO:  eta: 2:15:50  iter: 10459  total_loss: 0.312  loss_cls: 0.04405  loss_box_reg: 0.1096  loss_mask: 0.1273  loss_rpn_cls: 0.004088  loss_rpn_loc: 0.0163  time: 0.1014  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:45:41] d2.utils.events INFO:  eta: 2:15:38  iter: 10479  total_loss: 0.3119  loss_cls: 0.04975  loss_box_reg: 0.1354  loss_mask: 0.1165  loss_rpn_cls: 0.001771  loss_rpn_loc: 0.02387  time: 0.1014  data_time: 0.0018  lr: 0.0025  max_mem: 1630M
[10/27 18:45:43] d2.utils.events INFO:  eta: 2:15:25  iter: 10499  total_loss: 0.4354  loss_cls: 0.07595  loss_box_reg: 0.1607  loss_mask: 0.1155  loss_rpn_cls: 0.005721  loss_rpn_loc: 0.05261  time: 0.1014  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:45:45] d2.utils.events INFO:  eta: 2:15:35  iter: 10519  total_loss: 0.4728  loss_cls: 0.08232  loss_box_reg: 0.2214  loss_mask: 0.1221  loss_rpn_cls: 0.002094  loss_rpn_loc: 0.03001  time: 0.1014  data_time: 0.0018  lr: 0.0025  max_mem: 1630M
[10/27 18:45:47] d2.utils.events INFO:  eta: 2:15:18  iter: 10539  total_loss: 0.3835  loss_cls: 0.06549  loss_box_reg: 0.1677  loss_mask: 0.1437  loss_rpn_cls: 0.007581  loss_rpn_loc: 0.0525  time: 0.1013  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:45:49] d2.utils.events INFO:  eta: 2:15:02  iter: 10559  total_loss: 0.3917  loss_cls: 0.06683  loss_box_reg: 0.1831  loss_mask: 0.1211  loss_rpn_cls: 0.002376  loss_rpn_loc: 0.02128  time: 0.1013  data_time: 0.0018  lr: 0.0025  max_mem: 1630M
[10/27 18:45:51] d2.utils.events INFO:  eta: 2:14:33  iter: 10579  total_loss: 0.2809  loss_cls: 0.04595  loss_box_reg: 0.109  loss_mask: 0.1125  loss_rpn_cls: 0.001699  loss_rpn_loc: 0.02028  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:45:53] d2.utils.events INFO:  eta: 2:14:18  iter: 10599  total_loss: 0.4653  loss_cls: 0.08826  loss_box_reg: 0.1967  loss_mask: 0.1424  loss_rpn_cls: 0.003488  loss_rpn_loc: 0.03432  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:45:55] d2.utils.events INFO:  eta: 2:14:12  iter: 10619  total_loss: 0.2293  loss_cls: 0.02749  loss_box_reg: 0.09598  loss_mask: 0.1089  loss_rpn_cls: 0.00107  loss_rpn_loc: 0.01741  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:45:57] d2.utils.events INFO:  eta: 2:13:58  iter: 10639  total_loss: 0.3192  loss_cls: 0.05191  loss_box_reg: 0.1181  loss_mask: 0.1156  loss_rpn_cls: 0.001228  loss_rpn_loc: 0.01709  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:45:59] d2.utils.events INFO:  eta: 2:14:08  iter: 10659  total_loss: 0.3248  loss_cls: 0.05768  loss_box_reg: 0.1386  loss_mask: 0.133  loss_rpn_cls: 0.001705  loss_rpn_loc: 0.02467  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:01] d2.utils.events INFO:  eta: 2:14:00  iter: 10679  total_loss: 0.359  loss_cls: 0.06081  loss_box_reg: 0.1486  loss_mask: 0.1181  loss_rpn_cls: 0.004333  loss_rpn_loc: 0.02194  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:03] d2.utils.events INFO:  eta: 2:14:14  iter: 10699  total_loss: 0.3194  loss_cls: 0.05793  loss_box_reg: 0.1358  loss_mask: 0.1006  loss_rpn_cls: 0.002748  loss_rpn_loc: 0.0287  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:05] d2.utils.events INFO:  eta: 2:14:09  iter: 10719  total_loss: 0.3446  loss_cls: 0.06878  loss_box_reg: 0.1735  loss_mask: 0.1052  loss_rpn_cls: 0.00194  loss_rpn_loc: 0.02144  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:08] d2.utils.events INFO:  eta: 2:14:15  iter: 10739  total_loss: 0.4155  loss_cls: 0.08069  loss_box_reg: 0.1931  loss_mask: 0.1301  loss_rpn_cls: 0.003597  loss_rpn_loc: 0.03393  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:10] d2.utils.events INFO:  eta: 2:14:15  iter: 10759  total_loss: 0.3439  loss_cls: 0.05837  loss_box_reg: 0.1596  loss_mask: 0.1272  loss_rpn_cls: 0.002773  loss_rpn_loc: 0.02815  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:12] d2.utils.events INFO:  eta: 2:14:06  iter: 10779  total_loss: 0.2279  loss_cls: 0.03209  loss_box_reg: 0.102  loss_mask: 0.09518  loss_rpn_cls: 0.001066  loss_rpn_loc: 0.01351  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:46:14] d2.utils.events INFO:  eta: 2:13:57  iter: 10799  total_loss: 0.2952  loss_cls: 0.05138  loss_box_reg: 0.1302  loss_mask: 0.1226  loss_rpn_cls: 0.00255  loss_rpn_loc: 0.02498  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:46:16] d2.utils.events INFO:  eta: 2:13:40  iter: 10819  total_loss: 0.2748  loss_cls: 0.04002  loss_box_reg: 0.09848  loss_mask: 0.1253  loss_rpn_cls: 0.00254  loss_rpn_loc: 0.03464  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:18] d2.utils.events INFO:  eta: 2:13:38  iter: 10839  total_loss: 0.5018  loss_cls: 0.07776  loss_box_reg: 0.1935  loss_mask: 0.1513  loss_rpn_cls: 0.004701  loss_rpn_loc: 0.04977  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:46:20] d2.utils.events INFO:  eta: 2:13:32  iter: 10859  total_loss: 0.3633  loss_cls: 0.04562  loss_box_reg: 0.1683  loss_mask: 0.124  loss_rpn_cls: 0.003065  loss_rpn_loc: 0.02575  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:22] d2.utils.events INFO:  eta: 2:13:21  iter: 10879  total_loss: 0.3614  loss_cls: 0.05511  loss_box_reg: 0.1334  loss_mask: 0.108  loss_rpn_cls: 0.00311  loss_rpn_loc: 0.02913  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:24] d2.utils.events INFO:  eta: 2:13:09  iter: 10899  total_loss: 0.2459  loss_cls: 0.04224  loss_box_reg: 0.09692  loss_mask: 0.1031  loss_rpn_cls: 0.002895  loss_rpn_loc: 0.0112  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:46:26] d2.utils.events INFO:  eta: 2:13:11  iter: 10919  total_loss: 0.3153  loss_cls: 0.04414  loss_box_reg: 0.1113  loss_mask: 0.1094  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.01609  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:28] d2.utils.events INFO:  eta: 2:13:11  iter: 10939  total_loss: 0.4372  loss_cls: 0.05743  loss_box_reg: 0.1591  loss_mask: 0.1169  loss_rpn_cls: 0.003404  loss_rpn_loc: 0.0386  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:30] d2.utils.events INFO:  eta: 2:13:01  iter: 10959  total_loss: 0.2761  loss_cls: 0.05171  loss_box_reg: 0.1427  loss_mask: 0.1034  loss_rpn_cls: 0.002605  loss_rpn_loc: 0.01885  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:32] d2.utils.events INFO:  eta: 2:13:03  iter: 10979  total_loss: 0.2842  loss_cls: 0.04323  loss_box_reg: 0.127  loss_mask: 0.1086  loss_rpn_cls: 0.003124  loss_rpn_loc: 0.02217  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:34] d2.utils.events INFO:  eta: 2:13:01  iter: 10999  total_loss: 0.3402  loss_cls: 0.06324  loss_box_reg: 0.1614  loss_mask: 0.1018  loss_rpn_cls: 0.002667  loss_rpn_loc: 0.01598  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:46:36] d2.utils.events INFO:  eta: 2:13:08  iter: 11019  total_loss: 0.3203  loss_cls: 0.05051  loss_box_reg: 0.1163  loss_mask: 0.106  loss_rpn_cls: 0.003155  loss_rpn_loc: 0.0362  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:38] d2.utils.events INFO:  eta: 2:13:07  iter: 11039  total_loss: 0.4056  loss_cls: 0.06354  loss_box_reg: 0.1769  loss_mask: 0.13  loss_rpn_cls: 0.003937  loss_rpn_loc: 0.03299  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:40] d2.utils.events INFO:  eta: 2:12:59  iter: 11059  total_loss: 0.4037  loss_cls: 0.06841  loss_box_reg: 0.161  loss_mask: 0.1524  loss_rpn_cls: 0.001826  loss_rpn_loc: 0.02923  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:42] d2.utils.events INFO:  eta: 2:13:04  iter: 11079  total_loss: 0.3811  loss_cls: 0.06415  loss_box_reg: 0.1863  loss_mask: 0.1484  loss_rpn_cls: 0.003303  loss_rpn_loc: 0.02324  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:44] d2.utils.events INFO:  eta: 2:13:02  iter: 11099  total_loss: 0.2819  loss_cls: 0.05382  loss_box_reg: 0.1536  loss_mask: 0.1406  loss_rpn_cls: 0.00122  loss_rpn_loc: 0.02809  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:46] d2.utils.events INFO:  eta: 2:12:55  iter: 11119  total_loss: 0.3296  loss_cls: 0.05145  loss_box_reg: 0.1347  loss_mask: 0.1118  loss_rpn_cls: 0.001387  loss_rpn_loc: 0.0184  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:46:48] d2.utils.events INFO:  eta: 2:12:56  iter: 11139  total_loss: 0.306  loss_cls: 0.03649  loss_box_reg: 0.1362  loss_mask: 0.09266  loss_rpn_cls: 0.001651  loss_rpn_loc: 0.02421  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:50] d2.utils.events INFO:  eta: 2:12:55  iter: 11159  total_loss: 0.356  loss_cls: 0.05738  loss_box_reg: 0.1663  loss_mask: 0.09676  loss_rpn_cls: 0.002293  loss_rpn_loc: 0.01803  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:46:52] d2.utils.events INFO:  eta: 2:12:56  iter: 11179  total_loss: 0.4136  loss_cls: 0.07198  loss_box_reg: 0.1416  loss_mask: 0.1302  loss_rpn_cls: 0.003997  loss_rpn_loc: 0.02207  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:46:54] d2.utils.events INFO:  eta: 2:12:51  iter: 11199  total_loss: 0.3011  loss_cls: 0.0505  loss_box_reg: 0.1566  loss_mask: 0.09195  loss_rpn_cls: 0.001443  loss_rpn_loc: 0.01418  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:56] d2.utils.events INFO:  eta: 2:12:47  iter: 11219  total_loss: 0.3851  loss_cls: 0.07163  loss_box_reg: 0.1716  loss_mask: 0.1282  loss_rpn_cls: 0.001568  loss_rpn_loc: 0.03235  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:46:58] d2.utils.events INFO:  eta: 2:12:47  iter: 11239  total_loss: 0.3293  loss_cls: 0.0417  loss_box_reg: 0.1534  loss_mask: 0.1322  loss_rpn_cls: 0.002546  loss_rpn_loc: 0.02457  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:47:01] d2.utils.events INFO:  eta: 2:12:49  iter: 11259  total_loss: 0.4286  loss_cls: 0.07442  loss_box_reg: 0.1808  loss_mask: 0.1375  loss_rpn_cls: 0.002995  loss_rpn_loc: 0.031  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:47:03] d2.utils.events INFO:  eta: 2:12:39  iter: 11279  total_loss: 0.2007  loss_cls: 0.02347  loss_box_reg: 0.08868  loss_mask: 0.09127  loss_rpn_cls: 0.0007711  loss_rpn_loc: 0.01094  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:47:05] d2.utils.events INFO:  eta: 2:12:33  iter: 11299  total_loss: 0.2393  loss_cls: 0.03332  loss_box_reg: 0.108  loss_mask: 0.09322  loss_rpn_cls: 0.0007217  loss_rpn_loc: 0.01255  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:47:07] d2.utils.events INFO:  eta: 2:12:37  iter: 11319  total_loss: 0.3121  loss_cls: 0.03989  loss_box_reg: 0.1257  loss_mask: 0.09088  loss_rpn_cls: 0.002799  loss_rpn_loc: 0.02843  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:47:09] d2.utils.events INFO:  eta: 2:12:25  iter: 11339  total_loss: 0.348  loss_cls: 0.04578  loss_box_reg: 0.1474  loss_mask: 0.1342  loss_rpn_cls: 0.002805  loss_rpn_loc: 0.03296  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:11] d2.utils.events INFO:  eta: 2:12:08  iter: 11359  total_loss: 0.3767  loss_cls: 0.06499  loss_box_reg: 0.1696  loss_mask: 0.1281  loss_rpn_cls: 0.001283  loss_rpn_loc: 0.05886  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:13] d2.utils.events INFO:  eta: 2:12:14  iter: 11379  total_loss: 0.2908  loss_cls: 0.04313  loss_box_reg: 0.1  loss_mask: 0.1023  loss_rpn_cls: 0.0007183  loss_rpn_loc: 0.02386  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:15] d2.utils.events INFO:  eta: 2:11:55  iter: 11399  total_loss: 0.36  loss_cls: 0.0571  loss_box_reg: 0.118  loss_mask: 0.1099  loss_rpn_cls: 0.001251  loss_rpn_loc: 0.02221  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:47:17] d2.utils.events INFO:  eta: 2:11:58  iter: 11419  total_loss: 0.3144  loss_cls: 0.05575  loss_box_reg: 0.1362  loss_mask: 0.1125  loss_rpn_cls: 0.002763  loss_rpn_loc: 0.02457  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:19] d2.utils.events INFO:  eta: 2:12:19  iter: 11439  total_loss: 0.3799  loss_cls: 0.0581  loss_box_reg: 0.1537  loss_mask: 0.1019  loss_rpn_cls: 0.003284  loss_rpn_loc: 0.0304  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:21] d2.utils.events INFO:  eta: 2:12:26  iter: 11459  total_loss: 0.308  loss_cls: 0.05421  loss_box_reg: 0.14  loss_mask: 0.09475  loss_rpn_cls: 0.002138  loss_rpn_loc: 0.02002  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:47:23] d2.utils.events INFO:  eta: 2:12:27  iter: 11479  total_loss: 0.4651  loss_cls: 0.08195  loss_box_reg: 0.2089  loss_mask: 0.1415  loss_rpn_cls: 0.004457  loss_rpn_loc: 0.03041  time: 0.1013  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:47:25] d2.utils.events INFO:  eta: 2:12:25  iter: 11499  total_loss: 0.3087  loss_cls: 0.04501  loss_box_reg: 0.1434  loss_mask: 0.1015  loss_rpn_cls: 0.0008622  loss_rpn_loc: 0.02166  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:47:27] d2.utils.events INFO:  eta: 2:12:22  iter: 11519  total_loss: 0.3031  loss_cls: 0.04176  loss_box_reg: 0.1274  loss_mask: 0.1061  loss_rpn_cls: 0.001172  loss_rpn_loc: 0.02353  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:29] d2.utils.events INFO:  eta: 2:12:21  iter: 11539  total_loss: 0.3045  loss_cls: 0.0656  loss_box_reg: 0.1254  loss_mask: 0.1013  loss_rpn_cls: 0.004607  loss_rpn_loc: 0.02654  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:47:31] d2.utils.events INFO:  eta: 2:12:43  iter: 11559  total_loss: 0.3069  loss_cls: 0.05507  loss_box_reg: 0.1318  loss_mask: 0.1233  loss_rpn_cls: 0.002605  loss_rpn_loc: 0.01844  time: 0.1013  data_time: 0.0021  lr: 0.0025  max_mem: 1630M
[10/27 18:47:33] d2.utils.events INFO:  eta: 2:12:42  iter: 11579  total_loss: 0.3609  loss_cls: 0.05814  loss_box_reg: 0.1688  loss_mask: 0.1278  loss_rpn_cls: 0.001963  loss_rpn_loc: 0.02987  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:47:35] d2.utils.events INFO:  eta: 2:12:43  iter: 11599  total_loss: 0.3236  loss_cls: 0.05158  loss_box_reg: 0.1488  loss_mask: 0.1006  loss_rpn_cls: 0.002244  loss_rpn_loc: 0.02603  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:37] d2.utils.events INFO:  eta: 2:12:41  iter: 11619  total_loss: 0.3611  loss_cls: 0.05142  loss_box_reg: 0.1709  loss_mask: 0.1013  loss_rpn_cls: 0.002126  loss_rpn_loc: 0.02427  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:39] d2.utils.events INFO:  eta: 2:12:52  iter: 11639  total_loss: 0.3657  loss_cls: 0.0567  loss_box_reg: 0.1651  loss_mask: 0.1398  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.02945  time: 0.1013  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:47:41] d2.utils.events INFO:  eta: 2:12:50  iter: 11659  total_loss: 0.3141  loss_cls: 0.04706  loss_box_reg: 0.1207  loss_mask: 0.1065  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.01385  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:43] d2.utils.events INFO:  eta: 2:12:35  iter: 11679  total_loss: 0.3346  loss_cls: 0.05323  loss_box_reg: 0.1164  loss_mask: 0.09867  loss_rpn_cls: 0.002185  loss_rpn_loc: 0.01791  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:45] d2.utils.events INFO:  eta: 2:12:30  iter: 11699  total_loss: 0.4122  loss_cls: 0.07504  loss_box_reg: 0.176  loss_mask: 0.1322  loss_rpn_cls: 0.001837  loss_rpn_loc: 0.0241  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:47] d2.utils.events INFO:  eta: 2:12:27  iter: 11719  total_loss: 0.4654  loss_cls: 0.06188  loss_box_reg: 0.1564  loss_mask: 0.1387  loss_rpn_cls: 0.004535  loss_rpn_loc: 0.02951  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:49] d2.utils.events INFO:  eta: 2:12:03  iter: 11739  total_loss: 0.3373  loss_cls: 0.05279  loss_box_reg: 0.1406  loss_mask: 0.1236  loss_rpn_cls: 0.002562  loss_rpn_loc: 0.0207  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:51] d2.utils.events INFO:  eta: 2:11:59  iter: 11759  total_loss: 0.3375  loss_cls: 0.06354  loss_box_reg: 0.1352  loss_mask: 0.1171  loss_rpn_cls: 0.003131  loss_rpn_loc: 0.02221  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:53] d2.utils.events INFO:  eta: 2:11:56  iter: 11779  total_loss: 0.3952  loss_cls: 0.07056  loss_box_reg: 0.1668  loss_mask: 0.1283  loss_rpn_cls: 0.002778  loss_rpn_loc: 0.0193  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:47:55] d2.utils.events INFO:  eta: 2:11:54  iter: 11799  total_loss: 0.2757  loss_cls: 0.04744  loss_box_reg: 0.1269  loss_mask: 0.1252  loss_rpn_cls: 0.00188  loss_rpn_loc: 0.01789  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:47:58] d2.utils.events INFO:  eta: 2:12:03  iter: 11819  total_loss: 0.4095  loss_cls: 0.0642  loss_box_reg: 0.1809  loss_mask: 0.1281  loss_rpn_cls: 0.002815  loss_rpn_loc: 0.02599  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:00] d2.utils.events INFO:  eta: 2:11:51  iter: 11839  total_loss: 0.2589  loss_cls: 0.03216  loss_box_reg: 0.1046  loss_mask: 0.09459  loss_rpn_cls: 0.001611  loss_rpn_loc: 0.01982  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:02] d2.utils.events INFO:  eta: 2:11:51  iter: 11859  total_loss: 0.3713  loss_cls: 0.03973  loss_box_reg: 0.1325  loss_mask: 0.09928  loss_rpn_cls: 0.002945  loss_rpn_loc: 0.04363  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:04] d2.utils.events INFO:  eta: 2:11:57  iter: 11879  total_loss: 0.484  loss_cls: 0.08561  loss_box_reg: 0.2172  loss_mask: 0.1494  loss_rpn_cls: 0.002926  loss_rpn_loc: 0.02301  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:06] d2.utils.events INFO:  eta: 2:11:55  iter: 11899  total_loss: 0.2415  loss_cls: 0.05135  loss_box_reg: 0.09835  loss_mask: 0.08656  loss_rpn_cls: 0.0009556  loss_rpn_loc: 0.01462  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:08] d2.utils.events INFO:  eta: 2:11:53  iter: 11919  total_loss: 0.2212  loss_cls: 0.0387  loss_box_reg: 0.09525  loss_mask: 0.096  loss_rpn_cls: 0.001272  loss_rpn_loc: 0.009972  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:10] d2.utils.events INFO:  eta: 2:11:47  iter: 11939  total_loss: 0.338  loss_cls: 0.05224  loss_box_reg: 0.1519  loss_mask: 0.1093  loss_rpn_cls: 0.002745  loss_rpn_loc: 0.03491  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:12] d2.utils.events INFO:  eta: 2:11:49  iter: 11959  total_loss: 0.3591  loss_cls: 0.05689  loss_box_reg: 0.1572  loss_mask: 0.1152  loss_rpn_cls: 0.003679  loss_rpn_loc: 0.02103  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:48:14] d2.utils.events INFO:  eta: 2:11:55  iter: 11979  total_loss: 0.255  loss_cls: 0.04231  loss_box_reg: 0.114  loss_mask: 0.09908  loss_rpn_cls: 0.0008224  loss_rpn_loc: 0.008911  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:16] d2.utils.events INFO:  eta: 2:11:53  iter: 11999  total_loss: 0.3308  loss_cls: 0.0558  loss_box_reg: 0.1431  loss_mask: 0.1002  loss_rpn_cls: 0.003075  loss_rpn_loc: 0.03293  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:18] d2.utils.events INFO:  eta: 2:12:01  iter: 12019  total_loss: 0.3523  loss_cls: 0.04594  loss_box_reg: 0.1549  loss_mask: 0.1163  loss_rpn_cls: 0.001537  loss_rpn_loc: 0.02273  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:48:20] d2.utils.events INFO:  eta: 2:11:55  iter: 12039  total_loss: 0.3653  loss_cls: 0.05011  loss_box_reg: 0.1635  loss_mask: 0.1142  loss_rpn_cls: 0.0027  loss_rpn_loc: 0.02518  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:22] d2.utils.events INFO:  eta: 2:11:59  iter: 12059  total_loss: 0.2111  loss_cls: 0.03275  loss_box_reg: 0.1059  loss_mask: 0.08307  loss_rpn_cls: 0.0009204  loss_rpn_loc: 0.01613  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:24] d2.utils.events INFO:  eta: 2:11:40  iter: 12079  total_loss: 0.2435  loss_cls: 0.03476  loss_box_reg: 0.101  loss_mask: 0.1025  loss_rpn_cls: 0.001086  loss_rpn_loc: 0.01084  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:26] d2.utils.events INFO:  eta: 2:11:32  iter: 12099  total_loss: 0.3162  loss_cls: 0.04237  loss_box_reg: 0.1156  loss_mask: 0.1044  loss_rpn_cls: 0.002834  loss_rpn_loc: 0.02171  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:28] d2.utils.events INFO:  eta: 2:11:31  iter: 12119  total_loss: 0.4201  loss_cls: 0.06912  loss_box_reg: 0.2007  loss_mask: 0.1027  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.03323  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:30] d2.utils.events INFO:  eta: 2:11:20  iter: 12139  total_loss: 0.2721  loss_cls: 0.03733  loss_box_reg: 0.1077  loss_mask: 0.1032  loss_rpn_cls: 0.0008654  loss_rpn_loc: 0.009304  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:32] d2.utils.events INFO:  eta: 2:11:19  iter: 12159  total_loss: 0.3636  loss_cls: 0.0587  loss_box_reg: 0.1516  loss_mask: 0.12  loss_rpn_cls: 0.001744  loss_rpn_loc: 0.03157  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:34] d2.utils.events INFO:  eta: 2:11:17  iter: 12179  total_loss: 0.3176  loss_cls: 0.05331  loss_box_reg: 0.1813  loss_mask: 0.1127  loss_rpn_cls: 0.003569  loss_rpn_loc: 0.0333  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:48:36] d2.utils.events INFO:  eta: 2:11:17  iter: 12199  total_loss: 0.4567  loss_cls: 0.07234  loss_box_reg: 0.1894  loss_mask: 0.1454  loss_rpn_cls: 0.006393  loss_rpn_loc: 0.04315  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:48:38] d2.utils.events INFO:  eta: 2:11:13  iter: 12219  total_loss: 0.3243  loss_cls: 0.05144  loss_box_reg: 0.1449  loss_mask: 0.09799  loss_rpn_cls: 0.001747  loss_rpn_loc: 0.02144  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:40] d2.utils.events INFO:  eta: 2:11:20  iter: 12239  total_loss: 0.3797  loss_cls: 0.06736  loss_box_reg: 0.1407  loss_mask: 0.1231  loss_rpn_cls: 0.003895  loss_rpn_loc: 0.0249  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:42] d2.utils.events INFO:  eta: 2:11:05  iter: 12259  total_loss: 0.3215  loss_cls: 0.04857  loss_box_reg: 0.1426  loss_mask: 0.1138  loss_rpn_cls: 0.001887  loss_rpn_loc: 0.01792  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:44] d2.utils.events INFO:  eta: 2:11:11  iter: 12279  total_loss: 0.264  loss_cls: 0.03443  loss_box_reg: 0.1126  loss_mask: 0.1015  loss_rpn_cls: 0.000899  loss_rpn_loc: 0.01698  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:46] d2.utils.events INFO:  eta: 2:11:14  iter: 12299  total_loss: 0.3206  loss_cls: 0.05041  loss_box_reg: 0.1457  loss_mask: 0.09857  loss_rpn_cls: 0.00179  loss_rpn_loc: 0.01395  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:49] d2.utils.events INFO:  eta: 2:11:15  iter: 12319  total_loss: 0.3539  loss_cls: 0.06399  loss_box_reg: 0.141  loss_mask: 0.1427  loss_rpn_cls: 0.0027  loss_rpn_loc: 0.0269  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:51] d2.utils.events INFO:  eta: 2:11:14  iter: 12339  total_loss: 0.3768  loss_cls: 0.05452  loss_box_reg: 0.1473  loss_mask: 0.1208  loss_rpn_cls: 0.001806  loss_rpn_loc: 0.02428  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:53] d2.utils.events INFO:  eta: 2:11:12  iter: 12359  total_loss: 0.3067  loss_cls: 0.0477  loss_box_reg: 0.1404  loss_mask: 0.09575  loss_rpn_cls: 0.001015  loss_rpn_loc: 0.01465  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:48:55] d2.utils.events INFO:  eta: 2:11:08  iter: 12379  total_loss: 0.3496  loss_cls: 0.04987  loss_box_reg: 0.1437  loss_mask: 0.1234  loss_rpn_cls: 0.001983  loss_rpn_loc: 0.02238  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:48:57] d2.utils.events INFO:  eta: 2:11:12  iter: 12399  total_loss: 0.312  loss_cls: 0.05763  loss_box_reg: 0.1494  loss_mask: 0.0936  loss_rpn_cls: 0.001721  loss_rpn_loc: 0.01965  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:48:59] d2.utils.events INFO:  eta: 2:11:07  iter: 12419  total_loss: 0.2945  loss_cls: 0.0471  loss_box_reg: 0.139  loss_mask: 0.1386  loss_rpn_cls: 0.001029  loss_rpn_loc: 0.02973  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:49:01] d2.utils.events INFO:  eta: 2:11:04  iter: 12439  total_loss: 0.311  loss_cls: 0.04246  loss_box_reg: 0.1455  loss_mask: 0.08906  loss_rpn_cls: 0.002429  loss_rpn_loc: 0.03385  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:49:03] d2.utils.events INFO:  eta: 2:10:59  iter: 12459  total_loss: 0.386  loss_cls: 0.05992  loss_box_reg: 0.1369  loss_mask: 0.1292  loss_rpn_cls: 0.001252  loss_rpn_loc: 0.01638  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:49:05] d2.utils.events INFO:  eta: 2:10:59  iter: 12479  total_loss: 0.4884  loss_cls: 0.07704  loss_box_reg: 0.1945  loss_mask: 0.1737  loss_rpn_cls: 0.003955  loss_rpn_loc: 0.04348  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:49:07] d2.utils.events INFO:  eta: 2:11:06  iter: 12499  total_loss: 0.3292  loss_cls: 0.05099  loss_box_reg: 0.1472  loss_mask: 0.1086  loss_rpn_cls: 0.002359  loss_rpn_loc: 0.01823  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:09] d2.utils.events INFO:  eta: 2:11:08  iter: 12519  total_loss: 0.4144  loss_cls: 0.05774  loss_box_reg: 0.1661  loss_mask: 0.1127  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.03161  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:11] d2.utils.events INFO:  eta: 2:11:06  iter: 12539  total_loss: 0.3784  loss_cls: 0.06293  loss_box_reg: 0.1725  loss_mask: 0.1229  loss_rpn_cls: 0.002581  loss_rpn_loc: 0.02397  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:13] d2.utils.events INFO:  eta: 2:10:56  iter: 12559  total_loss: 0.3154  loss_cls: 0.06018  loss_box_reg: 0.1585  loss_mask: 0.1074  loss_rpn_cls: 0.004672  loss_rpn_loc: 0.03334  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:49:15] d2.utils.events INFO:  eta: 2:11:02  iter: 12579  total_loss: 0.4783  loss_cls: 0.08531  loss_box_reg: 0.1789  loss_mask: 0.1237  loss_rpn_cls: 0.005722  loss_rpn_loc: 0.04372  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:17] d2.utils.events INFO:  eta: 2:10:49  iter: 12599  total_loss: 0.2617  loss_cls: 0.04339  loss_box_reg: 0.08979  loss_mask: 0.1011  loss_rpn_cls: 0.0007596  loss_rpn_loc: 0.01886  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:49:19] d2.utils.events INFO:  eta: 2:10:47  iter: 12619  total_loss: 0.2895  loss_cls: 0.05412  loss_box_reg: 0.1167  loss_mask: 0.1091  loss_rpn_cls: 0.00229  loss_rpn_loc: 0.01889  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:21] d2.utils.events INFO:  eta: 2:10:42  iter: 12639  total_loss: 0.2379  loss_cls: 0.04098  loss_box_reg: 0.08753  loss_mask: 0.08114  loss_rpn_cls: 0.00083  loss_rpn_loc: 0.01344  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:49:23] d2.utils.events INFO:  eta: 2:10:40  iter: 12659  total_loss: 0.3659  loss_cls: 0.06145  loss_box_reg: 0.1626  loss_mask: 0.1199  loss_rpn_cls: 0.001957  loss_rpn_loc: 0.02516  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:25] d2.utils.events INFO:  eta: 2:10:39  iter: 12679  total_loss: 0.338  loss_cls: 0.04967  loss_box_reg: 0.1522  loss_mask: 0.1205  loss_rpn_cls: 0.00262  loss_rpn_loc: 0.02279  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:49:27] d2.utils.events INFO:  eta: 2:10:36  iter: 12699  total_loss: 0.4691  loss_cls: 0.09283  loss_box_reg: 0.1728  loss_mask: 0.1527  loss_rpn_cls: 0.02939  loss_rpn_loc: 0.0271  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:29] d2.utils.events INFO:  eta: 2:10:27  iter: 12719  total_loss: 0.4222  loss_cls: 0.06276  loss_box_reg: 0.06689  loss_mask: 0.1818  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.01333  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:49:31] d2.utils.events INFO:  eta: 2:10:31  iter: 12739  total_loss: 0.3191  loss_cls: 0.05798  loss_box_reg: 0.124  loss_mask: 0.1182  loss_rpn_cls: 0.004666  loss_rpn_loc: 0.02902  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:33] d2.utils.events INFO:  eta: 2:10:20  iter: 12759  total_loss: 0.3189  loss_cls: 0.05158  loss_box_reg: 0.1355  loss_mask: 0.1203  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.01759  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:35] d2.utils.events INFO:  eta: 2:10:21  iter: 12779  total_loss: 0.283  loss_cls: 0.05299  loss_box_reg: 0.1159  loss_mask: 0.1084  loss_rpn_cls: 0.003275  loss_rpn_loc: 0.01499  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:49:37] d2.utils.events INFO:  eta: 2:10:25  iter: 12799  total_loss: 0.3926  loss_cls: 0.05779  loss_box_reg: 0.1546  loss_mask: 0.1115  loss_rpn_cls: 0.006584  loss_rpn_loc: 0.01655  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:49:39] d2.utils.events INFO:  eta: 2:10:15  iter: 12819  total_loss: 0.4059  loss_cls: 0.06706  loss_box_reg: 0.1798  loss_mask: 0.1149  loss_rpn_cls: 0.003062  loss_rpn_loc: 0.02403  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:49:41] d2.utils.events INFO:  eta: 2:10:21  iter: 12839  total_loss: 0.4769  loss_cls: 0.08433  loss_box_reg: 0.2115  loss_mask: 0.1343  loss_rpn_cls: 0.006875  loss_rpn_loc: 0.04397  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:43] d2.utils.events INFO:  eta: 2:10:21  iter: 12859  total_loss: 0.3107  loss_cls: 0.05604  loss_box_reg: 0.1316  loss_mask: 0.1101  loss_rpn_cls: 0.003825  loss_rpn_loc: 0.02529  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:45] d2.utils.events INFO:  eta: 2:10:18  iter: 12879  total_loss: 0.4811  loss_cls: 0.06652  loss_box_reg: 0.1398  loss_mask: 0.1553  loss_rpn_cls: 0.005594  loss_rpn_loc: 0.04535  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:47] d2.utils.events INFO:  eta: 2:10:16  iter: 12899  total_loss: 0.2951  loss_cls: 0.0509  loss_box_reg: 0.1266  loss_mask: 0.1057  loss_rpn_cls: 0.003339  loss_rpn_loc: 0.01632  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:49:49] d2.utils.events INFO:  eta: 2:10:17  iter: 12919  total_loss: 0.3762  loss_cls: 0.0766  loss_box_reg: 0.1441  loss_mask: 0.1213  loss_rpn_cls: 0.004998  loss_rpn_loc: 0.02529  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:49:51] d2.utils.events INFO:  eta: 2:10:13  iter: 12939  total_loss: 0.1828  loss_cls: 0.03081  loss_box_reg: 0.06966  loss_mask: 0.07897  loss_rpn_cls: 0.001094  loss_rpn_loc: 0.008464  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:53] d2.utils.events INFO:  eta: 2:10:11  iter: 12959  total_loss: 0.4504  loss_cls: 0.06171  loss_box_reg: 0.1605  loss_mask: 0.1367  loss_rpn_cls: 0.007983  loss_rpn_loc: 0.03309  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:49:55] d2.utils.events INFO:  eta: 2:09:58  iter: 12979  total_loss: 0.5221  loss_cls: 0.08852  loss_box_reg: 0.2404  loss_mask: 0.1549  loss_rpn_cls: 0.007852  loss_rpn_loc: 0.05028  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:49:57] d2.utils.events INFO:  eta: 2:09:56  iter: 12999  total_loss: 0.2941  loss_cls: 0.03181  loss_box_reg: 0.09928  loss_mask: 0.1104  loss_rpn_cls: 0.003613  loss_rpn_loc: 0.01651  time: 0.1013  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:49:59] d2.utils.events INFO:  eta: 2:09:46  iter: 13019  total_loss: 0.3051  loss_cls: 0.04324  loss_box_reg: 0.1324  loss_mask: 0.09944  loss_rpn_cls: 0.001184  loss_rpn_loc: 0.01732  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:01] d2.utils.events INFO:  eta: 2:09:44  iter: 13039  total_loss: 0.3577  loss_cls: 0.04966  loss_box_reg: 0.1664  loss_mask: 0.134  loss_rpn_cls: 0.0047  loss_rpn_loc: 0.0171  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:03] d2.utils.events INFO:  eta: 2:09:38  iter: 13059  total_loss: 0.2325  loss_cls: 0.03571  loss_box_reg: 0.0847  loss_mask: 0.08525  loss_rpn_cls: 0.001835  loss_rpn_loc: 0.01643  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:50:05] d2.utils.events INFO:  eta: 2:09:49  iter: 13079  total_loss: 0.2876  loss_cls: 0.0476  loss_box_reg: 0.1122  loss_mask: 0.1167  loss_rpn_cls: 0.001536  loss_rpn_loc: 0.01846  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:08] d2.utils.events INFO:  eta: 2:09:51  iter: 13099  total_loss: 0.3277  loss_cls: 0.04655  loss_box_reg: 0.1128  loss_mask: 0.1136  loss_rpn_cls: 0.002951  loss_rpn_loc: 0.01883  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:09] d2.utils.events INFO:  eta: 2:09:41  iter: 13119  total_loss: 0.3078  loss_cls: 0.04327  loss_box_reg: 0.1332  loss_mask: 0.095  loss_rpn_cls: 0.002794  loss_rpn_loc: 0.01764  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:11] d2.utils.events INFO:  eta: 2:09:47  iter: 13139  total_loss: 0.2425  loss_cls: 0.04398  loss_box_reg: 0.1027  loss_mask: 0.09244  loss_rpn_cls: 0.0017  loss_rpn_loc: 0.01929  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:13] d2.utils.events INFO:  eta: 2:09:40  iter: 13159  total_loss: 0.3058  loss_cls: 0.04852  loss_box_reg: 0.1208  loss_mask: 0.1273  loss_rpn_cls: 0.002177  loss_rpn_loc: 0.02496  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:15] d2.utils.events INFO:  eta: 2:09:25  iter: 13179  total_loss: 0.2458  loss_cls: 0.037  loss_box_reg: 0.1034  loss_mask: 0.08381  loss_rpn_cls: 0.002372  loss_rpn_loc: 0.02048  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:18] d2.utils.events INFO:  eta: 2:09:11  iter: 13199  total_loss: 0.3732  loss_cls: 0.05841  loss_box_reg: 0.1536  loss_mask: 0.1121  loss_rpn_cls: 0.003483  loss_rpn_loc: 0.03152  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:20] d2.utils.events INFO:  eta: 2:09:20  iter: 13219  total_loss: 0.4206  loss_cls: 0.06418  loss_box_reg: 0.1722  loss_mask: 0.1271  loss_rpn_cls: 0.006608  loss_rpn_loc: 0.0374  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:21] d2.utils.events INFO:  eta: 2:08:48  iter: 13239  total_loss: 0.2468  loss_cls: 0.03423  loss_box_reg: 0.07174  loss_mask: 0.09397  loss_rpn_cls: 0.00188  loss_rpn_loc: 0.02331  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:24] d2.utils.events INFO:  eta: 2:08:48  iter: 13259  total_loss: 0.4155  loss_cls: 0.07678  loss_box_reg: 0.1718  loss_mask: 0.1514  loss_rpn_cls: 0.00406  loss_rpn_loc: 0.04218  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:26] d2.utils.events INFO:  eta: 2:08:40  iter: 13279  total_loss: 0.255  loss_cls: 0.03758  loss_box_reg: 0.1051  loss_mask: 0.0884  loss_rpn_cls: 0.0011  loss_rpn_loc: 0.01654  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:28] d2.utils.events INFO:  eta: 2:08:43  iter: 13299  total_loss: 0.3738  loss_cls: 0.06492  loss_box_reg: 0.1629  loss_mask: 0.126  loss_rpn_cls: 0.001921  loss_rpn_loc: 0.02115  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:30] d2.utils.events INFO:  eta: 2:08:41  iter: 13319  total_loss: 0.3711  loss_cls: 0.07529  loss_box_reg: 0.1478  loss_mask: 0.1395  loss_rpn_cls: 0.003118  loss_rpn_loc: 0.04492  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:50:32] d2.utils.events INFO:  eta: 2:08:44  iter: 13339  total_loss: 0.2647  loss_cls: 0.03996  loss_box_reg: 0.1306  loss_mask: 0.08704  loss_rpn_cls: 0.001491  loss_rpn_loc: 0.03005  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:34] d2.utils.events INFO:  eta: 2:08:42  iter: 13359  total_loss: 0.2044  loss_cls: 0.02489  loss_box_reg: 0.0646  loss_mask: 0.09189  loss_rpn_cls: 0.001309  loss_rpn_loc: 0.00901  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:36] d2.utils.events INFO:  eta: 2:08:53  iter: 13379  total_loss: 0.3942  loss_cls: 0.04778  loss_box_reg: 0.1742  loss_mask: 0.118  loss_rpn_cls: 0.004186  loss_rpn_loc: 0.04268  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:50:38] d2.utils.events INFO:  eta: 2:09:03  iter: 13399  total_loss: 0.3423  loss_cls: 0.05492  loss_box_reg: 0.1683  loss_mask: 0.08971  loss_rpn_cls: 0.001787  loss_rpn_loc: 0.02288  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:40] d2.utils.events INFO:  eta: 2:09:00  iter: 13419  total_loss: 0.2718  loss_cls: 0.04606  loss_box_reg: 0.09801  loss_mask: 0.1262  loss_rpn_cls: 0.003073  loss_rpn_loc: 0.02733  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:42] d2.utils.events INFO:  eta: 2:08:52  iter: 13439  total_loss: 0.2813  loss_cls: 0.03872  loss_box_reg: 0.09357  loss_mask: 0.08844  loss_rpn_cls: 0.00259  loss_rpn_loc: 0.02967  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:50:44] d2.utils.events INFO:  eta: 2:08:44  iter: 13459  total_loss: 0.2746  loss_cls: 0.03678  loss_box_reg: 0.1102  loss_mask: 0.09658  loss_rpn_cls: 0.001319  loss_rpn_loc: 0.01693  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:46] d2.utils.events INFO:  eta: 2:08:40  iter: 13479  total_loss: 0.5555  loss_cls: 0.09074  loss_box_reg: 0.201  loss_mask: 0.158  loss_rpn_cls: 0.002958  loss_rpn_loc: 0.04283  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:50:48] d2.utils.events INFO:  eta: 2:08:28  iter: 13499  total_loss: 0.3067  loss_cls: 0.04582  loss_box_reg: 0.1207  loss_mask: 0.1087  loss_rpn_cls: 0.002143  loss_rpn_loc: 0.02397  time: 0.1013  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:50:50] d2.utils.events INFO:  eta: 2:08:39  iter: 13519  total_loss: 0.3494  loss_cls: 0.0518  loss_box_reg: 0.1522  loss_mask: 0.1075  loss_rpn_cls: 0.003003  loss_rpn_loc: 0.01657  time: 0.1013  data_time: 0.0030  lr: 0.0025  max_mem: 1630M
[10/27 18:50:52] d2.utils.events INFO:  eta: 2:08:36  iter: 13539  total_loss: 0.2765  loss_cls: 0.03473  loss_box_reg: 0.1018  loss_mask: 0.1135  loss_rpn_cls: 0.002052  loss_rpn_loc: 0.01554  time: 0.1013  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:50:54] d2.utils.events INFO:  eta: 2:08:34  iter: 13559  total_loss: 0.2618  loss_cls: 0.04307  loss_box_reg: 0.104  loss_mask: 0.09127  loss_rpn_cls: 0.001012  loss_rpn_loc: 0.01657  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:56] d2.utils.events INFO:  eta: 2:08:25  iter: 13579  total_loss: 0.2479  loss_cls: 0.03638  loss_box_reg: 0.09912  loss_mask: 0.0725  loss_rpn_cls: 0.002353  loss_rpn_loc: 0.02605  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:50:58] d2.utils.events INFO:  eta: 2:08:29  iter: 13599  total_loss: 0.2824  loss_cls: 0.04729  loss_box_reg: 0.1109  loss_mask: 0.1092  loss_rpn_cls: 0.002971  loss_rpn_loc: 0.01762  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:00] d2.utils.events INFO:  eta: 2:08:25  iter: 13619  total_loss: 0.3339  loss_cls: 0.03928  loss_box_reg: 0.1561  loss_mask: 0.1019  loss_rpn_cls: 0.002763  loss_rpn_loc: 0.03732  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:02] d2.utils.events INFO:  eta: 2:08:39  iter: 13639  total_loss: 0.3773  loss_cls: 0.04796  loss_box_reg: 0.154  loss_mask: 0.1219  loss_rpn_cls: 0.002212  loss_rpn_loc: 0.01751  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:04] d2.utils.events INFO:  eta: 2:08:24  iter: 13659  total_loss: 0.2237  loss_cls: 0.02945  loss_box_reg: 0.08005  loss_mask: 0.09456  loss_rpn_cls: 0.0009243  loss_rpn_loc: 0.02117  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:06] d2.utils.events INFO:  eta: 2:08:10  iter: 13679  total_loss: 0.3046  loss_cls: 0.04074  loss_box_reg: 0.1162  loss_mask: 0.1062  loss_rpn_cls: 0.0006719  loss_rpn_loc: 0.01053  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:08] d2.utils.events INFO:  eta: 2:08:08  iter: 13699  total_loss: 0.3698  loss_cls: 0.05764  loss_box_reg: 0.1334  loss_mask: 0.133  loss_rpn_cls: 0.001332  loss_rpn_loc: 0.02005  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:11] d2.utils.events INFO:  eta: 2:08:18  iter: 13719  total_loss: 0.3748  loss_cls: 0.06208  loss_box_reg: 0.1528  loss_mask: 0.1262  loss_rpn_cls: 0.001706  loss_rpn_loc: 0.01949  time: 0.1013  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:51:13] d2.utils.events INFO:  eta: 2:08:17  iter: 13739  total_loss: 0.312  loss_cls: 0.0442  loss_box_reg: 0.1388  loss_mask: 0.1224  loss_rpn_cls: 0.001259  loss_rpn_loc: 0.01806  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:15] d2.utils.events INFO:  eta: 2:08:44  iter: 13759  total_loss: 0.3338  loss_cls: 0.04936  loss_box_reg: 0.1289  loss_mask: 0.1117  loss_rpn_cls: 0.003052  loss_rpn_loc: 0.02251  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:17] d2.utils.events INFO:  eta: 2:08:47  iter: 13779  total_loss: 0.3328  loss_cls: 0.06445  loss_box_reg: 0.1388  loss_mask: 0.1014  loss_rpn_cls: 0.002888  loss_rpn_loc: 0.03972  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:19] d2.utils.events INFO:  eta: 2:08:43  iter: 13799  total_loss: 0.4033  loss_cls: 0.05995  loss_box_reg: 0.1285  loss_mask: 0.1444  loss_rpn_cls: 0.004103  loss_rpn_loc: 0.03839  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:21] d2.utils.events INFO:  eta: 2:08:42  iter: 13819  total_loss: 0.3305  loss_cls: 0.04967  loss_box_reg: 0.1417  loss_mask: 0.1046  loss_rpn_cls: 0.003784  loss_rpn_loc: 0.02999  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:23] d2.utils.events INFO:  eta: 2:08:36  iter: 13839  total_loss: 0.2058  loss_cls: 0.02693  loss_box_reg: 0.08055  loss_mask: 0.08767  loss_rpn_cls: 0.00133  loss_rpn_loc: 0.01636  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:25] d2.utils.events INFO:  eta: 2:08:30  iter: 13859  total_loss: 0.2464  loss_cls: 0.03795  loss_box_reg: 0.1111  loss_mask: 0.07807  loss_rpn_cls: 0.001725  loss_rpn_loc: 0.0151  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:27] d2.utils.events INFO:  eta: 2:08:30  iter: 13879  total_loss: 0.4225  loss_cls: 0.05124  loss_box_reg: 0.169  loss_mask: 0.1325  loss_rpn_cls: 0.001558  loss_rpn_loc: 0.01775  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:29] d2.utils.events INFO:  eta: 2:08:26  iter: 13899  total_loss: 0.2669  loss_cls: 0.03079  loss_box_reg: 0.09109  loss_mask: 0.09482  loss_rpn_cls: 0.001603  loss_rpn_loc: 0.01354  time: 0.1013  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:51:31] d2.utils.events INFO:  eta: 2:08:23  iter: 13919  total_loss: 0.2768  loss_cls: 0.03469  loss_box_reg: 0.08627  loss_mask: 0.09791  loss_rpn_cls: 0.001822  loss_rpn_loc: 0.0256  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:33] d2.utils.events INFO:  eta: 2:08:26  iter: 13939  total_loss: 0.3248  loss_cls: 0.05894  loss_box_reg: 0.1628  loss_mask: 0.1306  loss_rpn_cls: 0.004209  loss_rpn_loc: 0.04119  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:35] d2.utils.events INFO:  eta: 2:08:24  iter: 13959  total_loss: 0.3543  loss_cls: 0.04845  loss_box_reg: 0.1315  loss_mask: 0.1129  loss_rpn_cls: 0.002275  loss_rpn_loc: 0.02973  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:37] d2.utils.events INFO:  eta: 2:08:32  iter: 13979  total_loss: 0.4393  loss_cls: 0.05756  loss_box_reg: 0.19  loss_mask: 0.1251  loss_rpn_cls: 0.001952  loss_rpn_loc: 0.01828  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:39] d2.utils.events INFO:  eta: 2:08:31  iter: 13999  total_loss: 0.3216  loss_cls: 0.04444  loss_box_reg: 0.1386  loss_mask: 0.1057  loss_rpn_cls: 0.001247  loss_rpn_loc: 0.02271  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:41] d2.utils.events INFO:  eta: 2:08:28  iter: 14019  total_loss: 0.2962  loss_cls: 0.04135  loss_box_reg: 0.1055  loss_mask: 0.1004  loss_rpn_cls: 0.00349  loss_rpn_loc: 0.0236  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:43] d2.utils.events INFO:  eta: 2:08:22  iter: 14039  total_loss: 0.3013  loss_cls: 0.04712  loss_box_reg: 0.1126  loss_mask: 0.1105  loss_rpn_cls: 0.0024  loss_rpn_loc: 0.01733  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:45] d2.utils.events INFO:  eta: 2:08:27  iter: 14059  total_loss: 0.2868  loss_cls: 0.04067  loss_box_reg: 0.1213  loss_mask: 0.08973  loss_rpn_cls: 0.00206  loss_rpn_loc: 0.02318  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:48] d2.utils.events INFO:  eta: 2:08:26  iter: 14079  total_loss: 0.434  loss_cls: 0.06196  loss_box_reg: 0.1978  loss_mask: 0.1103  loss_rpn_cls: 0.002755  loss_rpn_loc: 0.0323  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:51:50] d2.utils.events INFO:  eta: 2:08:23  iter: 14099  total_loss: 0.3433  loss_cls: 0.056  loss_box_reg: 0.1266  loss_mask: 0.1242  loss_rpn_cls: 0.002784  loss_rpn_loc: 0.03608  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:52] d2.utils.events INFO:  eta: 2:08:28  iter: 14119  total_loss: 0.3021  loss_cls: 0.03668  loss_box_reg: 0.105  loss_mask: 0.1081  loss_rpn_cls: 0.001856  loss_rpn_loc: 0.03182  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:51:54] d2.utils.events INFO:  eta: 2:08:22  iter: 14139  total_loss: 0.2656  loss_cls: 0.04734  loss_box_reg: 0.1011  loss_mask: 0.1058  loss_rpn_cls: 0.001132  loss_rpn_loc: 0.008913  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:51:56] d2.utils.events INFO:  eta: 2:08:07  iter: 14159  total_loss: 0.2771  loss_cls: 0.03995  loss_box_reg: 0.1225  loss_mask: 0.08563  loss_rpn_cls: 0.002454  loss_rpn_loc: 0.01986  time: 0.1013  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:51:58] d2.utils.events INFO:  eta: 2:08:15  iter: 14179  total_loss: 0.3295  loss_cls: 0.04731  loss_box_reg: 0.1472  loss_mask: 0.1174  loss_rpn_cls: 0.001903  loss_rpn_loc: 0.01941  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:00] d2.utils.events INFO:  eta: 2:08:16  iter: 14199  total_loss: 0.2378  loss_cls: 0.03234  loss_box_reg: 0.111  loss_mask: 0.09596  loss_rpn_cls: 0.002245  loss_rpn_loc: 0.02128  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:02] d2.utils.events INFO:  eta: 2:08:12  iter: 14219  total_loss: 0.3266  loss_cls: 0.05071  loss_box_reg: 0.1301  loss_mask: 0.1254  loss_rpn_cls: 0.002081  loss_rpn_loc: 0.02621  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:04] d2.utils.events INFO:  eta: 2:08:29  iter: 14239  total_loss: 0.4327  loss_cls: 0.05648  loss_box_reg: 0.2201  loss_mask: 0.1281  loss_rpn_cls: 0.003419  loss_rpn_loc: 0.03605  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:06] d2.utils.events INFO:  eta: 2:08:28  iter: 14259  total_loss: 0.1676  loss_cls: 0.02754  loss_box_reg: 0.0699  loss_mask: 0.08341  loss_rpn_cls: 0.000842  loss_rpn_loc: 0.01283  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:08] d2.utils.events INFO:  eta: 2:08:30  iter: 14279  total_loss: 0.33  loss_cls: 0.05172  loss_box_reg: 0.1343  loss_mask: 0.08191  loss_rpn_cls: 0.002065  loss_rpn_loc: 0.01587  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:10] d2.utils.events INFO:  eta: 2:08:25  iter: 14299  total_loss: 0.2953  loss_cls: 0.04734  loss_box_reg: 0.1034  loss_mask: 0.1121  loss_rpn_cls: 0.001108  loss_rpn_loc: 0.01922  time: 0.1013  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:12] d2.utils.events INFO:  eta: 2:08:13  iter: 14319  total_loss: 0.3556  loss_cls: 0.05054  loss_box_reg: 0.1629  loss_mask: 0.1111  loss_rpn_cls: 0.002079  loss_rpn_loc: 0.0196  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:14] d2.utils.events INFO:  eta: 2:08:07  iter: 14339  total_loss: 0.292  loss_cls: 0.04306  loss_box_reg: 0.1267  loss_mask: 0.09254  loss_rpn_cls: 0.0009441  loss_rpn_loc: 0.01681  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:52:16] d2.utils.events INFO:  eta: 2:08:26  iter: 14359  total_loss: 0.3901  loss_cls: 0.06174  loss_box_reg: 0.179  loss_mask: 0.1175  loss_rpn_cls: 0.002701  loss_rpn_loc: 0.02616  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:18] d2.utils.events INFO:  eta: 2:08:12  iter: 14379  total_loss: 0.2953  loss_cls: 0.04221  loss_box_reg: 0.1088  loss_mask: 0.1123  loss_rpn_cls: 0.001123  loss_rpn_loc: 0.01514  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:52:20] d2.utils.events INFO:  eta: 2:08:01  iter: 14399  total_loss: 0.2595  loss_cls: 0.03732  loss_box_reg: 0.1055  loss_mask: 0.1059  loss_rpn_cls: 0.001137  loss_rpn_loc: 0.0198  time: 0.1013  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:52:23] d2.utils.events INFO:  eta: 2:08:12  iter: 14419  total_loss: 0.3145  loss_cls: 0.03688  loss_box_reg: 0.1293  loss_mask: 0.09716  loss_rpn_cls: 0.002486  loss_rpn_loc: 0.03424  time: 0.1013  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:25] d2.utils.events INFO:  eta: 2:08:20  iter: 14439  total_loss: 0.4278  loss_cls: 0.06257  loss_box_reg: 0.1998  loss_mask: 0.154  loss_rpn_cls: 0.003274  loss_rpn_loc: 0.0352  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:27] d2.utils.events INFO:  eta: 2:08:29  iter: 14459  total_loss: 0.3064  loss_cls: 0.0413  loss_box_reg: 0.1275  loss_mask: 0.1019  loss_rpn_cls: 0.002103  loss_rpn_loc: 0.02921  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:52:29] d2.utils.events INFO:  eta: 2:08:22  iter: 14479  total_loss: 0.2934  loss_cls: 0.04166  loss_box_reg: 0.1106  loss_mask: 0.0982  loss_rpn_cls: 0.001567  loss_rpn_loc: 0.01698  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:31] d2.utils.events INFO:  eta: 2:08:27  iter: 14499  total_loss: 0.3047  loss_cls: 0.0483  loss_box_reg: 0.1441  loss_mask: 0.1024  loss_rpn_cls: 0.0005746  loss_rpn_loc: 0.0124  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:33] d2.utils.events INFO:  eta: 2:08:18  iter: 14519  total_loss: 0.2836  loss_cls: 0.03883  loss_box_reg: 0.1192  loss_mask: 0.08979  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.0217  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:35] d2.utils.events INFO:  eta: 2:08:23  iter: 14539  total_loss: 0.2452  loss_cls: 0.03373  loss_box_reg: 0.08523  loss_mask: 0.09177  loss_rpn_cls: 0.001485  loss_rpn_loc: 0.02605  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:52:37] d2.utils.events INFO:  eta: 2:08:10  iter: 14559  total_loss: 0.1973  loss_cls: 0.02686  loss_box_reg: 0.07166  loss_mask: 0.1057  loss_rpn_cls: 0.001958  loss_rpn_loc: 0.01915  time: 0.1014  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:52:39] d2.utils.events INFO:  eta: 2:08:08  iter: 14579  total_loss: 0.2484  loss_cls: 0.04381  loss_box_reg: 0.09939  loss_mask: 0.08826  loss_rpn_cls: 0.001564  loss_rpn_loc: 0.01864  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:41] d2.utils.events INFO:  eta: 2:08:06  iter: 14599  total_loss: 0.2354  loss_cls: 0.03273  loss_box_reg: 0.1069  loss_mask: 0.09175  loss_rpn_cls: 0.001554  loss_rpn_loc: 0.01713  time: 0.1014  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:52:43] d2.utils.events INFO:  eta: 2:08:03  iter: 14619  total_loss: 0.245  loss_cls: 0.03879  loss_box_reg: 0.08885  loss_mask: 0.08293  loss_rpn_cls: 0.001067  loss_rpn_loc: 0.01135  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:45] d2.utils.events INFO:  eta: 2:08:01  iter: 14639  total_loss: 0.4656  loss_cls: 0.08083  loss_box_reg: 0.1886  loss_mask: 0.1268  loss_rpn_cls: 0.003463  loss_rpn_loc: 0.04138  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:52:47] d2.utils.events INFO:  eta: 2:08:07  iter: 14659  total_loss: 0.494  loss_cls: 0.08247  loss_box_reg: 0.2019  loss_mask: 0.1681  loss_rpn_cls: 0.003657  loss_rpn_loc: 0.04647  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:49] d2.utils.events INFO:  eta: 2:08:12  iter: 14679  total_loss: 0.4338  loss_cls: 0.0897  loss_box_reg: 0.1873  loss_mask: 0.135  loss_rpn_cls: 0.003782  loss_rpn_loc: 0.03575  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:51] d2.utils.events INFO:  eta: 2:08:12  iter: 14699  total_loss: 0.4371  loss_cls: 0.0541  loss_box_reg: 0.1496  loss_mask: 0.1129  loss_rpn_cls: 0.002892  loss_rpn_loc: 0.02057  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:52:54] d2.utils.events INFO:  eta: 2:08:07  iter: 14719  total_loss: 0.4039  loss_cls: 0.05327  loss_box_reg: 0.1519  loss_mask: 0.1367  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.02799  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:56] d2.utils.events INFO:  eta: 2:08:04  iter: 14739  total_loss: 0.3565  loss_cls: 0.0434  loss_box_reg: 0.1522  loss_mask: 0.1289  loss_rpn_cls: 0.001482  loss_rpn_loc: 0.024  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:52:58] d2.utils.events INFO:  eta: 2:07:59  iter: 14759  total_loss: 0.3374  loss_cls: 0.05159  loss_box_reg: 0.1237  loss_mask: 0.1072  loss_rpn_cls: 0.001257  loss_rpn_loc: 0.01994  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:00] d2.utils.events INFO:  eta: 2:07:53  iter: 14779  total_loss: 0.3202  loss_cls: 0.04813  loss_box_reg: 0.1219  loss_mask: 0.09165  loss_rpn_cls: 0.001704  loss_rpn_loc: 0.01558  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:02] d2.utils.events INFO:  eta: 2:07:55  iter: 14799  total_loss: 0.3246  loss_cls: 0.06782  loss_box_reg: 0.1313  loss_mask: 0.1306  loss_rpn_cls: 0.003036  loss_rpn_loc: 0.02823  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:04] d2.utils.events INFO:  eta: 2:08:11  iter: 14819  total_loss: 0.3556  loss_cls: 0.05491  loss_box_reg: 0.1347  loss_mask: 0.1154  loss_rpn_cls: 0.002664  loss_rpn_loc: 0.02719  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:06] d2.utils.events INFO:  eta: 2:08:20  iter: 14839  total_loss: 0.3593  loss_cls: 0.04941  loss_box_reg: 0.1321  loss_mask: 0.0994  loss_rpn_cls: 0.002249  loss_rpn_loc: 0.02783  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:53:08] d2.utils.events INFO:  eta: 2:08:31  iter: 14859  total_loss: 0.2743  loss_cls: 0.04636  loss_box_reg: 0.1251  loss_mask: 0.0964  loss_rpn_cls: 0.0007961  loss_rpn_loc: 0.01438  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:10] d2.utils.events INFO:  eta: 2:08:31  iter: 14879  total_loss: 0.3373  loss_cls: 0.06033  loss_box_reg: 0.1472  loss_mask: 0.09877  loss_rpn_cls: 0.003699  loss_rpn_loc: 0.03348  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:13] d2.utils.events INFO:  eta: 2:08:48  iter: 14899  total_loss: 0.3399  loss_cls: 0.05203  loss_box_reg: 0.1418  loss_mask: 0.1157  loss_rpn_cls: 0.002288  loss_rpn_loc: 0.03399  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:53:15] d2.utils.events INFO:  eta: 2:08:43  iter: 14919  total_loss: 0.2431  loss_cls: 0.03293  loss_box_reg: 0.1033  loss_mask: 0.09896  loss_rpn_cls: 0.001918  loss_rpn_loc: 0.0204  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:17] d2.utils.events INFO:  eta: 2:08:30  iter: 14939  total_loss: 0.3482  loss_cls: 0.06238  loss_box_reg: 0.1365  loss_mask: 0.1071  loss_rpn_cls: 0.001937  loss_rpn_loc: 0.02711  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:19] d2.utils.events INFO:  eta: 2:08:26  iter: 14959  total_loss: 0.2751  loss_cls: 0.03873  loss_box_reg: 0.1237  loss_mask: 0.09517  loss_rpn_cls: 0.0007208  loss_rpn_loc: 0.02417  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:21] d2.utils.events INFO:  eta: 2:08:18  iter: 14979  total_loss: 0.2584  loss_cls: 0.03869  loss_box_reg: 0.09156  loss_mask: 0.1123  loss_rpn_cls: 0.0008407  loss_rpn_loc: 0.01323  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:23] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0014999.pth
[10/27 18:53:23] d2.utils.events INFO:  eta: 2:08:16  iter: 14999  total_loss: 0.3625  loss_cls: 0.05797  loss_box_reg: 0.1561  loss_mask: 0.1268  loss_rpn_cls: 0.001311  loss_rpn_loc: 0.01974  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:25] d2.utils.events INFO:  eta: 2:08:16  iter: 15019  total_loss: 0.2122  loss_cls: 0.03618  loss_box_reg: 0.1013  loss_mask: 0.09134  loss_rpn_cls: 0.002433  loss_rpn_loc: 0.0148  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:53:27] d2.utils.events INFO:  eta: 2:08:16  iter: 15039  total_loss: 0.3315  loss_cls: 0.06021  loss_box_reg: 0.1537  loss_mask: 0.09734  loss_rpn_cls: 0.001176  loss_rpn_loc: 0.01886  time: 0.1014  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:53:29] d2.utils.events INFO:  eta: 2:08:12  iter: 15059  total_loss: 0.3186  loss_cls: 0.05157  loss_box_reg: 0.1562  loss_mask: 0.1223  loss_rpn_cls: 0.0008405  loss_rpn_loc: 0.0139  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:31] d2.utils.events INFO:  eta: 2:08:03  iter: 15079  total_loss: 0.2987  loss_cls: 0.05953  loss_box_reg: 0.1308  loss_mask: 0.08862  loss_rpn_cls: 0.002249  loss_rpn_loc: 0.02115  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:34] d2.utils.events INFO:  eta: 2:08:04  iter: 15099  total_loss: 0.402  loss_cls: 0.06037  loss_box_reg: 0.1465  loss_mask: 0.1056  loss_rpn_cls: 0.002146  loss_rpn_loc: 0.02553  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:36] d2.utils.events INFO:  eta: 2:08:08  iter: 15119  total_loss: 0.3569  loss_cls: 0.05983  loss_box_reg: 0.1372  loss_mask: 0.1141  loss_rpn_cls: 0.001836  loss_rpn_loc: 0.02824  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:38] d2.utils.events INFO:  eta: 2:08:26  iter: 15139  total_loss: 0.3914  loss_cls: 0.07581  loss_box_reg: 0.165  loss_mask: 0.1203  loss_rpn_cls: 0.004954  loss_rpn_loc: 0.0456  time: 0.1014  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:53:40] d2.utils.events INFO:  eta: 2:08:46  iter: 15159  total_loss: 0.3168  loss_cls: 0.06323  loss_box_reg: 0.1345  loss_mask: 0.08207  loss_rpn_cls: 0.003148  loss_rpn_loc: 0.03048  time: 0.1014  data_time: 0.0028  lr: 0.0025  max_mem: 1630M
[10/27 18:53:42] d2.utils.events INFO:  eta: 2:08:45  iter: 15179  total_loss: 0.3681  loss_cls: 0.05257  loss_box_reg: 0.1477  loss_mask: 0.1316  loss_rpn_cls: 0.001438  loss_rpn_loc: 0.01969  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:44] d2.utils.events INFO:  eta: 2:08:44  iter: 15199  total_loss: 0.3989  loss_cls: 0.06032  loss_box_reg: 0.1513  loss_mask: 0.1108  loss_rpn_cls: 0.001261  loss_rpn_loc: 0.02331  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:46] d2.utils.events INFO:  eta: 2:08:41  iter: 15219  total_loss: 0.2827  loss_cls: 0.04142  loss_box_reg: 0.1049  loss_mask: 0.09268  loss_rpn_cls: 0.00102  loss_rpn_loc: 0.008853  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:53:48] d2.utils.events INFO:  eta: 2:08:37  iter: 15239  total_loss: 0.2662  loss_cls: 0.04355  loss_box_reg: 0.1059  loss_mask: 0.1007  loss_rpn_cls: 0.0009812  loss_rpn_loc: 0.01695  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:53:50] d2.utils.events INFO:  eta: 2:08:37  iter: 15259  total_loss: 0.3855  loss_cls: 0.05204  loss_box_reg: 0.16  loss_mask: 0.1364  loss_rpn_cls: 0.001526  loss_rpn_loc: 0.03012  time: 0.1015  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:53:52] d2.utils.events INFO:  eta: 2:08:35  iter: 15279  total_loss: 0.3244  loss_cls: 0.04863  loss_box_reg: 0.1113  loss_mask: 0.113  loss_rpn_cls: 0.003783  loss_rpn_loc: 0.0203  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:54] d2.utils.events INFO:  eta: 2:08:21  iter: 15299  total_loss: 0.2744  loss_cls: 0.0322  loss_box_reg: 0.08062  loss_mask: 0.08792  loss_rpn_cls: 0.001452  loss_rpn_loc: 0.0175  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:56] d2.utils.events INFO:  eta: 2:08:11  iter: 15319  total_loss: 0.2087  loss_cls: 0.02623  loss_box_reg: 0.07105  loss_mask: 0.07485  loss_rpn_cls: 0.0009457  loss_rpn_loc: 0.01583  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:53:58] d2.utils.events INFO:  eta: 2:08:05  iter: 15339  total_loss: 0.3661  loss_cls: 0.0616  loss_box_reg: 0.1676  loss_mask: 0.09506  loss_rpn_cls: 0.002147  loss_rpn_loc: 0.02695  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:54:00] d2.utils.events INFO:  eta: 2:07:55  iter: 15359  total_loss: 0.2798  loss_cls: 0.03747  loss_box_reg: 0.1119  loss_mask: 0.09242  loss_rpn_cls: 0.003469  loss_rpn_loc: 0.02231  time: 0.1014  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:54:02] d2.utils.events INFO:  eta: 2:07:59  iter: 15379  total_loss: 0.4977  loss_cls: 0.06245  loss_box_reg: 0.1925  loss_mask: 0.145  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.03895  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:04] d2.utils.events INFO:  eta: 2:07:35  iter: 15399  total_loss: 0.3364  loss_cls: 0.04358  loss_box_reg: 0.137  loss_mask: 0.1044  loss_rpn_cls: 0.001444  loss_rpn_loc: 0.01551  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:06] d2.utils.events INFO:  eta: 2:07:28  iter: 15419  total_loss: 0.3476  loss_cls: 0.0496  loss_box_reg: 0.1435  loss_mask: 0.1124  loss_rpn_cls: 0.0009718  loss_rpn_loc: 0.02198  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:08] d2.utils.events INFO:  eta: 2:07:23  iter: 15439  total_loss: 0.2735  loss_cls: 0.04282  loss_box_reg: 0.111  loss_mask: 0.09509  loss_rpn_cls: 0.001683  loss_rpn_loc: 0.01654  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:10] d2.utils.events INFO:  eta: 2:07:19  iter: 15459  total_loss: 0.4138  loss_cls: 0.05835  loss_box_reg: 0.1842  loss_mask: 0.1306  loss_rpn_cls: 0.002377  loss_rpn_loc: 0.02824  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:54:13] d2.utils.events INFO:  eta: 2:07:18  iter: 15479  total_loss: 0.395  loss_cls: 0.05518  loss_box_reg: 0.1643  loss_mask: 0.1416  loss_rpn_cls: 0.001874  loss_rpn_loc: 0.02323  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:54:15] d2.utils.events INFO:  eta: 2:07:15  iter: 15499  total_loss: 0.2267  loss_cls: 0.03424  loss_box_reg: 0.07955  loss_mask: 0.09519  loss_rpn_cls: 0.002689  loss_rpn_loc: 0.02418  time: 0.1014  data_time: 0.0029  lr: 0.0025  max_mem: 1630M
[10/27 18:54:17] d2.utils.events INFO:  eta: 2:07:14  iter: 15519  total_loss: 0.3836  loss_cls: 0.05566  loss_box_reg: 0.1509  loss_mask: 0.1024  loss_rpn_cls: 0.001224  loss_rpn_loc: 0.02209  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:19] d2.utils.events INFO:  eta: 2:07:14  iter: 15539  total_loss: 0.3248  loss_cls: 0.04858  loss_box_reg: 0.1499  loss_mask: 0.1035  loss_rpn_cls: 0.00177  loss_rpn_loc: 0.02285  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:21] d2.utils.events INFO:  eta: 2:07:09  iter: 15559  total_loss: 0.2681  loss_cls: 0.03828  loss_box_reg: 0.09839  loss_mask: 0.1092  loss_rpn_cls: 0.00126  loss_rpn_loc: 0.01085  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:54:23] d2.utils.events INFO:  eta: 2:07:08  iter: 15579  total_loss: 0.2768  loss_cls: 0.04144  loss_box_reg: 0.1184  loss_mask: 0.08685  loss_rpn_cls: 0.00166  loss_rpn_loc: 0.01744  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:25] d2.utils.events INFO:  eta: 2:07:04  iter: 15599  total_loss: 0.2468  loss_cls: 0.04378  loss_box_reg: 0.1022  loss_mask: 0.09569  loss_rpn_cls: 0.001341  loss_rpn_loc: 0.01463  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:27] d2.utils.events INFO:  eta: 2:07:05  iter: 15619  total_loss: 0.3036  loss_cls: 0.05588  loss_box_reg: 0.1183  loss_mask: 0.1064  loss_rpn_cls: 0.001921  loss_rpn_loc: 0.02805  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:29] d2.utils.events INFO:  eta: 2:07:03  iter: 15639  total_loss: 0.2775  loss_cls: 0.04268  loss_box_reg: 0.1166  loss_mask: 0.1069  loss_rpn_cls: 0.002202  loss_rpn_loc: 0.02113  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:54:31] d2.utils.events INFO:  eta: 2:06:59  iter: 15659  total_loss: 0.2877  loss_cls: 0.04747  loss_box_reg: 0.1349  loss_mask: 0.08607  loss_rpn_cls: 0.003106  loss_rpn_loc: 0.02038  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:54:33] d2.utils.events INFO:  eta: 2:06:51  iter: 15679  total_loss: 0.4085  loss_cls: 0.05977  loss_box_reg: 0.1847  loss_mask: 0.1079  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.02542  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:35] d2.utils.events INFO:  eta: 2:06:38  iter: 15699  total_loss: 0.2222  loss_cls: 0.0359  loss_box_reg: 0.07724  loss_mask: 0.08742  loss_rpn_cls: 0.0009583  loss_rpn_loc: 0.01423  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:37] d2.utils.events INFO:  eta: 2:06:31  iter: 15719  total_loss: 0.269  loss_cls: 0.04303  loss_box_reg: 0.1264  loss_mask: 0.09948  loss_rpn_cls: 0.002038  loss_rpn_loc: 0.02159  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:39] d2.utils.events INFO:  eta: 2:06:32  iter: 15739  total_loss: 0.2591  loss_cls: 0.03855  loss_box_reg: 0.1103  loss_mask: 0.09137  loss_rpn_cls: 0.003095  loss_rpn_loc: 0.0191  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:41] d2.utils.events INFO:  eta: 2:06:32  iter: 15759  total_loss: 0.2869  loss_cls: 0.03746  loss_box_reg: 0.1046  loss_mask: 0.1054  loss_rpn_cls: 0.001642  loss_rpn_loc: 0.01352  time: 0.1014  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:54:43] d2.utils.events INFO:  eta: 2:06:39  iter: 15779  total_loss: 0.3645  loss_cls: 0.0594  loss_box_reg: 0.1578  loss_mask: 0.1175  loss_rpn_cls: 0.001667  loss_rpn_loc: 0.0155  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:54:45] d2.utils.events INFO:  eta: 2:06:28  iter: 15799  total_loss: 0.4188  loss_cls: 0.06571  loss_box_reg: 0.1876  loss_mask: 0.1473  loss_rpn_cls: 0.006096  loss_rpn_loc: 0.03826  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:54:47] d2.utils.events INFO:  eta: 2:06:17  iter: 15819  total_loss: 0.2872  loss_cls: 0.04462  loss_box_reg: 0.1202  loss_mask: 0.08835  loss_rpn_cls: 0.001255  loss_rpn_loc: 0.01703  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:49] d2.utils.events INFO:  eta: 2:05:59  iter: 15839  total_loss: 0.2661  loss_cls: 0.04228  loss_box_reg: 0.1084  loss_mask: 0.105  loss_rpn_cls: 0.002721  loss_rpn_loc: 0.02701  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:51] d2.utils.events INFO:  eta: 2:06:01  iter: 15859  total_loss: 0.4733  loss_cls: 0.0773  loss_box_reg: 0.1887  loss_mask: 0.1178  loss_rpn_cls: 0.004569  loss_rpn_loc: 0.04807  time: 0.1014  data_time: 0.0022  lr: 0.0025  max_mem: 1630M
[10/27 18:54:53] d2.utils.events INFO:  eta: 2:05:59  iter: 15879  total_loss: 0.3316  loss_cls: 0.04808  loss_box_reg: 0.1495  loss_mask: 0.1245  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.0181  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:55] d2.utils.events INFO:  eta: 2:05:54  iter: 15899  total_loss: 0.3479  loss_cls: 0.06221  loss_box_reg: 0.158  loss_mask: 0.09647  loss_rpn_cls: 0.002592  loss_rpn_loc: 0.04234  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:54:57] d2.utils.events INFO:  eta: 2:05:58  iter: 15919  total_loss: 0.2529  loss_cls: 0.04128  loss_box_reg: 0.1237  loss_mask: 0.08672  loss_rpn_cls: 0.00181  loss_rpn_loc: 0.0181  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:54:59] d2.utils.events INFO:  eta: 2:06:00  iter: 15939  total_loss: 0.2948  loss_cls: 0.04811  loss_box_reg: 0.1039  loss_mask: 0.1069  loss_rpn_cls: 0.0008147  loss_rpn_loc: 0.0206  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:55:01] d2.utils.events INFO:  eta: 2:06:08  iter: 15959  total_loss: 0.3119  loss_cls: 0.04164  loss_box_reg: 0.135  loss_mask: 0.09494  loss_rpn_cls: 0.001201  loss_rpn_loc: 0.01398  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:55:03] d2.utils.events INFO:  eta: 2:06:10  iter: 15979  total_loss: 0.2819  loss_cls: 0.04735  loss_box_reg: 0.1054  loss_mask: 0.09979  loss_rpn_cls: 0.002272  loss_rpn_loc: 0.01604  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:55:05] d2.utils.events INFO:  eta: 2:06:02  iter: 15999  total_loss: 0.3797  loss_cls: 0.04836  loss_box_reg: 0.154  loss_mask: 0.1234  loss_rpn_cls: 0.002646  loss_rpn_loc: 0.03305  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:55:08] d2.utils.events INFO:  eta: 2:06:00  iter: 16019  total_loss: 0.248  loss_cls: 0.04655  loss_box_reg: 0.09659  loss_mask: 0.08879  loss_rpn_cls: 0.001845  loss_rpn_loc: 0.01652  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:55:09] d2.utils.events INFO:  eta: 2:05:38  iter: 16039  total_loss: 0.3689  loss_cls: 0.0519  loss_box_reg: 0.1619  loss_mask: 0.1101  loss_rpn_cls: 0.001523  loss_rpn_loc: 0.0244  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:55:12] d2.utils.events INFO:  eta: 2:05:39  iter: 16059  total_loss: 0.3186  loss_cls: 0.05957  loss_box_reg: 0.1463  loss_mask: 0.1001  loss_rpn_cls: 0.001394  loss_rpn_loc: 0.02328  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:55:14] d2.utils.events INFO:  eta: 2:05:34  iter: 16079  total_loss: 0.2658  loss_cls: 0.04241  loss_box_reg: 0.1068  loss_mask: 0.1034  loss_rpn_cls: 0.0003779  loss_rpn_loc: 0.01741  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:55:16] d2.utils.events INFO:  eta: 2:05:34  iter: 16099  total_loss: 0.3389  loss_cls: 0.05614  loss_box_reg: 0.1415  loss_mask: 0.1029  loss_rpn_cls: 0.001786  loss_rpn_loc: 0.02265  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:55:18] d2.utils.events INFO:  eta: 2:05:16  iter: 16119  total_loss: 0.3162  loss_cls: 0.04725  loss_box_reg: 0.1444  loss_mask: 0.09526  loss_rpn_cls: 0.0009475  loss_rpn_loc: 0.0233  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:55:20] d2.utils.events INFO:  eta: 2:05:05  iter: 16139  total_loss: 0.3545  loss_cls: 0.04837  loss_box_reg: 0.1461  loss_mask: 0.1074  loss_rpn_cls: 0.003352  loss_rpn_loc: 0.01998  time: 0.1014  data_time: 0.0025  lr: 0.0025  max_mem: 1630M
[10/27 18:55:22] d2.utils.events INFO:  eta: 2:04:54  iter: 16159  total_loss: 0.3575  loss_cls: 0.06773  loss_box_reg: 0.1817  loss_mask: 0.1016  loss_rpn_cls: 0.001778  loss_rpn_loc: 0.02042  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:55:24] d2.utils.events INFO:  eta: 2:04:32  iter: 16179  total_loss: 0.3311  loss_cls: 0.0489  loss_box_reg: 0.1219  loss_mask: 0.1119  loss_rpn_cls: 0.001734  loss_rpn_loc: 0.01547  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:55:26] d2.utils.events INFO:  eta: 2:04:27  iter: 16199  total_loss: 0.352  loss_cls: 0.05651  loss_box_reg: 0.1347  loss_mask: 0.1311  loss_rpn_cls: 0.002321  loss_rpn_loc: 0.02735  time: 0.1014  data_time: 0.0021  lr: 0.0025  max_mem: 1630M
[10/27 18:55:28] d2.utils.events INFO:  eta: 2:04:25  iter: 16219  total_loss: 0.2501  loss_cls: 0.03972  loss_box_reg: 0.1013  loss_mask: 0.09536  loss_rpn_cls: 0.001704  loss_rpn_loc: 0.03914  time: 0.1014  data_time: 0.0020  lr: 0.0025  max_mem: 1630M
[10/27 18:55:30] d2.utils.events INFO:  eta: 2:03:58  iter: 16239  total_loss: 0.1838  loss_cls: 0.02372  loss_box_reg: 0.05994  loss_mask: 0.06841  loss_rpn_cls: 0.0004764  loss_rpn_loc: 0.01391  time: 0.1014  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:55:32] d2.utils.events INFO:  eta: 2:03:55  iter: 16259  total_loss: 0.2449  loss_cls: 0.03591  loss_box_reg: 0.09037  loss_mask: 0.1033  loss_rpn_cls: 0.001626  loss_rpn_loc: 0.01462  time: 0.1014  data_time: 0.0019  lr: 0.0025  max_mem: 1630M
[10/27 18:55:34] d2.utils.events INFO:  eta: 2:03:56  iter: 16279  total_loss: 0.2653  loss_cls: 0.04268  loss_box_reg: 0.1112  loss_mask: 0.09584  loss_rpn_cls: 0.00312  loss_rpn_loc: 0.02335  time: 0.1014  data_time: 0.0023  lr: 0.0025  max_mem: 1630M
[10/27 18:55:36] d2.utils.events INFO:  eta: 2:04:07  iter: 16299  total_loss: 0.3697  loss_cls: 0.06027  loss_box_reg: 0.1711  loss_mask: 0.1203  loss_rpn_cls: 0.002224  loss_rpn_loc: 0.02744  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:55:38] d2.utils.events INFO:  eta: 2:04:23  iter: 16319  total_loss: 0.3384  loss_cls: 0.05102  loss_box_reg: 0.1339  loss_mask: 0.1063  loss_rpn_cls: 0.001503  loss_rpn_loc: 0.0169  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1630M
[10/27 18:55:40] d2.utils.events INFO:  eta: 2:04:41  iter: 16339  total_loss: 0.2479  loss_cls: 0.0406  loss_box_reg: 0.09963  loss_mask: 0.07249  loss_rpn_cls: 0.001213  loss_rpn_loc: 0.01749  time: 0.1014  data_time: 0.0024  lr: 0.0025  max_mem: 1630M
[10/27 18:55:42] d2.utils.events INFO:  eta: 2:04:46  iter: 16359  total_loss: 0.2734  loss_cls: 0.03805  loss_box_reg: 0.1259  loss_mask: 0.1019  loss_rpn_cls: 0.001464  loss_rpn_loc: 0.01984  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:55:44] d2.utils.events INFO:  eta: 2:04:50  iter: 16379  total_loss: 0.3103  loss_cls: 0.05242  loss_box_reg: 0.1453  loss_mask: 0.113  loss_rpn_cls: 0.002078  loss_rpn_loc: 0.02303  time: 0.1014  data_time: 0.0027  lr: 0.0025  max_mem: 1630M
[10/27 18:55:46] d2.utils.events INFO:  eta: 2:04:51  iter: 16399  total_loss: 0.408  loss_cls: 0.06153  loss_box_reg: 0.1649  loss_mask: 0.1164  loss_rpn_cls: 0.00261  loss_rpn_loc: 0.03816  time: 0.1014  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:55:49] d2.utils.events INFO:  eta: 2:04:55  iter: 16419  total_loss: 0.3892  loss_cls: 0.06104  loss_box_reg: 0.1564  loss_mask: 0.1221  loss_rpn_cls: 0.003109  loss_rpn_loc: 0.03422  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:55:51] d2.utils.events INFO:  eta: 2:04:58  iter: 16439  total_loss: 0.2359  loss_cls: 0.03187  loss_box_reg: 0.09765  loss_mask: 0.08586  loss_rpn_cls: 0.001226  loss_rpn_loc: 0.01572  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:55:53] d2.utils.events INFO:  eta: 2:04:45  iter: 16459  total_loss: 0.2391  loss_cls: 0.03916  loss_box_reg: 0.1109  loss_mask: 0.08531  loss_rpn_cls: 0.000594  loss_rpn_loc: 0.01593  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:55:55] d2.utils.events INFO:  eta: 2:04:40  iter: 16479  total_loss: 0.3277  loss_cls: 0.05466  loss_box_reg: 0.1135  loss_mask: 0.1251  loss_rpn_cls: 0.001156  loss_rpn_loc: 0.02976  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:55:57] d2.utils.events INFO:  eta: 2:04:36  iter: 16499  total_loss: 0.3126  loss_cls: 0.05887  loss_box_reg: 0.1584  loss_mask: 0.1038  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.02164  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:55:59] d2.utils.events INFO:  eta: 2:04:36  iter: 16519  total_loss: 0.2875  loss_cls: 0.04382  loss_box_reg: 0.1223  loss_mask: 0.09486  loss_rpn_cls: 0.0004685  loss_rpn_loc: 0.01643  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:56:01] d2.utils.events INFO:  eta: 2:04:24  iter: 16539  total_loss: 0.2774  loss_cls: 0.03722  loss_box_reg: 0.1038  loss_mask: 0.08206  loss_rpn_cls: 0.001143  loss_rpn_loc: 0.01872  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:03] d2.utils.events INFO:  eta: 2:04:38  iter: 16559  total_loss: 0.2955  loss_cls: 0.04394  loss_box_reg: 0.1252  loss_mask: 0.08127  loss_rpn_cls: 0.0009177  loss_rpn_loc: 0.01443  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:05] d2.utils.events INFO:  eta: 2:04:50  iter: 16579  total_loss: 0.2805  loss_cls: 0.05034  loss_box_reg: 0.1196  loss_mask: 0.1013  loss_rpn_cls: 0.0007851  loss_rpn_loc: 0.01664  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:07] d2.utils.events INFO:  eta: 2:05:01  iter: 16599  total_loss: 0.3035  loss_cls: 0.05905  loss_box_reg: 0.1391  loss_mask: 0.09758  loss_rpn_cls: 0.0007934  loss_rpn_loc: 0.02788  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:09] d2.utils.events INFO:  eta: 2:04:59  iter: 16619  total_loss: 0.3861  loss_cls: 0.06168  loss_box_reg: 0.1646  loss_mask: 0.1314  loss_rpn_cls: 0.002259  loss_rpn_loc: 0.02119  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:11] d2.utils.events INFO:  eta: 2:04:54  iter: 16639  total_loss: 0.2684  loss_cls: 0.0353  loss_box_reg: 0.09943  loss_mask: 0.0932  loss_rpn_cls: 0.001364  loss_rpn_loc: 0.01537  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:14] d2.utils.events INFO:  eta: 2:04:55  iter: 16659  total_loss: 0.3768  loss_cls: 0.04974  loss_box_reg: 0.1717  loss_mask: 0.101  loss_rpn_cls: 0.0009002  loss_rpn_loc: 0.02443  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:16] d2.utils.events INFO:  eta: 2:05:09  iter: 16679  total_loss: 0.448  loss_cls: 0.08346  loss_box_reg: 0.209  loss_mask: 0.1137  loss_rpn_cls: 0.002608  loss_rpn_loc: 0.02904  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:18] d2.utils.events INFO:  eta: 2:05:08  iter: 16699  total_loss: 0.1745  loss_cls: 0.02803  loss_box_reg: 0.06206  loss_mask: 0.08067  loss_rpn_cls: 0.0007643  loss_rpn_loc: 0.007593  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:20] d2.utils.events INFO:  eta: 2:05:06  iter: 16719  total_loss: 0.2082  loss_cls: 0.02645  loss_box_reg: 0.09593  loss_mask: 0.07493  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.01836  time: 0.1015  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:56:22] d2.utils.events INFO:  eta: 2:05:01  iter: 16739  total_loss: 0.352  loss_cls: 0.04278  loss_box_reg: 0.1414  loss_mask: 0.09952  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.01709  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:24] d2.utils.events INFO:  eta: 2:04:52  iter: 16759  total_loss: 0.2654  loss_cls: 0.03496  loss_box_reg: 0.09066  loss_mask: 0.1108  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.03133  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:26] d2.utils.events INFO:  eta: 2:04:41  iter: 16779  total_loss: 0.3025  loss_cls: 0.04358  loss_box_reg: 0.128  loss_mask: 0.1093  loss_rpn_cls: 0.001943  loss_rpn_loc: 0.02079  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:28] d2.utils.events INFO:  eta: 2:04:41  iter: 16799  total_loss: 0.2513  loss_cls: 0.03567  loss_box_reg: 0.1252  loss_mask: 0.09171  loss_rpn_cls: 0.0008515  loss_rpn_loc: 0.02175  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:30] d2.utils.events INFO:  eta: 2:04:44  iter: 16819  total_loss: 0.294  loss_cls: 0.04766  loss_box_reg: 0.1284  loss_mask: 0.08253  loss_rpn_cls: 0.001549  loss_rpn_loc: 0.01844  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:32] d2.utils.events INFO:  eta: 2:04:51  iter: 16839  total_loss: 0.3438  loss_cls: 0.0658  loss_box_reg: 0.1562  loss_mask: 0.1134  loss_rpn_cls: 0.003873  loss_rpn_loc: 0.02869  time: 0.1015  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:56:34] d2.utils.events INFO:  eta: 2:04:50  iter: 16859  total_loss: 0.2718  loss_cls: 0.0378  loss_box_reg: 0.1117  loss_mask: 0.09538  loss_rpn_cls: 0.001781  loss_rpn_loc: 0.02195  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:36] d2.utils.events INFO:  eta: 2:04:44  iter: 16879  total_loss: 0.2856  loss_cls: 0.04017  loss_box_reg: 0.1285  loss_mask: 0.09132  loss_rpn_cls: 0.001526  loss_rpn_loc: 0.01093  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:39] d2.utils.events INFO:  eta: 2:04:46  iter: 16899  total_loss: 0.2757  loss_cls: 0.03321  loss_box_reg: 0.1223  loss_mask: 0.08735  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.02368  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:41] d2.utils.events INFO:  eta: 2:04:44  iter: 16919  total_loss: 0.282  loss_cls: 0.04897  loss_box_reg: 0.1171  loss_mask: 0.1029  loss_rpn_cls: 0.0008454  loss_rpn_loc: 0.01746  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:56:43] d2.utils.events INFO:  eta: 2:04:47  iter: 16939  total_loss: 0.338  loss_cls: 0.04592  loss_box_reg: 0.1493  loss_mask: 0.0939  loss_rpn_cls: 0.001557  loss_rpn_loc: 0.01902  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:45] d2.utils.events INFO:  eta: 2:04:36  iter: 16959  total_loss: 0.1903  loss_cls: 0.03432  loss_box_reg: 0.07643  loss_mask: 0.08745  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.01778  time: 0.1015  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:56:47] d2.utils.events INFO:  eta: 2:04:38  iter: 16979  total_loss: 0.3589  loss_cls: 0.05507  loss_box_reg: 0.168  loss_mask: 0.1206  loss_rpn_cls: 0.001045  loss_rpn_loc: 0.01997  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:49] d2.utils.events INFO:  eta: 2:04:44  iter: 16999  total_loss: 0.3041  loss_cls: 0.04722  loss_box_reg: 0.1263  loss_mask: 0.1218  loss_rpn_cls: 0.00216  loss_rpn_loc: 0.01756  time: 0.1015  data_time: 0.0030  lr: 0.0025  max_mem: 1634M
[10/27 18:56:51] d2.utils.events INFO:  eta: 2:04:39  iter: 17019  total_loss: 0.3446  loss_cls: 0.04931  loss_box_reg: 0.1662  loss_mask: 0.1082  loss_rpn_cls: 0.001332  loss_rpn_loc: 0.01976  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:56:53] d2.utils.events INFO:  eta: 2:04:44  iter: 17039  total_loss: 0.2475  loss_cls: 0.04354  loss_box_reg: 0.1075  loss_mask: 0.1049  loss_rpn_cls: 0.001071  loss_rpn_loc: 0.02123  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:55] d2.utils.events INFO:  eta: 2:04:51  iter: 17059  total_loss: 0.3534  loss_cls: 0.04964  loss_box_reg: 0.1453  loss_mask: 0.1086  loss_rpn_cls: 0.002644  loss_rpn_loc: 0.03671  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:56:57] d2.utils.events INFO:  eta: 2:04:49  iter: 17079  total_loss: 0.2121  loss_cls: 0.03133  loss_box_reg: 0.07919  loss_mask: 0.09271  loss_rpn_cls: 0.0005428  loss_rpn_loc: 0.01149  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:56:59] d2.utils.events INFO:  eta: 2:04:47  iter: 17099  total_loss: 0.303  loss_cls: 0.04885  loss_box_reg: 0.118  loss_mask: 0.07982  loss_rpn_cls: 0.0009727  loss_rpn_loc: 0.01472  time: 0.1015  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:02] d2.utils.events INFO:  eta: 2:04:58  iter: 17119  total_loss: 0.4371  loss_cls: 0.05584  loss_box_reg: 0.2053  loss_mask: 0.123  loss_rpn_cls: 0.002959  loss_rpn_loc: 0.03369  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:04] d2.utils.events INFO:  eta: 2:04:53  iter: 17139  total_loss: 0.293  loss_cls: 0.04462  loss_box_reg: 0.1312  loss_mask: 0.08737  loss_rpn_cls: 0.001311  loss_rpn_loc: 0.01778  time: 0.1015  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:06] d2.utils.events INFO:  eta: 2:04:54  iter: 17159  total_loss: 0.3094  loss_cls: 0.04937  loss_box_reg: 0.1301  loss_mask: 0.09491  loss_rpn_cls: 0.000732  loss_rpn_loc: 0.01562  time: 0.1015  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:57:08] d2.utils.events INFO:  eta: 2:05:13  iter: 17179  total_loss: 0.3139  loss_cls: 0.04174  loss_box_reg: 0.1233  loss_mask: 0.101  loss_rpn_cls: 0.001341  loss_rpn_loc: 0.02983  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:57:10] d2.utils.events INFO:  eta: 2:05:13  iter: 17199  total_loss: 0.3546  loss_cls: 0.05332  loss_box_reg: 0.1499  loss_mask: 0.1043  loss_rpn_cls: 0.001777  loss_rpn_loc: 0.0178  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:12] d2.utils.events INFO:  eta: 2:05:19  iter: 17219  total_loss: 0.281  loss_cls: 0.04432  loss_box_reg: 0.125  loss_mask: 0.09138  loss_rpn_cls: 0.001425  loss_rpn_loc: 0.01838  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:14] d2.utils.events INFO:  eta: 2:05:19  iter: 17239  total_loss: 0.2345  loss_cls: 0.03529  loss_box_reg: 0.09699  loss_mask: 0.08002  loss_rpn_cls: 0.002091  loss_rpn_loc: 0.02627  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:57:16] d2.utils.events INFO:  eta: 2:05:23  iter: 17259  total_loss: 0.3537  loss_cls: 0.06075  loss_box_reg: 0.181  loss_mask: 0.1097  loss_rpn_cls: 0.001434  loss_rpn_loc: 0.02137  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:18] d2.utils.events INFO:  eta: 2:05:19  iter: 17279  total_loss: 0.3146  loss_cls: 0.04501  loss_box_reg: 0.1528  loss_mask: 0.107  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.01617  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:57:20] d2.utils.events INFO:  eta: 2:05:07  iter: 17299  total_loss: 0.2685  loss_cls: 0.05014  loss_box_reg: 0.1221  loss_mask: 0.08935  loss_rpn_cls: 0.0007158  loss_rpn_loc: 0.01596  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:22] d2.utils.events INFO:  eta: 2:04:53  iter: 17319  total_loss: 0.2268  loss_cls: 0.0323  loss_box_reg: 0.08481  loss_mask: 0.09646  loss_rpn_cls: 0.0005976  loss_rpn_loc: 0.006182  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:24] d2.utils.events INFO:  eta: 2:04:57  iter: 17339  total_loss: 0.3402  loss_cls: 0.04594  loss_box_reg: 0.1522  loss_mask: 0.1218  loss_rpn_cls: 0.002192  loss_rpn_loc: 0.01557  time: 0.1016  data_time: 0.0030  lr: 0.0025  max_mem: 1634M
[10/27 18:57:26] d2.utils.events INFO:  eta: 2:04:49  iter: 17359  total_loss: 0.4007  loss_cls: 0.06738  loss_box_reg: 0.187  loss_mask: 0.1331  loss_rpn_cls: 0.001783  loss_rpn_loc: 0.0292  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:28] d2.utils.events INFO:  eta: 2:04:41  iter: 17379  total_loss: 0.3067  loss_cls: 0.05148  loss_box_reg: 0.1476  loss_mask: 0.09799  loss_rpn_cls: 0.001168  loss_rpn_loc: 0.01289  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:30] d2.utils.events INFO:  eta: 2:04:40  iter: 17399  total_loss: 0.327  loss_cls: 0.05184  loss_box_reg: 0.1296  loss_mask: 0.1095  loss_rpn_cls: 0.0006806  loss_rpn_loc: 0.01461  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:33] d2.utils.events INFO:  eta: 2:04:32  iter: 17419  total_loss: 0.2844  loss_cls: 0.04718  loss_box_reg: 0.1461  loss_mask: 0.11  loss_rpn_cls: 0.001273  loss_rpn_loc: 0.0251  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:35] d2.utils.events INFO:  eta: 2:04:22  iter: 17439  total_loss: 0.2802  loss_cls: 0.04831  loss_box_reg: 0.1072  loss_mask: 0.1022  loss_rpn_cls: 0.001413  loss_rpn_loc: 0.01788  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:37] d2.utils.events INFO:  eta: 2:04:21  iter: 17459  total_loss: 0.2849  loss_cls: 0.04154  loss_box_reg: 0.1102  loss_mask: 0.09628  loss_rpn_cls: 0.001524  loss_rpn_loc: 0.01864  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:39] d2.utils.events INFO:  eta: 2:04:13  iter: 17479  total_loss: 0.2109  loss_cls: 0.0318  loss_box_reg: 0.08616  loss_mask: 0.08482  loss_rpn_cls: 0.001178  loss_rpn_loc: 0.01152  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:41] d2.utils.events INFO:  eta: 2:04:00  iter: 17499  total_loss: 0.2926  loss_cls: 0.04337  loss_box_reg: 0.1442  loss_mask: 0.08578  loss_rpn_cls: 0.001466  loss_rpn_loc: 0.02659  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:57:43] d2.utils.events INFO:  eta: 2:03:58  iter: 17519  total_loss: 0.2972  loss_cls: 0.04919  loss_box_reg: 0.1296  loss_mask: 0.1011  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.016  time: 0.1016  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:57:45] d2.utils.events INFO:  eta: 2:03:52  iter: 17539  total_loss: 0.1976  loss_cls: 0.02891  loss_box_reg: 0.09433  loss_mask: 0.07551  loss_rpn_cls: 0.001391  loss_rpn_loc: 0.009236  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:57:47] d2.utils.events INFO:  eta: 2:03:44  iter: 17559  total_loss: 0.3885  loss_cls: 0.04761  loss_box_reg: 0.1624  loss_mask: 0.1413  loss_rpn_cls: 0.001412  loss_rpn_loc: 0.04527  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:57:49] d2.utils.events INFO:  eta: 2:03:35  iter: 17579  total_loss: 0.2945  loss_cls: 0.04039  loss_box_reg: 0.1166  loss_mask: 0.08245  loss_rpn_cls: 0.0007818  loss_rpn_loc: 0.01824  time: 0.1016  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:57:51] d2.utils.events INFO:  eta: 2:03:30  iter: 17599  total_loss: 0.3848  loss_cls: 0.05973  loss_box_reg: 0.1745  loss_mask: 0.1172  loss_rpn_cls: 0.002304  loss_rpn_loc: 0.02829  time: 0.1016  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:57:53] d2.utils.events INFO:  eta: 2:03:19  iter: 17619  total_loss: 0.2847  loss_cls: 0.04831  loss_box_reg: 0.1463  loss_mask: 0.1076  loss_rpn_cls: 0.0009996  loss_rpn_loc: 0.01334  time: 0.1016  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 18:57:55] d2.utils.events INFO:  eta: 2:03:21  iter: 17639  total_loss: 0.4145  loss_cls: 0.07138  loss_box_reg: 0.1853  loss_mask: 0.1443  loss_rpn_cls: 0.001666  loss_rpn_loc: 0.02614  time: 0.1016  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 18:57:57] d2.utils.events INFO:  eta: 2:03:21  iter: 17659  total_loss: 0.4062  loss_cls: 0.06107  loss_box_reg: 0.1582  loss_mask: 0.1385  loss_rpn_cls: 0.001841  loss_rpn_loc: 0.022  time: 0.1016  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 18:57:59] d2.utils.events INFO:  eta: 2:02:56  iter: 17679  total_loss: 0.3199  loss_cls: 0.04081  loss_box_reg: 0.1362  loss_mask: 0.1108  loss_rpn_cls: 0.001408  loss_rpn_loc: 0.0106  time: 0.1016  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:58:01] d2.utils.events INFO:  eta: 2:02:57  iter: 17699  total_loss: 0.3071  loss_cls: 0.04039  loss_box_reg: 0.1269  loss_mask: 0.1118  loss_rpn_cls: 0.001236  loss_rpn_loc: 0.01947  time: 0.1016  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:58:03] d2.utils.events INFO:  eta: 2:02:52  iter: 17719  total_loss: 0.2664  loss_cls: 0.05189  loss_box_reg: 0.1088  loss_mask: 0.09198  loss_rpn_cls: 0.001604  loss_rpn_loc: 0.02108  time: 0.1016  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 18:58:05] d2.utils.events INFO:  eta: 2:02:49  iter: 17739  total_loss: 0.2192  loss_cls: 0.04352  loss_box_reg: 0.09519  loss_mask: 0.0869  loss_rpn_cls: 0.000903  loss_rpn_loc: 0.02126  time: 0.1015  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:58:07] d2.utils.events INFO:  eta: 2:02:47  iter: 17759  total_loss: 0.3083  loss_cls: 0.05479  loss_box_reg: 0.138  loss_mask: 0.09457  loss_rpn_cls: 0.001396  loss_rpn_loc: 0.02307  time: 0.1015  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 18:58:09] d2.utils.events INFO:  eta: 2:02:45  iter: 17779  total_loss: 0.3077  loss_cls: 0.03535  loss_box_reg: 0.1184  loss_mask: 0.09888  loss_rpn_cls: 0.0005201  loss_rpn_loc: 0.02204  time: 0.1015  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 18:58:11] d2.utils.events INFO:  eta: 2:02:43  iter: 17799  total_loss: 0.2986  loss_cls: 0.04778  loss_box_reg: 0.1258  loss_mask: 0.0803  loss_rpn_cls: 0.0007544  loss_rpn_loc: 0.01842  time: 0.1015  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:58:13] d2.utils.events INFO:  eta: 2:02:41  iter: 17819  total_loss: 0.2625  loss_cls: 0.02822  loss_box_reg: 0.0905  loss_mask: 0.07062  loss_rpn_cls: 0.0008891  loss_rpn_loc: 0.01094  time: 0.1015  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:15] d2.utils.events INFO:  eta: 2:02:35  iter: 17839  total_loss: 0.2501  loss_cls: 0.03015  loss_box_reg: 0.1015  loss_mask: 0.09354  loss_rpn_cls: 0.002151  loss_rpn_loc: 0.0265  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:58:17] d2.utils.events INFO:  eta: 2:02:30  iter: 17859  total_loss: 0.267  loss_cls: 0.03737  loss_box_reg: 0.1101  loss_mask: 0.1082  loss_rpn_cls: 0.001092  loss_rpn_loc: 0.02355  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:19] d2.utils.events INFO:  eta: 2:02:27  iter: 17879  total_loss: 0.3549  loss_cls: 0.06125  loss_box_reg: 0.1536  loss_mask: 0.09913  loss_rpn_cls: 0.001442  loss_rpn_loc: 0.01397  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:58:21] d2.utils.events INFO:  eta: 2:02:21  iter: 17899  total_loss: 0.3468  loss_cls: 0.05013  loss_box_reg: 0.1532  loss_mask: 0.09916  loss_rpn_cls: 0.001417  loss_rpn_loc: 0.03018  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:23] d2.utils.events INFO:  eta: 2:02:18  iter: 17919  total_loss: 0.3628  loss_cls: 0.05654  loss_box_reg: 0.1644  loss_mask: 0.1257  loss_rpn_cls: 0.002532  loss_rpn_loc: 0.02751  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:25] d2.utils.events INFO:  eta: 2:02:16  iter: 17939  total_loss: 0.3418  loss_cls: 0.05024  loss_box_reg: 0.1427  loss_mask: 0.09682  loss_rpn_cls: 0.001277  loss_rpn_loc: 0.02362  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:28] d2.utils.events INFO:  eta: 2:02:20  iter: 17959  total_loss: 0.3835  loss_cls: 0.06092  loss_box_reg: 0.174  loss_mask: 0.1126  loss_rpn_cls: 0.0033  loss_rpn_loc: 0.02262  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:30] d2.utils.events INFO:  eta: 2:02:17  iter: 17979  total_loss: 0.2993  loss_cls: 0.04369  loss_box_reg: 0.1309  loss_mask: 0.09934  loss_rpn_cls: 0.001827  loss_rpn_loc: 0.03077  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:32] d2.utils.events INFO:  eta: 2:02:16  iter: 17999  total_loss: 0.2521  loss_cls: 0.04551  loss_box_reg: 0.1141  loss_mask: 0.09483  loss_rpn_cls: 0.0009779  loss_rpn_loc: 0.01622  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:34] d2.utils.events INFO:  eta: 2:02:14  iter: 18019  total_loss: 0.3129  loss_cls: 0.05457  loss_box_reg: 0.15  loss_mask: 0.1045  loss_rpn_cls: 0.001367  loss_rpn_loc: 0.0238  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:36] d2.utils.events INFO:  eta: 2:02:03  iter: 18039  total_loss: 0.2396  loss_cls: 0.04073  loss_box_reg: 0.1111  loss_mask: 0.1029  loss_rpn_cls: 0.001817  loss_rpn_loc: 0.02008  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:38] d2.utils.events INFO:  eta: 2:01:43  iter: 18059  total_loss: 0.3022  loss_cls: 0.05096  loss_box_reg: 0.1135  loss_mask: 0.09277  loss_rpn_cls: 0.00125  loss_rpn_loc: 0.01982  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:58:40] d2.utils.events INFO:  eta: 2:01:43  iter: 18079  total_loss: 0.348  loss_cls: 0.04761  loss_box_reg: 0.1564  loss_mask: 0.1017  loss_rpn_cls: 0.001526  loss_rpn_loc: 0.02256  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:42] d2.utils.events INFO:  eta: 2:01:40  iter: 18099  total_loss: 0.2759  loss_cls: 0.03414  loss_box_reg: 0.1103  loss_mask: 0.08571  loss_rpn_cls: 0.0007738  loss_rpn_loc: 0.01199  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:44] d2.utils.events INFO:  eta: 2:01:36  iter: 18119  total_loss: 0.2045  loss_cls: 0.03574  loss_box_reg: 0.08407  loss_mask: 0.07853  loss_rpn_cls: 0.0007586  loss_rpn_loc: 0.01286  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:46] d2.utils.events INFO:  eta: 2:01:35  iter: 18139  total_loss: 0.3743  loss_cls: 0.06524  loss_box_reg: 0.1614  loss_mask: 0.1266  loss_rpn_cls: 0.00146  loss_rpn_loc: 0.02944  time: 0.1016  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 18:58:48] d2.utils.events INFO:  eta: 2:01:33  iter: 18159  total_loss: 0.2775  loss_cls: 0.03756  loss_box_reg: 0.09859  loss_mask: 0.09419  loss_rpn_cls: 0.001401  loss_rpn_loc: 0.01912  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:50] d2.utils.events INFO:  eta: 2:01:29  iter: 18179  total_loss: 0.3361  loss_cls: 0.05241  loss_box_reg: 0.1463  loss_mask: 0.118  loss_rpn_cls: 0.002796  loss_rpn_loc: 0.03769  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:53] d2.utils.events INFO:  eta: 2:01:26  iter: 18199  total_loss: 0.2155  loss_cls: 0.03139  loss_box_reg: 0.08205  loss_mask: 0.07478  loss_rpn_cls: 0.001415  loss_rpn_loc: 0.0136  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:55] d2.utils.events INFO:  eta: 2:01:27  iter: 18219  total_loss: 0.3246  loss_cls: 0.04985  loss_box_reg: 0.1014  loss_mask: 0.1096  loss_rpn_cls: 0.001297  loss_rpn_loc: 0.01805  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:58:57] d2.utils.events INFO:  eta: 2:01:33  iter: 18239  total_loss: 0.3614  loss_cls: 0.06007  loss_box_reg: 0.1441  loss_mask: 0.1083  loss_rpn_cls: 0.001679  loss_rpn_loc: 0.02755  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:58:59] d2.utils.events INFO:  eta: 2:01:43  iter: 18259  total_loss: 0.2896  loss_cls: 0.04693  loss_box_reg: 0.1258  loss_mask: 0.09724  loss_rpn_cls: 0.001282  loss_rpn_loc: 0.02413  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:59:01] d2.utils.events INFO:  eta: 2:01:40  iter: 18279  total_loss: 0.3033  loss_cls: 0.04098  loss_box_reg: 0.1208  loss_mask: 0.1028  loss_rpn_cls: 0.00169  loss_rpn_loc: 0.01599  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:03] d2.utils.events INFO:  eta: 2:01:49  iter: 18299  total_loss: 0.3209  loss_cls: 0.05063  loss_box_reg: 0.1315  loss_mask: 0.0839  loss_rpn_cls: 0.002551  loss_rpn_loc: 0.04433  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:05] d2.utils.events INFO:  eta: 2:01:50  iter: 18319  total_loss: 0.3036  loss_cls: 0.05775  loss_box_reg: 0.1364  loss_mask: 0.09708  loss_rpn_cls: 0.0006704  loss_rpn_loc: 0.01705  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:07] d2.utils.events INFO:  eta: 2:01:47  iter: 18339  total_loss: 0.4073  loss_cls: 0.05833  loss_box_reg: 0.1524  loss_mask: 0.1034  loss_rpn_cls: 0.002495  loss_rpn_loc: 0.02451  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:59:09] d2.utils.events INFO:  eta: 2:01:46  iter: 18359  total_loss: 0.3235  loss_cls: 0.05885  loss_box_reg: 0.1391  loss_mask: 0.1141  loss_rpn_cls: 0.002715  loss_rpn_loc: 0.03028  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:59:11] d2.utils.events INFO:  eta: 2:01:44  iter: 18379  total_loss: 0.2721  loss_cls: 0.04952  loss_box_reg: 0.1141  loss_mask: 0.0835  loss_rpn_cls: 0.004194  loss_rpn_loc: 0.0162  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:59:13] d2.utils.events INFO:  eta: 2:01:42  iter: 18399  total_loss: 0.3048  loss_cls: 0.04618  loss_box_reg: 0.1508  loss_mask: 0.088  loss_rpn_cls: 0.001562  loss_rpn_loc: 0.01869  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:16] d2.utils.events INFO:  eta: 2:01:49  iter: 18419  total_loss: 0.3126  loss_cls: 0.05433  loss_box_reg: 0.162  loss_mask: 0.095  loss_rpn_cls: 0.001536  loss_rpn_loc: 0.01791  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:18] d2.utils.events INFO:  eta: 2:01:59  iter: 18439  total_loss: 0.2739  loss_cls: 0.04928  loss_box_reg: 0.1381  loss_mask: 0.09425  loss_rpn_cls: 0.001918  loss_rpn_loc: 0.01611  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:59:20] d2.utils.events INFO:  eta: 2:01:55  iter: 18459  total_loss: 0.2818  loss_cls: 0.02808  loss_box_reg: 0.08886  loss_mask: 0.09406  loss_rpn_cls: 0.0007891  loss_rpn_loc: 0.02021  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:22] d2.utils.events INFO:  eta: 2:02:06  iter: 18479  total_loss: 0.3427  loss_cls: 0.05751  loss_box_reg: 0.143  loss_mask: 0.109  loss_rpn_cls: 0.002324  loss_rpn_loc: 0.03241  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:24] d2.utils.events INFO:  eta: 2:02:04  iter: 18499  total_loss: 0.3773  loss_cls: 0.04539  loss_box_reg: 0.1686  loss_mask: 0.1114  loss_rpn_cls: 0.002819  loss_rpn_loc: 0.02032  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:59:26] d2.utils.events INFO:  eta: 2:02:04  iter: 18519  total_loss: 0.3146  loss_cls: 0.03837  loss_box_reg: 0.1146  loss_mask: 0.1143  loss_rpn_cls: 0.0008336  loss_rpn_loc: 0.01549  time: 0.1016  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 18:59:28] d2.utils.events INFO:  eta: 2:02:01  iter: 18539  total_loss: 0.2284  loss_cls: 0.03569  loss_box_reg: 0.111  loss_mask: 0.07523  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.008877  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:30] d2.utils.events INFO:  eta: 2:01:59  iter: 18559  total_loss: 0.2891  loss_cls: 0.05137  loss_box_reg: 0.1067  loss_mask: 0.09805  loss_rpn_cls: 0.00205  loss_rpn_loc: 0.02555  time: 0.1016  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 18:59:32] d2.utils.events INFO:  eta: 2:01:59  iter: 18579  total_loss: 0.3256  loss_cls: 0.0447  loss_box_reg: 0.1486  loss_mask: 0.1061  loss_rpn_cls: 0.002992  loss_rpn_loc: 0.02546  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:34] d2.utils.events INFO:  eta: 2:01:57  iter: 18599  total_loss: 0.3032  loss_cls: 0.04592  loss_box_reg: 0.1209  loss_mask: 0.1038  loss_rpn_cls: 0.001882  loss_rpn_loc: 0.03041  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:36] d2.utils.events INFO:  eta: 2:02:01  iter: 18619  total_loss: 0.2746  loss_cls: 0.03463  loss_box_reg: 0.1176  loss_mask: 0.08605  loss_rpn_cls: 0.003196  loss_rpn_loc: 0.02361  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 18:59:38] d2.utils.events INFO:  eta: 2:01:52  iter: 18639  total_loss: 0.2723  loss_cls: 0.03351  loss_box_reg: 0.1112  loss_mask: 0.09827  loss_rpn_cls: 0.001452  loss_rpn_loc: 0.03175  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:40] d2.utils.events INFO:  eta: 2:01:55  iter: 18659  total_loss: 0.3413  loss_cls: 0.05561  loss_box_reg: 0.1536  loss_mask: 0.1051  loss_rpn_cls: 0.001489  loss_rpn_loc: 0.017  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:42] d2.utils.events INFO:  eta: 2:02:05  iter: 18679  total_loss: 0.3029  loss_cls: 0.04654  loss_box_reg: 0.08914  loss_mask: 0.08725  loss_rpn_cls: 0.0008545  loss_rpn_loc: 0.02399  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:44] d2.utils.events INFO:  eta: 2:02:03  iter: 18699  total_loss: 0.3405  loss_cls: 0.059  loss_box_reg: 0.1445  loss_mask: 0.1016  loss_rpn_cls: 0.000734  loss_rpn_loc: 0.01682  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:47] d2.utils.events INFO:  eta: 2:02:15  iter: 18719  total_loss: 0.2016  loss_cls: 0.0317  loss_box_reg: 0.08306  loss_mask: 0.08071  loss_rpn_cls: 0.0009532  loss_rpn_loc: 0.01414  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:59:49] d2.utils.events INFO:  eta: 2:02:27  iter: 18739  total_loss: 0.311  loss_cls: 0.05744  loss_box_reg: 0.1314  loss_mask: 0.08886  loss_rpn_cls: 0.001049  loss_rpn_loc: 0.0207  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:51] d2.utils.events INFO:  eta: 2:02:28  iter: 18759  total_loss: 0.331  loss_cls: 0.04476  loss_box_reg: 0.1457  loss_mask: 0.09786  loss_rpn_cls: 0.002597  loss_rpn_loc: 0.0332  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 18:59:53] d2.utils.events INFO:  eta: 2:02:27  iter: 18779  total_loss: 0.2517  loss_cls: 0.02777  loss_box_reg: 0.1005  loss_mask: 0.08318  loss_rpn_cls: 0.0007243  loss_rpn_loc: 0.01473  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 18:59:55] d2.utils.events INFO:  eta: 2:02:26  iter: 18799  total_loss: 0.3635  loss_cls: 0.05364  loss_box_reg: 0.1612  loss_mask: 0.1103  loss_rpn_cls: 0.001613  loss_rpn_loc: 0.0272  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:59:57] d2.utils.events INFO:  eta: 2:02:22  iter: 18819  total_loss: 0.4169  loss_cls: 0.06304  loss_box_reg: 0.1738  loss_mask: 0.1379  loss_rpn_cls: 0.002299  loss_rpn_loc: 0.03323  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 18:59:59] d2.utils.events INFO:  eta: 2:02:21  iter: 18839  total_loss: 0.3346  loss_cls: 0.04251  loss_box_reg: 0.1466  loss_mask: 0.09567  loss_rpn_cls: 0.001557  loss_rpn_loc: 0.03666  time: 0.1016  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:00:01] d2.utils.events INFO:  eta: 2:02:23  iter: 18859  total_loss: 0.2462  loss_cls: 0.04621  loss_box_reg: 0.1108  loss_mask: 0.08839  loss_rpn_cls: 0.0005515  loss_rpn_loc: 0.01901  time: 0.1016  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:03] d2.utils.events INFO:  eta: 2:02:29  iter: 18879  total_loss: 0.2793  loss_cls: 0.05787  loss_box_reg: 0.1164  loss_mask: 0.09412  loss_rpn_cls: 0.002872  loss_rpn_loc: 0.01857  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:05] d2.utils.events INFO:  eta: 2:02:16  iter: 18899  total_loss: 0.3624  loss_cls: 0.06749  loss_box_reg: 0.1618  loss_mask: 0.1224  loss_rpn_cls: 0.001723  loss_rpn_loc: 0.02013  time: 0.1016  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:07] d2.utils.events INFO:  eta: 2:02:14  iter: 18919  total_loss: 0.2861  loss_cls: 0.04452  loss_box_reg: 0.1177  loss_mask: 0.1017  loss_rpn_cls: 0.0007944  loss_rpn_loc: 0.01434  time: 0.1016  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:09] d2.utils.events INFO:  eta: 2:02:12  iter: 18939  total_loss: 0.2954  loss_cls: 0.03986  loss_box_reg: 0.1088  loss_mask: 0.09415  loss_rpn_cls: 0.001117  loss_rpn_loc: 0.02059  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:11] d2.utils.events INFO:  eta: 2:02:05  iter: 18959  total_loss: 0.2816  loss_cls: 0.04503  loss_box_reg: 0.1292  loss_mask: 0.08573  loss_rpn_cls: 0.001657  loss_rpn_loc: 0.01295  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:00:13] d2.utils.events INFO:  eta: 2:02:01  iter: 18979  total_loss: 0.2853  loss_cls: 0.0466  loss_box_reg: 0.1287  loss_mask: 0.1102  loss_rpn_cls: 0.001098  loss_rpn_loc: 0.0126  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:15] d2.utils.events INFO:  eta: 2:01:49  iter: 18999  total_loss: 0.3372  loss_cls: 0.05512  loss_box_reg: 0.1424  loss_mask: 0.1246  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.01693  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:18] d2.utils.events INFO:  eta: 2:01:52  iter: 19019  total_loss: 0.3517  loss_cls: 0.0598  loss_box_reg: 0.1571  loss_mask: 0.09716  loss_rpn_cls: 0.0009163  loss_rpn_loc: 0.03677  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:00:20] d2.utils.events INFO:  eta: 2:01:58  iter: 19039  total_loss: 0.3087  loss_cls: 0.0438  loss_box_reg: 0.1352  loss_mask: 0.09125  loss_rpn_cls: 0.001345  loss_rpn_loc: 0.01244  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:00:22] d2.utils.events INFO:  eta: 2:01:54  iter: 19059  total_loss: 0.2436  loss_cls: 0.0373  loss_box_reg: 0.1099  loss_mask: 0.06817  loss_rpn_cls: 0.0003868  loss_rpn_loc: 0.01558  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:24] d2.utils.events INFO:  eta: 2:01:54  iter: 19079  total_loss: 0.3593  loss_cls: 0.05133  loss_box_reg: 0.1859  loss_mask: 0.09534  loss_rpn_cls: 0.002502  loss_rpn_loc: 0.02209  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:26] d2.utils.events INFO:  eta: 2:01:53  iter: 19099  total_loss: 0.3667  loss_cls: 0.06272  loss_box_reg: 0.1717  loss_mask: 0.1188  loss_rpn_cls: 0.002503  loss_rpn_loc: 0.03599  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:28] d2.utils.events INFO:  eta: 2:02:00  iter: 19119  total_loss: 0.3979  loss_cls: 0.07444  loss_box_reg: 0.1969  loss_mask: 0.1175  loss_rpn_cls: 0.001461  loss_rpn_loc: 0.02421  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:00:30] d2.utils.events INFO:  eta: 2:01:54  iter: 19139  total_loss: 0.2498  loss_cls: 0.03575  loss_box_reg: 0.1074  loss_mask: 0.08912  loss_rpn_cls: 0.0009588  loss_rpn_loc: 0.01578  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:32] d2.utils.events INFO:  eta: 2:01:58  iter: 19159  total_loss: 0.3755  loss_cls: 0.0512  loss_box_reg: 0.1494  loss_mask: 0.1339  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.03227  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:34] d2.utils.events INFO:  eta: 2:01:54  iter: 19179  total_loss: 0.1925  loss_cls: 0.02605  loss_box_reg: 0.06537  loss_mask: 0.07552  loss_rpn_cls: 0.003191  loss_rpn_loc: 0.01357  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:36] d2.utils.events INFO:  eta: 2:01:54  iter: 19199  total_loss: 0.2543  loss_cls: 0.03562  loss_box_reg: 0.1158  loss_mask: 0.08568  loss_rpn_cls: 0.001245  loss_rpn_loc: 0.0164  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:38] d2.utils.events INFO:  eta: 2:01:50  iter: 19219  total_loss: 0.2688  loss_cls: 0.03894  loss_box_reg: 0.1005  loss_mask: 0.08097  loss_rpn_cls: 0.001459  loss_rpn_loc: 0.01818  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:40] d2.utils.events INFO:  eta: 2:01:41  iter: 19239  total_loss: 0.2629  loss_cls: 0.02753  loss_box_reg: 0.08168  loss_mask: 0.1046  loss_rpn_cls: 0.001254  loss_rpn_loc: 0.01538  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:00:42] d2.utils.events INFO:  eta: 2:01:33  iter: 19259  total_loss: 0.2326  loss_cls: 0.03841  loss_box_reg: 0.08633  loss_mask: 0.08493  loss_rpn_cls: 0.001181  loss_rpn_loc: 0.02177  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:45] d2.utils.events INFO:  eta: 2:01:35  iter: 19279  total_loss: 0.3456  loss_cls: 0.05866  loss_box_reg: 0.1486  loss_mask: 0.09703  loss_rpn_cls: 0.002127  loss_rpn_loc: 0.0223  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:47] d2.utils.events INFO:  eta: 2:01:33  iter: 19299  total_loss: 0.2411  loss_cls: 0.02912  loss_box_reg: 0.1118  loss_mask: 0.08063  loss_rpn_cls: 0.001444  loss_rpn_loc: 0.01699  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:49] d2.utils.events INFO:  eta: 2:01:30  iter: 19319  total_loss: 0.3217  loss_cls: 0.04278  loss_box_reg: 0.1527  loss_mask: 0.08588  loss_rpn_cls: 0.0009359  loss_rpn_loc: 0.01947  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:00:51] d2.utils.events INFO:  eta: 2:01:26  iter: 19339  total_loss: 0.2066  loss_cls: 0.03084  loss_box_reg: 0.08888  loss_mask: 0.08421  loss_rpn_cls: 0.001239  loss_rpn_loc: 0.01608  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:53] d2.utils.events INFO:  eta: 2:01:17  iter: 19359  total_loss: 0.3384  loss_cls: 0.05108  loss_box_reg: 0.1392  loss_mask: 0.1198  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.02447  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:00:55] d2.utils.events INFO:  eta: 2:01:21  iter: 19379  total_loss: 0.3653  loss_cls: 0.05551  loss_box_reg: 0.1654  loss_mask: 0.1004  loss_rpn_cls: 0.001241  loss_rpn_loc: 0.02376  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:57] d2.utils.events INFO:  eta: 2:01:17  iter: 19399  total_loss: 0.3175  loss_cls: 0.04016  loss_box_reg: 0.1479  loss_mask: 0.1097  loss_rpn_cls: 0.001691  loss_rpn_loc: 0.03276  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:00:59] d2.utils.events INFO:  eta: 2:01:13  iter: 19419  total_loss: 0.4179  loss_cls: 0.07098  loss_box_reg: 0.1789  loss_mask: 0.1099  loss_rpn_cls: 0.001529  loss_rpn_loc: 0.03174  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:01:01] d2.utils.events INFO:  eta: 2:01:09  iter: 19439  total_loss: 0.2451  loss_cls: 0.03557  loss_box_reg: 0.09485  loss_mask: 0.09801  loss_rpn_cls: 0.001126  loss_rpn_loc: 0.01919  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:03] d2.utils.events INFO:  eta: 2:01:14  iter: 19459  total_loss: 0.2756  loss_cls: 0.04851  loss_box_reg: 0.1221  loss_mask: 0.09558  loss_rpn_cls: 0.001012  loss_rpn_loc: 0.01571  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:01:05] d2.utils.events INFO:  eta: 2:01:04  iter: 19479  total_loss: 0.2694  loss_cls: 0.03504  loss_box_reg: 0.07709  loss_mask: 0.09498  loss_rpn_cls: 0.0009528  loss_rpn_loc: 0.0089  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:01:07] d2.utils.events INFO:  eta: 2:00:57  iter: 19499  total_loss: 0.2315  loss_cls: 0.04217  loss_box_reg: 0.1069  loss_mask: 0.08994  loss_rpn_cls: 0.001759  loss_rpn_loc: 0.009834  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:01:09] d2.utils.events INFO:  eta: 2:00:53  iter: 19519  total_loss: 0.2652  loss_cls: 0.04512  loss_box_reg: 0.1212  loss_mask: 0.07903  loss_rpn_cls: 0.001627  loss_rpn_loc: 0.03432  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:01:11] d2.utils.events INFO:  eta: 2:00:53  iter: 19539  total_loss: 0.2551  loss_cls: 0.03677  loss_box_reg: 0.08426  loss_mask: 0.1114  loss_rpn_cls: 0.0006586  loss_rpn_loc: 0.01635  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:01:13] d2.utils.events INFO:  eta: 2:00:51  iter: 19559  total_loss: 0.3369  loss_cls: 0.04052  loss_box_reg: 0.1384  loss_mask: 0.09522  loss_rpn_cls: 0.001362  loss_rpn_loc: 0.02308  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:15] d2.utils.events INFO:  eta: 2:00:48  iter: 19579  total_loss: 0.3849  loss_cls: 0.0512  loss_box_reg: 0.1748  loss_mask: 0.129  loss_rpn_cls: 0.001692  loss_rpn_loc: 0.03149  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:17] d2.utils.events INFO:  eta: 2:00:46  iter: 19599  total_loss: 0.3256  loss_cls: 0.05583  loss_box_reg: 0.1205  loss_mask: 0.1209  loss_rpn_cls: 0.001762  loss_rpn_loc: 0.0197  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:19] d2.utils.events INFO:  eta: 2:00:44  iter: 19619  total_loss: 0.2117  loss_cls: 0.03218  loss_box_reg: 0.06893  loss_mask: 0.07267  loss_rpn_cls: 0.0005029  loss_rpn_loc: 0.01319  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:21] d2.utils.events INFO:  eta: 2:00:43  iter: 19639  total_loss: 0.2827  loss_cls: 0.04762  loss_box_reg: 0.1219  loss_mask: 0.08433  loss_rpn_cls: 0.0007904  loss_rpn_loc: 0.01848  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:01:23] d2.utils.events INFO:  eta: 2:00:31  iter: 19659  total_loss: 0.3122  loss_cls: 0.04467  loss_box_reg: 0.1206  loss_mask: 0.1192  loss_rpn_cls: 0.00157  loss_rpn_loc: 0.02642  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:25] d2.utils.events INFO:  eta: 2:00:30  iter: 19679  total_loss: 0.2389  loss_cls: 0.03888  loss_box_reg: 0.105  loss_mask: 0.09385  loss_rpn_cls: 0.0008782  loss_rpn_loc: 0.01562  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:28] d2.utils.events INFO:  eta: 2:00:33  iter: 19699  total_loss: 0.3194  loss_cls: 0.05713  loss_box_reg: 0.1527  loss_mask: 0.114  loss_rpn_cls: 0.003949  loss_rpn_loc: 0.02475  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:01:30] d2.utils.events INFO:  eta: 2:00:26  iter: 19719  total_loss: 0.2684  loss_cls: 0.04499  loss_box_reg: 0.09853  loss_mask: 0.1003  loss_rpn_cls: 0.0007113  loss_rpn_loc: 0.01483  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:32] d2.utils.events INFO:  eta: 2:00:24  iter: 19739  total_loss: 0.2945  loss_cls: 0.04094  loss_box_reg: 0.149  loss_mask: 0.08929  loss_rpn_cls: 0.001216  loss_rpn_loc: 0.01629  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:34] d2.utils.events INFO:  eta: 2:00:20  iter: 19759  total_loss: 0.3672  loss_cls: 0.05336  loss_box_reg: 0.152  loss_mask: 0.102  loss_rpn_cls: 0.003642  loss_rpn_loc: 0.03418  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:36] d2.utils.events INFO:  eta: 2:00:20  iter: 19779  total_loss: 0.2998  loss_cls: 0.04006  loss_box_reg: 0.1275  loss_mask: 0.09589  loss_rpn_cls: 0.001181  loss_rpn_loc: 0.01991  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:38] d2.utils.events INFO:  eta: 2:00:18  iter: 19799  total_loss: 0.314  loss_cls: 0.04694  loss_box_reg: 0.1348  loss_mask: 0.09954  loss_rpn_cls: 0.001408  loss_rpn_loc: 0.0296  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:40] d2.utils.events INFO:  eta: 2:00:14  iter: 19819  total_loss: 0.2619  loss_cls: 0.039  loss_box_reg: 0.1226  loss_mask: 0.08142  loss_rpn_cls: 0.002818  loss_rpn_loc: 0.01161  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:42] d2.utils.events INFO:  eta: 2:00:10  iter: 19839  total_loss: 0.2902  loss_cls: 0.05081  loss_box_reg: 0.1243  loss_mask: 0.1239  loss_rpn_cls: 0.00213  loss_rpn_loc: 0.01795  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:44] d2.utils.events INFO:  eta: 1:59:51  iter: 19859  total_loss: 0.2688  loss_cls: 0.03841  loss_box_reg: 0.1096  loss_mask: 0.1039  loss_rpn_cls: 0.0009152  loss_rpn_loc: 0.01355  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:01:46] d2.utils.events INFO:  eta: 1:59:42  iter: 19879  total_loss: 0.3406  loss_cls: 0.04698  loss_box_reg: 0.1773  loss_mask: 0.1068  loss_rpn_cls: 0.0007924  loss_rpn_loc: 0.02424  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:48] d2.utils.events INFO:  eta: 1:59:46  iter: 19899  total_loss: 0.294  loss_cls: 0.04547  loss_box_reg: 0.1309  loss_mask: 0.1032  loss_rpn_cls: 0.001786  loss_rpn_loc: 0.02256  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:50] d2.utils.events INFO:  eta: 1:59:45  iter: 19919  total_loss: 0.3084  loss_cls: 0.04441  loss_box_reg: 0.1321  loss_mask: 0.08901  loss_rpn_cls: 0.00142  loss_rpn_loc: 0.0126  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:01:52] d2.utils.events INFO:  eta: 1:59:39  iter: 19939  total_loss: 0.3061  loss_cls: 0.05347  loss_box_reg: 0.1148  loss_mask: 0.08272  loss_rpn_cls: 0.001859  loss_rpn_loc: 0.01912  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:01:54] d2.utils.events INFO:  eta: 1:59:39  iter: 19959  total_loss: 0.3099  loss_cls: 0.04502  loss_box_reg: 0.1268  loss_mask: 0.09081  loss_rpn_cls: 0.002627  loss_rpn_loc: 0.01698  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:01:56] d2.utils.events INFO:  eta: 1:59:35  iter: 19979  total_loss: 0.3031  loss_cls: 0.05884  loss_box_reg: 0.1357  loss_mask: 0.09267  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.02293  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:01:58] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0019999.pth
[10/27 19:01:59] d2.utils.events INFO:  eta: 1:59:36  iter: 19999  total_loss: 0.3817  loss_cls: 0.05201  loss_box_reg: 0.1295  loss_mask: 0.1155  loss_rpn_cls: 0.001426  loss_rpn_loc: 0.03266  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:01] d2.utils.events INFO:  eta: 1:59:25  iter: 20019  total_loss: 0.2521  loss_cls: 0.03323  loss_box_reg: 0.0914  loss_mask: 0.07775  loss_rpn_cls: 0.0008346  loss_rpn_loc: 0.01427  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:02:03] d2.utils.events INFO:  eta: 1:59:18  iter: 20039  total_loss: 0.2685  loss_cls: 0.04484  loss_box_reg: 0.1311  loss_mask: 0.09357  loss_rpn_cls: 0.001731  loss_rpn_loc: 0.0184  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:02:05] d2.utils.events INFO:  eta: 1:59:18  iter: 20059  total_loss: 0.2129  loss_cls: 0.04864  loss_box_reg: 0.07186  loss_mask: 0.1002  loss_rpn_cls: 0.001336  loss_rpn_loc: 0.03178  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:02:07] d2.utils.events INFO:  eta: 1:59:14  iter: 20079  total_loss: 0.29  loss_cls: 0.04604  loss_box_reg: 0.1322  loss_mask: 0.084  loss_rpn_cls: 0.004228  loss_rpn_loc: 0.01571  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:02:09] d2.utils.events INFO:  eta: 1:59:07  iter: 20099  total_loss: 0.2478  loss_cls: 0.04786  loss_box_reg: 0.09079  loss_mask: 0.09335  loss_rpn_cls: 0.002616  loss_rpn_loc: 0.01712  time: 0.1017  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 19:02:11] d2.utils.events INFO:  eta: 1:59:07  iter: 20119  total_loss: 0.3737  loss_cls: 0.05446  loss_box_reg: 0.1611  loss_mask: 0.1137  loss_rpn_cls: 0.001024  loss_rpn_loc: 0.0243  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:02:13] d2.utils.events INFO:  eta: 1:59:01  iter: 20139  total_loss: 0.2589  loss_cls: 0.03596  loss_box_reg: 0.09634  loss_mask: 0.08813  loss_rpn_cls: 0.0007772  loss_rpn_loc: 0.01887  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:02:15] d2.utils.events INFO:  eta: 1:58:47  iter: 20159  total_loss: 0.2884  loss_cls: 0.03551  loss_box_reg: 0.1402  loss_mask: 0.1004  loss_rpn_cls: 0.0008953  loss_rpn_loc: 0.01572  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:02:17] d2.utils.events INFO:  eta: 1:58:40  iter: 20179  total_loss: 0.2526  loss_cls: 0.03335  loss_box_reg: 0.1151  loss_mask: 0.08134  loss_rpn_cls: 0.0009271  loss_rpn_loc: 0.01572  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:02:19] d2.utils.events INFO:  eta: 1:58:25  iter: 20199  total_loss: 0.2351  loss_cls: 0.04051  loss_box_reg: 0.09048  loss_mask: 0.0748  loss_rpn_cls: 0.0006858  loss_rpn_loc: 0.01435  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:02:21] d2.utils.events INFO:  eta: 1:58:18  iter: 20219  total_loss: 0.3847  loss_cls: 0.05668  loss_box_reg: 0.1688  loss_mask: 0.1095  loss_rpn_cls: 0.001255  loss_rpn_loc: 0.02569  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:02:23] d2.utils.events INFO:  eta: 1:58:22  iter: 20239  total_loss: 0.2768  loss_cls: 0.04096  loss_box_reg: 0.1204  loss_mask: 0.1018  loss_rpn_cls: 0.002442  loss_rpn_loc: 0.01581  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:25] d2.utils.events INFO:  eta: 1:58:19  iter: 20259  total_loss: 0.2115  loss_cls: 0.02409  loss_box_reg: 0.06602  loss_mask: 0.09321  loss_rpn_cls: 0.001953  loss_rpn_loc: 0.02901  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:27] d2.utils.events INFO:  eta: 1:57:58  iter: 20279  total_loss: 0.2542  loss_cls: 0.03748  loss_box_reg: 0.1336  loss_mask: 0.08112  loss_rpn_cls: 0.0007891  loss_rpn_loc: 0.01644  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:29] d2.utils.events INFO:  eta: 1:57:53  iter: 20299  total_loss: 0.3471  loss_cls: 0.0457  loss_box_reg: 0.1568  loss_mask: 0.1021  loss_rpn_cls: 0.001576  loss_rpn_loc: 0.02392  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:31] d2.utils.events INFO:  eta: 1:57:50  iter: 20319  total_loss: 0.2614  loss_cls: 0.04178  loss_box_reg: 0.1332  loss_mask: 0.09233  loss_rpn_cls: 0.001318  loss_rpn_loc: 0.01988  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:02:33] d2.utils.events INFO:  eta: 1:57:59  iter: 20339  total_loss: 0.3343  loss_cls: 0.06084  loss_box_reg: 0.144  loss_mask: 0.1109  loss_rpn_cls: 0.001501  loss_rpn_loc: 0.01722  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:36] d2.utils.events INFO:  eta: 1:58:04  iter: 20359  total_loss: 0.3529  loss_cls: 0.05402  loss_box_reg: 0.1518  loss_mask: 0.1214  loss_rpn_cls: 0.003173  loss_rpn_loc: 0.03174  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:38] d2.utils.events INFO:  eta: 1:57:59  iter: 20379  total_loss: 0.3016  loss_cls: 0.04902  loss_box_reg: 0.1394  loss_mask: 0.09551  loss_rpn_cls: 0.0009062  loss_rpn_loc: 0.02581  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:02:40] d2.utils.events INFO:  eta: 1:57:45  iter: 20399  total_loss: 0.2268  loss_cls: 0.03595  loss_box_reg: 0.09561  loss_mask: 0.09828  loss_rpn_cls: 0.0008094  loss_rpn_loc: 0.01195  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:02:42] d2.utils.events INFO:  eta: 1:57:33  iter: 20419  total_loss: 0.2443  loss_cls: 0.03586  loss_box_reg: 0.09565  loss_mask: 0.08578  loss_rpn_cls: 0.0005021  loss_rpn_loc: 0.01279  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:02:44] d2.utils.events INFO:  eta: 1:57:32  iter: 20439  total_loss: 0.2521  loss_cls: 0.03529  loss_box_reg: 0.09501  loss_mask: 0.09448  loss_rpn_cls: 0.0006951  loss_rpn_loc: 0.009629  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:46] d2.utils.events INFO:  eta: 1:57:20  iter: 20459  total_loss: 0.3181  loss_cls: 0.05053  loss_box_reg: 0.1418  loss_mask: 0.07967  loss_rpn_cls: 0.001644  loss_rpn_loc: 0.02545  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:48] d2.utils.events INFO:  eta: 1:57:11  iter: 20479  total_loss: 0.3419  loss_cls: 0.05773  loss_box_reg: 0.146  loss_mask: 0.1208  loss_rpn_cls: 0.002502  loss_rpn_loc: 0.03981  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:50] d2.utils.events INFO:  eta: 1:57:12  iter: 20499  total_loss: 0.3222  loss_cls: 0.04119  loss_box_reg: 0.09585  loss_mask: 0.1116  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.01935  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:02:52] d2.utils.events INFO:  eta: 1:57:03  iter: 20519  total_loss: 0.2581  loss_cls: 0.04559  loss_box_reg: 0.09972  loss_mask: 0.08789  loss_rpn_cls: 0.001059  loss_rpn_loc: 0.01518  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:54] d2.utils.events INFO:  eta: 1:57:01  iter: 20539  total_loss: 0.273  loss_cls: 0.03922  loss_box_reg: 0.1327  loss_mask: 0.1009  loss_rpn_cls: 0.001454  loss_rpn_loc: 0.01634  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:02:56] d2.utils.events INFO:  eta: 1:56:59  iter: 20559  total_loss: 0.3286  loss_cls: 0.04274  loss_box_reg: 0.121  loss_mask: 0.09293  loss_rpn_cls: 0.0008647  loss_rpn_loc: 0.0123  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:02:58] d2.utils.events INFO:  eta: 1:56:48  iter: 20579  total_loss: 0.224  loss_cls: 0.03386  loss_box_reg: 0.09827  loss_mask: 0.08506  loss_rpn_cls: 0.001263  loss_rpn_loc: 0.01754  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:03:00] d2.utils.events INFO:  eta: 1:56:40  iter: 20599  total_loss: 0.3826  loss_cls: 0.06862  loss_box_reg: 0.1526  loss_mask: 0.1094  loss_rpn_cls: 0.001328  loss_rpn_loc: 0.0265  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:03:02] d2.utils.events INFO:  eta: 1:56:34  iter: 20619  total_loss: 0.2751  loss_cls: 0.04735  loss_box_reg: 0.106  loss_mask: 0.08328  loss_rpn_cls: 0.001329  loss_rpn_loc: 0.02751  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:03:04] d2.utils.events INFO:  eta: 1:56:38  iter: 20639  total_loss: 0.3023  loss_cls: 0.04702  loss_box_reg: 0.1266  loss_mask: 0.09493  loss_rpn_cls: 0.001394  loss_rpn_loc: 0.02251  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:03:06] d2.utils.events INFO:  eta: 1:56:47  iter: 20659  total_loss: 0.2936  loss_cls: 0.03721  loss_box_reg: 0.1316  loss_mask: 0.09139  loss_rpn_cls: 0.0007493  loss_rpn_loc: 0.02003  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:03:08] d2.utils.events INFO:  eta: 1:56:46  iter: 20679  total_loss: 0.3356  loss_cls: 0.05313  loss_box_reg: 0.1486  loss_mask: 0.1057  loss_rpn_cls: 0.002468  loss_rpn_loc: 0.02565  time: 0.1017  data_time: 0.0021  lr: 0.0025  max_mem: 1634M
[10/27 19:03:10] d2.utils.events INFO:  eta: 1:56:45  iter: 20699  total_loss: 0.2498  loss_cls: 0.041  loss_box_reg: 0.1183  loss_mask: 0.09371  loss_rpn_cls: 0.0008627  loss_rpn_loc: 0.01847  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:03:12] d2.utils.events INFO:  eta: 1:56:43  iter: 20719  total_loss: 0.2435  loss_cls: 0.03564  loss_box_reg: 0.09679  loss_mask: 0.08802  loss_rpn_cls: 0.0008034  loss_rpn_loc: 0.009311  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:03:14] d2.utils.events INFO:  eta: 1:56:43  iter: 20739  total_loss: 0.3787  loss_cls: 0.05589  loss_box_reg: 0.1429  loss_mask: 0.1513  loss_rpn_cls: 0.002321  loss_rpn_loc: 0.03433  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:03:16] d2.utils.events INFO:  eta: 1:56:38  iter: 20759  total_loss: 0.2082  loss_cls: 0.02678  loss_box_reg: 0.08567  loss_mask: 0.06885  loss_rpn_cls: 0.00203  loss_rpn_loc: 0.01435  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:03:18] d2.utils.events INFO:  eta: 1:56:35  iter: 20779  total_loss: 0.2461  loss_cls: 0.03389  loss_box_reg: 0.0915  loss_mask: 0.08184  loss_rpn_cls: 0.00085  loss_rpn_loc: 0.02186  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:03:20] d2.utils.events INFO:  eta: 1:56:30  iter: 20799  total_loss: 0.3169  loss_cls: 0.04817  loss_box_reg: 0.1463  loss_mask: 0.1121  loss_rpn_cls: 0.002006  loss_rpn_loc: 0.02126  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:03:22] d2.utils.events INFO:  eta: 1:56:22  iter: 20819  total_loss: 0.1995  loss_cls: 0.03728  loss_box_reg: 0.09184  loss_mask: 0.07359  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.01362  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:03:24] d2.utils.events INFO:  eta: 1:56:20  iter: 20839  total_loss: 0.2621  loss_cls: 0.04262  loss_box_reg: 0.1078  loss_mask: 0.09279  loss_rpn_cls: 0.001011  loss_rpn_loc: 0.0161  time: 0.1017  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 19:03:26] d2.utils.events INFO:  eta: 1:56:20  iter: 20859  total_loss: 0.3641  loss_cls: 0.04965  loss_box_reg: 0.1294  loss_mask: 0.105  loss_rpn_cls: 0.001352  loss_rpn_loc: 0.01593  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:03:28] d2.utils.events INFO:  eta: 1:56:26  iter: 20879  total_loss: 0.3716  loss_cls: 0.06498  loss_box_reg: 0.1701  loss_mask: 0.1097  loss_rpn_cls: 0.002881  loss_rpn_loc: 0.02335  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:03:30] d2.utils.events INFO:  eta: 1:56:15  iter: 20899  total_loss: 0.2623  loss_cls: 0.03912  loss_box_reg: 0.1198  loss_mask: 0.07992  loss_rpn_cls: 0.0008504  loss_rpn_loc: 0.02229  time: 0.1017  data_time: 0.0018  lr: 0.0025  max_mem: 1634M
[10/27 19:03:32] d2.utils.events INFO:  eta: 1:56:03  iter: 20919  total_loss: 0.2714  loss_cls: 0.04109  loss_box_reg: 0.1153  loss_mask: 0.09935  loss_rpn_cls: 0.0009387  loss_rpn_loc: 0.01832  time: 0.1017  data_time: 0.0017  lr: 0.0025  max_mem: 1634M
[10/27 19:03:34] d2.utils.events INFO:  eta: 1:56:01  iter: 20939  total_loss: 0.2661  loss_cls: 0.03183  loss_box_reg: 0.09428  loss_mask: 0.08596  loss_rpn_cls: 0.002195  loss_rpn_loc: 0.01457  time: 0.1017  data_time: 0.0021  lr: 0.0025  max_mem: 1634M
[10/27 19:03:36] d2.utils.events INFO:  eta: 1:55:57  iter: 20959  total_loss: 0.3418  loss_cls: 0.05768  loss_box_reg: 0.1388  loss_mask: 0.099  loss_rpn_cls: 0.001862  loss_rpn_loc: 0.03897  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:03:38] d2.utils.events INFO:  eta: 1:55:52  iter: 20979  total_loss: 0.2907  loss_cls: 0.04222  loss_box_reg: 0.1221  loss_mask: 0.102  loss_rpn_cls: 0.001426  loss_rpn_loc: 0.01456  time: 0.1017  data_time: 0.0030  lr: 0.0025  max_mem: 1634M
[10/27 19:03:41] d2.utils.events INFO:  eta: 1:55:48  iter: 20999  total_loss: 0.3048  loss_cls: 0.06076  loss_box_reg: 0.1282  loss_mask: 0.09309  loss_rpn_cls: 0.001991  loss_rpn_loc: 0.02237  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:03:43] d2.utils.events INFO:  eta: 1:55:54  iter: 21019  total_loss: 0.4156  loss_cls: 0.06995  loss_box_reg: 0.1791  loss_mask: 0.1365  loss_rpn_cls: 0.002727  loss_rpn_loc: 0.03971  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:03:45] d2.utils.events INFO:  eta: 1:55:50  iter: 21039  total_loss: 0.3566  loss_cls: 0.04865  loss_box_reg: 0.1302  loss_mask: 0.1218  loss_rpn_cls: 0.002328  loss_rpn_loc: 0.02274  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:03:47] d2.utils.events INFO:  eta: 1:55:48  iter: 21059  total_loss: 0.2136  loss_cls: 0.02339  loss_box_reg: 0.07828  loss_mask: 0.07664  loss_rpn_cls: 0.0006538  loss_rpn_loc: 0.01219  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:03:49] d2.utils.events INFO:  eta: 1:55:48  iter: 21079  total_loss: 0.3266  loss_cls: 0.04361  loss_box_reg: 0.1421  loss_mask: 0.0901  loss_rpn_cls: 0.001303  loss_rpn_loc: 0.0222  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:03:51] d2.utils.events INFO:  eta: 1:55:56  iter: 21099  total_loss: 0.3145  loss_cls: 0.04124  loss_box_reg: 0.1433  loss_mask: 0.08565  loss_rpn_cls: 0.001665  loss_rpn_loc: 0.0168  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:03:53] d2.utils.events INFO:  eta: 1:55:45  iter: 21119  total_loss: 0.2269  loss_cls: 0.03237  loss_box_reg: 0.08123  loss_mask: 0.08312  loss_rpn_cls: 0.001232  loss_rpn_loc: 0.0179  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:03:55] d2.utils.events INFO:  eta: 1:55:48  iter: 21139  total_loss: 0.2902  loss_cls: 0.04716  loss_box_reg: 0.1183  loss_mask: 0.09108  loss_rpn_cls: 0.00153  loss_rpn_loc: 0.02662  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:03:57] d2.utils.events INFO:  eta: 1:55:57  iter: 21159  total_loss: 0.3926  loss_cls: 0.06633  loss_box_reg: 0.1654  loss_mask: 0.107  loss_rpn_cls: 0.002816  loss_rpn_loc: 0.02536  time: 0.1017  data_time: 0.0032  lr: 0.0025  max_mem: 1634M
[10/27 19:03:59] d2.utils.events INFO:  eta: 1:55:58  iter: 21179  total_loss: 0.3507  loss_cls: 0.04832  loss_box_reg: 0.1553  loss_mask: 0.09809  loss_rpn_cls: 0.001941  loss_rpn_loc: 0.02046  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:04:01] d2.utils.events INFO:  eta: 1:56:08  iter: 21199  total_loss: 0.2394  loss_cls: 0.03795  loss_box_reg: 0.1062  loss_mask: 0.09959  loss_rpn_cls: 0.0008187  loss_rpn_loc: 0.0124  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:03] d2.utils.events INFO:  eta: 1:56:00  iter: 21219  total_loss: 0.2384  loss_cls: 0.03608  loss_box_reg: 0.09071  loss_mask: 0.0995  loss_rpn_cls: 0.001212  loss_rpn_loc: 0.02337  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:05] d2.utils.events INFO:  eta: 1:55:51  iter: 21239  total_loss: 0.2175  loss_cls: 0.02958  loss_box_reg: 0.09139  loss_mask: 0.1014  loss_rpn_cls: 0.002232  loss_rpn_loc: 0.02327  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:08] d2.utils.events INFO:  eta: 1:55:56  iter: 21259  total_loss: 0.2732  loss_cls: 0.03631  loss_box_reg: 0.1278  loss_mask: 0.07928  loss_rpn_cls: 0.0008116  loss_rpn_loc: 0.01656  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:04:10] d2.utils.events INFO:  eta: 1:56:17  iter: 21279  total_loss: 0.2902  loss_cls: 0.05956  loss_box_reg: 0.1289  loss_mask: 0.09073  loss_rpn_cls: 0.002499  loss_rpn_loc: 0.02843  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:04:12] d2.utils.events INFO:  eta: 1:56:15  iter: 21299  total_loss: 0.3619  loss_cls: 0.05398  loss_box_reg: 0.148  loss_mask: 0.1222  loss_rpn_cls: 0.001649  loss_rpn_loc: 0.02792  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:14] d2.utils.events INFO:  eta: 1:56:15  iter: 21319  total_loss: 0.22  loss_cls: 0.04276  loss_box_reg: 0.09733  loss_mask: 0.08235  loss_rpn_cls: 0.001112  loss_rpn_loc: 0.01358  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:04:16] d2.utils.events INFO:  eta: 1:56:08  iter: 21339  total_loss: 0.2274  loss_cls: 0.03164  loss_box_reg: 0.07465  loss_mask: 0.09554  loss_rpn_cls: 0.0008079  loss_rpn_loc: 0.01425  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:18] d2.utils.events INFO:  eta: 1:56:09  iter: 21359  total_loss: 0.3003  loss_cls: 0.0424  loss_box_reg: 0.124  loss_mask: 0.0973  loss_rpn_cls: 0.001229  loss_rpn_loc: 0.01474  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:20] d2.utils.events INFO:  eta: 1:56:07  iter: 21379  total_loss: 0.3752  loss_cls: 0.05934  loss_box_reg: 0.1512  loss_mask: 0.09444  loss_rpn_cls: 0.00338  loss_rpn_loc: 0.03538  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:04:22] d2.utils.events INFO:  eta: 1:56:21  iter: 21399  total_loss: 0.2814  loss_cls: 0.04357  loss_box_reg: 0.1186  loss_mask: 0.08384  loss_rpn_cls: 0.001298  loss_rpn_loc: 0.01723  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:04:24] d2.utils.events INFO:  eta: 1:56:22  iter: 21419  total_loss: 0.2273  loss_cls: 0.03818  loss_box_reg: 0.07762  loss_mask: 0.07993  loss_rpn_cls: 0.002178  loss_rpn_loc: 0.01839  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:04:26] d2.utils.events INFO:  eta: 1:56:23  iter: 21439  total_loss: 0.3032  loss_cls: 0.05062  loss_box_reg: 0.1413  loss_mask: 0.1122  loss_rpn_cls: 0.001818  loss_rpn_loc: 0.03896  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:28] d2.utils.events INFO:  eta: 1:56:21  iter: 21459  total_loss: 0.2605  loss_cls: 0.0417  loss_box_reg: 0.09631  loss_mask: 0.09081  loss_rpn_cls: 0.000841  loss_rpn_loc: 0.01369  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:31] d2.utils.events INFO:  eta: 1:56:23  iter: 21479  total_loss: 0.3041  loss_cls: 0.04304  loss_box_reg: 0.1216  loss_mask: 0.09335  loss_rpn_cls: 0.0008503  loss_rpn_loc: 0.02179  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:33] d2.utils.events INFO:  eta: 1:56:43  iter: 21499  total_loss: 0.2964  loss_cls: 0.04384  loss_box_reg: 0.1137  loss_mask: 0.1071  loss_rpn_cls: 0.0008966  loss_rpn_loc: 0.01622  time: 0.1017  data_time: 0.0031  lr: 0.0025  max_mem: 1634M
[10/27 19:04:35] d2.utils.events INFO:  eta: 1:56:48  iter: 21519  total_loss: 0.2658  loss_cls: 0.0473  loss_box_reg: 0.1284  loss_mask: 0.1003  loss_rpn_cls: 0.0007592  loss_rpn_loc: 0.01685  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:04:37] d2.utils.events INFO:  eta: 1:56:44  iter: 21539  total_loss: 0.1915  loss_cls: 0.03219  loss_box_reg: 0.07869  loss_mask: 0.06546  loss_rpn_cls: 0.0004834  loss_rpn_loc: 0.01249  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:39] d2.utils.events INFO:  eta: 1:56:44  iter: 21559  total_loss: 0.3077  loss_cls: 0.0467  loss_box_reg: 0.1313  loss_mask: 0.08824  loss_rpn_cls: 0.001641  loss_rpn_loc: 0.02089  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:41] d2.utils.events INFO:  eta: 1:56:52  iter: 21579  total_loss: 0.2962  loss_cls: 0.05318  loss_box_reg: 0.152  loss_mask: 0.09342  loss_rpn_cls: 0.002012  loss_rpn_loc: 0.02908  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:43] d2.utils.events INFO:  eta: 1:56:50  iter: 21599  total_loss: 0.2271  loss_cls: 0.03392  loss_box_reg: 0.1105  loss_mask: 0.09787  loss_rpn_cls: 0.0005771  loss_rpn_loc: 0.01373  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:04:45] d2.utils.events INFO:  eta: 1:56:54  iter: 21619  total_loss: 0.3479  loss_cls: 0.0627  loss_box_reg: 0.1543  loss_mask: 0.1041  loss_rpn_cls: 0.003276  loss_rpn_loc: 0.02375  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:04:47] d2.utils.events INFO:  eta: 1:56:52  iter: 21639  total_loss: 0.2477  loss_cls: 0.0326  loss_box_reg: 0.1172  loss_mask: 0.08191  loss_rpn_cls: 0.001302  loss_rpn_loc: 0.01368  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:04:49] d2.utils.events INFO:  eta: 1:56:51  iter: 21659  total_loss: 0.2851  loss_cls: 0.04491  loss_box_reg: 0.1311  loss_mask: 0.08034  loss_rpn_cls: 0.002161  loss_rpn_loc: 0.02215  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:04:51] d2.utils.events INFO:  eta: 1:56:47  iter: 21679  total_loss: 0.2481  loss_cls: 0.04364  loss_box_reg: 0.1093  loss_mask: 0.07564  loss_rpn_cls: 0.001139  loss_rpn_loc: 0.01545  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:04:54] d2.utils.events INFO:  eta: 1:56:46  iter: 21699  total_loss: 0.3397  loss_cls: 0.04952  loss_box_reg: 0.1582  loss_mask: 0.09494  loss_rpn_cls: 0.001297  loss_rpn_loc: 0.01651  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:04:56] d2.utils.events INFO:  eta: 1:56:32  iter: 21719  total_loss: 0.2572  loss_cls: 0.03495  loss_box_reg: 0.1133  loss_mask: 0.08742  loss_rpn_cls: 0.0007827  loss_rpn_loc: 0.01248  time: 0.1017  data_time: 0.0032  lr: 0.0025  max_mem: 1634M
[10/27 19:04:58] d2.utils.events INFO:  eta: 1:56:20  iter: 21739  total_loss: 0.3168  loss_cls: 0.04472  loss_box_reg: 0.1331  loss_mask: 0.1069  loss_rpn_cls: 0.001088  loss_rpn_loc: 0.01227  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:05:00] d2.utils.events INFO:  eta: 1:56:28  iter: 21759  total_loss: 0.4163  loss_cls: 0.06228  loss_box_reg: 0.1975  loss_mask: 0.1173  loss_rpn_cls: 0.003951  loss_rpn_loc: 0.03114  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:02] d2.utils.events INFO:  eta: 1:56:40  iter: 21779  total_loss: 0.3231  loss_cls: 0.0459  loss_box_reg: 0.1436  loss_mask: 0.1226  loss_rpn_cls: 0.001267  loss_rpn_loc: 0.01998  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:05:04] d2.utils.events INFO:  eta: 1:56:38  iter: 21799  total_loss: 0.248  loss_cls: 0.0438  loss_box_reg: 0.1119  loss_mask: 0.08654  loss_rpn_cls: 0.0006017  loss_rpn_loc: 0.01632  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:06] d2.utils.events INFO:  eta: 1:56:45  iter: 21819  total_loss: 0.282  loss_cls: 0.05072  loss_box_reg: 0.113  loss_mask: 0.09008  loss_rpn_cls: 0.001603  loss_rpn_loc: 0.03057  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:08] d2.utils.events INFO:  eta: 1:56:55  iter: 21839  total_loss: 0.301  loss_cls: 0.0463  loss_box_reg: 0.1307  loss_mask: 0.0861  loss_rpn_cls: 0.001658  loss_rpn_loc: 0.02807  time: 0.1017  data_time: 0.0021  lr: 0.0025  max_mem: 1634M
[10/27 19:05:10] d2.utils.events INFO:  eta: 1:56:54  iter: 21859  total_loss: 0.2129  loss_cls: 0.03073  loss_box_reg: 0.07722  loss_mask: 0.079  loss_rpn_cls: 0.0003936  loss_rpn_loc: 0.01204  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:12] d2.utils.events INFO:  eta: 1:56:52  iter: 21879  total_loss: 0.4357  loss_cls: 0.06559  loss_box_reg: 0.1759  loss_mask: 0.1347  loss_rpn_cls: 0.002208  loss_rpn_loc: 0.03453  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:05:14] d2.utils.events INFO:  eta: 1:56:53  iter: 21899  total_loss: 0.2558  loss_cls: 0.03736  loss_box_reg: 0.1221  loss_mask: 0.09563  loss_rpn_cls: 0.0006778  loss_rpn_loc: 0.01234  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:05:16] d2.utils.events INFO:  eta: 1:56:51  iter: 21919  total_loss: 0.3319  loss_cls: 0.05495  loss_box_reg: 0.1404  loss_mask: 0.1223  loss_rpn_cls: 0.001239  loss_rpn_loc: 0.02381  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:05:18] d2.utils.events INFO:  eta: 1:56:52  iter: 21939  total_loss: 0.2675  loss_cls: 0.04655  loss_box_reg: 0.1025  loss_mask: 0.08567  loss_rpn_cls: 0.001047  loss_rpn_loc: 0.01423  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:05:21] d2.utils.events INFO:  eta: 1:56:53  iter: 21959  total_loss: 0.309  loss_cls: 0.04428  loss_box_reg: 0.122  loss_mask: 0.08608  loss_rpn_cls: 0.0008426  loss_rpn_loc: 0.01706  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:22] d2.utils.events INFO:  eta: 1:56:51  iter: 21979  total_loss: 0.2674  loss_cls: 0.04227  loss_box_reg: 0.09912  loss_mask: 0.07847  loss_rpn_cls: 0.00105  loss_rpn_loc: 0.02065  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:25] d2.utils.events INFO:  eta: 1:56:46  iter: 21999  total_loss: 0.3187  loss_cls: 0.04284  loss_box_reg: 0.1231  loss_mask: 0.08769  loss_rpn_cls: 0.001765  loss_rpn_loc: 0.02962  time: 0.1017  data_time: 0.0030  lr: 0.0025  max_mem: 1634M
[10/27 19:05:27] d2.utils.events INFO:  eta: 1:56:37  iter: 22019  total_loss: 0.4109  loss_cls: 0.06815  loss_box_reg: 0.1558  loss_mask: 0.1284  loss_rpn_cls: 0.001937  loss_rpn_loc: 0.03636  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:05:29] d2.utils.events INFO:  eta: 1:56:36  iter: 22039  total_loss: 0.2911  loss_cls: 0.0492  loss_box_reg: 0.1156  loss_mask: 0.0978  loss_rpn_cls: 0.002076  loss_rpn_loc: 0.0212  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:05:31] d2.utils.events INFO:  eta: 1:56:33  iter: 22059  total_loss: 0.2554  loss_cls: 0.03347  loss_box_reg: 0.09663  loss_mask: 0.07745  loss_rpn_cls: 0.001341  loss_rpn_loc: 0.01996  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:33] d2.utils.events INFO:  eta: 1:56:10  iter: 22079  total_loss: 0.2917  loss_cls: 0.04521  loss_box_reg: 0.1167  loss_mask: 0.1027  loss_rpn_cls: 0.001821  loss_rpn_loc: 0.02192  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:05:35] d2.utils.events INFO:  eta: 1:55:55  iter: 22099  total_loss: 0.2663  loss_cls: 0.04226  loss_box_reg: 0.1132  loss_mask: 0.1001  loss_rpn_cls: 0.0007699  loss_rpn_loc: 0.0175  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:05:37] d2.utils.events INFO:  eta: 1:56:05  iter: 22119  total_loss: 0.1707  loss_cls: 0.03057  loss_box_reg: 0.07764  loss_mask: 0.06719  loss_rpn_cls: 0.0006485  loss_rpn_loc: 0.01598  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:05:39] d2.utils.events INFO:  eta: 1:55:47  iter: 22139  total_loss: 0.2049  loss_cls: 0.03567  loss_box_reg: 0.06141  loss_mask: 0.09007  loss_rpn_cls: 0.0007706  loss_rpn_loc: 0.01601  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:41] d2.utils.events INFO:  eta: 1:55:34  iter: 22159  total_loss: 0.4148  loss_cls: 0.066  loss_box_reg: 0.1778  loss_mask: 0.1306  loss_rpn_cls: 0.004527  loss_rpn_loc: 0.0345  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:05:43] d2.utils.events INFO:  eta: 1:55:27  iter: 22179  total_loss: 0.3531  loss_cls: 0.06497  loss_box_reg: 0.1573  loss_mask: 0.09463  loss_rpn_cls: 0.003681  loss_rpn_loc: 0.03459  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:45] d2.utils.events INFO:  eta: 1:55:36  iter: 22199  total_loss: 0.2915  loss_cls: 0.04266  loss_box_reg: 0.1366  loss_mask: 0.1005  loss_rpn_cls: 0.001137  loss_rpn_loc: 0.02758  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:05:47] d2.utils.events INFO:  eta: 1:55:31  iter: 22219  total_loss: 0.2218  loss_cls: 0.03485  loss_box_reg: 0.09196  loss_mask: 0.07613  loss_rpn_cls: 0.0004845  loss_rpn_loc: 0.01198  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:49] d2.utils.events INFO:  eta: 1:55:29  iter: 22239  total_loss: 0.2101  loss_cls: 0.02835  loss_box_reg: 0.08265  loss_mask: 0.09005  loss_rpn_cls: 0.0006671  loss_rpn_loc: 0.01195  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:05:51] d2.utils.events INFO:  eta: 1:55:22  iter: 22259  total_loss: 0.2437  loss_cls: 0.03733  loss_box_reg: 0.107  loss_mask: 0.08479  loss_rpn_cls: 0.002824  loss_rpn_loc: 0.02784  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:05:53] d2.utils.events INFO:  eta: 1:55:01  iter: 22279  total_loss: 0.2397  loss_cls: 0.03847  loss_box_reg: 0.09828  loss_mask: 0.08439  loss_rpn_cls: 0.0007507  loss_rpn_loc: 0.009929  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:05:55] d2.utils.events INFO:  eta: 1:54:53  iter: 22299  total_loss: 0.3473  loss_cls: 0.05482  loss_box_reg: 0.1639  loss_mask: 0.09598  loss_rpn_cls: 0.00216  loss_rpn_loc: 0.02595  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:05:57] d2.utils.events INFO:  eta: 1:54:47  iter: 22319  total_loss: 0.2394  loss_cls: 0.04382  loss_box_reg: 0.1136  loss_mask: 0.08389  loss_rpn_cls: 0.001389  loss_rpn_loc: 0.02309  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:05:59] d2.utils.events INFO:  eta: 1:54:52  iter: 22339  total_loss: 0.215  loss_cls: 0.03216  loss_box_reg: 0.08015  loss_mask: 0.0809  loss_rpn_cls: 0.0006693  loss_rpn_loc: 0.01182  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:01] d2.utils.events INFO:  eta: 1:54:41  iter: 22359  total_loss: 0.2557  loss_cls: 0.04533  loss_box_reg: 0.1083  loss_mask: 0.08686  loss_rpn_cls: 0.001162  loss_rpn_loc: 0.02719  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:06:03] d2.utils.events INFO:  eta: 1:54:43  iter: 22379  total_loss: 0.2596  loss_cls: 0.05174  loss_box_reg: 0.1213  loss_mask: 0.08899  loss_rpn_cls: 0.0009959  loss_rpn_loc: 0.01591  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:06:05] d2.utils.events INFO:  eta: 1:54:31  iter: 22399  total_loss: 0.2641  loss_cls: 0.04066  loss_box_reg: 0.1065  loss_mask: 0.08541  loss_rpn_cls: 0.0009792  loss_rpn_loc: 0.01463  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:07] d2.utils.events INFO:  eta: 1:54:29  iter: 22419  total_loss: 0.2931  loss_cls: 0.03953  loss_box_reg: 0.1322  loss_mask: 0.1007  loss_rpn_cls: 0.0005243  loss_rpn_loc: 0.0157  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:09] d2.utils.events INFO:  eta: 1:54:24  iter: 22439  total_loss: 0.3819  loss_cls: 0.05922  loss_box_reg: 0.1542  loss_mask: 0.1108  loss_rpn_cls: 0.001834  loss_rpn_loc: 0.02215  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:11] d2.utils.events INFO:  eta: 1:54:26  iter: 22459  total_loss: 0.3239  loss_cls: 0.04242  loss_box_reg: 0.1321  loss_mask: 0.1236  loss_rpn_cls: 0.001612  loss_rpn_loc: 0.02283  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:06:13] d2.utils.events INFO:  eta: 1:54:24  iter: 22479  total_loss: 0.3119  loss_cls: 0.0481  loss_box_reg: 0.1216  loss_mask: 0.1053  loss_rpn_cls: 0.0008273  loss_rpn_loc: 0.02166  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:16] d2.utils.events INFO:  eta: 1:54:05  iter: 22499  total_loss: 0.2993  loss_cls: 0.03759  loss_box_reg: 0.1378  loss_mask: 0.107  loss_rpn_cls: 0.00212  loss_rpn_loc: 0.01947  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:18] d2.utils.events INFO:  eta: 1:54:11  iter: 22519  total_loss: 0.3058  loss_cls: 0.04473  loss_box_reg: 0.1199  loss_mask: 0.09663  loss_rpn_cls: 0.001075  loss_rpn_loc: 0.01511  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:06:20] d2.utils.events INFO:  eta: 1:54:05  iter: 22539  total_loss: 0.3003  loss_cls: 0.04587  loss_box_reg: 0.1088  loss_mask: 0.109  loss_rpn_cls: 0.001357  loss_rpn_loc: 0.02457  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:22] d2.utils.events INFO:  eta: 1:53:51  iter: 22559  total_loss: 0.2712  loss_cls: 0.03435  loss_box_reg: 0.1081  loss_mask: 0.0944  loss_rpn_cls: 0.0009943  loss_rpn_loc: 0.02032  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:24] d2.utils.events INFO:  eta: 1:53:49  iter: 22579  total_loss: 0.2215  loss_cls: 0.03423  loss_box_reg: 0.09739  loss_mask: 0.08275  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.0148  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:26] d2.utils.events INFO:  eta: 1:53:43  iter: 22599  total_loss: 0.2433  loss_cls: 0.03442  loss_box_reg: 0.09672  loss_mask: 0.08674  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.0119  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:28] d2.utils.events INFO:  eta: 1:53:36  iter: 22619  total_loss: 0.3277  loss_cls: 0.06213  loss_box_reg: 0.1576  loss_mask: 0.08922  loss_rpn_cls: 0.001673  loss_rpn_loc: 0.02275  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:06:30] d2.utils.events INFO:  eta: 1:53:34  iter: 22639  total_loss: 0.25  loss_cls: 0.03708  loss_box_reg: 0.09689  loss_mask: 0.08691  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.01872  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:32] d2.utils.events INFO:  eta: 1:53:31  iter: 22659  total_loss: 0.3186  loss_cls: 0.05943  loss_box_reg: 0.1267  loss_mask: 0.1039  loss_rpn_cls: 0.0008417  loss_rpn_loc: 0.02018  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:34] d2.utils.events INFO:  eta: 1:53:22  iter: 22679  total_loss: 0.2706  loss_cls: 0.03937  loss_box_reg: 0.1245  loss_mask: 0.09925  loss_rpn_cls: 0.002159  loss_rpn_loc: 0.02922  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:36] d2.utils.events INFO:  eta: 1:53:23  iter: 22699  total_loss: 0.3672  loss_cls: 0.06082  loss_box_reg: 0.1586  loss_mask: 0.1176  loss_rpn_cls: 0.002146  loss_rpn_loc: 0.03199  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:38] d2.utils.events INFO:  eta: 1:53:31  iter: 22719  total_loss: 0.2771  loss_cls: 0.0379  loss_box_reg: 0.1173  loss_mask: 0.08409  loss_rpn_cls: 0.001283  loss_rpn_loc: 0.01752  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:40] d2.utils.events INFO:  eta: 1:53:36  iter: 22739  total_loss: 0.2795  loss_cls: 0.03776  loss_box_reg: 0.1255  loss_mask: 0.08937  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.01848  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:42] d2.utils.events INFO:  eta: 1:53:31  iter: 22759  total_loss: 0.3134  loss_cls: 0.04423  loss_box_reg: 0.1473  loss_mask: 0.07953  loss_rpn_cls: 0.0009218  loss_rpn_loc: 0.02312  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:44] d2.utils.events INFO:  eta: 1:53:20  iter: 22779  total_loss: 0.1977  loss_cls: 0.02966  loss_box_reg: 0.07966  loss_mask: 0.0746  loss_rpn_cls: 0.001051  loss_rpn_loc: 0.01573  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:46] d2.utils.events INFO:  eta: 1:53:16  iter: 22799  total_loss: 0.1939  loss_cls: 0.03715  loss_box_reg: 0.07035  loss_mask: 0.07199  loss_rpn_cls: 0.0006028  loss_rpn_loc: 0.01487  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:06:48] d2.utils.events INFO:  eta: 1:53:06  iter: 22819  total_loss: 0.2845  loss_cls: 0.04881  loss_box_reg: 0.1147  loss_mask: 0.09612  loss_rpn_cls: 0.001025  loss_rpn_loc: 0.0183  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:50] d2.utils.events INFO:  eta: 1:52:56  iter: 22839  total_loss: 0.2096  loss_cls: 0.0308  loss_box_reg: 0.09303  loss_mask: 0.08027  loss_rpn_cls: 0.0006161  loss_rpn_loc: 0.01647  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:06:52] d2.utils.events INFO:  eta: 1:52:54  iter: 22859  total_loss: 0.3592  loss_cls: 0.06853  loss_box_reg: 0.171  loss_mask: 0.1123  loss_rpn_cls: 0.0008211  loss_rpn_loc: 0.0332  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:06:54] d2.utils.events INFO:  eta: 1:52:51  iter: 22879  total_loss: 0.3092  loss_cls: 0.04692  loss_box_reg: 0.1022  loss_mask: 0.09049  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.02054  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:06:56] d2.utils.events INFO:  eta: 1:52:48  iter: 22899  total_loss: 0.3095  loss_cls: 0.04537  loss_box_reg: 0.1397  loss_mask: 0.1037  loss_rpn_cls: 0.0007896  loss_rpn_loc: 0.02347  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:06:58] d2.utils.events INFO:  eta: 1:52:50  iter: 22919  total_loss: 0.3956  loss_cls: 0.06554  loss_box_reg: 0.1722  loss_mask: 0.1269  loss_rpn_cls: 0.002152  loss_rpn_loc: 0.02225  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:07:00] d2.utils.events INFO:  eta: 1:52:51  iter: 22939  total_loss: 0.2996  loss_cls: 0.04996  loss_box_reg: 0.1442  loss_mask: 0.1008  loss_rpn_cls: 0.001543  loss_rpn_loc: 0.013  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:07:02] d2.utils.events INFO:  eta: 1:52:46  iter: 22959  total_loss: 0.3283  loss_cls: 0.04388  loss_box_reg: 0.1599  loss_mask: 0.09335  loss_rpn_cls: 0.001624  loss_rpn_loc: 0.01912  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:05] d2.utils.events INFO:  eta: 1:52:53  iter: 22979  total_loss: 0.231  loss_cls: 0.03771  loss_box_reg: 0.09597  loss_mask: 0.08433  loss_rpn_cls: 0.001032  loss_rpn_loc: 0.01085  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:07] d2.utils.events INFO:  eta: 1:52:55  iter: 22999  total_loss: 0.2653  loss_cls: 0.0362  loss_box_reg: 0.1101  loss_mask: 0.08491  loss_rpn_cls: 0.001566  loss_rpn_loc: 0.02653  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:09] d2.utils.events INFO:  eta: 1:52:59  iter: 23019  total_loss: 0.2505  loss_cls: 0.04177  loss_box_reg: 0.08676  loss_mask: 0.07866  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.01932  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:11] d2.utils.events INFO:  eta: 1:52:50  iter: 23039  total_loss: 0.1991  loss_cls: 0.02154  loss_box_reg: 0.08892  loss_mask: 0.0823  loss_rpn_cls: 0.0003955  loss_rpn_loc: 0.01029  time: 0.1017  data_time: 0.0030  lr: 0.0025  max_mem: 1634M
[10/27 19:07:13] d2.utils.events INFO:  eta: 1:52:56  iter: 23059  total_loss: 0.3575  loss_cls: 0.04289  loss_box_reg: 0.1333  loss_mask: 0.09315  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.02508  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:15] d2.utils.events INFO:  eta: 1:53:00  iter: 23079  total_loss: 0.2739  loss_cls: 0.04046  loss_box_reg: 0.1255  loss_mask: 0.08146  loss_rpn_cls: 0.001107  loss_rpn_loc: 0.01483  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:17] d2.utils.events INFO:  eta: 1:53:04  iter: 23099  total_loss: 0.3527  loss_cls: 0.05738  loss_box_reg: 0.1489  loss_mask: 0.1101  loss_rpn_cls: 0.001515  loss_rpn_loc: 0.02999  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:19] d2.utils.events INFO:  eta: 1:53:00  iter: 23119  total_loss: 0.274  loss_cls: 0.05505  loss_box_reg: 0.1187  loss_mask: 0.106  loss_rpn_cls: 0.001881  loss_rpn_loc: 0.01908  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:21] d2.utils.events INFO:  eta: 1:53:08  iter: 23139  total_loss: 0.2168  loss_cls: 0.02982  loss_box_reg: 0.08754  loss_mask: 0.06652  loss_rpn_cls: 0.001037  loss_rpn_loc: 0.02122  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:23] d2.utils.events INFO:  eta: 1:53:15  iter: 23159  total_loss: 0.2982  loss_cls: 0.05482  loss_box_reg: 0.136  loss_mask: 0.08985  loss_rpn_cls: 0.001311  loss_rpn_loc: 0.02015  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:25] d2.utils.events INFO:  eta: 1:53:07  iter: 23179  total_loss: 0.1904  loss_cls: 0.02869  loss_box_reg: 0.06612  loss_mask: 0.0691  loss_rpn_cls: 0.0005986  loss_rpn_loc: 0.01093  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:27] d2.utils.events INFO:  eta: 1:53:00  iter: 23199  total_loss: 0.2796  loss_cls: 0.04947  loss_box_reg: 0.1101  loss_mask: 0.08794  loss_rpn_cls: 0.001287  loss_rpn_loc: 0.02837  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:07:29] d2.utils.events INFO:  eta: 1:53:00  iter: 23219  total_loss: 0.2648  loss_cls: 0.05413  loss_box_reg: 0.1137  loss_mask: 0.09963  loss_rpn_cls: 0.002326  loss_rpn_loc: 0.0174  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:31] d2.utils.events INFO:  eta: 1:53:11  iter: 23239  total_loss: 0.3169  loss_cls: 0.04578  loss_box_reg: 0.1296  loss_mask: 0.1044  loss_rpn_cls: 0.001041  loss_rpn_loc: 0.02038  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:33] d2.utils.events INFO:  eta: 1:53:08  iter: 23259  total_loss: 0.2071  loss_cls: 0.03806  loss_box_reg: 0.09315  loss_mask: 0.06443  loss_rpn_cls: 0.001414  loss_rpn_loc: 0.01882  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:35] d2.utils.events INFO:  eta: 1:53:06  iter: 23279  total_loss: 0.2249  loss_cls: 0.02775  loss_box_reg: 0.09305  loss_mask: 0.0862  loss_rpn_cls: 0.001482  loss_rpn_loc: 0.01732  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:37] d2.utils.events INFO:  eta: 1:53:02  iter: 23299  total_loss: 0.3258  loss_cls: 0.0473  loss_box_reg: 0.1275  loss_mask: 0.1034  loss_rpn_cls: 0.001995  loss_rpn_loc: 0.02564  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:39] d2.utils.events INFO:  eta: 1:53:03  iter: 23319  total_loss: 0.2718  loss_cls: 0.0332  loss_box_reg: 0.1239  loss_mask: 0.08456  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.01539  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:07:41] d2.utils.events INFO:  eta: 1:53:01  iter: 23339  total_loss: 0.2816  loss_cls: 0.04163  loss_box_reg: 0.1315  loss_mask: 0.06734  loss_rpn_cls: 0.0009313  loss_rpn_loc: 0.02602  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:07:43] d2.utils.events INFO:  eta: 1:52:55  iter: 23359  total_loss: 0.3082  loss_cls: 0.05183  loss_box_reg: 0.1325  loss_mask: 0.09681  loss_rpn_cls: 0.0007741  loss_rpn_loc: 0.01587  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:07:45] d2.utils.events INFO:  eta: 1:52:51  iter: 23379  total_loss: 0.3033  loss_cls: 0.05399  loss_box_reg: 0.1523  loss_mask: 0.109  loss_rpn_cls: 0.001072  loss_rpn_loc: 0.0234  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:47] d2.utils.events INFO:  eta: 1:52:55  iter: 23399  total_loss: 0.2393  loss_cls: 0.03265  loss_box_reg: 0.08791  loss_mask: 0.08551  loss_rpn_cls: 0.0008937  loss_rpn_loc: 0.01592  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:49] d2.utils.events INFO:  eta: 1:52:58  iter: 23419  total_loss: 0.2238  loss_cls: 0.02703  loss_box_reg: 0.08626  loss_mask: 0.08444  loss_rpn_cls: 0.002429  loss_rpn_loc: 0.02252  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:51] d2.utils.events INFO:  eta: 1:53:06  iter: 23439  total_loss: 0.2205  loss_cls: 0.03582  loss_box_reg: 0.09086  loss_mask: 0.08871  loss_rpn_cls: 0.0009542  loss_rpn_loc: 0.01031  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:07:54] d2.utils.events INFO:  eta: 1:53:12  iter: 23459  total_loss: 0.3365  loss_cls: 0.06749  loss_box_reg: 0.1496  loss_mask: 0.1129  loss_rpn_cls: 0.00114  loss_rpn_loc: 0.01723  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:07:56] d2.utils.events INFO:  eta: 1:53:11  iter: 23479  total_loss: 0.2336  loss_cls: 0.0241  loss_box_reg: 0.08978  loss_mask: 0.08526  loss_rpn_cls: 0.0006946  loss_rpn_loc: 0.0184  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:07:58] d2.utils.events INFO:  eta: 1:53:09  iter: 23499  total_loss: 0.274  loss_cls: 0.05216  loss_box_reg: 0.135  loss_mask: 0.07575  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.01681  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:08:00] d2.utils.events INFO:  eta: 1:52:58  iter: 23519  total_loss: 0.1926  loss_cls: 0.02605  loss_box_reg: 0.08349  loss_mask: 0.07648  loss_rpn_cls: 0.000984  loss_rpn_loc: 0.01195  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:08:02] d2.utils.events INFO:  eta: 1:52:51  iter: 23539  total_loss: 0.2835  loss_cls: 0.03868  loss_box_reg: 0.1289  loss_mask: 0.0991  loss_rpn_cls: 0.001165  loss_rpn_loc: 0.01174  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:08:04] d2.utils.events INFO:  eta: 1:53:03  iter: 23559  total_loss: 0.38  loss_cls: 0.0701  loss_box_reg: 0.1665  loss_mask: 0.1156  loss_rpn_cls: 0.002491  loss_rpn_loc: 0.02681  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:08:06] d2.utils.events INFO:  eta: 1:53:01  iter: 23579  total_loss: 0.2885  loss_cls: 0.0423  loss_box_reg: 0.1353  loss_mask: 0.08151  loss_rpn_cls: 0.003673  loss_rpn_loc: 0.02056  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:08:08] d2.utils.events INFO:  eta: 1:53:03  iter: 23599  total_loss: 0.3167  loss_cls: 0.04982  loss_box_reg: 0.1281  loss_mask: 0.09465  loss_rpn_cls: 0.002657  loss_rpn_loc: 0.01745  time: 0.1017  data_time: 0.0020  lr: 0.0025  max_mem: 1634M
[10/27 19:08:10] d2.utils.events INFO:  eta: 1:52:56  iter: 23619  total_loss: 0.2917  loss_cls: 0.04551  loss_box_reg: 0.1393  loss_mask: 0.0922  loss_rpn_cls: 0.001101  loss_rpn_loc: 0.02602  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:08:12] d2.utils.events INFO:  eta: 1:52:54  iter: 23639  total_loss: 0.2211  loss_cls: 0.03908  loss_box_reg: 0.08606  loss_mask: 0.08934  loss_rpn_cls: 0.000761  loss_rpn_loc: 0.01245  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:08:14] d2.utils.events INFO:  eta: 1:52:29  iter: 23659  total_loss: 0.2404  loss_cls: 0.03688  loss_box_reg: 0.1074  loss_mask: 0.09142  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.01761  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:08:16] d2.utils.events INFO:  eta: 1:52:27  iter: 23679  total_loss: 0.2323  loss_cls: 0.03166  loss_box_reg: 0.0882  loss_mask: 0.07079  loss_rpn_cls: 0.0008376  loss_rpn_loc: 0.01372  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:08:18] d2.utils.events INFO:  eta: 1:52:26  iter: 23699  total_loss: 0.3517  loss_cls: 0.04465  loss_box_reg: 0.1389  loss_mask: 0.1074  loss_rpn_cls: 0.0009541  loss_rpn_loc: 0.02115  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:08:20] d2.utils.events INFO:  eta: 1:52:18  iter: 23719  total_loss: 0.1962  loss_cls: 0.03195  loss_box_reg: 0.07318  loss_mask: 0.08338  loss_rpn_cls: 0.001122  loss_rpn_loc: 0.01309  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:08:22] d2.utils.events INFO:  eta: 1:52:08  iter: 23739  total_loss: 0.2552  loss_cls: 0.04362  loss_box_reg: 0.1242  loss_mask: 0.07742  loss_rpn_cls: 0.0009446  loss_rpn_loc: 0.0199  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:08:24] d2.utils.events INFO:  eta: 1:52:08  iter: 23759  total_loss: 0.2633  loss_cls: 0.04126  loss_box_reg: 0.105  loss_mask: 0.1005  loss_rpn_cls: 0.00174  loss_rpn_loc: 0.02315  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:08:26] d2.utils.events INFO:  eta: 1:52:06  iter: 23779  total_loss: 0.2728  loss_cls: 0.03869  loss_box_reg: 0.1089  loss_mask: 0.08092  loss_rpn_cls: 0.0009639  loss_rpn_loc: 0.0246  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:28] d2.utils.events INFO:  eta: 1:52:12  iter: 23799  total_loss: 0.2817  loss_cls: 0.05117  loss_box_reg: 0.1144  loss_mask: 0.07798  loss_rpn_cls: 0.001537  loss_rpn_loc: 0.01392  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:30] d2.utils.events INFO:  eta: 1:52:12  iter: 23819  total_loss: 0.266  loss_cls: 0.03691  loss_box_reg: 0.1022  loss_mask: 0.09126  loss_rpn_cls: 0.0005746  loss_rpn_loc: 0.01326  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:32] d2.utils.events INFO:  eta: 1:52:39  iter: 23839  total_loss: 0.3767  loss_cls: 0.05208  loss_box_reg: 0.1611  loss_mask: 0.114  loss_rpn_cls: 0.004491  loss_rpn_loc: 0.03342  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:08:34] d2.utils.events INFO:  eta: 1:52:31  iter: 23859  total_loss: 0.2435  loss_cls: 0.03356  loss_box_reg: 0.09769  loss_mask: 0.09195  loss_rpn_cls: 0.0003771  loss_rpn_loc: 0.01143  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:08:36] d2.utils.events INFO:  eta: 1:52:29  iter: 23879  total_loss: 0.1399  loss_cls: 0.02338  loss_box_reg: 0.05513  loss_mask: 0.06005  loss_rpn_cls: 0.0006563  loss_rpn_loc: 0.004898  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:08:38] d2.utils.events INFO:  eta: 1:52:22  iter: 23899  total_loss: 0.3109  loss_cls: 0.05199  loss_box_reg: 0.1391  loss_mask: 0.1232  loss_rpn_cls: 0.002927  loss_rpn_loc: 0.02628  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:08:40] d2.utils.events INFO:  eta: 1:52:02  iter: 23919  total_loss: 0.2267  loss_cls: 0.03262  loss_box_reg: 0.07089  loss_mask: 0.08491  loss_rpn_cls: 0.0009044  loss_rpn_loc: 0.01073  time: 0.1017  data_time: 0.0019  lr: 0.0025  max_mem: 1634M
[10/27 19:08:42] d2.utils.events INFO:  eta: 1:51:55  iter: 23939  total_loss: 0.3635  loss_cls: 0.06398  loss_box_reg: 0.1651  loss_mask: 0.09632  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.0335  time: 0.1017  data_time: 0.0021  lr: 0.0025  max_mem: 1634M
[10/27 19:08:44] d2.utils.events INFO:  eta: 1:51:53  iter: 23959  total_loss: 0.2819  loss_cls: 0.04704  loss_box_reg: 0.1302  loss_mask: 0.09228  loss_rpn_cls: 0.002154  loss_rpn_loc: 0.02146  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:08:46] d2.utils.events INFO:  eta: 1:51:42  iter: 23979  total_loss: 0.2251  loss_cls: 0.02978  loss_box_reg: 0.1001  loss_mask: 0.07616  loss_rpn_cls: 0.001102  loss_rpn_loc: 0.01908  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:48] d2.utils.events INFO:  eta: 1:51:26  iter: 23999  total_loss: 0.2738  loss_cls: 0.03732  loss_box_reg: 0.1105  loss_mask: 0.1012  loss_rpn_cls: 0.001275  loss_rpn_loc: 0.01621  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:50] d2.utils.events INFO:  eta: 1:51:16  iter: 24019  total_loss: 0.4477  loss_cls: 0.06363  loss_box_reg: 0.162  loss_mask: 0.1215  loss_rpn_cls: 0.001064  loss_rpn_loc: 0.02619  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:08:52] d2.utils.events INFO:  eta: 1:51:22  iter: 24039  total_loss: 0.2327  loss_cls: 0.03799  loss_box_reg: 0.1034  loss_mask: 0.0742  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.01149  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:08:55] d2.utils.events INFO:  eta: 1:51:12  iter: 24059  total_loss: 0.3578  loss_cls: 0.05874  loss_box_reg: 0.1551  loss_mask: 0.1124  loss_rpn_cls: 0.001281  loss_rpn_loc: 0.03397  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:08:57] d2.utils.events INFO:  eta: 1:51:07  iter: 24079  total_loss: 0.2674  loss_cls: 0.04714  loss_box_reg: 0.1258  loss_mask: 0.07916  loss_rpn_cls: 0.001106  loss_rpn_loc: 0.01511  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:08:59] d2.utils.events INFO:  eta: 1:51:05  iter: 24099  total_loss: 0.3075  loss_cls: 0.06029  loss_box_reg: 0.1402  loss_mask: 0.08811  loss_rpn_cls: 0.001392  loss_rpn_loc: 0.02886  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:09:01] d2.utils.events INFO:  eta: 1:51:00  iter: 24119  total_loss: 0.259  loss_cls: 0.04177  loss_box_reg: 0.1074  loss_mask: 0.1004  loss_rpn_cls: 0.0008552  loss_rpn_loc: 0.01524  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:03] d2.utils.events INFO:  eta: 1:50:56  iter: 24139  total_loss: 0.3481  loss_cls: 0.05203  loss_box_reg: 0.1435  loss_mask: 0.1142  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.04242  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:09:05] d2.utils.events INFO:  eta: 1:50:44  iter: 24159  total_loss: 0.2537  loss_cls: 0.0374  loss_box_reg: 0.1099  loss_mask: 0.09038  loss_rpn_cls: 0.000454  loss_rpn_loc: 0.01378  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:07] d2.utils.events INFO:  eta: 1:50:37  iter: 24179  total_loss: 0.2503  loss_cls: 0.03422  loss_box_reg: 0.09602  loss_mask: 0.09021  loss_rpn_cls: 0.0005399  loss_rpn_loc: 0.01027  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:09:09] d2.utils.events INFO:  eta: 1:50:40  iter: 24199  total_loss: 0.2859  loss_cls: 0.04372  loss_box_reg: 0.1452  loss_mask: 0.08861  loss_rpn_cls: 0.002762  loss_rpn_loc: 0.01372  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:11] d2.utils.events INFO:  eta: 1:50:38  iter: 24219  total_loss: 0.3463  loss_cls: 0.04825  loss_box_reg: 0.156  loss_mask: 0.1089  loss_rpn_cls: 0.001725  loss_rpn_loc: 0.01422  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:09:13] d2.utils.events INFO:  eta: 1:50:33  iter: 24239  total_loss: 0.3983  loss_cls: 0.07343  loss_box_reg: 0.1774  loss_mask: 0.09292  loss_rpn_cls: 0.001602  loss_rpn_loc: 0.03317  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:15] d2.utils.events INFO:  eta: 1:50:31  iter: 24259  total_loss: 0.2169  loss_cls: 0.03271  loss_box_reg: 0.09274  loss_mask: 0.07841  loss_rpn_cls: 0.001329  loss_rpn_loc: 0.01792  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:17] d2.utils.events INFO:  eta: 1:50:38  iter: 24279  total_loss: 0.2549  loss_cls: 0.04057  loss_box_reg: 0.09693  loss_mask: 0.09183  loss_rpn_cls: 0.001651  loss_rpn_loc: 0.025  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:19] d2.utils.events INFO:  eta: 1:50:42  iter: 24299  total_loss: 0.2631  loss_cls: 0.03117  loss_box_reg: 0.09161  loss_mask: 0.07893  loss_rpn_cls: 0.001149  loss_rpn_loc: 0.01512  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:09:21] d2.utils.events INFO:  eta: 1:50:47  iter: 24319  total_loss: 0.33  loss_cls: 0.05281  loss_box_reg: 0.141  loss_mask: 0.1039  loss_rpn_cls: 0.001267  loss_rpn_loc: 0.02132  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:09:23] d2.utils.events INFO:  eta: 1:50:48  iter: 24339  total_loss: 0.266  loss_cls: 0.04349  loss_box_reg: 0.1072  loss_mask: 0.1155  loss_rpn_cls: 0.001454  loss_rpn_loc: 0.02363  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:25] d2.utils.events INFO:  eta: 1:50:49  iter: 24359  total_loss: 0.1699  loss_cls: 0.02174  loss_box_reg: 0.06425  loss_mask: 0.06511  loss_rpn_cls: 0.0007701  loss_rpn_loc: 0.0184  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:27] d2.utils.events INFO:  eta: 1:50:46  iter: 24379  total_loss: 0.2594  loss_cls: 0.03082  loss_box_reg: 0.1102  loss_mask: 0.08697  loss_rpn_cls: 0.002257  loss_rpn_loc: 0.0149  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:29] d2.utils.events INFO:  eta: 1:50:40  iter: 24399  total_loss: 0.2372  loss_cls: 0.02994  loss_box_reg: 0.09489  loss_mask: 0.08129  loss_rpn_cls: 0.0009423  loss_rpn_loc: 0.03658  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:31] d2.utils.events INFO:  eta: 1:50:35  iter: 24419  total_loss: 0.2446  loss_cls: 0.03607  loss_box_reg: 0.09549  loss_mask: 0.08683  loss_rpn_cls: 0.001169  loss_rpn_loc: 0.009855  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:09:33] d2.utils.events INFO:  eta: 1:50:21  iter: 24439  total_loss: 0.3528  loss_cls: 0.03509  loss_box_reg: 0.1633  loss_mask: 0.12  loss_rpn_cls: 0.001533  loss_rpn_loc: 0.02052  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:35] d2.utils.events INFO:  eta: 1:50:17  iter: 24459  total_loss: 0.2984  loss_cls: 0.03947  loss_box_reg: 0.1281  loss_mask: 0.09266  loss_rpn_cls: 0.00125  loss_rpn_loc: 0.02119  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:38] d2.utils.events INFO:  eta: 1:50:23  iter: 24479  total_loss: 0.3621  loss_cls: 0.06089  loss_box_reg: 0.1689  loss_mask: 0.09817  loss_rpn_cls: 0.0017  loss_rpn_loc: 0.02369  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:40] d2.utils.events INFO:  eta: 1:50:13  iter: 24499  total_loss: 0.2794  loss_cls: 0.04739  loss_box_reg: 0.1207  loss_mask: 0.09394  loss_rpn_cls: 0.001619  loss_rpn_loc: 0.03072  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:42] d2.utils.events INFO:  eta: 1:50:09  iter: 24519  total_loss: 0.2027  loss_cls: 0.02809  loss_box_reg: 0.08439  loss_mask: 0.07048  loss_rpn_cls: 0.0005574  loss_rpn_loc: 0.01183  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:44] d2.utils.events INFO:  eta: 1:50:09  iter: 24539  total_loss: 0.2679  loss_cls: 0.03612  loss_box_reg: 0.09837  loss_mask: 0.1021  loss_rpn_cls: 0.002154  loss_rpn_loc: 0.04117  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:09:46] d2.utils.events INFO:  eta: 1:50:07  iter: 24559  total_loss: 0.2672  loss_cls: 0.04162  loss_box_reg: 0.09666  loss_mask: 0.07122  loss_rpn_cls: 0.001178  loss_rpn_loc: 0.01467  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:48] d2.utils.events INFO:  eta: 1:50:08  iter: 24579  total_loss: 0.2467  loss_cls: 0.03039  loss_box_reg: 0.1036  loss_mask: 0.08071  loss_rpn_cls: 0.0006283  loss_rpn_loc: 0.01351  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:09:50] d2.utils.events INFO:  eta: 1:50:08  iter: 24599  total_loss: 0.2396  loss_cls: 0.04383  loss_box_reg: 0.1029  loss_mask: 0.09848  loss_rpn_cls: 0.002002  loss_rpn_loc: 0.01385  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:52] d2.utils.events INFO:  eta: 1:50:15  iter: 24619  total_loss: 0.3215  loss_cls: 0.04983  loss_box_reg: 0.1354  loss_mask: 0.103  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.0148  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:09:54] d2.utils.events INFO:  eta: 1:50:11  iter: 24639  total_loss: 0.2495  loss_cls: 0.04089  loss_box_reg: 0.1126  loss_mask: 0.08461  loss_rpn_cls: 0.001255  loss_rpn_loc: 0.01833  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:56] d2.utils.events INFO:  eta: 1:50:11  iter: 24659  total_loss: 0.2718  loss_cls: 0.04099  loss_box_reg: 0.1379  loss_mask: 0.1008  loss_rpn_cls: 0.000922  loss_rpn_loc: 0.01341  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:09:58] d2.utils.events INFO:  eta: 1:50:09  iter: 24679  total_loss: 0.328  loss_cls: 0.04367  loss_box_reg: 0.1361  loss_mask: 0.1007  loss_rpn_cls: 0.001072  loss_rpn_loc: 0.01719  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:10:00] d2.utils.events INFO:  eta: 1:49:55  iter: 24699  total_loss: 0.2513  loss_cls: 0.03328  loss_box_reg: 0.09582  loss_mask: 0.09806  loss_rpn_cls: 0.00069  loss_rpn_loc: 0.01112  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:02] d2.utils.events INFO:  eta: 1:49:54  iter: 24719  total_loss: 0.313  loss_cls: 0.04896  loss_box_reg: 0.135  loss_mask: 0.09703  loss_rpn_cls: 0.001451  loss_rpn_loc: 0.02968  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:04] d2.utils.events INFO:  eta: 1:49:58  iter: 24739  total_loss: 0.2455  loss_cls: 0.03462  loss_box_reg: 0.1008  loss_mask: 0.07311  loss_rpn_cls: 0.0003375  loss_rpn_loc: 0.01434  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:06] d2.utils.events INFO:  eta: 1:49:49  iter: 24759  total_loss: 0.2377  loss_cls: 0.03271  loss_box_reg: 0.1078  loss_mask: 0.1025  loss_rpn_cls: 0.0004887  loss_rpn_loc: 0.0106  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:08] d2.utils.events INFO:  eta: 1:49:45  iter: 24779  total_loss: 0.2275  loss_cls: 0.03226  loss_box_reg: 0.09722  loss_mask: 0.08168  loss_rpn_cls: 0.0007882  loss_rpn_loc: 0.01316  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:10] d2.utils.events INFO:  eta: 1:49:36  iter: 24799  total_loss: 0.2202  loss_cls: 0.03111  loss_box_reg: 0.07283  loss_mask: 0.06229  loss_rpn_cls: 0.002173  loss_rpn_loc: 0.02264  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:12] d2.utils.events INFO:  eta: 1:49:37  iter: 24819  total_loss: 0.3112  loss_cls: 0.05109  loss_box_reg: 0.1142  loss_mask: 0.1157  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.01708  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:10:14] d2.utils.events INFO:  eta: 1:49:15  iter: 24839  total_loss: 0.3003  loss_cls: 0.05666  loss_box_reg: 0.1282  loss_mask: 0.09567  loss_rpn_cls: 0.001792  loss_rpn_loc: 0.03367  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:16] d2.utils.events INFO:  eta: 1:49:30  iter: 24859  total_loss: 0.3331  loss_cls: 0.05085  loss_box_reg: 0.1256  loss_mask: 0.09812  loss_rpn_cls: 0.00139  loss_rpn_loc: 0.01971  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:19] d2.utils.events INFO:  eta: 1:49:32  iter: 24879  total_loss: 0.3137  loss_cls: 0.04053  loss_box_reg: 0.1388  loss_mask: 0.08039  loss_rpn_cls: 0.001757  loss_rpn_loc: 0.0249  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:10:21] d2.utils.events INFO:  eta: 1:49:31  iter: 24899  total_loss: 0.3086  loss_cls: 0.03693  loss_box_reg: 0.1283  loss_mask: 0.0888  loss_rpn_cls: 0.0008446  loss_rpn_loc: 0.01703  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:10:23] d2.utils.events INFO:  eta: 1:49:34  iter: 24919  total_loss: 0.3111  loss_cls: 0.04001  loss_box_reg: 0.1499  loss_mask: 0.09029  loss_rpn_cls: 0.001094  loss_rpn_loc: 0.01595  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:25] d2.utils.events INFO:  eta: 1:49:39  iter: 24939  total_loss: 0.2394  loss_cls: 0.03169  loss_box_reg: 0.09236  loss_mask: 0.08131  loss_rpn_cls: 0.0009005  loss_rpn_loc: 0.01135  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:10:27] d2.utils.events INFO:  eta: 1:49:41  iter: 24959  total_loss: 0.2867  loss_cls: 0.0488  loss_box_reg: 0.1297  loss_mask: 0.08443  loss_rpn_cls: 0.0008128  loss_rpn_loc: 0.01376  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:29] d2.utils.events INFO:  eta: 1:49:42  iter: 24979  total_loss: 0.3222  loss_cls: 0.04776  loss_box_reg: 0.1192  loss_mask: 0.08473  loss_rpn_cls: 0.001634  loss_rpn_loc: 0.04032  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:10:31] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0024999.pth
[10/27 19:10:31] d2.utils.events INFO:  eta: 1:49:52  iter: 24999  total_loss: 0.2407  loss_cls: 0.03358  loss_box_reg: 0.09289  loss_mask: 0.08427  loss_rpn_cls: 0.0008104  loss_rpn_loc: 0.01381  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:33] d2.utils.events INFO:  eta: 1:50:01  iter: 25019  total_loss: 0.286  loss_cls: 0.05271  loss_box_reg: 0.125  loss_mask: 0.09457  loss_rpn_cls: 0.001618  loss_rpn_loc: 0.02029  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:35] d2.utils.events INFO:  eta: 1:50:06  iter: 25039  total_loss: 0.3243  loss_cls: 0.04061  loss_box_reg: 0.1074  loss_mask: 0.08788  loss_rpn_cls: 0.002308  loss_rpn_loc: 0.04043  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:37] d2.utils.events INFO:  eta: 1:50:00  iter: 25059  total_loss: 0.2273  loss_cls: 0.03598  loss_box_reg: 0.1028  loss_mask: 0.07578  loss_rpn_cls: 0.001199  loss_rpn_loc: 0.01279  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:10:40] d2.utils.events INFO:  eta: 1:50:13  iter: 25079  total_loss: 0.2808  loss_cls: 0.05229  loss_box_reg: 0.1318  loss_mask: 0.1032  loss_rpn_cls: 0.0006326  loss_rpn_loc: 0.03395  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:10:42] d2.utils.events INFO:  eta: 1:50:11  iter: 25099  total_loss: 0.2376  loss_cls: 0.03501  loss_box_reg: 0.1019  loss_mask: 0.07851  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.01308  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:44] d2.utils.events INFO:  eta: 1:50:00  iter: 25119  total_loss: 0.3246  loss_cls: 0.05548  loss_box_reg: 0.1481  loss_mask: 0.09514  loss_rpn_cls: 0.002782  loss_rpn_loc: 0.02842  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:46] d2.utils.events INFO:  eta: 1:49:58  iter: 25139  total_loss: 0.2559  loss_cls: 0.04163  loss_box_reg: 0.101  loss_mask: 0.09113  loss_rpn_cls: 0.0008545  loss_rpn_loc: 0.01371  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:10:48] d2.utils.events INFO:  eta: 1:50:05  iter: 25159  total_loss: 0.2661  loss_cls: 0.05081  loss_box_reg: 0.09147  loss_mask: 0.06703  loss_rpn_cls: 0.001074  loss_rpn_loc: 0.0175  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:50] d2.utils.events INFO:  eta: 1:50:14  iter: 25179  total_loss: 0.3434  loss_cls: 0.05796  loss_box_reg: 0.1562  loss_mask: 0.1018  loss_rpn_cls: 0.002509  loss_rpn_loc: 0.02192  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:52] d2.utils.events INFO:  eta: 1:50:11  iter: 25199  total_loss: 0.1853  loss_cls: 0.02979  loss_box_reg: 0.07666  loss_mask: 0.08644  loss_rpn_cls: 0.0003889  loss_rpn_loc: 0.008134  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:10:54] d2.utils.events INFO:  eta: 1:50:04  iter: 25219  total_loss: 0.2546  loss_cls: 0.04051  loss_box_reg: 0.1139  loss_mask: 0.0883  loss_rpn_cls: 0.001427  loss_rpn_loc: 0.01323  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:10:56] d2.utils.events INFO:  eta: 1:49:48  iter: 25239  total_loss: 0.2458  loss_cls: 0.03493  loss_box_reg: 0.1055  loss_mask: 0.07473  loss_rpn_cls: 0.0006315  loss_rpn_loc: 0.01752  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:10:58] d2.utils.events INFO:  eta: 1:49:46  iter: 25259  total_loss: 0.2741  loss_cls: 0.04623  loss_box_reg: 0.1238  loss_mask: 0.07484  loss_rpn_cls: 0.0008686  loss_rpn_loc: 0.01545  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:00] d2.utils.events INFO:  eta: 1:49:44  iter: 25279  total_loss: 0.3876  loss_cls: 0.06383  loss_box_reg: 0.1588  loss_mask: 0.1008  loss_rpn_cls: 0.0008161  loss_rpn_loc: 0.02929  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:02] d2.utils.events INFO:  eta: 1:49:34  iter: 25299  total_loss: 0.1994  loss_cls: 0.02651  loss_box_reg: 0.06562  loss_mask: 0.06832  loss_rpn_cls: 0.00203  loss_rpn_loc: 0.01489  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:11:04] d2.utils.events INFO:  eta: 1:49:27  iter: 25319  total_loss: 0.204  loss_cls: 0.03646  loss_box_reg: 0.08301  loss_mask: 0.07519  loss_rpn_cls: 0.001053  loss_rpn_loc: 0.01084  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:06] d2.utils.events INFO:  eta: 1:49:23  iter: 25339  total_loss: 0.2498  loss_cls: 0.0382  loss_box_reg: 0.09859  loss_mask: 0.08936  loss_rpn_cls: 0.0004497  loss_rpn_loc: 0.01376  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:11:08] d2.utils.events INFO:  eta: 1:49:19  iter: 25359  total_loss: 0.1972  loss_cls: 0.03021  loss_box_reg: 0.08306  loss_mask: 0.07491  loss_rpn_cls: 0.0004724  loss_rpn_loc: 0.01297  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:10] d2.utils.events INFO:  eta: 1:49:17  iter: 25379  total_loss: 0.3338  loss_cls: 0.04875  loss_box_reg: 0.1413  loss_mask: 0.09913  loss_rpn_cls: 0.002247  loss_rpn_loc: 0.02654  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:11:12] d2.utils.events INFO:  eta: 1:49:17  iter: 25399  total_loss: 0.2586  loss_cls: 0.03182  loss_box_reg: 0.1198  loss_mask: 0.0893  loss_rpn_cls: 0.0002994  loss_rpn_loc: 0.01465  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:14] d2.utils.events INFO:  eta: 1:49:15  iter: 25419  total_loss: 0.294  loss_cls: 0.04069  loss_box_reg: 0.1291  loss_mask: 0.08592  loss_rpn_cls: 0.0007872  loss_rpn_loc: 0.01643  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:16] d2.utils.events INFO:  eta: 1:49:19  iter: 25439  total_loss: 0.2384  loss_cls: 0.03384  loss_box_reg: 0.09628  loss_mask: 0.0703  loss_rpn_cls: 0.0007891  loss_rpn_loc: 0.01599  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:18] d2.utils.events INFO:  eta: 1:49:18  iter: 25459  total_loss: 0.3313  loss_cls: 0.05869  loss_box_reg: 0.1635  loss_mask: 0.0975  loss_rpn_cls: 0.002924  loss_rpn_loc: 0.02898  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:21] d2.utils.events INFO:  eta: 1:49:13  iter: 25479  total_loss: 0.369  loss_cls: 0.0639  loss_box_reg: 0.1682  loss_mask: 0.1239  loss_rpn_cls: 0.001158  loss_rpn_loc: 0.02689  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:11:23] d2.utils.events INFO:  eta: 1:49:14  iter: 25499  total_loss: 0.2917  loss_cls: 0.04601  loss_box_reg: 0.1004  loss_mask: 0.09996  loss_rpn_cls: 0.001137  loss_rpn_loc: 0.02943  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:25] d2.utils.events INFO:  eta: 1:49:33  iter: 25519  total_loss: 0.2353  loss_cls: 0.03023  loss_box_reg: 0.09649  loss_mask: 0.08058  loss_rpn_cls: 0.0008786  loss_rpn_loc: 0.02244  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:27] d2.utils.events INFO:  eta: 1:49:34  iter: 25539  total_loss: 0.2421  loss_cls: 0.03086  loss_box_reg: 0.1005  loss_mask: 0.08659  loss_rpn_cls: 0.0006331  loss_rpn_loc: 0.01005  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:29] d2.utils.events INFO:  eta: 1:49:35  iter: 25559  total_loss: 0.3509  loss_cls: 0.0437  loss_box_reg: 0.1304  loss_mask: 0.1264  loss_rpn_cls: 0.002196  loss_rpn_loc: 0.03055  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:31] d2.utils.events INFO:  eta: 1:49:30  iter: 25579  total_loss: 0.2092  loss_cls: 0.03239  loss_box_reg: 0.09355  loss_mask: 0.07214  loss_rpn_cls: 0.001738  loss_rpn_loc: 0.02035  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:33] d2.utils.events INFO:  eta: 1:49:25  iter: 25599  total_loss: 0.4265  loss_cls: 0.05812  loss_box_reg: 0.1562  loss_mask: 0.1146  loss_rpn_cls: 0.002085  loss_rpn_loc: 0.04486  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:11:35] d2.utils.events INFO:  eta: 1:49:23  iter: 25619  total_loss: 0.2863  loss_cls: 0.04017  loss_box_reg: 0.137  loss_mask: 0.08553  loss_rpn_cls: 0.001082  loss_rpn_loc: 0.02404  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:11:37] d2.utils.events INFO:  eta: 1:49:24  iter: 25639  total_loss: 0.3539  loss_cls: 0.05103  loss_box_reg: 0.1404  loss_mask: 0.1146  loss_rpn_cls: 0.001765  loss_rpn_loc: 0.03058  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:39] d2.utils.events INFO:  eta: 1:49:22  iter: 25659  total_loss: 0.315  loss_cls: 0.04251  loss_box_reg: 0.1174  loss_mask: 0.1101  loss_rpn_cls: 0.001784  loss_rpn_loc: 0.03668  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:11:41] d2.utils.events INFO:  eta: 1:49:26  iter: 25679  total_loss: 0.2924  loss_cls: 0.04478  loss_box_reg: 0.1404  loss_mask: 0.08902  loss_rpn_cls: 0.001636  loss_rpn_loc: 0.02682  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:43] d2.utils.events INFO:  eta: 1:49:26  iter: 25699  total_loss: 0.3672  loss_cls: 0.04874  loss_box_reg: 0.1578  loss_mask: 0.09978  loss_rpn_cls: 0.001642  loss_rpn_loc: 0.02325  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:45] d2.utils.events INFO:  eta: 1:49:24  iter: 25719  total_loss: 0.2535  loss_cls: 0.03557  loss_box_reg: 0.1057  loss_mask: 0.08736  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.03757  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:47] d2.utils.events INFO:  eta: 1:49:22  iter: 25739  total_loss: 0.3211  loss_cls: 0.04818  loss_box_reg: 0.1414  loss_mask: 0.09071  loss_rpn_cls: 0.002501  loss_rpn_loc: 0.02834  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:49] d2.utils.events INFO:  eta: 1:49:20  iter: 25759  total_loss: 0.1992  loss_cls: 0.0349  loss_box_reg: 0.07955  loss_mask: 0.07093  loss_rpn_cls: 0.001518  loss_rpn_loc: 0.01106  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:51] d2.utils.events INFO:  eta: 1:49:18  iter: 25779  total_loss: 0.1801  loss_cls: 0.02348  loss_box_reg: 0.07661  loss_mask: 0.06795  loss_rpn_cls: 0.0009354  loss_rpn_loc: 0.008017  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:11:53] d2.utils.events INFO:  eta: 1:49:26  iter: 25799  total_loss: 0.2751  loss_cls: 0.04206  loss_box_reg: 0.1225  loss_mask: 0.0986  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.01389  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:55] d2.utils.events INFO:  eta: 1:49:23  iter: 25819  total_loss: 0.2881  loss_cls: 0.04972  loss_box_reg: 0.146  loss_mask: 0.09533  loss_rpn_cls: 0.001456  loss_rpn_loc: 0.01876  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:11:57] d2.utils.events INFO:  eta: 1:49:19  iter: 25839  total_loss: 0.2403  loss_cls: 0.03648  loss_box_reg: 0.1119  loss_mask: 0.08639  loss_rpn_cls: 0.0004844  loss_rpn_loc: 0.01568  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:11:59] d2.utils.events INFO:  eta: 1:49:10  iter: 25859  total_loss: 0.1921  loss_cls: 0.02788  loss_box_reg: 0.0774  loss_mask: 0.07031  loss_rpn_cls: 0.0003587  loss_rpn_loc: 0.01005  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:12:01] d2.utils.events INFO:  eta: 1:49:05  iter: 25879  total_loss: 0.2965  loss_cls: 0.04301  loss_box_reg: 0.1301  loss_mask: 0.08672  loss_rpn_cls: 0.001464  loss_rpn_loc: 0.01456  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:03] d2.utils.events INFO:  eta: 1:49:03  iter: 25899  total_loss: 0.2646  loss_cls: 0.04649  loss_box_reg: 0.1156  loss_mask: 0.09861  loss_rpn_cls: 0.002125  loss_rpn_loc: 0.01583  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:06] d2.utils.events INFO:  eta: 1:49:01  iter: 25919  total_loss: 0.2231  loss_cls: 0.03838  loss_box_reg: 0.09753  loss_mask: 0.08342  loss_rpn_cls: 0.002006  loss_rpn_loc: 0.01199  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:08] d2.utils.events INFO:  eta: 1:49:02  iter: 25939  total_loss: 0.2922  loss_cls: 0.03709  loss_box_reg: 0.1223  loss_mask: 0.0985  loss_rpn_cls: 0.001472  loss_rpn_loc: 0.01291  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:10] d2.utils.events INFO:  eta: 1:49:03  iter: 25959  total_loss: 0.3493  loss_cls: 0.04839  loss_box_reg: 0.1341  loss_mask: 0.1319  loss_rpn_cls: 0.001288  loss_rpn_loc: 0.024  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:12] d2.utils.events INFO:  eta: 1:48:54  iter: 25979  total_loss: 0.2603  loss_cls: 0.03533  loss_box_reg: 0.09647  loss_mask: 0.07664  loss_rpn_cls: 0.001292  loss_rpn_loc: 0.01592  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:14] d2.utils.events INFO:  eta: 1:48:45  iter: 25999  total_loss: 0.1892  loss_cls: 0.0314  loss_box_reg: 0.08238  loss_mask: 0.07082  loss_rpn_cls: 0.001605  loss_rpn_loc: 0.01737  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:16] d2.utils.events INFO:  eta: 1:48:33  iter: 26019  total_loss: 0.3095  loss_cls: 0.04472  loss_box_reg: 0.1319  loss_mask: 0.09466  loss_rpn_cls: 0.001994  loss_rpn_loc: 0.01961  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:18] d2.utils.events INFO:  eta: 1:48:25  iter: 26039  total_loss: 0.2516  loss_cls: 0.03428  loss_box_reg: 0.09196  loss_mask: 0.08471  loss_rpn_cls: 0.0009356  loss_rpn_loc: 0.01898  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:12:20] d2.utils.events INFO:  eta: 1:48:32  iter: 26059  total_loss: 0.2602  loss_cls: 0.03354  loss_box_reg: 0.09909  loss_mask: 0.08189  loss_rpn_cls: 0.001824  loss_rpn_loc: 0.0209  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:22] d2.utils.events INFO:  eta: 1:48:28  iter: 26079  total_loss: 0.3671  loss_cls: 0.05828  loss_box_reg: 0.1631  loss_mask: 0.1063  loss_rpn_cls: 0.001831  loss_rpn_loc: 0.02603  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:12:24] d2.utils.events INFO:  eta: 1:48:19  iter: 26099  total_loss: 0.2347  loss_cls: 0.03441  loss_box_reg: 0.09813  loss_mask: 0.08633  loss_rpn_cls: 0.0007217  loss_rpn_loc: 0.01595  time: 0.1017  data_time: 0.0022  lr: 0.0025  max_mem: 1634M
[10/27 19:12:26] d2.utils.events INFO:  eta: 1:48:09  iter: 26119  total_loss: 0.1872  loss_cls: 0.02449  loss_box_reg: 0.06796  loss_mask: 0.08236  loss_rpn_cls: 0.0004658  loss_rpn_loc: 0.01183  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:28] d2.utils.events INFO:  eta: 1:48:07  iter: 26139  total_loss: 0.2305  loss_cls: 0.03593  loss_box_reg: 0.1042  loss_mask: 0.07361  loss_rpn_cls: 0.0006494  loss_rpn_loc: 0.01304  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:30] d2.utils.events INFO:  eta: 1:48:09  iter: 26159  total_loss: 0.4119  loss_cls: 0.06006  loss_box_reg: 0.1665  loss_mask: 0.1191  loss_rpn_cls: 0.001796  loss_rpn_loc: 0.02532  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:32] d2.utils.events INFO:  eta: 1:48:06  iter: 26179  total_loss: 0.2494  loss_cls: 0.04865  loss_box_reg: 0.1233  loss_mask: 0.09125  loss_rpn_cls: 0.001003  loss_rpn_loc: 0.02108  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:34] d2.utils.events INFO:  eta: 1:48:05  iter: 26199  total_loss: 0.4166  loss_cls: 0.05866  loss_box_reg: 0.1716  loss_mask: 0.1086  loss_rpn_cls: 0.001877  loss_rpn_loc: 0.02151  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:36] d2.utils.events INFO:  eta: 1:48:03  iter: 26219  total_loss: 0.3751  loss_cls: 0.06387  loss_box_reg: 0.1471  loss_mask: 0.1067  loss_rpn_cls: 0.001893  loss_rpn_loc: 0.01919  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:38] d2.utils.events INFO:  eta: 1:48:14  iter: 26239  total_loss: 0.2656  loss_cls: 0.04082  loss_box_reg: 0.132  loss_mask: 0.09323  loss_rpn_cls: 0.000831  loss_rpn_loc: 0.01987  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:41] d2.utils.events INFO:  eta: 1:48:16  iter: 26259  total_loss: 0.2725  loss_cls: 0.04415  loss_box_reg: 0.09564  loss_mask: 0.09035  loss_rpn_cls: 0.0008825  loss_rpn_loc: 0.03176  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:43] d2.utils.events INFO:  eta: 1:48:05  iter: 26279  total_loss: 0.1826  loss_cls: 0.02352  loss_box_reg: 0.063  loss_mask: 0.09133  loss_rpn_cls: 0.0007962  loss_rpn_loc: 0.00796  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:44] d2.utils.events INFO:  eta: 1:48:02  iter: 26299  total_loss: 0.2602  loss_cls: 0.04028  loss_box_reg: 0.08848  loss_mask: 0.07419  loss_rpn_cls: 0.001191  loss_rpn_loc: 0.01149  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:46] d2.utils.events INFO:  eta: 1:47:53  iter: 26319  total_loss: 0.2379  loss_cls: 0.03743  loss_box_reg: 0.1139  loss_mask: 0.07511  loss_rpn_cls: 0.0007112  loss_rpn_loc: 0.02252  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:48] d2.utils.events INFO:  eta: 1:47:55  iter: 26339  total_loss: 0.3376  loss_cls: 0.05992  loss_box_reg: 0.1662  loss_mask: 0.1068  loss_rpn_cls: 0.002106  loss_rpn_loc: 0.0308  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:12:51] d2.utils.events INFO:  eta: 1:48:01  iter: 26359  total_loss: 0.2525  loss_cls: 0.03831  loss_box_reg: 0.1129  loss_mask: 0.07752  loss_rpn_cls: 0.001139  loss_rpn_loc: 0.02735  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:12:53] d2.utils.events INFO:  eta: 1:47:59  iter: 26379  total_loss: 0.2697  loss_cls: 0.04855  loss_box_reg: 0.1246  loss_mask: 0.08215  loss_rpn_cls: 0.0009437  loss_rpn_loc: 0.01377  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:12:55] d2.utils.events INFO:  eta: 1:47:52  iter: 26399  total_loss: 0.2828  loss_cls: 0.04148  loss_box_reg: 0.1228  loss_mask: 0.09533  loss_rpn_cls: 0.0003984  loss_rpn_loc: 0.01509  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:57] d2.utils.events INFO:  eta: 1:47:43  iter: 26419  total_loss: 0.2618  loss_cls: 0.03866  loss_box_reg: 0.0901  loss_mask: 0.07993  loss_rpn_cls: 0.002278  loss_rpn_loc: 0.0212  time: 0.1017  data_time: 0.0026  lr: 0.0025  max_mem: 1634M
[10/27 19:12:59] d2.utils.events INFO:  eta: 1:47:45  iter: 26439  total_loss: 0.2456  loss_cls: 0.0387  loss_box_reg: 0.1332  loss_mask: 0.07156  loss_rpn_cls: 0.0004892  loss_rpn_loc: 0.01396  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:13:01] d2.utils.events INFO:  eta: 1:47:51  iter: 26459  total_loss: 0.317  loss_cls: 0.04632  loss_box_reg: 0.1228  loss_mask: 0.08668  loss_rpn_cls: 0.0008986  loss_rpn_loc: 0.01585  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:13:03] d2.utils.events INFO:  eta: 1:47:40  iter: 26479  total_loss: 0.2244  loss_cls: 0.03689  loss_box_reg: 0.09623  loss_mask: 0.07562  loss_rpn_cls: 0.0008442  loss_rpn_loc: 0.01408  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:13:05] d2.utils.events INFO:  eta: 1:47:38  iter: 26499  total_loss: 0.2567  loss_cls: 0.03662  loss_box_reg: 0.1079  loss_mask: 0.09375  loss_rpn_cls: 0.0006509  loss_rpn_loc: 0.01455  time: 0.1017  data_time: 0.0023  lr: 0.0025  max_mem: 1634M
[10/27 19:13:07] d2.utils.events INFO:  eta: 1:47:29  iter: 26519  total_loss: 0.2958  loss_cls: 0.04728  loss_box_reg: 0.1304  loss_mask: 0.07873  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.02028  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:13:09] d2.utils.events INFO:  eta: 1:47:14  iter: 26539  total_loss: 0.2229  loss_cls: 0.02526  loss_box_reg: 0.07164  loss_mask: 0.08612  loss_rpn_cls: 0.0006862  loss_rpn_loc: 0.01942  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:13:11] d2.utils.events INFO:  eta: 1:47:15  iter: 26559  total_loss: 0.3464  loss_cls: 0.05562  loss_box_reg: 0.146  loss_mask: 0.1092  loss_rpn_cls: 0.001246  loss_rpn_loc: 0.02971  time: 0.1017  data_time: 0.0024  lr: 0.0025  max_mem: 1634M
[10/27 19:13:13] d2.utils.events INFO:  eta: 1:47:16  iter: 26579  total_loss: 0.2021  loss_cls: 0.0397  loss_box_reg: 0.08458  loss_mask: 0.07307  loss_rpn_cls: 0.0009228  loss_rpn_loc: 0.01337  time: 0.1017  data_time: 0.0027  lr: 0.0025  max_mem: 1634M
[10/27 19:13:15] d2.utils.events INFO:  eta: 1:47:22  iter: 26599  total_loss: 0.2389  loss_cls: 0.02594  loss_box_reg: 0.08155  loss_mask: 0.07984  loss_rpn_cls: 0.0008341  loss_rpn_loc: 0.008319  time: 0.1017  data_time: 0.0028  lr: 0.0025  max_mem: 1634M
[10/27 19:13:18] d2.utils.events INFO:  eta: 1:47:23  iter: 26619  total_loss: 0.2963  loss_cls: 0.04698  loss_box_reg: 0.1366  loss_mask: 0.09688  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.02111  time: 0.1017  data_time: 0.0029  lr: 0.0025  max_mem: 1634M
[10/27 19:13:20] d2.utils.events INFO:  eta: 1:47:18  iter: 26639  total_loss: 0.2132  loss_cls: 0.04007  loss_box_reg: 0.1008  loss_mask: 0.07137  loss_rpn_cls: 0.00142  loss_rpn_loc: 0.02427  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:13:21] d2.engine.hooks INFO: Overall training speed: 26646 iterations in 0:45:11 (0.1018 s / it)
[10/27 19:13:21] d2.engine.hooks INFO: Total training time: 0:45:28 (0:00:16 on hooks)
[10/27 19:13:21] d2.utils.events INFO:  eta: 1:47:19  iter: 26648  total_loss: 0.2382  loss_cls: 0.04394  loss_box_reg: 0.1119  loss_mask: 0.07852  loss_rpn_cls: 0.002031  loss_rpn_loc: 0.01854  time: 0.1017  data_time: 0.0025  lr: 0.0025  max_mem: 1634M
[10/27 19:14:01] detectron2 INFO: Rank of current process: 0. World size: 1
[10/27 19:14:02] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.113.01
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/27 19:14:02] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[10/27 19:14:02] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[10/27 19:14:02] detectron2 INFO: Full config saved to ./output_300/config.yaml
[10/27 19:14:02] d2.utils.env INFO: Using a generated random seed 5078335
[10/27 19:14:17] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.47 seconds.
[10/27 19:14:18] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[10/27 19:14:26] d2.data.build INFO: Removed 0 images with no usable annotations. 301 images left.
[10/27 19:14:26] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 656          |   bicycle    | 18           |      car      | 133          |
|  motorcycle   | 38           |   airplane   | 5            |      bus      | 26           |
|     train     | 13           |    truck     | 33           |     boat      | 29           |
| traffic light | 28           | fire hydrant | 7            |   stop sign   | 2            |
| parking meter | 5            |    bench     | 15           |     bird      | 19           |
|      cat      | 12           |     dog      | 13           |     horse     | 13           |
|     sheep     | 3            |     cow      | 39           |   elephant    | 13           |
|     bear      | 5            |    zebra     | 25           |    giraffe    | 9            |
|   backpack    | 26           |   umbrella   | 32           |    handbag    | 44           |
|      tie      | 25           |   suitcase   | 9            |    frisbee    | 5            |
|     skis      | 15           |  snowboard   | 5            |  sports ball  | 26           |
|     kite      | 19           | baseball bat | 9            | baseball gl.. | 17           |
|  skateboard   | 18           |  surfboard   | 8            | tennis racket | 12           |
|    bottle     | 65           |  wine glass  | 5            |      cup      | 27           |
|     fork      | 8            |    knife     | 13           |     spoon     | 26           |
|     bowl      | 43           |    banana    | 28           |     apple     | 24           |
|   sandwich    | 8            |    orange    | 26           |   broccoli    | 13           |
|    carrot     | 12           |   hot dog    | 8            |     pizza     | 5            |
|     donut     | 31           |     cake     | 15           |     chair     | 84           |
|     couch     | 25           | potted plant | 25           |      bed      | 11           |
| dining table  | 31           |    toilet    | 5            |      tv       | 22           |
|    laptop     | 12           |    mouse     | 5            |    remote     | 27           |
|   keyboard    | 8            |  cell phone  | 12           |   microwave   | 7            |
|     oven      | 11           |   toaster    | 1            |     sink      | 17           |
| refrigerator  | 5            |     book     | 49           |     clock     | 22           |
|     vase      | 15           |   scissors   | 2            |  teddy bear   | 8            |
|  hair drier   | 1            |  toothbrush  | 5            |               |              |
|     total     | 2196         |              |              |               |              |[0m
[10/27 19:14:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[10/27 19:14:28] d2.data.build INFO: Using training sampler TrainingSampler
[10/27 19:14:28] d2.data.common INFO: Serializing 301 elements to byte tensors and concatenating them all ...
[10/27 19:14:28] d2.data.common INFO: Serialized dataset takes 1.19 MiB
[10/27 19:14:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_0024999.pth ...
[10/27 19:14:28] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_0024999.pth ...
[10/27 19:14:28] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[10/27 19:14:29] d2.engine.train_loop INFO: Starting training from iteration 25000
[10/27 19:14:31] d2.utils.events INFO:  eta: 1:53:19  iter: 25019  total_loss: 0.2886  loss_cls: 0.04472  loss_box_reg: 0.1205  loss_mask: 0.09317  loss_rpn_cls: 0.000825  loss_rpn_loc: 0.01791  time: 0.1131  data_time: 0.0097  lr: 0.0025  max_mem: 1339M
[10/27 19:14:34] d2.utils.events INFO:  eta: 1:48:10  iter: 25039  total_loss: 0.2764  loss_cls: 0.03688  loss_box_reg: 0.1011  loss_mask: 0.1012  loss_rpn_cls: 0.0008421  loss_rpn_loc: 0.01682  time: 0.1076  data_time: 0.0025  lr: 0.0025  max_mem: 1409M
[10/27 19:14:36] d2.utils.events INFO:  eta: 1:46:10  iter: 25059  total_loss: 0.2632  loss_cls: 0.03875  loss_box_reg: 0.1082  loss_mask: 0.09352  loss_rpn_cls: 0.00102  loss_rpn_loc: 0.02485  time: 0.1051  data_time: 0.0024  lr: 0.0025  max_mem: 1413M
[10/27 19:14:38] d2.utils.events INFO:  eta: 1:44:28  iter: 25079  total_loss: 0.2966  loss_cls: 0.0427  loss_box_reg: 0.1278  loss_mask: 0.09509  loss_rpn_cls: 0.001362  loss_rpn_loc: 0.01607  time: 0.1038  data_time: 0.0025  lr: 0.0025  max_mem: 1413M
[10/27 19:14:40] d2.utils.events INFO:  eta: 1:44:14  iter: 25099  total_loss: 0.2737  loss_cls: 0.03417  loss_box_reg: 0.1217  loss_mask: 0.09822  loss_rpn_cls: 0.0007651  loss_rpn_loc: 0.01192  time: 0.1025  data_time: 0.0023  lr: 0.0025  max_mem: 1413M
[10/27 19:14:41] d2.utils.events INFO:  eta: 1:43:07  iter: 25119  total_loss: 0.2142  loss_cls: 0.03889  loss_box_reg: 0.09263  loss_mask: 0.09214  loss_rpn_cls: 0.001416  loss_rpn_loc: 0.01416  time: 0.1012  data_time: 0.0023  lr: 0.0025  max_mem: 1472M
[10/27 19:14:43] d2.utils.events INFO:  eta: 1:43:13  iter: 25139  total_loss: 0.3575  loss_cls: 0.04293  loss_box_reg: 0.1578  loss_mask: 0.09629  loss_rpn_cls: 0.00221  loss_rpn_loc: 0.03598  time: 0.1009  data_time: 0.0024  lr: 0.0025  max_mem: 1472M
[10/27 19:14:45] d2.utils.events INFO:  eta: 1:42:54  iter: 25159  total_loss: 0.2784  loss_cls: 0.03395  loss_box_reg: 0.119  loss_mask: 0.09105  loss_rpn_cls: 0.001676  loss_rpn_loc: 0.01497  time: 0.1001  data_time: 0.0023  lr: 0.0025  max_mem: 1472M
[10/27 19:14:47] d2.utils.events INFO:  eta: 1:42:39  iter: 25179  total_loss: 0.3717  loss_cls: 0.05845  loss_box_reg: 0.1772  loss_mask: 0.1153  loss_rpn_cls: 0.001914  loss_rpn_loc: 0.02732  time: 0.0996  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:14:49] d2.utils.events INFO:  eta: 1:42:12  iter: 25199  total_loss: 0.2396  loss_cls: 0.03361  loss_box_reg: 0.1181  loss_mask: 0.07823  loss_rpn_cls: 0.001473  loss_rpn_loc: 0.01818  time: 0.0988  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:14:51] d2.utils.events INFO:  eta: 1:42:04  iter: 25219  total_loss: 0.3169  loss_cls: 0.03634  loss_box_reg: 0.1171  loss_mask: 0.102  loss_rpn_cls: 0.0006126  loss_rpn_loc: 0.01382  time: 0.0980  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:14:53] d2.utils.events INFO:  eta: 1:41:52  iter: 25239  total_loss: 0.202  loss_cls: 0.02705  loss_box_reg: 0.06087  loss_mask: 0.07412  loss_rpn_cls: 0.0008831  loss_rpn_loc: 0.01528  time: 0.0976  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:14:55] d2.utils.events INFO:  eta: 1:41:37  iter: 25259  total_loss: 0.1398  loss_cls: 0.02535  loss_box_reg: 0.0565  loss_mask: 0.05495  loss_rpn_cls: 0.0008627  loss_rpn_loc: 0.00973  time: 0.0968  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:14:56] d2.utils.events INFO:  eta: 1:41:20  iter: 25279  total_loss: 0.2325  loss_cls: 0.03843  loss_box_reg: 0.09926  loss_mask: 0.07246  loss_rpn_cls: 0.0007873  loss_rpn_loc: 0.01462  time: 0.0963  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:14:58] d2.utils.events INFO:  eta: 1:41:01  iter: 25299  total_loss: 0.2542  loss_cls: 0.0428  loss_box_reg: 0.1061  loss_mask: 0.08493  loss_rpn_cls: 0.001084  loss_rpn_loc: 0.01946  time: 0.0961  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:15:00] d2.utils.events INFO:  eta: 1:40:47  iter: 25319  total_loss: 0.2528  loss_cls: 0.03456  loss_box_reg: 0.09625  loss_mask: 0.08765  loss_rpn_cls: 0.0006345  loss_rpn_loc: 0.01321  time: 0.0957  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:02] d2.utils.events INFO:  eta: 1:40:44  iter: 25339  total_loss: 0.3042  loss_cls: 0.05545  loss_box_reg: 0.1346  loss_mask: 0.1005  loss_rpn_cls: 0.0008477  loss_rpn_loc: 0.0234  time: 0.0953  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:15:04] d2.utils.events INFO:  eta: 1:40:28  iter: 25359  total_loss: 0.3469  loss_cls: 0.05343  loss_box_reg: 0.1572  loss_mask: 0.11  loss_rpn_cls: 0.001119  loss_rpn_loc: 0.02299  time: 0.0949  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:05] d2.utils.events INFO:  eta: 1:40:15  iter: 25379  total_loss: 0.2633  loss_cls: 0.04272  loss_box_reg: 0.1163  loss_mask: 0.09031  loss_rpn_cls: 0.0006922  loss_rpn_loc: 0.01114  time: 0.0945  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:07] d2.utils.events INFO:  eta: 1:40:03  iter: 25399  total_loss: 0.3131  loss_cls: 0.04719  loss_box_reg: 0.1327  loss_mask: 0.104  loss_rpn_cls: 0.0008592  loss_rpn_loc: 0.02853  time: 0.0943  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:09] d2.utils.events INFO:  eta: 1:40:01  iter: 25419  total_loss: 0.1882  loss_cls: 0.02791  loss_box_reg: 0.08125  loss_mask: 0.05931  loss_rpn_cls: 0.0004996  loss_rpn_loc: 0.008881  time: 0.0941  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:15:11] d2.utils.events INFO:  eta: 1:39:55  iter: 25439  total_loss: 0.2096  loss_cls: 0.033  loss_box_reg: 0.07912  loss_mask: 0.08264  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.0191  time: 0.0938  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:13] d2.utils.events INFO:  eta: 1:39:50  iter: 25459  total_loss: 0.2854  loss_cls: 0.04203  loss_box_reg: 0.1255  loss_mask: 0.09239  loss_rpn_cls: 0.001346  loss_rpn_loc: 0.03089  time: 0.0936  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:14] d2.utils.events INFO:  eta: 1:39:38  iter: 25479  total_loss: 0.2203  loss_cls: 0.03358  loss_box_reg: 0.09339  loss_mask: 0.09223  loss_rpn_cls: 0.001004  loss_rpn_loc: 0.0146  time: 0.0934  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:16] d2.utils.events INFO:  eta: 1:39:31  iter: 25499  total_loss: 0.2695  loss_cls: 0.04021  loss_box_reg: 0.1256  loss_mask: 0.08799  loss_rpn_cls: 0.0006628  loss_rpn_loc: 0.01267  time: 0.0932  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:18] d2.utils.events INFO:  eta: 1:39:25  iter: 25519  total_loss: 0.2178  loss_cls: 0.03857  loss_box_reg: 0.08528  loss_mask: 0.08318  loss_rpn_cls: 0.0004814  loss_rpn_loc: 0.01205  time: 0.0931  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:20] d2.utils.events INFO:  eta: 1:39:25  iter: 25539  total_loss: 0.238  loss_cls: 0.03128  loss_box_reg: 0.1045  loss_mask: 0.09098  loss_rpn_cls: 0.0009431  loss_rpn_loc: 0.01698  time: 0.0931  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:22] d2.utils.events INFO:  eta: 1:39:29  iter: 25559  total_loss: 0.3711  loss_cls: 0.05991  loss_box_reg: 0.163  loss_mask: 0.1112  loss_rpn_cls: 0.001565  loss_rpn_loc: 0.0303  time: 0.0931  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:23] d2.utils.events INFO:  eta: 1:39:19  iter: 25579  total_loss: 0.239  loss_cls: 0.03923  loss_box_reg: 0.09568  loss_mask: 0.07404  loss_rpn_cls: 0.00157  loss_rpn_loc: 0.01568  time: 0.0929  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:25] d2.utils.events INFO:  eta: 1:39:17  iter: 25599  total_loss: 0.3531  loss_cls: 0.05674  loss_box_reg: 0.1721  loss_mask: 0.12  loss_rpn_cls: 0.001835  loss_rpn_loc: 0.02391  time: 0.0929  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:27] d2.utils.events INFO:  eta: 1:39:13  iter: 25619  total_loss: 0.2787  loss_cls: 0.03285  loss_box_reg: 0.1227  loss_mask: 0.08716  loss_rpn_cls: 0.0007711  loss_rpn_loc: 0.0141  time: 0.0928  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:29] d2.utils.events INFO:  eta: 1:39:09  iter: 25639  total_loss: 0.2782  loss_cls: 0.03375  loss_box_reg: 0.1297  loss_mask: 0.1162  loss_rpn_cls: 0.001829  loss_rpn_loc: 0.01481  time: 0.0926  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:15:31] d2.utils.events INFO:  eta: 1:39:02  iter: 25659  total_loss: 0.2112  loss_cls: 0.03061  loss_box_reg: 0.09532  loss_mask: 0.07627  loss_rpn_cls: 0.000484  loss_rpn_loc: 0.01061  time: 0.0924  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:15:32] d2.utils.events INFO:  eta: 1:39:01  iter: 25679  total_loss: 0.4159  loss_cls: 0.05904  loss_box_reg: 0.1633  loss_mask: 0.113  loss_rpn_cls: 0.001667  loss_rpn_loc: 0.03203  time: 0.0924  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:34] d2.utils.events INFO:  eta: 1:38:58  iter: 25699  total_loss: 0.3586  loss_cls: 0.05225  loss_box_reg: 0.1265  loss_mask: 0.1075  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.01655  time: 0.0923  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:36] d2.utils.events INFO:  eta: 1:38:47  iter: 25719  total_loss: 0.2039  loss_cls: 0.02206  loss_box_reg: 0.09328  loss_mask: 0.08368  loss_rpn_cls: 0.0006053  loss_rpn_loc: 0.01029  time: 0.0921  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:38] d2.utils.events INFO:  eta: 1:38:37  iter: 25739  total_loss: 0.2377  loss_cls: 0.03727  loss_box_reg: 0.1119  loss_mask: 0.07364  loss_rpn_cls: 0.0006682  loss_rpn_loc: 0.008831  time: 0.0920  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:39] d2.utils.events INFO:  eta: 1:38:36  iter: 25759  total_loss: 0.2684  loss_cls: 0.04391  loss_box_reg: 0.1192  loss_mask: 0.08973  loss_rpn_cls: 0.0006679  loss_rpn_loc: 0.01818  time: 0.0919  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:41] d2.utils.events INFO:  eta: 1:38:31  iter: 25779  total_loss: 0.2491  loss_cls: 0.03857  loss_box_reg: 0.1217  loss_mask: 0.07883  loss_rpn_cls: 0.0008598  loss_rpn_loc: 0.02565  time: 0.0918  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:15:43] d2.utils.events INFO:  eta: 1:38:26  iter: 25799  total_loss: 0.2155  loss_cls: 0.02608  loss_box_reg: 0.08361  loss_mask: 0.07477  loss_rpn_cls: 0.001324  loss_rpn_loc: 0.01359  time: 0.0917  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:15:45] d2.utils.events INFO:  eta: 1:38:26  iter: 25819  total_loss: 0.3433  loss_cls: 0.0531  loss_box_reg: 0.1431  loss_mask: 0.1083  loss_rpn_cls: 0.001087  loss_rpn_loc: 0.02  time: 0.0916  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:47] d2.utils.events INFO:  eta: 1:38:22  iter: 25839  total_loss: 0.2915  loss_cls: 0.05495  loss_box_reg: 0.1266  loss_mask: 0.08468  loss_rpn_cls: 0.001599  loss_rpn_loc: 0.02169  time: 0.0916  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:48] d2.utils.events INFO:  eta: 1:38:18  iter: 25859  total_loss: 0.273  loss_cls: 0.04513  loss_box_reg: 0.112  loss_mask: 0.0991  loss_rpn_cls: 0.0009015  loss_rpn_loc: 0.01911  time: 0.0915  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:50] d2.utils.events INFO:  eta: 1:38:18  iter: 25879  total_loss: 0.3652  loss_cls: 0.0498  loss_box_reg: 0.1463  loss_mask: 0.1111  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.02554  time: 0.0915  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:52] d2.utils.events INFO:  eta: 1:38:14  iter: 25899  total_loss: 0.235  loss_cls: 0.03577  loss_box_reg: 0.1099  loss_mask: 0.09826  loss_rpn_cls: 0.0005636  loss_rpn_loc: 0.01253  time: 0.0915  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:54] d2.utils.events INFO:  eta: 1:38:12  iter: 25919  total_loss: 0.2133  loss_cls: 0.02339  loss_box_reg: 0.07108  loss_mask: 0.08759  loss_rpn_cls: 0.001159  loss_rpn_loc: 0.01687  time: 0.0913  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:56] d2.utils.events INFO:  eta: 1:38:10  iter: 25939  total_loss: 0.2271  loss_cls: 0.03231  loss_box_reg: 0.09067  loss_mask: 0.06528  loss_rpn_cls: 0.0008107  loss_rpn_loc: 0.01522  time: 0.0913  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:57] d2.utils.events INFO:  eta: 1:38:01  iter: 25959  total_loss: 0.2569  loss_cls: 0.04225  loss_box_reg: 0.1363  loss_mask: 0.09436  loss_rpn_cls: 0.001314  loss_rpn_loc: 0.01235  time: 0.0912  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:15:59] d2.utils.events INFO:  eta: 1:37:47  iter: 25979  total_loss: 0.2189  loss_cls: 0.02108  loss_box_reg: 0.07185  loss_mask: 0.08319  loss_rpn_cls: 0.0006159  loss_rpn_loc: 0.01294  time: 0.0911  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:01] d2.utils.events INFO:  eta: 1:37:45  iter: 25999  total_loss: 0.3288  loss_cls: 0.04702  loss_box_reg: 0.1373  loss_mask: 0.1127  loss_rpn_cls: 0.001528  loss_rpn_loc: 0.01919  time: 0.0911  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:03] d2.utils.events INFO:  eta: 1:37:34  iter: 26019  total_loss: 0.253  loss_cls: 0.04044  loss_box_reg: 0.1093  loss_mask: 0.08765  loss_rpn_cls: 0.0009957  loss_rpn_loc: 0.01149  time: 0.0910  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:04] d2.utils.events INFO:  eta: 1:37:23  iter: 26039  total_loss: 0.3082  loss_cls: 0.04437  loss_box_reg: 0.136  loss_mask: 0.09285  loss_rpn_cls: 0.0006737  loss_rpn_loc: 0.01506  time: 0.0910  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:06] d2.utils.events INFO:  eta: 1:37:18  iter: 26059  total_loss: 0.3449  loss_cls: 0.06149  loss_box_reg: 0.1572  loss_mask: 0.1106  loss_rpn_cls: 0.00122  loss_rpn_loc: 0.02772  time: 0.0910  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:08] d2.utils.events INFO:  eta: 1:37:07  iter: 26079  total_loss: 0.2836  loss_cls: 0.04417  loss_box_reg: 0.1369  loss_mask: 0.07824  loss_rpn_cls: 0.0008017  loss_rpn_loc: 0.01666  time: 0.0910  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:10] d2.utils.events INFO:  eta: 1:37:03  iter: 26099  total_loss: 0.2916  loss_cls: 0.03679  loss_box_reg: 0.1448  loss_mask: 0.08649  loss_rpn_cls: 0.002011  loss_rpn_loc: 0.02731  time: 0.0910  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:12] d2.utils.events INFO:  eta: 1:37:01  iter: 26119  total_loss: 0.2771  loss_cls: 0.04978  loss_box_reg: 0.1207  loss_mask: 0.07642  loss_rpn_cls: 0.002413  loss_rpn_loc: 0.02229  time: 0.0910  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:13] d2.utils.events INFO:  eta: 1:36:44  iter: 26139  total_loss: 0.2769  loss_cls: 0.04266  loss_box_reg: 0.1308  loss_mask: 0.08061  loss_rpn_cls: 0.000809  loss_rpn_loc: 0.0135  time: 0.0909  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:15] d2.utils.events INFO:  eta: 1:36:37  iter: 26159  total_loss: 0.2231  loss_cls: 0.03046  loss_box_reg: 0.09844  loss_mask: 0.07761  loss_rpn_cls: 0.0004377  loss_rpn_loc: 0.01064  time: 0.0909  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:17] d2.utils.events INFO:  eta: 1:36:03  iter: 26179  total_loss: 0.187  loss_cls: 0.03282  loss_box_reg: 0.07738  loss_mask: 0.07968  loss_rpn_cls: 0.0004851  loss_rpn_loc: 0.008689  time: 0.0908  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:19] d2.utils.events INFO:  eta: 1:35:51  iter: 26199  total_loss: 0.2591  loss_cls: 0.04167  loss_box_reg: 0.1162  loss_mask: 0.1303  loss_rpn_cls: 0.0007092  loss_rpn_loc: 0.01521  time: 0.0908  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:21] d2.utils.events INFO:  eta: 1:35:40  iter: 26219  total_loss: 0.2864  loss_cls: 0.04501  loss_box_reg: 0.1083  loss_mask: 0.08171  loss_rpn_cls: 0.001198  loss_rpn_loc: 0.02092  time: 0.0907  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:22] d2.utils.events INFO:  eta: 1:35:44  iter: 26239  total_loss: 0.3384  loss_cls: 0.05295  loss_box_reg: 0.1371  loss_mask: 0.1121  loss_rpn_cls: 0.0008478  loss_rpn_loc: 0.01844  time: 0.0907  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:24] d2.utils.events INFO:  eta: 1:35:45  iter: 26259  total_loss: 0.2138  loss_cls: 0.03126  loss_box_reg: 0.1043  loss_mask: 0.0857  loss_rpn_cls: 0.0007676  loss_rpn_loc: 0.00897  time: 0.0907  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:26] d2.utils.events INFO:  eta: 1:35:54  iter: 26279  total_loss: 0.2744  loss_cls: 0.04704  loss_box_reg: 0.1087  loss_mask: 0.08568  loss_rpn_cls: 0.0008724  loss_rpn_loc: 0.01423  time: 0.0906  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:28] d2.utils.events INFO:  eta: 1:35:53  iter: 26299  total_loss: 0.2616  loss_cls: 0.03824  loss_box_reg: 0.1076  loss_mask: 0.1108  loss_rpn_cls: 0.002674  loss_rpn_loc: 0.01578  time: 0.0907  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:16:30] d2.utils.events INFO:  eta: 1:35:52  iter: 26319  total_loss: 0.2674  loss_cls: 0.03373  loss_box_reg: 0.1186  loss_mask: 0.1035  loss_rpn_cls: 0.0009825  loss_rpn_loc: 0.01902  time: 0.0906  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:31] d2.utils.events INFO:  eta: 1:35:38  iter: 26339  total_loss: 0.2422  loss_cls: 0.02953  loss_box_reg: 0.09541  loss_mask: 0.09474  loss_rpn_cls: 0.0008181  loss_rpn_loc: 0.01022  time: 0.0906  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:33] d2.utils.events INFO:  eta: 1:35:26  iter: 26359  total_loss: 0.1964  loss_cls: 0.03118  loss_box_reg: 0.06569  loss_mask: 0.06966  loss_rpn_cls: 0.00099  loss_rpn_loc: 0.01159  time: 0.0904  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:35] d2.utils.events INFO:  eta: 1:35:24  iter: 26379  total_loss: 0.2708  loss_cls: 0.04136  loss_box_reg: 0.1148  loss_mask: 0.08899  loss_rpn_cls: 0.0008989  loss_rpn_loc: 0.01672  time: 0.0904  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:37] d2.utils.events INFO:  eta: 1:35:22  iter: 26399  total_loss: 0.3443  loss_cls: 0.04334  loss_box_reg: 0.1325  loss_mask: 0.0992  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.02872  time: 0.0904  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:38] d2.utils.events INFO:  eta: 1:35:13  iter: 26419  total_loss: 0.2194  loss_cls: 0.03836  loss_box_reg: 0.09316  loss_mask: 0.06608  loss_rpn_cls: 0.0007826  loss_rpn_loc: 0.01899  time: 0.0904  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:40] d2.utils.events INFO:  eta: 1:35:05  iter: 26439  total_loss: 0.2481  loss_cls: 0.03625  loss_box_reg: 0.1145  loss_mask: 0.07221  loss_rpn_cls: 0.001043  loss_rpn_loc: 0.01813  time: 0.0903  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:42] d2.utils.events INFO:  eta: 1:35:04  iter: 26459  total_loss: 0.2554  loss_cls: 0.04191  loss_box_reg: 0.1143  loss_mask: 0.0917  loss_rpn_cls: 0.0007884  loss_rpn_loc: 0.008337  time: 0.0903  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:44] d2.utils.events INFO:  eta: 1:35:06  iter: 26479  total_loss: 0.2501  loss_cls: 0.0356  loss_box_reg: 0.09786  loss_mask: 0.09242  loss_rpn_cls: 0.0006517  loss_rpn_loc: 0.01105  time: 0.0903  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:45] d2.utils.events INFO:  eta: 1:35:10  iter: 26499  total_loss: 0.29  loss_cls: 0.04234  loss_box_reg: 0.1441  loss_mask: 0.08754  loss_rpn_cls: 0.0006286  loss_rpn_loc: 0.01931  time: 0.0903  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:47] d2.utils.events INFO:  eta: 1:35:12  iter: 26519  total_loss: 0.3566  loss_cls: 0.05426  loss_box_reg: 0.1436  loss_mask: 0.1079  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.02523  time: 0.0903  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:49] d2.utils.events INFO:  eta: 1:35:02  iter: 26539  total_loss: 0.1534  loss_cls: 0.02014  loss_box_reg: 0.05084  loss_mask: 0.07785  loss_rpn_cls: 0.0003087  loss_rpn_loc: 0.005051  time: 0.0902  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:51] d2.utils.events INFO:  eta: 1:34:54  iter: 26559  total_loss: 0.2361  loss_cls: 0.04161  loss_box_reg: 0.1035  loss_mask: 0.08094  loss_rpn_cls: 0.0005046  loss_rpn_loc: 0.01273  time: 0.0902  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:53] d2.utils.events INFO:  eta: 1:34:50  iter: 26579  total_loss: 0.2154  loss_cls: 0.0316  loss_box_reg: 0.09138  loss_mask: 0.07664  loss_rpn_cls: 0.0006887  loss_rpn_loc: 0.01255  time: 0.0902  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:54] d2.utils.events INFO:  eta: 1:34:44  iter: 26599  total_loss: 0.2863  loss_cls: 0.05162  loss_box_reg: 0.125  loss_mask: 0.1011  loss_rpn_cls: 0.001581  loss_rpn_loc: 0.01965  time: 0.0902  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:16:56] d2.utils.events INFO:  eta: 1:34:39  iter: 26619  total_loss: 0.2937  loss_cls: 0.03595  loss_box_reg: 0.1454  loss_mask: 0.08258  loss_rpn_cls: 0.0008412  loss_rpn_loc: 0.007892  time: 0.0902  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:16:58] d2.utils.events INFO:  eta: 1:34:37  iter: 26639  total_loss: 0.2872  loss_cls: 0.04296  loss_box_reg: 0.1154  loss_mask: 0.08504  loss_rpn_cls: 0.001006  loss_rpn_loc: 0.0163  time: 0.0902  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:00] d2.utils.events INFO:  eta: 1:34:36  iter: 26659  total_loss: 0.2309  loss_cls: 0.03081  loss_box_reg: 0.099  loss_mask: 0.07345  loss_rpn_cls: 0.0008329  loss_rpn_loc: 0.01757  time: 0.0901  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:01] d2.utils.events INFO:  eta: 1:34:28  iter: 26679  total_loss: 0.2439  loss_cls: 0.03046  loss_box_reg: 0.07766  loss_mask: 0.08497  loss_rpn_cls: 0.0009745  loss_rpn_loc: 0.01299  time: 0.0901  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:03] d2.utils.events INFO:  eta: 1:34:27  iter: 26699  total_loss: 0.2584  loss_cls: 0.03563  loss_box_reg: 0.1017  loss_mask: 0.08184  loss_rpn_cls: 0.0009705  loss_rpn_loc: 0.01321  time: 0.0901  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:05] d2.utils.events INFO:  eta: 1:34:25  iter: 26719  total_loss: 0.2115  loss_cls: 0.03008  loss_box_reg: 0.08804  loss_mask: 0.07045  loss_rpn_cls: 0.0008799  loss_rpn_loc: 0.008704  time: 0.0900  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:07] d2.utils.events INFO:  eta: 1:34:23  iter: 26739  total_loss: 0.1987  loss_cls: 0.02485  loss_box_reg: 0.06754  loss_mask: 0.0795  loss_rpn_cls: 0.0006414  loss_rpn_loc: 0.009425  time: 0.0900  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:08] d2.utils.events INFO:  eta: 1:34:22  iter: 26759  total_loss: 0.3  loss_cls: 0.05182  loss_box_reg: 0.1241  loss_mask: 0.1164  loss_rpn_cls: 0.002513  loss_rpn_loc: 0.02181  time: 0.0900  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:10] d2.utils.events INFO:  eta: 1:34:19  iter: 26779  total_loss: 0.2727  loss_cls: 0.04277  loss_box_reg: 0.1133  loss_mask: 0.09458  loss_rpn_cls: 0.0004711  loss_rpn_loc: 0.01174  time: 0.0900  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:12] d2.utils.events INFO:  eta: 1:34:29  iter: 26799  total_loss: 0.4259  loss_cls: 0.0678  loss_box_reg: 0.1807  loss_mask: 0.1401  loss_rpn_cls: 0.003209  loss_rpn_loc: 0.03778  time: 0.0900  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:14] d2.utils.events INFO:  eta: 1:34:17  iter: 26819  total_loss: 0.1995  loss_cls: 0.02865  loss_box_reg: 0.08441  loss_mask: 0.07367  loss_rpn_cls: 0.00128  loss_rpn_loc: 0.01147  time: 0.0900  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:16] d2.utils.events INFO:  eta: 1:34:15  iter: 26839  total_loss: 0.2605  loss_cls: 0.04736  loss_box_reg: 0.1035  loss_mask: 0.0989  loss_rpn_cls: 0.001421  loss_rpn_loc: 0.01399  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:17] d2.utils.events INFO:  eta: 1:34:13  iter: 26859  total_loss: 0.3395  loss_cls: 0.03869  loss_box_reg: 0.1322  loss_mask: 0.09939  loss_rpn_cls: 0.002238  loss_rpn_loc: 0.02419  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:19] d2.utils.events INFO:  eta: 1:34:10  iter: 26879  total_loss: 0.2896  loss_cls: 0.03943  loss_box_reg: 0.1019  loss_mask: 0.0988  loss_rpn_cls: 0.001586  loss_rpn_loc: 0.02112  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:21] d2.utils.events INFO:  eta: 1:33:57  iter: 26899  total_loss: 0.2851  loss_cls: 0.03763  loss_box_reg: 0.1183  loss_mask: 0.09677  loss_rpn_cls: 0.001198  loss_rpn_loc: 0.01678  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:23] d2.utils.events INFO:  eta: 1:33:59  iter: 26919  total_loss: 0.2276  loss_cls: 0.03426  loss_box_reg: 0.1126  loss_mask: 0.07547  loss_rpn_cls: 0.0005395  loss_rpn_loc: 0.01638  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:25] d2.utils.events INFO:  eta: 1:33:47  iter: 26939  total_loss: 0.2595  loss_cls: 0.0532  loss_box_reg: 0.1079  loss_mask: 0.07862  loss_rpn_cls: 0.00139  loss_rpn_loc: 0.01735  time: 0.0899  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:26] d2.utils.events INFO:  eta: 1:34:00  iter: 26959  total_loss: 0.3293  loss_cls: 0.05674  loss_box_reg: 0.1715  loss_mask: 0.09678  loss_rpn_cls: 0.001386  loss_rpn_loc: 0.02515  time: 0.0899  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:28] d2.utils.events INFO:  eta: 1:34:03  iter: 26979  total_loss: 0.298  loss_cls: 0.04162  loss_box_reg: 0.1438  loss_mask: 0.09348  loss_rpn_cls: 0.001859  loss_rpn_loc: 0.02049  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:30] d2.utils.events INFO:  eta: 1:33:52  iter: 26999  total_loss: 0.1948  loss_cls: 0.03258  loss_box_reg: 0.08064  loss_mask: 0.07334  loss_rpn_cls: 0.0006108  loss_rpn_loc: 0.01041  time: 0.0899  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:32] d2.utils.events INFO:  eta: 1:33:55  iter: 27019  total_loss: 0.3106  loss_cls: 0.04942  loss_box_reg: 0.1431  loss_mask: 0.1015  loss_rpn_cls: 0.0007692  loss_rpn_loc: 0.01556  time: 0.0898  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:33] d2.utils.events INFO:  eta: 1:33:39  iter: 27039  total_loss: 0.2397  loss_cls: 0.02776  loss_box_reg: 0.09655  loss_mask: 0.07168  loss_rpn_cls: 0.001034  loss_rpn_loc: 0.01299  time: 0.0898  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:35] d2.utils.events INFO:  eta: 1:33:39  iter: 27059  total_loss: 0.3297  loss_cls: 0.05309  loss_box_reg: 0.1605  loss_mask: 0.08927  loss_rpn_cls: 0.0008979  loss_rpn_loc: 0.01339  time: 0.0898  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:17:37] d2.utils.events INFO:  eta: 1:33:29  iter: 27079  total_loss: 0.1883  loss_cls: 0.02401  loss_box_reg: 0.06583  loss_mask: 0.07493  loss_rpn_cls: 0.0008166  loss_rpn_loc: 0.009541  time: 0.0898  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:39] d2.utils.events INFO:  eta: 1:33:17  iter: 27099  total_loss: 0.2017  loss_cls: 0.02522  loss_box_reg: 0.07315  loss_mask: 0.07135  loss_rpn_cls: 0.0004573  loss_rpn_loc: 0.008235  time: 0.0898  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:41] d2.utils.events INFO:  eta: 1:33:13  iter: 27119  total_loss: 0.2042  loss_cls: 0.04049  loss_box_reg: 0.09864  loss_mask: 0.07388  loss_rpn_cls: 0.000636  loss_rpn_loc: 0.01468  time: 0.0898  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:42] d2.utils.events INFO:  eta: 1:33:11  iter: 27139  total_loss: 0.2  loss_cls: 0.02886  loss_box_reg: 0.07468  loss_mask: 0.07684  loss_rpn_cls: 0.002103  loss_rpn_loc: 0.01488  time: 0.0897  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:44] d2.utils.events INFO:  eta: 1:33:03  iter: 27159  total_loss: 0.1868  loss_cls: 0.02705  loss_box_reg: 0.08003  loss_mask: 0.07614  loss_rpn_cls: 0.0005689  loss_rpn_loc: 0.008492  time: 0.0897  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:46] d2.utils.events INFO:  eta: 1:33:06  iter: 27179  total_loss: 0.2342  loss_cls: 0.03635  loss_box_reg: 0.08654  loss_mask: 0.07666  loss_rpn_cls: 0.0009286  loss_rpn_loc: 0.01197  time: 0.0897  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:47] d2.utils.events INFO:  eta: 1:33:00  iter: 27199  total_loss: 0.2742  loss_cls: 0.05062  loss_box_reg: 0.1259  loss_mask: 0.09412  loss_rpn_cls: 0.0008444  loss_rpn_loc: 0.01983  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:49] d2.utils.events INFO:  eta: 1:32:59  iter: 27219  total_loss: 0.2916  loss_cls: 0.04017  loss_box_reg: 0.1138  loss_mask: 0.09808  loss_rpn_cls: 0.001334  loss_rpn_loc: 0.01867  time: 0.0896  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:51] d2.utils.events INFO:  eta: 1:32:54  iter: 27239  total_loss: 0.2314  loss_cls: 0.03384  loss_box_reg: 0.09755  loss_mask: 0.07944  loss_rpn_cls: 0.0009899  loss_rpn_loc: 0.01446  time: 0.0896  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:53] d2.utils.events INFO:  eta: 1:32:53  iter: 27259  total_loss: 0.2745  loss_cls: 0.0293  loss_box_reg: 0.0887  loss_mask: 0.09102  loss_rpn_cls: 0.0009998  loss_rpn_loc: 0.01746  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:55] d2.utils.events INFO:  eta: 1:33:06  iter: 27279  total_loss: 0.3066  loss_cls: 0.05281  loss_box_reg: 0.1324  loss_mask: 0.09217  loss_rpn_cls: 0.003048  loss_rpn_loc: 0.03387  time: 0.0896  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:17:56] d2.utils.events INFO:  eta: 1:32:55  iter: 27299  total_loss: 0.2686  loss_cls: 0.03759  loss_box_reg: 0.1141  loss_mask: 0.07907  loss_rpn_cls: 0.001403  loss_rpn_loc: 0.01946  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:17:58] d2.utils.events INFO:  eta: 1:32:56  iter: 27319  total_loss: 0.2066  loss_cls: 0.03011  loss_box_reg: 0.09463  loss_mask: 0.08018  loss_rpn_cls: 0.001094  loss_rpn_loc: 0.01067  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:00] d2.utils.events INFO:  eta: 1:33:07  iter: 27339  total_loss: 0.2581  loss_cls: 0.03361  loss_box_reg: 0.1417  loss_mask: 0.08371  loss_rpn_cls: 0.001138  loss_rpn_loc: 0.02034  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:02] d2.utils.events INFO:  eta: 1:33:14  iter: 27359  total_loss: 0.2341  loss_cls: 0.02795  loss_box_reg: 0.1081  loss_mask: 0.09137  loss_rpn_cls: 0.0006707  loss_rpn_loc: 0.01072  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:04] d2.utils.events INFO:  eta: 1:33:14  iter: 27379  total_loss: 0.2878  loss_cls: 0.03663  loss_box_reg: 0.1491  loss_mask: 0.07092  loss_rpn_cls: 0.0008538  loss_rpn_loc: 0.0203  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:05] d2.utils.events INFO:  eta: 1:33:05  iter: 27399  total_loss: 0.1849  loss_cls: 0.02608  loss_box_reg: 0.08463  loss_mask: 0.06858  loss_rpn_cls: 0.0007454  loss_rpn_loc: 0.01361  time: 0.0896  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:07] d2.utils.events INFO:  eta: 1:33:05  iter: 27419  total_loss: 0.2018  loss_cls: 0.02649  loss_box_reg: 0.1001  loss_mask: 0.07567  loss_rpn_cls: 0.0002257  loss_rpn_loc: 0.006708  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:09] d2.utils.events INFO:  eta: 1:33:03  iter: 27439  total_loss: 0.1974  loss_cls: 0.02688  loss_box_reg: 0.07093  loss_mask: 0.08579  loss_rpn_cls: 0.0004763  loss_rpn_loc: 0.009382  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:11] d2.utils.events INFO:  eta: 1:32:57  iter: 27459  total_loss: 0.1916  loss_cls: 0.02564  loss_box_reg: 0.07435  loss_mask: 0.07158  loss_rpn_cls: 0.0006729  loss_rpn_loc: 0.0151  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:12] d2.utils.events INFO:  eta: 1:32:50  iter: 27479  total_loss: 0.2796  loss_cls: 0.04586  loss_box_reg: 0.1278  loss_mask: 0.08946  loss_rpn_cls: 0.0009848  loss_rpn_loc: 0.0131  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:14] d2.utils.events INFO:  eta: 1:32:52  iter: 27499  total_loss: 0.3807  loss_cls: 0.06228  loss_box_reg: 0.1589  loss_mask: 0.118  loss_rpn_cls: 0.002391  loss_rpn_loc: 0.03522  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:16] d2.utils.events INFO:  eta: 1:32:36  iter: 27519  total_loss: 0.2177  loss_cls: 0.0332  loss_box_reg: 0.0827  loss_mask: 0.09366  loss_rpn_cls: 0.0008686  loss_rpn_loc: 0.01247  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:18] d2.utils.events INFO:  eta: 1:32:34  iter: 27539  total_loss: 0.215  loss_cls: 0.03169  loss_box_reg: 0.09534  loss_mask: 0.0754  loss_rpn_cls: 0.0006119  loss_rpn_loc: 0.008286  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:19] d2.utils.events INFO:  eta: 1:32:28  iter: 27559  total_loss: 0.2522  loss_cls: 0.04372  loss_box_reg: 0.1138  loss_mask: 0.08029  loss_rpn_cls: 0.002206  loss_rpn_loc: 0.01736  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:21] d2.utils.events INFO:  eta: 1:32:31  iter: 27579  total_loss: 0.3845  loss_cls: 0.05618  loss_box_reg: 0.1604  loss_mask: 0.103  loss_rpn_cls: 0.0008028  loss_rpn_loc: 0.02271  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:23] d2.utils.events INFO:  eta: 1:32:30  iter: 27599  total_loss: 0.24  loss_cls: 0.03164  loss_box_reg: 0.09758  loss_mask: 0.08771  loss_rpn_cls: 0.0007077  loss_rpn_loc: 0.01236  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:25] d2.utils.events INFO:  eta: 1:32:42  iter: 27619  total_loss: 0.2733  loss_cls: 0.03884  loss_box_reg: 0.1054  loss_mask: 0.08438  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.02393  time: 0.0895  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:18:27] d2.utils.events INFO:  eta: 1:32:42  iter: 27639  total_loss: 0.268  loss_cls: 0.03661  loss_box_reg: 0.1301  loss_mask: 0.07425  loss_rpn_cls: 0.001066  loss_rpn_loc: 0.01249  time: 0.0895  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:18:29] d2.utils.events INFO:  eta: 1:32:58  iter: 27659  total_loss: 0.3964  loss_cls: 0.05205  loss_box_reg: 0.1567  loss_mask: 0.1082  loss_rpn_cls: 0.001297  loss_rpn_loc: 0.02601  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:31] d2.utils.events INFO:  eta: 1:32:57  iter: 27679  total_loss: 0.2689  loss_cls: 0.04577  loss_box_reg: 0.134  loss_mask: 0.08548  loss_rpn_cls: 0.001396  loss_rpn_loc: 0.02605  time: 0.0896  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:32] d2.utils.events INFO:  eta: 1:32:54  iter: 27699  total_loss: 0.2696  loss_cls: 0.03616  loss_box_reg: 0.138  loss_mask: 0.08159  loss_rpn_cls: 0.001024  loss_rpn_loc: 0.02121  time: 0.0896  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:34] d2.utils.events INFO:  eta: 1:32:54  iter: 27719  total_loss: 0.2011  loss_cls: 0.02806  loss_box_reg: 0.07432  loss_mask: 0.08281  loss_rpn_cls: 0.000306  loss_rpn_loc: 0.01195  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:36] d2.utils.events INFO:  eta: 1:32:54  iter: 27739  total_loss: 0.2654  loss_cls: 0.04031  loss_box_reg: 0.1172  loss_mask: 0.07838  loss_rpn_cls: 0.0008349  loss_rpn_loc: 0.01807  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:38] d2.utils.events INFO:  eta: 1:32:52  iter: 27759  total_loss: 0.2546  loss_cls: 0.03558  loss_box_reg: 0.1272  loss_mask: 0.06824  loss_rpn_cls: 0.0008911  loss_rpn_loc: 0.01527  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:39] d2.utils.events INFO:  eta: 1:32:53  iter: 27779  total_loss: 0.2856  loss_cls: 0.04337  loss_box_reg: 0.1254  loss_mask: 0.09379  loss_rpn_cls: 0.001357  loss_rpn_loc: 0.02249  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:41] d2.utils.events INFO:  eta: 1:32:31  iter: 27799  total_loss: 0.2652  loss_cls: 0.04212  loss_box_reg: 0.09589  loss_mask: 0.08208  loss_rpn_cls: 0.0008754  loss_rpn_loc: 0.01809  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:43] d2.utils.events INFO:  eta: 1:32:29  iter: 27819  total_loss: 0.2537  loss_cls: 0.03198  loss_box_reg: 0.1244  loss_mask: 0.07874  loss_rpn_cls: 0.0008401  loss_rpn_loc: 0.01231  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:45] d2.utils.events INFO:  eta: 1:32:28  iter: 27839  total_loss: 0.1926  loss_cls: 0.0295  loss_box_reg: 0.07087  loss_mask: 0.06512  loss_rpn_cls: 0.0009551  loss_rpn_loc: 0.0104  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:46] d2.utils.events INFO:  eta: 1:32:26  iter: 27859  total_loss: 0.2875  loss_cls: 0.04428  loss_box_reg: 0.1254  loss_mask: 0.09582  loss_rpn_cls: 0.00117  loss_rpn_loc: 0.01638  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:48] d2.utils.events INFO:  eta: 1:32:19  iter: 27879  total_loss: 0.1824  loss_cls: 0.0259  loss_box_reg: 0.08037  loss_mask: 0.07707  loss_rpn_cls: 0.0007102  loss_rpn_loc: 0.00865  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:50] d2.utils.events INFO:  eta: 1:32:17  iter: 27899  total_loss: 0.2083  loss_cls: 0.03007  loss_box_reg: 0.07698  loss_mask: 0.08047  loss_rpn_cls: 0.000487  loss_rpn_loc: 0.006877  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:52] d2.utils.events INFO:  eta: 1:32:17  iter: 27919  total_loss: 0.2393  loss_cls: 0.02975  loss_box_reg: 0.1239  loss_mask: 0.06998  loss_rpn_cls: 0.0005542  loss_rpn_loc: 0.0124  time: 0.0894  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:54] d2.utils.events INFO:  eta: 1:32:25  iter: 27939  total_loss: 0.3149  loss_cls: 0.04176  loss_box_reg: 0.1475  loss_mask: 0.08634  loss_rpn_cls: 0.00139  loss_rpn_loc: 0.02214  time: 0.0894  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:18:55] d2.utils.events INFO:  eta: 1:32:13  iter: 27959  total_loss: 0.2823  loss_cls: 0.04724  loss_box_reg: 0.14  loss_mask: 0.09312  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.01876  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:18:57] d2.utils.events INFO:  eta: 1:32:22  iter: 27979  total_loss: 0.3128  loss_cls: 0.05731  loss_box_reg: 0.1555  loss_mask: 0.1038  loss_rpn_cls: 0.001073  loss_rpn_loc: 0.01531  time: 0.0895  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:18:59] d2.utils.events INFO:  eta: 1:32:28  iter: 27999  total_loss: 0.3082  loss_cls: 0.04815  loss_box_reg: 0.1312  loss_mask: 0.08344  loss_rpn_cls: 0.001357  loss_rpn_loc: 0.02486  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:01] d2.utils.events INFO:  eta: 1:32:25  iter: 28019  total_loss: 0.279  loss_cls: 0.03765  loss_box_reg: 0.1429  loss_mask: 0.09628  loss_rpn_cls: 0.0007362  loss_rpn_loc: 0.01016  time: 0.0895  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:03] d2.utils.events INFO:  eta: 1:32:24  iter: 28039  total_loss: 0.2234  loss_cls: 0.03097  loss_box_reg: 0.09188  loss_mask: 0.07783  loss_rpn_cls: 0.0006505  loss_rpn_loc: 0.01297  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:04] d2.utils.events INFO:  eta: 1:32:06  iter: 28059  total_loss: 0.2701  loss_cls: 0.05094  loss_box_reg: 0.1093  loss_mask: 0.09867  loss_rpn_cls: 0.001307  loss_rpn_loc: 0.02339  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:06] d2.utils.events INFO:  eta: 1:32:16  iter: 28079  total_loss: 0.3651  loss_cls: 0.04589  loss_box_reg: 0.1494  loss_mask: 0.1075  loss_rpn_cls: 0.001407  loss_rpn_loc: 0.02699  time: 0.0894  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:08] d2.utils.events INFO:  eta: 1:32:15  iter: 28099  total_loss: 0.2652  loss_cls: 0.03383  loss_box_reg: 0.1287  loss_mask: 0.08268  loss_rpn_cls: 0.0008583  loss_rpn_loc: 0.01736  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:10] d2.utils.events INFO:  eta: 1:32:13  iter: 28119  total_loss: 0.168  loss_cls: 0.0212  loss_box_reg: 0.06834  loss_mask: 0.08261  loss_rpn_cls: 0.0005313  loss_rpn_loc: 0.007851  time: 0.0894  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:12] d2.utils.events INFO:  eta: 1:32:16  iter: 28139  total_loss: 0.3229  loss_cls: 0.04606  loss_box_reg: 0.1291  loss_mask: 0.1251  loss_rpn_cls: 0.001903  loss_rpn_loc: 0.0281  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:13] d2.utils.events INFO:  eta: 1:32:33  iter: 28159  total_loss: 0.2894  loss_cls: 0.0348  loss_box_reg: 0.1069  loss_mask: 0.09542  loss_rpn_cls: 0.0008367  loss_rpn_loc: 0.01817  time: 0.0895  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:15] d2.utils.events INFO:  eta: 1:32:31  iter: 28179  total_loss: 0.2376  loss_cls: 0.03569  loss_box_reg: 0.1006  loss_mask: 0.07084  loss_rpn_cls: 0.0009364  loss_rpn_loc: 0.01096  time: 0.0894  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:17] d2.utils.events INFO:  eta: 1:32:29  iter: 28199  total_loss: 0.1757  loss_cls: 0.0274  loss_box_reg: 0.07192  loss_mask: 0.06682  loss_rpn_cls: 0.0007242  loss_rpn_loc: 0.008803  time: 0.0894  data_time: 0.0019  lr: 0.0025  max_mem: 1491M
[10/27 19:19:19] d2.utils.events INFO:  eta: 1:32:22  iter: 28219  total_loss: 0.166  loss_cls: 0.02267  loss_box_reg: 0.07619  loss_mask: 0.05983  loss_rpn_cls: 0.0009588  loss_rpn_loc: 0.01017  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:20] d2.utils.events INFO:  eta: 1:32:17  iter: 28239  total_loss: 0.2537  loss_cls: 0.04835  loss_box_reg: 0.1178  loss_mask: 0.07236  loss_rpn_cls: 0.0009012  loss_rpn_loc: 0.01091  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:22] d2.utils.events INFO:  eta: 1:32:05  iter: 28259  total_loss: 0.1909  loss_cls: 0.02811  loss_box_reg: 0.07029  loss_mask: 0.07432  loss_rpn_cls: 0.0007276  loss_rpn_loc: 0.008671  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:24] d2.utils.events INFO:  eta: 1:31:55  iter: 28279  total_loss: 0.287  loss_cls: 0.04103  loss_box_reg: 0.1245  loss_mask: 0.09272  loss_rpn_cls: 0.001511  loss_rpn_loc: 0.02436  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:26] d2.utils.events INFO:  eta: 1:31:48  iter: 28299  total_loss: 0.2497  loss_cls: 0.04006  loss_box_reg: 0.1039  loss_mask: 0.08231  loss_rpn_cls: 0.000744  loss_rpn_loc: 0.0173  time: 0.0894  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:27] d2.utils.events INFO:  eta: 1:31:44  iter: 28319  total_loss: 0.2303  loss_cls: 0.03201  loss_box_reg: 0.06739  loss_mask: 0.08124  loss_rpn_cls: 0.0005584  loss_rpn_loc: 0.008944  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:29] d2.utils.events INFO:  eta: 1:31:39  iter: 28339  total_loss: 0.2933  loss_cls: 0.04305  loss_box_reg: 0.1289  loss_mask: 0.09075  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.01528  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:31] d2.utils.events INFO:  eta: 1:31:43  iter: 28359  total_loss: 0.2509  loss_cls: 0.04187  loss_box_reg: 0.1161  loss_mask: 0.09158  loss_rpn_cls: 0.0008288  loss_rpn_loc: 0.01779  time: 0.0893  data_time: 0.0019  lr: 0.0025  max_mem: 1491M
[10/27 19:19:33] d2.utils.events INFO:  eta: 1:31:33  iter: 28379  total_loss: 0.1649  loss_cls: 0.02488  loss_box_reg: 0.07315  loss_mask: 0.07236  loss_rpn_cls: 0.0003701  loss_rpn_loc: 0.009971  time: 0.0893  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:35] d2.utils.events INFO:  eta: 1:31:38  iter: 28399  total_loss: 0.3281  loss_cls: 0.05219  loss_box_reg: 0.1494  loss_mask: 0.07483  loss_rpn_cls: 0.0007079  loss_rpn_loc: 0.01647  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:36] d2.utils.events INFO:  eta: 1:31:36  iter: 28419  total_loss: 0.2983  loss_cls: 0.03816  loss_box_reg: 0.1282  loss_mask: 0.08179  loss_rpn_cls: 0.001134  loss_rpn_loc: 0.01719  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:38] d2.utils.events INFO:  eta: 1:31:34  iter: 28439  total_loss: 0.2074  loss_cls: 0.03569  loss_box_reg: 0.08548  loss_mask: 0.071  loss_rpn_cls: 0.001477  loss_rpn_loc: 0.01376  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:40] d2.utils.events INFO:  eta: 1:31:43  iter: 28459  total_loss: 0.1918  loss_cls: 0.02653  loss_box_reg: 0.07399  loss_mask: 0.07604  loss_rpn_cls: 0.001551  loss_rpn_loc: 0.01628  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:42] d2.utils.events INFO:  eta: 1:31:34  iter: 28479  total_loss: 0.1524  loss_cls: 0.03149  loss_box_reg: 0.05152  loss_mask: 0.06517  loss_rpn_cls: 0.0004814  loss_rpn_loc: 0.00767  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:43] d2.utils.events INFO:  eta: 1:31:32  iter: 28499  total_loss: 0.2343  loss_cls: 0.03483  loss_box_reg: 0.1212  loss_mask: 0.07125  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.01851  time: 0.0893  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:45] d2.utils.events INFO:  eta: 1:31:31  iter: 28519  total_loss: 0.18  loss_cls: 0.03082  loss_box_reg: 0.07141  loss_mask: 0.07313  loss_rpn_cls: 0.0008286  loss_rpn_loc: 0.009452  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:47] d2.utils.events INFO:  eta: 1:31:35  iter: 28539  total_loss: 0.2319  loss_cls: 0.03543  loss_box_reg: 0.103  loss_mask: 0.08371  loss_rpn_cls: 0.0007331  loss_rpn_loc: 0.01268  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:49] d2.utils.events INFO:  eta: 1:31:31  iter: 28559  total_loss: 0.2269  loss_cls: 0.0414  loss_box_reg: 0.08831  loss_mask: 0.08656  loss_rpn_cls: 0.0005936  loss_rpn_loc: 0.01024  time: 0.0893  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:19:50] d2.utils.events INFO:  eta: 1:31:25  iter: 28579  total_loss: 0.296  loss_cls: 0.04227  loss_box_reg: 0.1297  loss_mask: 0.09071  loss_rpn_cls: 0.000995  loss_rpn_loc: 0.01823  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:52] d2.utils.events INFO:  eta: 1:31:20  iter: 28599  total_loss: 0.3497  loss_cls: 0.0602  loss_box_reg: 0.1602  loss_mask: 0.1105  loss_rpn_cls: 0.0009799  loss_rpn_loc: 0.02668  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:54] d2.utils.events INFO:  eta: 1:31:13  iter: 28619  total_loss: 0.3227  loss_cls: 0.03959  loss_box_reg: 0.1677  loss_mask: 0.08534  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.01128  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:19:56] d2.utils.events INFO:  eta: 1:31:10  iter: 28639  total_loss: 0.2306  loss_cls: 0.03168  loss_box_reg: 0.1036  loss_mask: 0.07511  loss_rpn_cls: 0.000827  loss_rpn_loc: 0.01253  time: 0.0893  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:19:58] d2.utils.events INFO:  eta: 1:31:03  iter: 28659  total_loss: 0.2823  loss_cls: 0.03217  loss_box_reg: 0.1234  loss_mask: 0.08898  loss_rpn_cls: 0.0009161  loss_rpn_loc: 0.01138  time: 0.0893  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:00] d2.utils.events INFO:  eta: 1:31:00  iter: 28679  total_loss: 0.2023  loss_cls: 0.03061  loss_box_reg: 0.098  loss_mask: 0.08514  loss_rpn_cls: 0.001533  loss_rpn_loc: 0.01028  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:01] d2.utils.events INFO:  eta: 1:31:00  iter: 28699  total_loss: 0.276  loss_cls: 0.04397  loss_box_reg: 0.1262  loss_mask: 0.08396  loss_rpn_cls: 0.0008169  loss_rpn_loc: 0.01891  time: 0.0893  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:03] d2.utils.events INFO:  eta: 1:30:57  iter: 28719  total_loss: 0.2501  loss_cls: 0.04582  loss_box_reg: 0.1193  loss_mask: 0.08372  loss_rpn_cls: 0.0009391  loss_rpn_loc: 0.01525  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:05] d2.utils.events INFO:  eta: 1:30:51  iter: 28739  total_loss: 0.215  loss_cls: 0.04073  loss_box_reg: 0.09638  loss_mask: 0.07834  loss_rpn_cls: 0.0009574  loss_rpn_loc: 0.02348  time: 0.0893  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:07] d2.utils.events INFO:  eta: 1:30:41  iter: 28759  total_loss: 0.1972  loss_cls: 0.02745  loss_box_reg: 0.084  loss_mask: 0.07667  loss_rpn_cls: 0.0008287  loss_rpn_loc: 0.01846  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:08] d2.utils.events INFO:  eta: 1:30:39  iter: 28779  total_loss: 0.2287  loss_cls: 0.03074  loss_box_reg: 0.08814  loss_mask: 0.07448  loss_rpn_cls: 0.001874  loss_rpn_loc: 0.01488  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:10] d2.utils.events INFO:  eta: 1:30:43  iter: 28799  total_loss: 0.3105  loss_cls: 0.04581  loss_box_reg: 0.1495  loss_mask: 0.09127  loss_rpn_cls: 0.001476  loss_rpn_loc: 0.02468  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:12] d2.utils.events INFO:  eta: 1:30:41  iter: 28819  total_loss: 0.2336  loss_cls: 0.03881  loss_box_reg: 0.1106  loss_mask: 0.07497  loss_rpn_cls: 0.001081  loss_rpn_loc: 0.01447  time: 0.0892  data_time: 0.0019  lr: 0.0025  max_mem: 1491M
[10/27 19:20:14] d2.utils.events INFO:  eta: 1:30:39  iter: 28839  total_loss: 0.2006  loss_cls: 0.02682  loss_box_reg: 0.06734  loss_mask: 0.06654  loss_rpn_cls: 0.0005643  loss_rpn_loc: 0.009356  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:15] d2.utils.events INFO:  eta: 1:30:32  iter: 28859  total_loss: 0.1853  loss_cls: 0.02554  loss_box_reg: 0.08376  loss_mask: 0.06941  loss_rpn_cls: 0.0004731  loss_rpn_loc: 0.007391  time: 0.0892  data_time: 0.0019  lr: 0.0025  max_mem: 1491M
[10/27 19:20:17] d2.utils.events INFO:  eta: 1:30:35  iter: 28879  total_loss: 0.2726  loss_cls: 0.04435  loss_box_reg: 0.1255  loss_mask: 0.09145  loss_rpn_cls: 0.0008342  loss_rpn_loc: 0.01524  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:19] d2.utils.events INFO:  eta: 1:30:34  iter: 28899  total_loss: 0.2163  loss_cls: 0.03561  loss_box_reg: 0.07707  loss_mask: 0.08677  loss_rpn_cls: 0.0005048  loss_rpn_loc: 0.007553  time: 0.0892  data_time: 0.0019  lr: 0.0025  max_mem: 1491M
[10/27 19:20:21] d2.utils.events INFO:  eta: 1:30:30  iter: 28919  total_loss: 0.2722  loss_cls: 0.03174  loss_box_reg: 0.1144  loss_mask: 0.08565  loss_rpn_cls: 0.001412  loss_rpn_loc: 0.02215  time: 0.0892  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:22] d2.utils.events INFO:  eta: 1:30:26  iter: 28939  total_loss: 0.2611  loss_cls: 0.03759  loss_box_reg: 0.1141  loss_mask: 0.08636  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.01083  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:24] d2.utils.events INFO:  eta: 1:30:22  iter: 28959  total_loss: 0.2735  loss_cls: 0.0393  loss_box_reg: 0.1137  loss_mask: 0.08656  loss_rpn_cls: 0.0007404  loss_rpn_loc: 0.02562  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:26] d2.utils.events INFO:  eta: 1:30:14  iter: 28979  total_loss: 0.3398  loss_cls: 0.04312  loss_box_reg: 0.1244  loss_mask: 0.1009  loss_rpn_cls: 0.0007895  loss_rpn_loc: 0.01162  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:28] d2.utils.events INFO:  eta: 1:30:09  iter: 28999  total_loss: 0.2  loss_cls: 0.03142  loss_box_reg: 0.0872  loss_mask: 0.07239  loss_rpn_cls: 0.000777  loss_rpn_loc: 0.01685  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:29] d2.utils.events INFO:  eta: 1:30:03  iter: 29019  total_loss: 0.1945  loss_cls: 0.0309  loss_box_reg: 0.07553  loss_mask: 0.06615  loss_rpn_cls: 0.000559  loss_rpn_loc: 0.01246  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:31] d2.utils.events INFO:  eta: 1:30:02  iter: 29039  total_loss: 0.2084  loss_cls: 0.02975  loss_box_reg: 0.08396  loss_mask: 0.07498  loss_rpn_cls: 0.001344  loss_rpn_loc: 0.02097  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:33] d2.utils.events INFO:  eta: 1:30:08  iter: 29059  total_loss: 0.2666  loss_cls: 0.0509  loss_box_reg: 0.125  loss_mask: 0.07641  loss_rpn_cls: 0.0005325  loss_rpn_loc: 0.01168  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:35] d2.utils.events INFO:  eta: 1:30:07  iter: 29079  total_loss: 0.2685  loss_cls: 0.0421  loss_box_reg: 0.1247  loss_mask: 0.07458  loss_rpn_cls: 0.001209  loss_rpn_loc: 0.02286  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:37] d2.utils.events INFO:  eta: 1:30:06  iter: 29099  total_loss: 0.2238  loss_cls: 0.03281  loss_box_reg: 0.09569  loss_mask: 0.07743  loss_rpn_cls: 0.001104  loss_rpn_loc: 0.01738  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:38] d2.utils.events INFO:  eta: 1:30:03  iter: 29119  total_loss: 0.2422  loss_cls: 0.03747  loss_box_reg: 0.1204  loss_mask: 0.073  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.01473  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:40] d2.utils.events INFO:  eta: 1:29:52  iter: 29139  total_loss: 0.256  loss_cls: 0.0341  loss_box_reg: 0.1  loss_mask: 0.08246  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.01725  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:42] d2.utils.events INFO:  eta: 1:29:50  iter: 29159  total_loss: 0.1976  loss_cls: 0.0337  loss_box_reg: 0.09  loss_mask: 0.076  loss_rpn_cls: 0.0007317  loss_rpn_loc: 0.0132  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:44] d2.utils.events INFO:  eta: 1:29:50  iter: 29179  total_loss: 0.2509  loss_cls: 0.04493  loss_box_reg: 0.1174  loss_mask: 0.09284  loss_rpn_cls: 0.001284  loss_rpn_loc: 0.01296  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:45] d2.utils.events INFO:  eta: 1:29:55  iter: 29199  total_loss: 0.2315  loss_cls: 0.03831  loss_box_reg: 0.1056  loss_mask: 0.08365  loss_rpn_cls: 0.0008349  loss_rpn_loc: 0.01294  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:47] d2.utils.events INFO:  eta: 1:29:55  iter: 29219  total_loss: 0.2941  loss_cls: 0.04531  loss_box_reg: 0.1121  loss_mask: 0.09973  loss_rpn_cls: 0.002238  loss_rpn_loc: 0.01228  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:49] d2.utils.events INFO:  eta: 1:29:59  iter: 29239  total_loss: 0.2948  loss_cls: 0.04701  loss_box_reg: 0.1369  loss_mask: 0.0842  loss_rpn_cls: 0.00138  loss_rpn_loc: 0.01867  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:51] d2.utils.events INFO:  eta: 1:30:07  iter: 29259  total_loss: 0.2253  loss_cls: 0.02837  loss_box_reg: 0.1081  loss_mask: 0.06766  loss_rpn_cls: 0.0008753  loss_rpn_loc: 0.01379  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:53] d2.utils.events INFO:  eta: 1:30:10  iter: 29279  total_loss: 0.3545  loss_cls: 0.05235  loss_box_reg: 0.1466  loss_mask: 0.108  loss_rpn_cls: 0.001982  loss_rpn_loc: 0.03774  time: 0.0891  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:20:55] d2.utils.events INFO:  eta: 1:30:17  iter: 29299  total_loss: 0.2624  loss_cls: 0.04032  loss_box_reg: 0.1033  loss_mask: 0.07658  loss_rpn_cls: 0.0004211  loss_rpn_loc: 0.01261  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:20:56] d2.utils.events INFO:  eta: 1:30:06  iter: 29319  total_loss: 0.1922  loss_cls: 0.02771  loss_box_reg: 0.08706  loss_mask: 0.06313  loss_rpn_cls: 0.0004849  loss_rpn_loc: 0.0112  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:20:58] d2.utils.events INFO:  eta: 1:30:02  iter: 29339  total_loss: 0.2395  loss_cls: 0.03527  loss_box_reg: 0.09611  loss_mask: 0.06853  loss_rpn_cls: 0.0006142  loss_rpn_loc: 0.01203  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:00] d2.utils.events INFO:  eta: 1:30:00  iter: 29359  total_loss: 0.2949  loss_cls: 0.05369  loss_box_reg: 0.1407  loss_mask: 0.09157  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.021  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:02] d2.utils.events INFO:  eta: 1:29:56  iter: 29379  total_loss: 0.1746  loss_cls: 0.03356  loss_box_reg: 0.07365  loss_mask: 0.06099  loss_rpn_cls: 0.000573  loss_rpn_loc: 0.01113  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:03] d2.utils.events INFO:  eta: 1:29:54  iter: 29399  total_loss: 0.269  loss_cls: 0.03713  loss_box_reg: 0.1252  loss_mask: 0.07854  loss_rpn_cls: 0.00104  loss_rpn_loc: 0.01976  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:05] d2.utils.events INFO:  eta: 1:29:52  iter: 29419  total_loss: 0.1804  loss_cls: 0.02196  loss_box_reg: 0.07762  loss_mask: 0.0759  loss_rpn_cls: 0.0009438  loss_rpn_loc: 0.01269  time: 0.0891  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:21:07] d2.utils.events INFO:  eta: 1:29:56  iter: 29439  total_loss: 0.2905  loss_cls: 0.04182  loss_box_reg: 0.1209  loss_mask: 0.1139  loss_rpn_cls: 0.001319  loss_rpn_loc: 0.01922  time: 0.0891  data_time: 0.0023  lr: 0.0025  max_mem: 1491M
[10/27 19:21:09] d2.utils.events INFO:  eta: 1:29:50  iter: 29459  total_loss: 0.1975  loss_cls: 0.02943  loss_box_reg: 0.07948  loss_mask: 0.07287  loss_rpn_cls: 0.0004012  loss_rpn_loc: 0.01136  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:11] d2.utils.events INFO:  eta: 1:29:47  iter: 29479  total_loss: 0.1545  loss_cls: 0.01995  loss_box_reg: 0.06537  loss_mask: 0.06101  loss_rpn_cls: 0.0002426  loss_rpn_loc: 0.006017  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:12] d2.utils.events INFO:  eta: 1:29:43  iter: 29499  total_loss: 0.3247  loss_cls: 0.04445  loss_box_reg: 0.1309  loss_mask: 0.08622  loss_rpn_cls: 0.001328  loss_rpn_loc: 0.0194  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:14] d2.utils.events INFO:  eta: 1:29:39  iter: 29519  total_loss: 0.1951  loss_cls: 0.02571  loss_box_reg: 0.08828  loss_mask: 0.08056  loss_rpn_cls: 0.000632  loss_rpn_loc: 0.01229  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:16] d2.utils.events INFO:  eta: 1:29:41  iter: 29539  total_loss: 0.31  loss_cls: 0.0608  loss_box_reg: 0.1404  loss_mask: 0.09873  loss_rpn_cls: 0.001145  loss_rpn_loc: 0.02008  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:18] d2.utils.events INFO:  eta: 1:29:43  iter: 29559  total_loss: 0.3393  loss_cls: 0.04878  loss_box_reg: 0.1296  loss_mask: 0.1134  loss_rpn_cls: 0.001662  loss_rpn_loc: 0.02738  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:19] d2.utils.events INFO:  eta: 1:29:39  iter: 29579  total_loss: 0.2294  loss_cls: 0.03924  loss_box_reg: 0.093  loss_mask: 0.07743  loss_rpn_cls: 0.0007614  loss_rpn_loc: 0.01268  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:21] d2.utils.events INFO:  eta: 1:29:36  iter: 29599  total_loss: 0.2101  loss_cls: 0.03592  loss_box_reg: 0.08544  loss_mask: 0.07324  loss_rpn_cls: 0.001159  loss_rpn_loc: 0.02048  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:23] d2.utils.events INFO:  eta: 1:29:35  iter: 29619  total_loss: 0.2935  loss_cls: 0.04565  loss_box_reg: 0.1279  loss_mask: 0.105  loss_rpn_cls: 0.001035  loss_rpn_loc: 0.01884  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:25] d2.utils.events INFO:  eta: 1:29:31  iter: 29639  total_loss: 0.2397  loss_cls: 0.03497  loss_box_reg: 0.1205  loss_mask: 0.0792  loss_rpn_cls: 0.001211  loss_rpn_loc: 0.01366  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:27] d2.utils.events INFO:  eta: 1:29:31  iter: 29659  total_loss: 0.2128  loss_cls: 0.0316  loss_box_reg: 0.08664  loss_mask: 0.08218  loss_rpn_cls: 0.001176  loss_rpn_loc: 0.02023  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:28] d2.utils.events INFO:  eta: 1:29:29  iter: 29679  total_loss: 0.2269  loss_cls: 0.02838  loss_box_reg: 0.09672  loss_mask: 0.08924  loss_rpn_cls: 0.0006169  loss_rpn_loc: 0.01299  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:30] d2.utils.events INFO:  eta: 1:29:23  iter: 29699  total_loss: 0.1947  loss_cls: 0.03105  loss_box_reg: 0.08773  loss_mask: 0.07588  loss_rpn_cls: 0.0008932  loss_rpn_loc: 0.01343  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:32] d2.utils.events INFO:  eta: 1:29:18  iter: 29719  total_loss: 0.1972  loss_cls: 0.0268  loss_box_reg: 0.08216  loss_mask: 0.06036  loss_rpn_cls: 0.000345  loss_rpn_loc: 0.00714  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:34] d2.utils.events INFO:  eta: 1:29:24  iter: 29739  total_loss: 0.2633  loss_cls: 0.03427  loss_box_reg: 0.1009  loss_mask: 0.07036  loss_rpn_cls: 0.001272  loss_rpn_loc: 0.02016  time: 0.0891  data_time: 0.0022  lr: 0.0025  max_mem: 1491M
[10/27 19:21:35] d2.utils.events INFO:  eta: 1:29:22  iter: 29759  total_loss: 0.1634  loss_cls: 0.02746  loss_box_reg: 0.07679  loss_mask: 0.06598  loss_rpn_cls: 0.0008988  loss_rpn_loc: 0.008105  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:37] d2.utils.events INFO:  eta: 1:29:21  iter: 29779  total_loss: 0.2756  loss_cls: 0.03505  loss_box_reg: 0.1213  loss_mask: 0.08823  loss_rpn_cls: 0.001108  loss_rpn_loc: 0.02235  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:39] d2.utils.events INFO:  eta: 1:29:14  iter: 29799  total_loss: 0.1736  loss_cls: 0.0253  loss_box_reg: 0.06528  loss_mask: 0.06727  loss_rpn_cls: 0.0002892  loss_rpn_loc: 0.008051  time: 0.0890  data_time: 0.0020  lr: 0.0025  max_mem: 1491M
[10/27 19:21:41] d2.utils.events INFO:  eta: 1:29:17  iter: 29819  total_loss: 0.3914  loss_cls: 0.0575  loss_box_reg: 0.1593  loss_mask: 0.1193  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.02855  time: 0.0890  data_time: 0.0021  lr: 0.0025  max_mem: 1491M
[10/27 19:21:43] d2.utils.events INFO:  eta: 1:29:25  iter: 29839  total_loss: 0.3651  loss_cls: 0.05548  loss_box_reg: 0.158  loss_mask: 0.1239  loss_rpn_cls: 0.001971  loss_rpn_loc: 0.03402  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:21:44] d2.utils.events INFO:  eta: 1:29:24  iter: 29859  total_loss: 0.1744  loss_cls: 0.02581  loss_box_reg: 0.0714  loss_mask: 0.06819  loss_rpn_cls: 0.0006422  loss_rpn_loc: 0.02  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:21:46] d2.utils.events INFO:  eta: 1:29:19  iter: 29879  total_loss: 0.2431  loss_cls: 0.04106  loss_box_reg: 0.09619  loss_mask: 0.0753  loss_rpn_cls: 0.0008163  loss_rpn_loc: 0.01248  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:21:48] d2.utils.events INFO:  eta: 1:29:32  iter: 29899  total_loss: 0.2531  loss_cls: 0.03356  loss_box_reg: 0.1084  loss_mask: 0.09001  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.01281  time: 0.0891  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:21:50] d2.utils.events INFO:  eta: 1:29:38  iter: 29919  total_loss: 0.2316  loss_cls: 0.03152  loss_box_reg: 0.09232  loss_mask: 0.06986  loss_rpn_cls: 0.0006965  loss_rpn_loc: 0.00995  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:21:52] d2.utils.events INFO:  eta: 1:29:32  iter: 29939  total_loss: 0.1676  loss_cls: 0.02215  loss_box_reg: 0.05421  loss_mask: 0.06182  loss_rpn_cls: 0.000274  loss_rpn_loc: 0.007157  time: 0.0891  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:21:53] d2.utils.events INFO:  eta: 1:29:23  iter: 29959  total_loss: 0.2328  loss_cls: 0.03114  loss_box_reg: 0.08753  loss_mask: 0.06757  loss_rpn_cls: 0.0004557  loss_rpn_loc: 0.006977  time: 0.0890  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:21:55] d2.utils.events INFO:  eta: 1:29:13  iter: 29979  total_loss: 0.2253  loss_cls: 0.02884  loss_box_reg: 0.08656  loss_mask: 0.083  loss_rpn_cls: 0.0009238  loss_rpn_loc: 0.02083  time: 0.0890  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:21:57] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0029999.pth
[10/27 19:21:57] d2.utils.events INFO:  eta: 1:29:15  iter: 29999  total_loss: 0.2475  loss_cls: 0.04237  loss_box_reg: 0.1197  loss_mask: 0.08326  loss_rpn_cls: 0.001377  loss_rpn_loc: 0.02075  time: 0.0890  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:21:59] d2.utils.events INFO:  eta: 1:29:20  iter: 30019  total_loss: 0.2268  loss_cls: 0.02538  loss_box_reg: 0.07342  loss_mask: 0.07518  loss_rpn_cls: 0.0003423  loss_rpn_loc: 0.01939  time: 0.0890  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:22:01] d2.utils.events INFO:  eta: 1:29:07  iter: 30039  total_loss: 0.1997  loss_cls: 0.03449  loss_box_reg: 0.08543  loss_mask: 0.07133  loss_rpn_cls: 0.0005154  loss_rpn_loc: 0.008682  time: 0.0890  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:22:02] d2.utils.events INFO:  eta: 1:29:02  iter: 30059  total_loss: 0.3977  loss_cls: 0.04659  loss_box_reg: 0.1576  loss_mask: 0.1209  loss_rpn_cls: 0.001446  loss_rpn_loc: 0.02514  time: 0.0890  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:22:04] d2.utils.events INFO:  eta: 1:29:00  iter: 30079  total_loss: 0.2949  loss_cls: 0.04197  loss_box_reg: 0.1265  loss_mask: 0.07555  loss_rpn_cls: 0.002043  loss_rpn_loc: 0.02473  time: 0.0890  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:06] d2.utils.events INFO:  eta: 1:28:55  iter: 30099  total_loss: 0.2359  loss_cls: 0.03782  loss_box_reg: 0.1099  loss_mask: 0.07622  loss_rpn_cls: 0.001017  loss_rpn_loc: 0.01948  time: 0.0890  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:08] d2.utils.events INFO:  eta: 1:28:50  iter: 30119  total_loss: 0.1705  loss_cls: 0.02133  loss_box_reg: 0.07037  loss_mask: 0.06206  loss_rpn_cls: 0.0008063  loss_rpn_loc: 0.009491  time: 0.0890  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:09] d2.utils.events INFO:  eta: 1:28:50  iter: 30139  total_loss: 0.2384  loss_cls: 0.0412  loss_box_reg: 0.1008  loss_mask: 0.09931  loss_rpn_cls: 0.0006825  loss_rpn_loc: 0.0131  time: 0.0890  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:11] d2.utils.events INFO:  eta: 1:28:47  iter: 30159  total_loss: 0.2317  loss_cls: 0.03168  loss_box_reg: 0.07972  loss_mask: 0.07818  loss_rpn_cls: 0.0005958  loss_rpn_loc: 0.01071  time: 0.0890  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:13] d2.utils.events INFO:  eta: 1:28:44  iter: 30179  total_loss: 0.2414  loss_cls: 0.03448  loss_box_reg: 0.08807  loss_mask: 0.0835  loss_rpn_cls: 0.001494  loss_rpn_loc: 0.01074  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:15] d2.utils.events INFO:  eta: 1:28:39  iter: 30199  total_loss: 0.2284  loss_cls: 0.03661  loss_box_reg: 0.09883  loss_mask: 0.08083  loss_rpn_cls: 0.0006244  loss_rpn_loc: 0.01654  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:16] d2.utils.events INFO:  eta: 1:28:34  iter: 30219  total_loss: 0.1788  loss_cls: 0.02464  loss_box_reg: 0.06923  loss_mask: 0.06578  loss_rpn_cls: 0.0008657  loss_rpn_loc: 0.01251  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:18] d2.utils.events INFO:  eta: 1:28:27  iter: 30239  total_loss: 0.2096  loss_cls: 0.03346  loss_box_reg: 0.0861  loss_mask: 0.105  loss_rpn_cls: 0.001275  loss_rpn_loc: 0.01591  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:20] d2.utils.events INFO:  eta: 1:28:22  iter: 30259  total_loss: 0.2751  loss_cls: 0.03888  loss_box_reg: 0.1215  loss_mask: 0.09372  loss_rpn_cls: 0.0007316  loss_rpn_loc: 0.0114  time: 0.0889  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:22:22] d2.utils.events INFO:  eta: 1:27:53  iter: 30279  total_loss: 0.2046  loss_cls: 0.03679  loss_box_reg: 0.0883  loss_mask: 0.07132  loss_rpn_cls: 0.0005758  loss_rpn_loc: 0.01315  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:23] d2.utils.events INFO:  eta: 1:27:55  iter: 30299  total_loss: 0.2312  loss_cls: 0.02881  loss_box_reg: 0.1093  loss_mask: 0.07083  loss_rpn_cls: 0.0005598  loss_rpn_loc: 0.01604  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:25] d2.utils.events INFO:  eta: 1:27:55  iter: 30319  total_loss: 0.2415  loss_cls: 0.03712  loss_box_reg: 0.1056  loss_mask: 0.06168  loss_rpn_cls: 0.000942  loss_rpn_loc: 0.02696  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:27] d2.utils.events INFO:  eta: 1:27:53  iter: 30339  total_loss: 0.2198  loss_cls: 0.04031  loss_box_reg: 0.1078  loss_mask: 0.07221  loss_rpn_cls: 0.0008058  loss_rpn_loc: 0.01467  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:29] d2.utils.events INFO:  eta: 1:27:38  iter: 30359  total_loss: 0.238  loss_cls: 0.04219  loss_box_reg: 0.116  loss_mask: 0.08399  loss_rpn_cls: 0.0008736  loss_rpn_loc: 0.01364  time: 0.0889  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:22:30] d2.utils.events INFO:  eta: 1:27:51  iter: 30379  total_loss: 0.1985  loss_cls: 0.03038  loss_box_reg: 0.09148  loss_mask: 0.07315  loss_rpn_cls: 0.0006115  loss_rpn_loc: 0.01174  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:32] d2.utils.events INFO:  eta: 1:27:49  iter: 30399  total_loss: 0.3082  loss_cls: 0.05239  loss_box_reg: 0.1249  loss_mask: 0.09168  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.0252  time: 0.0889  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:34] d2.utils.events INFO:  eta: 1:27:50  iter: 30419  total_loss: 0.1934  loss_cls: 0.03493  loss_box_reg: 0.07153  loss_mask: 0.07862  loss_rpn_cls: 0.000522  loss_rpn_loc: 0.01327  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:36] d2.utils.events INFO:  eta: 1:27:45  iter: 30439  total_loss: 0.2805  loss_cls: 0.04521  loss_box_reg: 0.1309  loss_mask: 0.106  loss_rpn_cls: 0.000936  loss_rpn_loc: 0.01918  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:37] d2.utils.events INFO:  eta: 1:27:52  iter: 30459  total_loss: 0.2767  loss_cls: 0.0368  loss_box_reg: 0.1204  loss_mask: 0.07026  loss_rpn_cls: 0.0006765  loss_rpn_loc: 0.01496  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:22:39] d2.utils.events INFO:  eta: 1:27:53  iter: 30479  total_loss: 0.3068  loss_cls: 0.03908  loss_box_reg: 0.1169  loss_mask: 0.09559  loss_rpn_cls: 0.001072  loss_rpn_loc: 0.03435  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:41] d2.utils.events INFO:  eta: 1:27:48  iter: 30499  total_loss: 0.321  loss_cls: 0.0373  loss_box_reg: 0.1396  loss_mask: 0.1026  loss_rpn_cls: 0.001183  loss_rpn_loc: 0.02033  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:43] d2.utils.events INFO:  eta: 1:27:49  iter: 30519  total_loss: 0.1898  loss_cls: 0.0268  loss_box_reg: 0.07736  loss_mask: 0.07672  loss_rpn_cls: 0.0007209  loss_rpn_loc: 0.01354  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:44] d2.utils.events INFO:  eta: 1:27:36  iter: 30539  total_loss: 0.1919  loss_cls: 0.03222  loss_box_reg: 0.08782  loss_mask: 0.06522  loss_rpn_cls: 0.0006315  loss_rpn_loc: 0.01726  time: 0.0888  data_time: 0.0018  lr: 0.0025  max_mem: 1493M
[10/27 19:22:46] d2.utils.events INFO:  eta: 1:27:19  iter: 30559  total_loss: 0.2102  loss_cls: 0.03416  loss_box_reg: 0.08449  loss_mask: 0.07214  loss_rpn_cls: 0.0005517  loss_rpn_loc: 0.01193  time: 0.0888  data_time: 0.0018  lr: 0.0025  max_mem: 1493M
[10/27 19:22:48] d2.utils.events INFO:  eta: 1:27:26  iter: 30579  total_loss: 0.2504  loss_cls: 0.03725  loss_box_reg: 0.1127  loss_mask: 0.08529  loss_rpn_cls: 0.001231  loss_rpn_loc: 0.01796  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:49] d2.utils.events INFO:  eta: 1:27:20  iter: 30599  total_loss: 0.2034  loss_cls: 0.02717  loss_box_reg: 0.1033  loss_mask: 0.06169  loss_rpn_cls: 0.000563  loss_rpn_loc: 0.01395  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:51] d2.utils.events INFO:  eta: 1:27:01  iter: 30619  total_loss: 0.1691  loss_cls: 0.02561  loss_box_reg: 0.07734  loss_mask: 0.05331  loss_rpn_cls: 0.0009694  loss_rpn_loc: 0.007477  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:53] d2.utils.events INFO:  eta: 1:26:53  iter: 30639  total_loss: 0.1512  loss_cls: 0.02288  loss_box_reg: 0.06723  loss_mask: 0.06299  loss_rpn_cls: 0.000489  loss_rpn_loc: 0.007707  time: 0.0888  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:22:55] d2.utils.events INFO:  eta: 1:26:55  iter: 30659  total_loss: 0.2629  loss_cls: 0.03781  loss_box_reg: 0.1287  loss_mask: 0.08938  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.01108  time: 0.0888  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:22:56] d2.utils.events INFO:  eta: 1:26:55  iter: 30679  total_loss: 0.2237  loss_cls: 0.02662  loss_box_reg: 0.09599  loss_mask: 0.07783  loss_rpn_cls: 0.0003835  loss_rpn_loc: 0.009461  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:22:58] d2.utils.events INFO:  eta: 1:26:57  iter: 30699  total_loss: 0.2545  loss_cls: 0.04128  loss_box_reg: 0.1256  loss_mask: 0.07238  loss_rpn_cls: 0.000948  loss_rpn_loc: 0.01516  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:00] d2.utils.events INFO:  eta: 1:27:01  iter: 30719  total_loss: 0.2901  loss_cls: 0.04074  loss_box_reg: 0.1144  loss_mask: 0.09886  loss_rpn_cls: 0.001073  loss_rpn_loc: 0.02204  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:02] d2.utils.events INFO:  eta: 1:26:55  iter: 30739  total_loss: 0.2874  loss_cls: 0.05123  loss_box_reg: 0.1473  loss_mask: 0.07347  loss_rpn_cls: 0.0005669  loss_rpn_loc: 0.01136  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:04] d2.utils.events INFO:  eta: 1:27:06  iter: 30759  total_loss: 0.271  loss_cls: 0.04168  loss_box_reg: 0.1164  loss_mask: 0.08221  loss_rpn_cls: 0.001151  loss_rpn_loc: 0.02087  time: 0.0888  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:05] d2.utils.events INFO:  eta: 1:26:59  iter: 30779  total_loss: 0.3258  loss_cls: 0.04178  loss_box_reg: 0.1325  loss_mask: 0.08716  loss_rpn_cls: 0.0006146  loss_rpn_loc: 0.01581  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:07] d2.utils.events INFO:  eta: 1:27:19  iter: 30799  total_loss: 0.2962  loss_cls: 0.04244  loss_box_reg: 0.1215  loss_mask: 0.08356  loss_rpn_cls: 0.001246  loss_rpn_loc: 0.02197  time: 0.0888  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:09] d2.utils.events INFO:  eta: 1:26:55  iter: 30819  total_loss: 0.2072  loss_cls: 0.02938  loss_box_reg: 0.08237  loss_mask: 0.07246  loss_rpn_cls: 0.0006386  loss_rpn_loc: 0.008941  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:11] d2.utils.events INFO:  eta: 1:26:49  iter: 30839  total_loss: 0.2498  loss_cls: 0.03936  loss_box_reg: 0.1133  loss_mask: 0.1087  loss_rpn_cls: 0.001442  loss_rpn_loc: 0.01616  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:13] d2.utils.events INFO:  eta: 1:27:12  iter: 30859  total_loss: 0.3226  loss_cls: 0.04185  loss_box_reg: 0.1329  loss_mask: 0.0845  loss_rpn_cls: 0.001733  loss_rpn_loc: 0.01796  time: 0.0888  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:14] d2.utils.events INFO:  eta: 1:27:02  iter: 30879  total_loss: 0.188  loss_cls: 0.02211  loss_box_reg: 0.0664  loss_mask: 0.0698  loss_rpn_cls: 0.0005422  loss_rpn_loc: 0.01215  time: 0.0888  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:16] d2.utils.events INFO:  eta: 1:26:39  iter: 30899  total_loss: 0.1858  loss_cls: 0.02325  loss_box_reg: 0.051  loss_mask: 0.08428  loss_rpn_cls: 0.0008595  loss_rpn_loc: 0.01603  time: 0.0887  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:23:18] d2.utils.events INFO:  eta: 1:26:34  iter: 30919  total_loss: 0.3006  loss_cls: 0.03571  loss_box_reg: 0.1165  loss_mask: 0.09501  loss_rpn_cls: 0.001237  loss_rpn_loc: 0.02009  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:20] d2.utils.events INFO:  eta: 1:26:36  iter: 30939  total_loss: 0.2927  loss_cls: 0.03852  loss_box_reg: 0.1219  loss_mask: 0.09446  loss_rpn_cls: 0.001008  loss_rpn_loc: 0.02302  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:21] d2.utils.events INFO:  eta: 1:26:34  iter: 30959  total_loss: 0.1705  loss_cls: 0.02783  loss_box_reg: 0.06069  loss_mask: 0.07126  loss_rpn_cls: 0.0005505  loss_rpn_loc: 0.008734  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:23] d2.utils.events INFO:  eta: 1:26:19  iter: 30979  total_loss: 0.1686  loss_cls: 0.02082  loss_box_reg: 0.06948  loss_mask: 0.05929  loss_rpn_cls: 0.000349  loss_rpn_loc: 0.01215  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:25] d2.utils.events INFO:  eta: 1:26:21  iter: 30999  total_loss: 0.2834  loss_cls: 0.03758  loss_box_reg: 0.1231  loss_mask: 0.07354  loss_rpn_cls: 0.001948  loss_rpn_loc: 0.0318  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:27] d2.utils.events INFO:  eta: 1:26:29  iter: 31019  total_loss: 0.278  loss_cls: 0.03912  loss_box_reg: 0.1255  loss_mask: 0.08298  loss_rpn_cls: 0.0009446  loss_rpn_loc: 0.01328  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:28] d2.utils.events INFO:  eta: 1:26:36  iter: 31039  total_loss: 0.3186  loss_cls: 0.05339  loss_box_reg: 0.1382  loss_mask: 0.1006  loss_rpn_cls: 0.0009058  loss_rpn_loc: 0.01878  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:30] d2.utils.events INFO:  eta: 1:26:29  iter: 31059  total_loss: 0.219  loss_cls: 0.03231  loss_box_reg: 0.08944  loss_mask: 0.06943  loss_rpn_cls: 0.0007773  loss_rpn_loc: 0.008334  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:32] d2.utils.events INFO:  eta: 1:26:11  iter: 31079  total_loss: 0.2304  loss_cls: 0.03756  loss_box_reg: 0.08432  loss_mask: 0.07594  loss_rpn_cls: 0.0005758  loss_rpn_loc: 0.006731  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:34] d2.utils.events INFO:  eta: 1:26:20  iter: 31099  total_loss: 0.2079  loss_cls: 0.03095  loss_box_reg: 0.1004  loss_mask: 0.07128  loss_rpn_cls: 0.0007809  loss_rpn_loc: 0.01162  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:35] d2.utils.events INFO:  eta: 1:26:34  iter: 31119  total_loss: 0.2165  loss_cls: 0.03196  loss_box_reg: 0.08638  loss_mask: 0.07793  loss_rpn_cls: 0.0008598  loss_rpn_loc: 0.0115  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:37] d2.utils.events INFO:  eta: 1:26:28  iter: 31139  total_loss: 0.2254  loss_cls: 0.02897  loss_box_reg: 0.09008  loss_mask: 0.08975  loss_rpn_cls: 0.0006602  loss_rpn_loc: 0.01741  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:39] d2.utils.events INFO:  eta: 1:26:30  iter: 31159  total_loss: 0.2214  loss_cls: 0.03844  loss_box_reg: 0.1121  loss_mask: 0.07698  loss_rpn_cls: 0.001358  loss_rpn_loc: 0.01391  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:41] d2.utils.events INFO:  eta: 1:26:44  iter: 31179  total_loss: 0.2356  loss_cls: 0.0304  loss_box_reg: 0.1196  loss_mask: 0.07562  loss_rpn_cls: 0.0004367  loss_rpn_loc: 0.007874  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:43] d2.utils.events INFO:  eta: 1:26:48  iter: 31199  total_loss: 0.1849  loss_cls: 0.03298  loss_box_reg: 0.08512  loss_mask: 0.05878  loss_rpn_cls: 0.0009022  loss_rpn_loc: 0.01247  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:44] d2.utils.events INFO:  eta: 1:26:47  iter: 31219  total_loss: 0.2215  loss_cls: 0.03347  loss_box_reg: 0.0887  loss_mask: 0.06812  loss_rpn_cls: 0.0007742  loss_rpn_loc: 0.01541  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:46] d2.utils.events INFO:  eta: 1:26:49  iter: 31239  total_loss: 0.2208  loss_cls: 0.02967  loss_box_reg: 0.09121  loss_mask: 0.07693  loss_rpn_cls: 0.000627  loss_rpn_loc: 0.01553  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:48] d2.utils.events INFO:  eta: 1:26:47  iter: 31259  total_loss: 0.2078  loss_cls: 0.03  loss_box_reg: 0.09218  loss_mask: 0.06694  loss_rpn_cls: 0.0006374  loss_rpn_loc: 0.01162  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:50] d2.utils.events INFO:  eta: 1:27:05  iter: 31279  total_loss: 0.313  loss_cls: 0.03713  loss_box_reg: 0.131  loss_mask: 0.07978  loss_rpn_cls: 0.001243  loss_rpn_loc: 0.02259  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:52] d2.utils.events INFO:  eta: 1:26:59  iter: 31299  total_loss: 0.2659  loss_cls: 0.03953  loss_box_reg: 0.1102  loss_mask: 0.09406  loss_rpn_cls: 0.001064  loss_rpn_loc: 0.01424  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:23:53] d2.utils.events INFO:  eta: 1:27:06  iter: 31319  total_loss: 0.224  loss_cls: 0.03895  loss_box_reg: 0.08585  loss_mask: 0.09433  loss_rpn_cls: 0.001099  loss_rpn_loc: 0.01238  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:55] d2.utils.events INFO:  eta: 1:27:07  iter: 31339  total_loss: 0.2981  loss_cls: 0.05061  loss_box_reg: 0.1303  loss_mask: 0.1118  loss_rpn_cls: 0.001202  loss_rpn_loc: 0.02374  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:57] d2.utils.events INFO:  eta: 1:27:05  iter: 31359  total_loss: 0.1983  loss_cls: 0.0393  loss_box_reg: 0.09384  loss_mask: 0.06486  loss_rpn_cls: 0.0007344  loss_rpn_loc: 0.01252  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:23:59] d2.utils.events INFO:  eta: 1:26:42  iter: 31379  total_loss: 0.208  loss_cls: 0.03004  loss_box_reg: 0.08542  loss_mask: 0.07161  loss_rpn_cls: 0.0005222  loss_rpn_loc: 0.007753  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:00] d2.utils.events INFO:  eta: 1:26:34  iter: 31399  total_loss: 0.2322  loss_cls: 0.03345  loss_box_reg: 0.1064  loss_mask: 0.07701  loss_rpn_cls: 0.000653  loss_rpn_loc: 0.01294  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:02] d2.utils.events INFO:  eta: 1:26:33  iter: 31419  total_loss: 0.2156  loss_cls: 0.03496  loss_box_reg: 0.1051  loss_mask: 0.07293  loss_rpn_cls: 0.000476  loss_rpn_loc: 0.009709  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:04] d2.utils.events INFO:  eta: 1:26:28  iter: 31439  total_loss: 0.1931  loss_cls: 0.02475  loss_box_reg: 0.07868  loss_mask: 0.06411  loss_rpn_cls: 0.0004172  loss_rpn_loc: 0.01358  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:06] d2.utils.events INFO:  eta: 1:26:29  iter: 31459  total_loss: 0.2629  loss_cls: 0.04807  loss_box_reg: 0.1179  loss_mask: 0.07218  loss_rpn_cls: 0.0007562  loss_rpn_loc: 0.01541  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:08] d2.utils.events INFO:  eta: 1:26:33  iter: 31479  total_loss: 0.2673  loss_cls: 0.02819  loss_box_reg: 0.1094  loss_mask: 0.07517  loss_rpn_cls: 0.0005287  loss_rpn_loc: 0.02032  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:09] d2.utils.events INFO:  eta: 1:26:26  iter: 31499  total_loss: 0.2397  loss_cls: 0.0286  loss_box_reg: 0.1049  loss_mask: 0.07458  loss_rpn_cls: 0.001063  loss_rpn_loc: 0.01758  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:11] d2.utils.events INFO:  eta: 1:26:21  iter: 31519  total_loss: 0.1674  loss_cls: 0.02005  loss_box_reg: 0.06328  loss_mask: 0.06576  loss_rpn_cls: 0.0006169  loss_rpn_loc: 0.01004  time: 0.0887  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:24:13] d2.utils.events INFO:  eta: 1:26:23  iter: 31539  total_loss: 0.2315  loss_cls: 0.04721  loss_box_reg: 0.09896  loss_mask: 0.07976  loss_rpn_cls: 0.000676  loss_rpn_loc: 0.01128  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:15] d2.utils.events INFO:  eta: 1:26:36  iter: 31559  total_loss: 0.2149  loss_cls: 0.03931  loss_box_reg: 0.09178  loss_mask: 0.08143  loss_rpn_cls: 0.0008236  loss_rpn_loc: 0.0168  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:16] d2.utils.events INFO:  eta: 1:26:34  iter: 31579  total_loss: 0.2955  loss_cls: 0.04224  loss_box_reg: 0.1213  loss_mask: 0.09822  loss_rpn_cls: 0.001551  loss_rpn_loc: 0.01367  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:18] d2.utils.events INFO:  eta: 1:26:51  iter: 31599  total_loss: 0.28  loss_cls: 0.04804  loss_box_reg: 0.1356  loss_mask: 0.0807  loss_rpn_cls: 0.001622  loss_rpn_loc: 0.02173  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:20] d2.utils.events INFO:  eta: 1:26:55  iter: 31619  total_loss: 0.1954  loss_cls: 0.03375  loss_box_reg: 0.08334  loss_mask: 0.08347  loss_rpn_cls: 0.0005532  loss_rpn_loc: 0.01149  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:22] d2.utils.events INFO:  eta: 1:26:48  iter: 31639  total_loss: 0.17  loss_cls: 0.02215  loss_box_reg: 0.06134  loss_mask: 0.05518  loss_rpn_cls: 0.0009701  loss_rpn_loc: 0.00892  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:23] d2.utils.events INFO:  eta: 1:26:40  iter: 31659  total_loss: 0.1969  loss_cls: 0.03184  loss_box_reg: 0.08457  loss_mask: 0.06409  loss_rpn_cls: 0.0006581  loss_rpn_loc: 0.01462  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:25] d2.utils.events INFO:  eta: 1:26:54  iter: 31679  total_loss: 0.3034  loss_cls: 0.04703  loss_box_reg: 0.1312  loss_mask: 0.08142  loss_rpn_cls: 0.001365  loss_rpn_loc: 0.02326  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:27] d2.utils.events INFO:  eta: 1:26:57  iter: 31699  total_loss: 0.28  loss_cls: 0.0477  loss_box_reg: 0.131  loss_mask: 0.0887  loss_rpn_cls: 0.00142  loss_rpn_loc: 0.02653  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:29] d2.utils.events INFO:  eta: 1:26:43  iter: 31719  total_loss: 0.1522  loss_cls: 0.0177  loss_box_reg: 0.04998  loss_mask: 0.06325  loss_rpn_cls: 0.0008584  loss_rpn_loc: 0.0116  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:31] d2.utils.events INFO:  eta: 1:26:37  iter: 31739  total_loss: 0.198  loss_cls: 0.02991  loss_box_reg: 0.07913  loss_mask: 0.07421  loss_rpn_cls: 0.0005105  loss_rpn_loc: 0.01016  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:32] d2.utils.events INFO:  eta: 1:26:26  iter: 31759  total_loss: 0.2672  loss_cls: 0.04522  loss_box_reg: 0.1122  loss_mask: 0.08363  loss_rpn_cls: 0.0008906  loss_rpn_loc: 0.01567  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:34] d2.utils.events INFO:  eta: 1:26:24  iter: 31779  total_loss: 0.2223  loss_cls: 0.02869  loss_box_reg: 0.1015  loss_mask: 0.07594  loss_rpn_cls: 0.0004952  loss_rpn_loc: 0.01175  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:36] d2.utils.events INFO:  eta: 1:26:15  iter: 31799  total_loss: 0.2746  loss_cls: 0.04034  loss_box_reg: 0.1239  loss_mask: 0.07351  loss_rpn_cls: 0.0008289  loss_rpn_loc: 0.02336  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:38] d2.utils.events INFO:  eta: 1:26:31  iter: 31819  total_loss: 0.2402  loss_cls: 0.03712  loss_box_reg: 0.1217  loss_mask: 0.07516  loss_rpn_cls: 0.0007297  loss_rpn_loc: 0.01084  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:39] d2.utils.events INFO:  eta: 1:26:23  iter: 31839  total_loss: 0.2526  loss_cls: 0.04145  loss_box_reg: 0.1124  loss_mask: 0.07032  loss_rpn_cls: 0.0005535  loss_rpn_loc: 0.01712  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:41] d2.utils.events INFO:  eta: 1:26:16  iter: 31859  total_loss: 0.2029  loss_cls: 0.03059  loss_box_reg: 0.09329  loss_mask: 0.07535  loss_rpn_cls: 0.001414  loss_rpn_loc: 0.01933  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:43] d2.utils.events INFO:  eta: 1:26:22  iter: 31879  total_loss: 0.2866  loss_cls: 0.04632  loss_box_reg: 0.1106  loss_mask: 0.09812  loss_rpn_cls: 0.0005956  loss_rpn_loc: 0.01679  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:24:45] d2.utils.events INFO:  eta: 1:26:20  iter: 31899  total_loss: 0.2276  loss_cls: 0.03202  loss_box_reg: 0.0846  loss_mask: 0.07985  loss_rpn_cls: 0.0006456  loss_rpn_loc: 0.01976  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:47] d2.utils.events INFO:  eta: 1:26:08  iter: 31919  total_loss: 0.1806  loss_cls: 0.0282  loss_box_reg: 0.08132  loss_mask: 0.07458  loss_rpn_cls: 0.0005452  loss_rpn_loc: 0.009057  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:48] d2.utils.events INFO:  eta: 1:26:06  iter: 31939  total_loss: 0.2166  loss_cls: 0.03221  loss_box_reg: 0.1101  loss_mask: 0.06094  loss_rpn_cls: 0.0009943  loss_rpn_loc: 0.01674  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:50] d2.utils.events INFO:  eta: 1:26:05  iter: 31959  total_loss: 0.1807  loss_cls: 0.02505  loss_box_reg: 0.0757  loss_mask: 0.06987  loss_rpn_cls: 0.0003484  loss_rpn_loc: 0.007781  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:52] d2.utils.events INFO:  eta: 1:26:06  iter: 31979  total_loss: 0.2394  loss_cls: 0.03402  loss_box_reg: 0.1038  loss_mask: 0.07738  loss_rpn_cls: 0.002067  loss_rpn_loc: 0.01819  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:54] d2.utils.events INFO:  eta: 1:25:52  iter: 31999  total_loss: 0.2309  loss_cls: 0.03206  loss_box_reg: 0.1137  loss_mask: 0.08263  loss_rpn_cls: 0.000951  loss_rpn_loc: 0.01493  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:55] d2.utils.events INFO:  eta: 1:25:48  iter: 32019  total_loss: 0.2553  loss_cls: 0.03775  loss_box_reg: 0.1041  loss_mask: 0.08491  loss_rpn_cls: 0.000909  loss_rpn_loc: 0.01633  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:57] d2.utils.events INFO:  eta: 1:25:34  iter: 32039  total_loss: 0.1858  loss_cls: 0.02699  loss_box_reg: 0.07693  loss_mask: 0.06594  loss_rpn_cls: 0.000622  loss_rpn_loc: 0.01168  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:24:59] d2.utils.events INFO:  eta: 1:25:37  iter: 32059  total_loss: 0.2707  loss_cls: 0.04039  loss_box_reg: 0.1205  loss_mask: 0.08115  loss_rpn_cls: 0.001319  loss_rpn_loc: 0.01815  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:01] d2.utils.events INFO:  eta: 1:25:39  iter: 32079  total_loss: 0.16  loss_cls: 0.02488  loss_box_reg: 0.06782  loss_mask: 0.06318  loss_rpn_cls: 0.0004495  loss_rpn_loc: 0.009713  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:02] d2.utils.events INFO:  eta: 1:25:45  iter: 32099  total_loss: 0.2995  loss_cls: 0.04872  loss_box_reg: 0.1279  loss_mask: 0.08759  loss_rpn_cls: 0.001687  loss_rpn_loc: 0.021  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:04] d2.utils.events INFO:  eta: 1:25:58  iter: 32119  total_loss: 0.2079  loss_cls: 0.03572  loss_box_reg: 0.1002  loss_mask: 0.06479  loss_rpn_cls: 0.001964  loss_rpn_loc: 0.02159  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:06] d2.utils.events INFO:  eta: 1:26:01  iter: 32139  total_loss: 0.2664  loss_cls: 0.02895  loss_box_reg: 0.12  loss_mask: 0.08716  loss_rpn_cls: 0.001047  loss_rpn_loc: 0.01529  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:08] d2.utils.events INFO:  eta: 1:25:58  iter: 32159  total_loss: 0.174  loss_cls: 0.031  loss_box_reg: 0.06524  loss_mask: 0.07758  loss_rpn_cls: 0.0009049  loss_rpn_loc: 0.01018  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:10] d2.utils.events INFO:  eta: 1:25:55  iter: 32179  total_loss: 0.2126  loss_cls: 0.03552  loss_box_reg: 0.09818  loss_mask: 0.07696  loss_rpn_cls: 0.0005259  loss_rpn_loc: 0.01277  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:11] d2.utils.events INFO:  eta: 1:25:53  iter: 32199  total_loss: 0.188  loss_cls: 0.01687  loss_box_reg: 0.07539  loss_mask: 0.06983  loss_rpn_cls: 0.0004984  loss_rpn_loc: 0.008788  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:13] d2.utils.events INFO:  eta: 1:25:49  iter: 32219  total_loss: 0.2226  loss_cls: 0.03873  loss_box_reg: 0.09416  loss_mask: 0.06935  loss_rpn_cls: 0.0006853  loss_rpn_loc: 0.01483  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:15] d2.utils.events INFO:  eta: 1:25:40  iter: 32239  total_loss: 0.191  loss_cls: 0.03078  loss_box_reg: 0.09124  loss_mask: 0.06767  loss_rpn_cls: 0.001158  loss_rpn_loc: 0.01323  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:17] d2.utils.events INFO:  eta: 1:25:38  iter: 32259  total_loss: 0.2459  loss_cls: 0.03862  loss_box_reg: 0.1169  loss_mask: 0.08248  loss_rpn_cls: 0.0007641  loss_rpn_loc: 0.01788  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:18] d2.utils.events INFO:  eta: 1:25:35  iter: 32279  total_loss: 0.2696  loss_cls: 0.04599  loss_box_reg: 0.1149  loss_mask: 0.09574  loss_rpn_cls: 0.0009105  loss_rpn_loc: 0.01926  time: 0.0887  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:20] d2.utils.events INFO:  eta: 1:25:33  iter: 32299  total_loss: 0.2336  loss_cls: 0.03498  loss_box_reg: 0.09403  loss_mask: 0.07999  loss_rpn_cls: 0.000493  loss_rpn_loc: 0.01656  time: 0.0887  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:22] d2.utils.events INFO:  eta: 1:25:25  iter: 32319  total_loss: 0.1858  loss_cls: 0.02378  loss_box_reg: 0.07379  loss_mask: 0.07393  loss_rpn_cls: 0.0005591  loss_rpn_loc: 0.01137  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:24] d2.utils.events INFO:  eta: 1:25:10  iter: 32339  total_loss: 0.2118  loss_cls: 0.03329  loss_box_reg: 0.07594  loss_mask: 0.07085  loss_rpn_cls: 0.0008368  loss_rpn_loc: 0.01513  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:25] d2.utils.events INFO:  eta: 1:25:05  iter: 32359  total_loss: 0.1754  loss_cls: 0.02348  loss_box_reg: 0.06869  loss_mask: 0.06864  loss_rpn_cls: 0.0009765  loss_rpn_loc: 0.01031  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:27] d2.utils.events INFO:  eta: 1:25:26  iter: 32379  total_loss: 0.3035  loss_cls: 0.0479  loss_box_reg: 0.1454  loss_mask: 0.0787  loss_rpn_cls: 0.001473  loss_rpn_loc: 0.01765  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:29] d2.utils.events INFO:  eta: 1:25:25  iter: 32399  total_loss: 0.2043  loss_cls: 0.02915  loss_box_reg: 0.0964  loss_mask: 0.06768  loss_rpn_cls: 0.0009773  loss_rpn_loc: 0.01016  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:31] d2.utils.events INFO:  eta: 1:25:26  iter: 32419  total_loss: 0.2227  loss_cls: 0.03572  loss_box_reg: 0.08584  loss_mask: 0.08818  loss_rpn_cls: 0.0005998  loss_rpn_loc: 0.0104  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:33] d2.utils.events INFO:  eta: 1:25:29  iter: 32439  total_loss: 0.2688  loss_cls: 0.03229  loss_box_reg: 0.1071  loss_mask: 0.08047  loss_rpn_cls: 0.0006195  loss_rpn_loc: 0.01143  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:34] d2.utils.events INFO:  eta: 1:25:31  iter: 32459  total_loss: 0.3818  loss_cls: 0.05126  loss_box_reg: 0.1418  loss_mask: 0.124  loss_rpn_cls: 0.001725  loss_rpn_loc: 0.03448  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:36] d2.utils.events INFO:  eta: 1:25:20  iter: 32479  total_loss: 0.1169  loss_cls: 0.01969  loss_box_reg: 0.05095  loss_mask: 0.05399  loss_rpn_cls: 0.0004954  loss_rpn_loc: 0.007817  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:38] d2.utils.events INFO:  eta: 1:25:18  iter: 32499  total_loss: 0.2676  loss_cls: 0.03021  loss_box_reg: 0.1133  loss_mask: 0.06817  loss_rpn_cls: 0.0008386  loss_rpn_loc: 0.01602  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:40] d2.utils.events INFO:  eta: 1:25:24  iter: 32519  total_loss: 0.1987  loss_cls: 0.02501  loss_box_reg: 0.08476  loss_mask: 0.07351  loss_rpn_cls: 0.0006065  loss_rpn_loc: 0.01641  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:41] d2.utils.events INFO:  eta: 1:25:12  iter: 32539  total_loss: 0.1698  loss_cls: 0.02652  loss_box_reg: 0.06984  loss_mask: 0.06272  loss_rpn_cls: 0.0003619  loss_rpn_loc: 0.005522  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:43] d2.utils.events INFO:  eta: 1:25:11  iter: 32559  total_loss: 0.2375  loss_cls: 0.04164  loss_box_reg: 0.1093  loss_mask: 0.06478  loss_rpn_cls: 0.0007954  loss_rpn_loc: 0.01289  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:45] d2.utils.events INFO:  eta: 1:25:12  iter: 32579  total_loss: 0.2362  loss_cls: 0.03435  loss_box_reg: 0.1067  loss_mask: 0.08007  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.0199  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:47] d2.utils.events INFO:  eta: 1:25:06  iter: 32599  total_loss: 0.224  loss_cls: 0.03988  loss_box_reg: 0.1038  loss_mask: 0.08568  loss_rpn_cls: 0.0008952  loss_rpn_loc: 0.01604  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:49] d2.utils.events INFO:  eta: 1:25:05  iter: 32619  total_loss: 0.209  loss_cls: 0.03044  loss_box_reg: 0.09899  loss_mask: 0.07958  loss_rpn_cls: 0.000866  loss_rpn_loc: 0.01436  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:50] d2.utils.events INFO:  eta: 1:25:04  iter: 32639  total_loss: 0.1945  loss_cls: 0.02784  loss_box_reg: 0.07275  loss_mask: 0.06634  loss_rpn_cls: 0.0009988  loss_rpn_loc: 0.01614  time: 0.0886  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:25:52] d2.utils.events INFO:  eta: 1:25:01  iter: 32659  total_loss: 0.1546  loss_cls: 0.02313  loss_box_reg: 0.06256  loss_mask: 0.05996  loss_rpn_cls: 0.0006376  loss_rpn_loc: 0.008609  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:54] d2.utils.events INFO:  eta: 1:24:46  iter: 32679  total_loss: 0.1989  loss_cls: 0.02144  loss_box_reg: 0.09237  loss_mask: 0.06848  loss_rpn_cls: 0.001028  loss_rpn_loc: 0.009548  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:25:56] d2.utils.events INFO:  eta: 1:24:40  iter: 32699  total_loss: 0.1629  loss_cls: 0.0227  loss_box_reg: 0.06637  loss_mask: 0.06118  loss_rpn_cls: 0.0006567  loss_rpn_loc: 0.01097  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:25:57] d2.utils.events INFO:  eta: 1:24:52  iter: 32719  total_loss: 0.251  loss_cls: 0.03287  loss_box_reg: 0.09613  loss_mask: 0.07252  loss_rpn_cls: 0.0008895  loss_rpn_loc: 0.02018  time: 0.0886  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:25:59] d2.utils.events INFO:  eta: 1:24:52  iter: 32739  total_loss: 0.2403  loss_cls: 0.03298  loss_box_reg: 0.09746  loss_mask: 0.07361  loss_rpn_cls: 0.0005571  loss_rpn_loc: 0.01082  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:01] d2.utils.events INFO:  eta: 1:24:55  iter: 32759  total_loss: 0.3064  loss_cls: 0.04602  loss_box_reg: 0.1373  loss_mask: 0.1124  loss_rpn_cls: 0.002429  loss_rpn_loc: 0.02421  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:03] d2.utils.events INFO:  eta: 1:24:50  iter: 32779  total_loss: 0.2152  loss_cls: 0.02999  loss_box_reg: 0.06587  loss_mask: 0.08064  loss_rpn_cls: 0.0007155  loss_rpn_loc: 0.01567  time: 0.0886  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:26:05] d2.utils.events INFO:  eta: 1:24:51  iter: 32799  total_loss: 0.4072  loss_cls: 0.05781  loss_box_reg: 0.1498  loss_mask: 0.1051  loss_rpn_cls: 0.001949  loss_rpn_loc: 0.04256  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:06] d2.utils.events INFO:  eta: 1:24:35  iter: 32819  total_loss: 0.1868  loss_cls: 0.02207  loss_box_reg: 0.0705  loss_mask: 0.07543  loss_rpn_cls: 0.0004142  loss_rpn_loc: 0.009011  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:08] d2.utils.events INFO:  eta: 1:24:41  iter: 32839  total_loss: 0.3236  loss_cls: 0.04813  loss_box_reg: 0.1303  loss_mask: 0.08205  loss_rpn_cls: 0.001551  loss_rpn_loc: 0.02878  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:10] d2.utils.events INFO:  eta: 1:24:22  iter: 32859  total_loss: 0.2025  loss_cls: 0.02747  loss_box_reg: 0.08808  loss_mask: 0.07203  loss_rpn_cls: 0.0007999  loss_rpn_loc: 0.0143  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:12] d2.utils.events INFO:  eta: 1:24:16  iter: 32879  total_loss: 0.2324  loss_cls: 0.03544  loss_box_reg: 0.1154  loss_mask: 0.07246  loss_rpn_cls: 0.001451  loss_rpn_loc: 0.01515  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:13] d2.utils.events INFO:  eta: 1:24:21  iter: 32899  total_loss: 0.2202  loss_cls: 0.02711  loss_box_reg: 0.08748  loss_mask: 0.07162  loss_rpn_cls: 0.001631  loss_rpn_loc: 0.01643  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:15] d2.utils.events INFO:  eta: 1:24:27  iter: 32919  total_loss: 0.3184  loss_cls: 0.0446  loss_box_reg: 0.1325  loss_mask: 0.09962  loss_rpn_cls: 0.001459  loss_rpn_loc: 0.02606  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:17] d2.utils.events INFO:  eta: 1:24:17  iter: 32939  total_loss: 0.1973  loss_cls: 0.03112  loss_box_reg: 0.07993  loss_mask: 0.06843  loss_rpn_cls: 0.00108  loss_rpn_loc: 0.01727  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:19] d2.utils.events INFO:  eta: 1:24:16  iter: 32959  total_loss: 0.1676  loss_cls: 0.0266  loss_box_reg: 0.08011  loss_mask: 0.0644  loss_rpn_cls: 0.0004743  loss_rpn_loc: 0.01203  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:20] d2.utils.events INFO:  eta: 1:24:21  iter: 32979  total_loss: 0.248  loss_cls: 0.03046  loss_box_reg: 0.09415  loss_mask: 0.08531  loss_rpn_cls: 0.0008531  loss_rpn_loc: 0.01851  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:22] d2.utils.events INFO:  eta: 1:24:13  iter: 32999  total_loss: 0.1541  loss_cls: 0.02419  loss_box_reg: 0.06897  loss_mask: 0.06308  loss_rpn_cls: 0.0003358  loss_rpn_loc: 0.007153  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:24] d2.utils.events INFO:  eta: 1:24:12  iter: 33019  total_loss: 0.2274  loss_cls: 0.04207  loss_box_reg: 0.1152  loss_mask: 0.06833  loss_rpn_cls: 0.00086  loss_rpn_loc: 0.01514  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:26] d2.utils.events INFO:  eta: 1:24:17  iter: 33039  total_loss: 0.1672  loss_cls: 0.02245  loss_box_reg: 0.07211  loss_mask: 0.04906  loss_rpn_cls: 0.0003955  loss_rpn_loc: 0.009365  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:27] d2.utils.events INFO:  eta: 1:24:15  iter: 33059  total_loss: 0.1787  loss_cls: 0.02647  loss_box_reg: 0.08224  loss_mask: 0.06348  loss_rpn_cls: 0.0005724  loss_rpn_loc: 0.01132  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:29] d2.utils.events INFO:  eta: 1:24:22  iter: 33079  total_loss: 0.2677  loss_cls: 0.04385  loss_box_reg: 0.1162  loss_mask: 0.07601  loss_rpn_cls: 0.0007871  loss_rpn_loc: 0.01403  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:31] d2.utils.events INFO:  eta: 1:24:03  iter: 33099  total_loss: 0.2284  loss_cls: 0.03489  loss_box_reg: 0.1171  loss_mask: 0.0758  loss_rpn_cls: 0.001448  loss_rpn_loc: 0.01123  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:33] d2.utils.events INFO:  eta: 1:23:59  iter: 33119  total_loss: 0.2495  loss_cls: 0.03699  loss_box_reg: 0.1075  loss_mask: 0.09677  loss_rpn_cls: 0.001084  loss_rpn_loc: 0.01035  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:35] d2.utils.events INFO:  eta: 1:23:53  iter: 33139  total_loss: 0.2278  loss_cls: 0.03428  loss_box_reg: 0.08478  loss_mask: 0.08491  loss_rpn_cls: 0.0009769  loss_rpn_loc: 0.01637  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:36] d2.utils.events INFO:  eta: 1:23:58  iter: 33159  total_loss: 0.3064  loss_cls: 0.04839  loss_box_reg: 0.1294  loss_mask: 0.06767  loss_rpn_cls: 0.001044  loss_rpn_loc: 0.01863  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:38] d2.utils.events INFO:  eta: 1:23:54  iter: 33179  total_loss: 0.2648  loss_cls: 0.03831  loss_box_reg: 0.1096  loss_mask: 0.08227  loss_rpn_cls: 0.0009088  loss_rpn_loc: 0.01477  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:40] d2.utils.events INFO:  eta: 1:23:46  iter: 33199  total_loss: 0.1784  loss_cls: 0.02294  loss_box_reg: 0.07003  loss_mask: 0.06088  loss_rpn_cls: 0.0004279  loss_rpn_loc: 0.01242  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:42] d2.utils.events INFO:  eta: 1:23:46  iter: 33219  total_loss: 0.1737  loss_cls: 0.02781  loss_box_reg: 0.06698  loss_mask: 0.06409  loss_rpn_cls: 0.0005101  loss_rpn_loc: 0.01074  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:43] d2.utils.events INFO:  eta: 1:23:48  iter: 33239  total_loss: 0.2359  loss_cls: 0.03388  loss_box_reg: 0.1052  loss_mask: 0.06664  loss_rpn_cls: 0.000652  loss_rpn_loc: 0.01385  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:45] d2.utils.events INFO:  eta: 1:23:40  iter: 33259  total_loss: 0.1782  loss_cls: 0.02363  loss_box_reg: 0.07244  loss_mask: 0.07984  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.0131  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:47] d2.utils.events INFO:  eta: 1:23:31  iter: 33279  total_loss: 0.1768  loss_cls: 0.03057  loss_box_reg: 0.06564  loss_mask: 0.0809  loss_rpn_cls: 0.000895  loss_rpn_loc: 0.01354  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:49] d2.utils.events INFO:  eta: 1:23:30  iter: 33299  total_loss: 0.2215  loss_cls: 0.03652  loss_box_reg: 0.09035  loss_mask: 0.07636  loss_rpn_cls: 0.000591  loss_rpn_loc: 0.01351  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:50] d2.utils.events INFO:  eta: 1:23:29  iter: 33319  total_loss: 0.1573  loss_cls: 0.02293  loss_box_reg: 0.07096  loss_mask: 0.06204  loss_rpn_cls: 0.0008149  loss_rpn_loc: 0.01127  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:52] d2.utils.events INFO:  eta: 1:23:42  iter: 33339  total_loss: 0.2864  loss_cls: 0.04539  loss_box_reg: 0.1221  loss_mask: 0.08955  loss_rpn_cls: 0.0008888  loss_rpn_loc: 0.01974  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:54] d2.utils.events INFO:  eta: 1:23:54  iter: 33359  total_loss: 0.2986  loss_cls: 0.04589  loss_box_reg: 0.1235  loss_mask: 0.0817  loss_rpn_cls: 0.0009725  loss_rpn_loc: 0.03609  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:56] d2.utils.events INFO:  eta: 1:23:39  iter: 33379  total_loss: 0.2202  loss_cls: 0.03153  loss_box_reg: 0.07998  loss_mask: 0.0803  loss_rpn_cls: 0.0007108  loss_rpn_loc: 0.01248  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:26:58] d2.utils.events INFO:  eta: 1:23:41  iter: 33399  total_loss: 0.2292  loss_cls: 0.03808  loss_box_reg: 0.09304  loss_mask: 0.07847  loss_rpn_cls: 0.001015  loss_rpn_loc: 0.01498  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:26:59] d2.utils.events INFO:  eta: 1:23:28  iter: 33419  total_loss: 0.1847  loss_cls: 0.02312  loss_box_reg: 0.07377  loss_mask: 0.06881  loss_rpn_cls: 0.0007954  loss_rpn_loc: 0.01099  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:01] d2.utils.events INFO:  eta: 1:23:35  iter: 33439  total_loss: 0.3219  loss_cls: 0.04817  loss_box_reg: 0.1356  loss_mask: 0.09774  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.0262  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:03] d2.utils.events INFO:  eta: 1:23:17  iter: 33459  total_loss: 0.194  loss_cls: 0.03317  loss_box_reg: 0.08258  loss_mask: 0.07787  loss_rpn_cls: 0.0007836  loss_rpn_loc: 0.01318  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:05] d2.utils.events INFO:  eta: 1:23:23  iter: 33479  total_loss: 0.2458  loss_cls: 0.0332  loss_box_reg: 0.103  loss_mask: 0.07567  loss_rpn_cls: 0.0007929  loss_rpn_loc: 0.01545  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:06] d2.utils.events INFO:  eta: 1:23:28  iter: 33499  total_loss: 0.2965  loss_cls: 0.03829  loss_box_reg: 0.1189  loss_mask: 0.1004  loss_rpn_cls: 0.001303  loss_rpn_loc: 0.021  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:08] d2.utils.events INFO:  eta: 1:23:24  iter: 33519  total_loss: 0.2491  loss_cls: 0.03793  loss_box_reg: 0.113  loss_mask: 0.08359  loss_rpn_cls: 0.001105  loss_rpn_loc: 0.01718  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:10] d2.utils.events INFO:  eta: 1:23:34  iter: 33539  total_loss: 0.2391  loss_cls: 0.03985  loss_box_reg: 0.1084  loss_mask: 0.06986  loss_rpn_cls: 0.0005024  loss_rpn_loc: 0.01354  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:12] d2.utils.events INFO:  eta: 1:23:35  iter: 33559  total_loss: 0.2723  loss_cls: 0.03857  loss_box_reg: 0.1232  loss_mask: 0.07559  loss_rpn_cls: 0.001375  loss_rpn_loc: 0.01811  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:14] d2.utils.events INFO:  eta: 1:23:22  iter: 33579  total_loss: 0.2056  loss_cls: 0.03333  loss_box_reg: 0.08816  loss_mask: 0.0748  loss_rpn_cls: 0.001576  loss_rpn_loc: 0.02892  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:15] d2.utils.events INFO:  eta: 1:23:12  iter: 33599  total_loss: 0.1936  loss_cls: 0.02889  loss_box_reg: 0.08159  loss_mask: 0.07043  loss_rpn_cls: 0.001072  loss_rpn_loc: 0.008562  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:17] d2.utils.events INFO:  eta: 1:23:03  iter: 33619  total_loss: 0.1524  loss_cls: 0.02795  loss_box_reg: 0.07051  loss_mask: 0.05762  loss_rpn_cls: 0.0003393  loss_rpn_loc: 0.004793  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:19] d2.utils.events INFO:  eta: 1:23:04  iter: 33639  total_loss: 0.2075  loss_cls: 0.02956  loss_box_reg: 0.09712  loss_mask: 0.05874  loss_rpn_cls: 0.0005242  loss_rpn_loc: 0.008411  time: 0.0886  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:21] d2.utils.events INFO:  eta: 1:23:13  iter: 33659  total_loss: 0.2678  loss_cls: 0.04873  loss_box_reg: 0.1311  loss_mask: 0.07594  loss_rpn_cls: 0.001259  loss_rpn_loc: 0.01853  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:22] d2.utils.events INFO:  eta: 1:23:11  iter: 33679  total_loss: 0.209  loss_cls: 0.02707  loss_box_reg: 0.09186  loss_mask: 0.06189  loss_rpn_cls: 0.0005579  loss_rpn_loc: 0.01145  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:24] d2.utils.events INFO:  eta: 1:23:05  iter: 33699  total_loss: 0.1398  loss_cls: 0.02109  loss_box_reg: 0.05099  loss_mask: 0.06624  loss_rpn_cls: 0.0005607  loss_rpn_loc: 0.01085  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:26] d2.utils.events INFO:  eta: 1:23:04  iter: 33719  total_loss: 0.2838  loss_cls: 0.04167  loss_box_reg: 0.1253  loss_mask: 0.06522  loss_rpn_cls: 0.0005938  loss_rpn_loc: 0.01159  time: 0.0886  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:28] d2.utils.events INFO:  eta: 1:23:02  iter: 33739  total_loss: 0.1988  loss_cls: 0.0344  loss_box_reg: 0.08878  loss_mask: 0.06252  loss_rpn_cls: 0.000579  loss_rpn_loc: 0.01409  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:29] d2.utils.events INFO:  eta: 1:22:46  iter: 33759  total_loss: 0.1855  loss_cls: 0.02638  loss_box_reg: 0.09106  loss_mask: 0.06549  loss_rpn_cls: 0.0004625  loss_rpn_loc: 0.01444  time: 0.0885  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:27:31] d2.utils.events INFO:  eta: 1:22:42  iter: 33779  total_loss: 0.1526  loss_cls: 0.02756  loss_box_reg: 0.06654  loss_mask: 0.06382  loss_rpn_cls: 0.0002332  loss_rpn_loc: 0.007862  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:33] d2.utils.events INFO:  eta: 1:22:45  iter: 33799  total_loss: 0.2637  loss_cls: 0.04628  loss_box_reg: 0.1316  loss_mask: 0.07828  loss_rpn_cls: 0.0009087  loss_rpn_loc: 0.02014  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:35] d2.utils.events INFO:  eta: 1:22:50  iter: 33819  total_loss: 0.2466  loss_cls: 0.03242  loss_box_reg: 0.1078  loss_mask: 0.07573  loss_rpn_cls: 0.0004763  loss_rpn_loc: 0.01209  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:36] d2.utils.events INFO:  eta: 1:22:48  iter: 33839  total_loss: 0.2887  loss_cls: 0.04397  loss_box_reg: 0.1283  loss_mask: 0.08952  loss_rpn_cls: 0.00205  loss_rpn_loc: 0.02302  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:38] d2.utils.events INFO:  eta: 1:22:49  iter: 33859  total_loss: 0.2817  loss_cls: 0.03445  loss_box_reg: 0.1022  loss_mask: 0.08668  loss_rpn_cls: 0.0008722  loss_rpn_loc: 0.02139  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:40] d2.utils.events INFO:  eta: 1:22:53  iter: 33879  total_loss: 0.3394  loss_cls: 0.05642  loss_box_reg: 0.1408  loss_mask: 0.09997  loss_rpn_cls: 0.001342  loss_rpn_loc: 0.02751  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:42] d2.utils.events INFO:  eta: 1:22:57  iter: 33899  total_loss: 0.2782  loss_cls: 0.04546  loss_box_reg: 0.1344  loss_mask: 0.07682  loss_rpn_cls: 0.001142  loss_rpn_loc: 0.01713  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:44] d2.utils.events INFO:  eta: 1:22:51  iter: 33919  total_loss: 0.1564  loss_cls: 0.02421  loss_box_reg: 0.06016  loss_mask: 0.0672  loss_rpn_cls: 0.0005165  loss_rpn_loc: 0.006851  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:45] d2.utils.events INFO:  eta: 1:22:56  iter: 33939  total_loss: 0.2542  loss_cls: 0.03799  loss_box_reg: 0.1013  loss_mask: 0.06775  loss_rpn_cls: 0.001336  loss_rpn_loc: 0.01459  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:47] d2.utils.events INFO:  eta: 1:22:48  iter: 33959  total_loss: 0.1397  loss_cls: 0.02062  loss_box_reg: 0.04909  loss_mask: 0.06369  loss_rpn_cls: 0.0005341  loss_rpn_loc: 0.007556  time: 0.0885  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:27:49] d2.utils.events INFO:  eta: 1:22:40  iter: 33979  total_loss: 0.1505  loss_cls: 0.02514  loss_box_reg: 0.07216  loss_mask: 0.05842  loss_rpn_cls: 0.000381  loss_rpn_loc: 0.005919  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:51] d2.utils.events INFO:  eta: 1:22:48  iter: 33999  total_loss: 0.256  loss_cls: 0.04297  loss_box_reg: 0.1112  loss_mask: 0.08489  loss_rpn_cls: 0.001582  loss_rpn_loc: 0.01793  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:27:52] d2.utils.events INFO:  eta: 1:22:37  iter: 34019  total_loss: 0.2275  loss_cls: 0.02965  loss_box_reg: 0.08481  loss_mask: 0.07024  loss_rpn_cls: 0.0007026  loss_rpn_loc: 0.009264  time: 0.0885  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:27:54] d2.utils.events INFO:  eta: 1:22:37  iter: 34039  total_loss: 0.2072  loss_cls: 0.03107  loss_box_reg: 0.06894  loss_mask: 0.07071  loss_rpn_cls: 0.0005652  loss_rpn_loc: 0.01133  time: 0.0885  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:27:56] d2.utils.events INFO:  eta: 1:22:37  iter: 34059  total_loss: 0.2006  loss_cls: 0.02583  loss_box_reg: 0.09064  loss_mask: 0.07461  loss_rpn_cls: 0.0008167  loss_rpn_loc: 0.01702  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:58] d2.utils.events INFO:  eta: 1:22:37  iter: 34079  total_loss: 0.2165  loss_cls: 0.03241  loss_box_reg: 0.09848  loss_mask: 0.08499  loss_rpn_cls: 0.001479  loss_rpn_loc: 0.01989  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:27:59] d2.utils.events INFO:  eta: 1:22:34  iter: 34099  total_loss: 0.1955  loss_cls: 0.02574  loss_box_reg: 0.08453  loss_mask: 0.07733  loss_rpn_cls: 0.0006402  loss_rpn_loc: 0.01061  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:01] d2.utils.events INFO:  eta: 1:22:32  iter: 34119  total_loss: 0.3119  loss_cls: 0.04866  loss_box_reg: 0.1304  loss_mask: 0.0895  loss_rpn_cls: 0.0007451  loss_rpn_loc: 0.01953  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:03] d2.utils.events INFO:  eta: 1:22:25  iter: 34139  total_loss: 0.1919  loss_cls: 0.03297  loss_box_reg: 0.08343  loss_mask: 0.06466  loss_rpn_cls: 0.0008972  loss_rpn_loc: 0.01108  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:05] d2.utils.events INFO:  eta: 1:22:23  iter: 34159  total_loss: 0.2281  loss_cls: 0.02866  loss_box_reg: 0.0989  loss_mask: 0.08082  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.01321  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:06] d2.utils.events INFO:  eta: 1:22:17  iter: 34179  total_loss: 0.1594  loss_cls: 0.01996  loss_box_reg: 0.07259  loss_mask: 0.06958  loss_rpn_cls: 0.0006813  loss_rpn_loc: 0.008341  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:08] d2.utils.events INFO:  eta: 1:22:20  iter: 34199  total_loss: 0.2519  loss_cls: 0.03597  loss_box_reg: 0.1252  loss_mask: 0.06674  loss_rpn_cls: 0.0006153  loss_rpn_loc: 0.01491  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:10] d2.utils.events INFO:  eta: 1:22:20  iter: 34219  total_loss: 0.2211  loss_cls: 0.03483  loss_box_reg: 0.08967  loss_mask: 0.06955  loss_rpn_cls: 0.0008147  loss_rpn_loc: 0.01362  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:12] d2.utils.events INFO:  eta: 1:22:19  iter: 34239  total_loss: 0.2737  loss_cls: 0.03303  loss_box_reg: 0.1204  loss_mask: 0.07238  loss_rpn_cls: 0.0008808  loss_rpn_loc: 0.01927  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:13] d2.utils.events INFO:  eta: 1:22:14  iter: 34259  total_loss: 0.1547  loss_cls: 0.02614  loss_box_reg: 0.05786  loss_mask: 0.06739  loss_rpn_cls: 0.0004276  loss_rpn_loc: 0.01004  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:15] d2.utils.events INFO:  eta: 1:22:13  iter: 34279  total_loss: 0.1377  loss_cls: 0.02543  loss_box_reg: 0.05197  loss_mask: 0.06431  loss_rpn_cls: 0.0004618  loss_rpn_loc: 0.01089  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:17] d2.utils.events INFO:  eta: 1:22:11  iter: 34299  total_loss: 0.2809  loss_cls: 0.03565  loss_box_reg: 0.1101  loss_mask: 0.06984  loss_rpn_cls: 0.0009742  loss_rpn_loc: 0.01802  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:19] d2.utils.events INFO:  eta: 1:22:10  iter: 34319  total_loss: 0.2304  loss_cls: 0.03219  loss_box_reg: 0.1096  loss_mask: 0.06067  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.01298  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:20] d2.utils.events INFO:  eta: 1:22:03  iter: 34339  total_loss: 0.1985  loss_cls: 0.02507  loss_box_reg: 0.08012  loss_mask: 0.06483  loss_rpn_cls: 0.0007325  loss_rpn_loc: 0.01198  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:22] d2.utils.events INFO:  eta: 1:21:47  iter: 34359  total_loss: 0.1346  loss_cls: 0.02014  loss_box_reg: 0.03549  loss_mask: 0.06487  loss_rpn_cls: 0.0006258  loss_rpn_loc: 0.01237  time: 0.0885  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:24] d2.utils.events INFO:  eta: 1:21:46  iter: 34379  total_loss: 0.208  loss_cls: 0.03465  loss_box_reg: 0.08486  loss_mask: 0.07521  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.01709  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:25] d2.utils.events INFO:  eta: 1:21:36  iter: 34399  total_loss: 0.1922  loss_cls: 0.0307  loss_box_reg: 0.08017  loss_mask: 0.06547  loss_rpn_cls: 0.0009267  loss_rpn_loc: 0.01236  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:27] d2.utils.events INFO:  eta: 1:21:40  iter: 34419  total_loss: 0.1962  loss_cls: 0.03522  loss_box_reg: 0.08155  loss_mask: 0.08086  loss_rpn_cls: 0.000621  loss_rpn_loc: 0.01264  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:29] d2.utils.events INFO:  eta: 1:21:33  iter: 34439  total_loss: 0.1956  loss_cls: 0.03531  loss_box_reg: 0.09414  loss_mask: 0.05792  loss_rpn_cls: 0.0006015  loss_rpn_loc: 0.012  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:31] d2.utils.events INFO:  eta: 1:21:53  iter: 34459  total_loss: 0.3154  loss_cls: 0.04053  loss_box_reg: 0.1146  loss_mask: 0.07772  loss_rpn_cls: 0.0008434  loss_rpn_loc: 0.02101  time: 0.0885  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:33] d2.utils.events INFO:  eta: 1:21:37  iter: 34479  total_loss: 0.2173  loss_cls: 0.0323  loss_box_reg: 0.0805  loss_mask: 0.07657  loss_rpn_cls: 0.001251  loss_rpn_loc: 0.02205  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:34] d2.utils.events INFO:  eta: 1:21:18  iter: 34499  total_loss: 0.1711  loss_cls: 0.02208  loss_box_reg: 0.06357  loss_mask: 0.0665  loss_rpn_cls: 0.000472  loss_rpn_loc: 0.005956  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:36] d2.utils.events INFO:  eta: 1:21:18  iter: 34519  total_loss: 0.2095  loss_cls: 0.02498  loss_box_reg: 0.09924  loss_mask: 0.07684  loss_rpn_cls: 0.0007291  loss_rpn_loc: 0.01222  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:38] d2.utils.events INFO:  eta: 1:21:14  iter: 34539  total_loss: 0.2236  loss_cls: 0.03037  loss_box_reg: 0.1148  loss_mask: 0.05716  loss_rpn_cls: 0.0006737  loss_rpn_loc: 0.01688  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:40] d2.utils.events INFO:  eta: 1:21:16  iter: 34559  total_loss: 0.222  loss_cls: 0.036  loss_box_reg: 0.103  loss_mask: 0.08862  loss_rpn_cls: 0.0007692  loss_rpn_loc: 0.01036  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:41] d2.utils.events INFO:  eta: 1:21:16  iter: 34579  total_loss: 0.2316  loss_cls: 0.03119  loss_box_reg: 0.1077  loss_mask: 0.07495  loss_rpn_cls: 0.0007345  loss_rpn_loc: 0.0113  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:43] d2.utils.events INFO:  eta: 1:21:19  iter: 34599  total_loss: 0.1855  loss_cls: 0.02385  loss_box_reg: 0.07459  loss_mask: 0.07108  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.01121  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:45] d2.utils.events INFO:  eta: 1:21:28  iter: 34619  total_loss: 0.2555  loss_cls: 0.03054  loss_box_reg: 0.1064  loss_mask: 0.07719  loss_rpn_cls: 0.0007187  loss_rpn_loc: 0.016  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:47] d2.utils.events INFO:  eta: 1:21:26  iter: 34639  total_loss: 0.1628  loss_cls: 0.02298  loss_box_reg: 0.06955  loss_mask: 0.07268  loss_rpn_cls: 0.0007359  loss_rpn_loc: 0.00946  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:48] d2.utils.events INFO:  eta: 1:21:21  iter: 34659  total_loss: 0.2058  loss_cls: 0.03761  loss_box_reg: 0.1078  loss_mask: 0.0768  loss_rpn_cls: 0.001534  loss_rpn_loc: 0.02128  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:50] d2.utils.events INFO:  eta: 1:21:05  iter: 34679  total_loss: 0.1833  loss_cls: 0.02398  loss_box_reg: 0.07875  loss_mask: 0.07201  loss_rpn_cls: 0.0006501  loss_rpn_loc: 0.0108  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:52] d2.utils.events INFO:  eta: 1:21:03  iter: 34699  total_loss: 0.1491  loss_cls: 0.02057  loss_box_reg: 0.05062  loss_mask: 0.06745  loss_rpn_cls: 0.0007157  loss_rpn_loc: 0.01105  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:54] d2.utils.events INFO:  eta: 1:20:55  iter: 34719  total_loss: 0.1885  loss_cls: 0.02036  loss_box_reg: 0.07134  loss_mask: 0.06383  loss_rpn_cls: 0.0007328  loss_rpn_loc: 0.01135  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:55] d2.utils.events INFO:  eta: 1:20:53  iter: 34739  total_loss: 0.1965  loss_cls: 0.03557  loss_box_reg: 0.07228  loss_mask: 0.07486  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.01901  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:28:57] d2.utils.events INFO:  eta: 1:20:55  iter: 34759  total_loss: 0.2738  loss_cls: 0.05062  loss_box_reg: 0.111  loss_mask: 0.08299  loss_rpn_cls: 0.0009942  loss_rpn_loc: 0.01695  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:28:59] d2.utils.events INFO:  eta: 1:20:55  iter: 34779  total_loss: 0.1673  loss_cls: 0.0224  loss_box_reg: 0.06842  loss_mask: 0.06616  loss_rpn_cls: 0.0004752  loss_rpn_loc: 0.01191  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:01] d2.utils.events INFO:  eta: 1:20:46  iter: 34799  total_loss: 0.212  loss_cls: 0.02801  loss_box_reg: 0.08125  loss_mask: 0.07803  loss_rpn_cls: 0.0005304  loss_rpn_loc: 0.008094  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:02] d2.utils.events INFO:  eta: 1:20:41  iter: 34819  total_loss: 0.1091  loss_cls: 0.01868  loss_box_reg: 0.04428  loss_mask: 0.05885  loss_rpn_cls: 0.0003445  loss_rpn_loc: 0.005364  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:04] d2.utils.events INFO:  eta: 1:20:34  iter: 34839  total_loss: 0.2123  loss_cls: 0.03691  loss_box_reg: 0.1029  loss_mask: 0.06949  loss_rpn_cls: 0.0004288  loss_rpn_loc: 0.008965  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:06] d2.utils.events INFO:  eta: 1:20:35  iter: 34859  total_loss: 0.2469  loss_cls: 0.03497  loss_box_reg: 0.1142  loss_mask: 0.07761  loss_rpn_cls: 0.0006613  loss_rpn_loc: 0.01294  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:08] d2.utils.events INFO:  eta: 1:20:29  iter: 34879  total_loss: 0.2177  loss_cls: 0.02917  loss_box_reg: 0.08708  loss_mask: 0.07161  loss_rpn_cls: 0.0008686  loss_rpn_loc: 0.01583  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:09] d2.utils.events INFO:  eta: 1:20:22  iter: 34899  total_loss: 0.2391  loss_cls: 0.04804  loss_box_reg: 0.1186  loss_mask: 0.07126  loss_rpn_cls: 0.000495  loss_rpn_loc: 0.0157  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:11] d2.utils.events INFO:  eta: 1:20:24  iter: 34919  total_loss: 0.234  loss_cls: 0.03895  loss_box_reg: 0.1037  loss_mask: 0.07233  loss_rpn_cls: 0.0006365  loss_rpn_loc: 0.01218  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:13] d2.utils.events INFO:  eta: 1:20:25  iter: 34939  total_loss: 0.2453  loss_cls: 0.03206  loss_box_reg: 0.1173  loss_mask: 0.09439  loss_rpn_cls: 0.0007884  loss_rpn_loc: 0.01601  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:15] d2.utils.events INFO:  eta: 1:20:26  iter: 34959  total_loss: 0.1606  loss_cls: 0.02177  loss_box_reg: 0.0418  loss_mask: 0.05983  loss_rpn_cls: 0.0005694  loss_rpn_loc: 0.01702  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:16] d2.utils.events INFO:  eta: 1:20:29  iter: 34979  total_loss: 0.1636  loss_cls: 0.0195  loss_box_reg: 0.07488  loss_mask: 0.0516  loss_rpn_cls: 0.0006928  loss_rpn_loc: 0.009313  time: 0.0884  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:29:18] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0034999.pth
[10/27 19:29:19] d2.utils.events INFO:  eta: 1:20:25  iter: 34999  total_loss: 0.2695  loss_cls: 0.03964  loss_box_reg: 0.1101  loss_mask: 0.0854  loss_rpn_cls: 0.0008089  loss_rpn_loc: 0.01609  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:20] d2.utils.events INFO:  eta: 1:20:21  iter: 35019  total_loss: 0.1622  loss_cls: 0.0244  loss_box_reg: 0.07997  loss_mask: 0.06202  loss_rpn_cls: 0.0002949  loss_rpn_loc: 0.006664  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:22] d2.utils.events INFO:  eta: 1:20:09  iter: 35039  total_loss: 0.1681  loss_cls: 0.02906  loss_box_reg: 0.06627  loss_mask: 0.06483  loss_rpn_cls: 0.000726  loss_rpn_loc: 0.01317  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:24] d2.utils.events INFO:  eta: 1:20:13  iter: 35059  total_loss: 0.2649  loss_cls: 0.03919  loss_box_reg: 0.09814  loss_mask: 0.07822  loss_rpn_cls: 0.00111  loss_rpn_loc: 0.01837  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:26] d2.utils.events INFO:  eta: 1:20:18  iter: 35079  total_loss: 0.2643  loss_cls: 0.03662  loss_box_reg: 0.1236  loss_mask: 0.08984  loss_rpn_cls: 0.0008849  loss_rpn_loc: 0.02323  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:27] d2.utils.events INFO:  eta: 1:20:08  iter: 35099  total_loss: 0.1811  loss_cls: 0.02215  loss_box_reg: 0.07741  loss_mask: 0.07174  loss_rpn_cls: 0.0006089  loss_rpn_loc: 0.008813  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:29] d2.utils.events INFO:  eta: 1:20:06  iter: 35119  total_loss: 0.32  loss_cls: 0.04339  loss_box_reg: 0.1343  loss_mask: 0.09132  loss_rpn_cls: 0.001179  loss_rpn_loc: 0.02755  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:31] d2.utils.events INFO:  eta: 1:20:13  iter: 35139  total_loss: 0.2631  loss_cls: 0.03557  loss_box_reg: 0.1042  loss_mask: 0.07924  loss_rpn_cls: 0.0006868  loss_rpn_loc: 0.02055  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:33] d2.utils.events INFO:  eta: 1:20:11  iter: 35159  total_loss: 0.2163  loss_cls: 0.03171  loss_box_reg: 0.08976  loss_mask: 0.07153  loss_rpn_cls: 0.0006  loss_rpn_loc: 0.01352  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:34] d2.utils.events INFO:  eta: 1:20:12  iter: 35179  total_loss: 0.2664  loss_cls: 0.042  loss_box_reg: 0.1089  loss_mask: 0.07492  loss_rpn_cls: 0.0007675  loss_rpn_loc: 0.01821  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:36] d2.utils.events INFO:  eta: 1:20:09  iter: 35199  total_loss: 0.2174  loss_cls: 0.04002  loss_box_reg: 0.08892  loss_mask: 0.08114  loss_rpn_cls: 0.001714  loss_rpn_loc: 0.01592  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:38] d2.utils.events INFO:  eta: 1:20:01  iter: 35219  total_loss: 0.1637  loss_cls: 0.02134  loss_box_reg: 0.06866  loss_mask: 0.05539  loss_rpn_cls: 0.000639  loss_rpn_loc: 0.007137  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:40] d2.utils.events INFO:  eta: 1:20:00  iter: 35239  total_loss: 0.2423  loss_cls: 0.04052  loss_box_reg: 0.1189  loss_mask: 0.0821  loss_rpn_cls: 0.001537  loss_rpn_loc: 0.01788  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:42] d2.utils.events INFO:  eta: 1:20:05  iter: 35259  total_loss: 0.2131  loss_cls: 0.02989  loss_box_reg: 0.08909  loss_mask: 0.08498  loss_rpn_cls: 0.001262  loss_rpn_loc: 0.01437  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:43] d2.utils.events INFO:  eta: 1:20:03  iter: 35279  total_loss: 0.2091  loss_cls: 0.02731  loss_box_reg: 0.1024  loss_mask: 0.06389  loss_rpn_cls: 0.00103  loss_rpn_loc: 0.01243  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:45] d2.utils.events INFO:  eta: 1:20:01  iter: 35299  total_loss: 0.1651  loss_cls: 0.02412  loss_box_reg: 0.06885  loss_mask: 0.06336  loss_rpn_cls: 0.0005071  loss_rpn_loc: 0.005989  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:47] d2.utils.events INFO:  eta: 1:19:58  iter: 35319  total_loss: 0.2087  loss_cls: 0.034  loss_box_reg: 0.09654  loss_mask: 0.07314  loss_rpn_cls: 0.0007583  loss_rpn_loc: 0.007495  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:48] d2.utils.events INFO:  eta: 1:19:58  iter: 35339  total_loss: 0.2368  loss_cls: 0.04013  loss_box_reg: 0.08818  loss_mask: 0.06998  loss_rpn_cls: 0.001271  loss_rpn_loc: 0.01663  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:50] d2.utils.events INFO:  eta: 1:19:58  iter: 35359  total_loss: 0.1871  loss_cls: 0.03696  loss_box_reg: 0.06824  loss_mask: 0.06462  loss_rpn_cls: 0.0007325  loss_rpn_loc: 0.01444  time: 0.0884  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:52] d2.utils.events INFO:  eta: 1:20:01  iter: 35379  total_loss: 0.2482  loss_cls: 0.04322  loss_box_reg: 0.1106  loss_mask: 0.07004  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.01198  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:54] d2.utils.events INFO:  eta: 1:19:56  iter: 35399  total_loss: 0.2311  loss_cls: 0.03626  loss_box_reg: 0.07317  loss_mask: 0.07726  loss_rpn_cls: 0.0007374  loss_rpn_loc: 0.01489  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:56] d2.utils.events INFO:  eta: 1:19:58  iter: 35419  total_loss: 0.2301  loss_cls: 0.0363  loss_box_reg: 0.09968  loss_mask: 0.08342  loss_rpn_cls: 0.001592  loss_rpn_loc: 0.02545  time: 0.0884  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:29:57] d2.utils.events INFO:  eta: 1:19:52  iter: 35439  total_loss: 0.2726  loss_cls: 0.04326  loss_box_reg: 0.1313  loss_mask: 0.07727  loss_rpn_cls: 0.001012  loss_rpn_loc: 0.01947  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:29:59] d2.utils.events INFO:  eta: 1:19:44  iter: 35459  total_loss: 0.1941  loss_cls: 0.02958  loss_box_reg: 0.08025  loss_mask: 0.06855  loss_rpn_cls: 0.0007576  loss_rpn_loc: 0.009987  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:01] d2.utils.events INFO:  eta: 1:19:56  iter: 35479  total_loss: 0.336  loss_cls: 0.05679  loss_box_reg: 0.1435  loss_mask: 0.1108  loss_rpn_cls: 0.0009486  loss_rpn_loc: 0.02318  time: 0.0884  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:30:03] d2.utils.events INFO:  eta: 1:20:01  iter: 35499  total_loss: 0.2006  loss_cls: 0.02819  loss_box_reg: 0.08059  loss_mask: 0.06933  loss_rpn_cls: 0.0005525  loss_rpn_loc: 0.01323  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:04] d2.utils.events INFO:  eta: 1:19:51  iter: 35519  total_loss: 0.1807  loss_cls: 0.03129  loss_box_reg: 0.08007  loss_mask: 0.06539  loss_rpn_cls: 0.000539  loss_rpn_loc: 0.006743  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:06] d2.utils.events INFO:  eta: 1:19:48  iter: 35539  total_loss: 0.1677  loss_cls: 0.02515  loss_box_reg: 0.07624  loss_mask: 0.06558  loss_rpn_cls: 0.0003716  loss_rpn_loc: 0.01372  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:08] d2.utils.events INFO:  eta: 1:19:42  iter: 35559  total_loss: 0.2959  loss_cls: 0.04841  loss_box_reg: 0.1246  loss_mask: 0.08602  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.01847  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:10] d2.utils.events INFO:  eta: 1:19:42  iter: 35579  total_loss: 0.1926  loss_cls: 0.02899  loss_box_reg: 0.1052  loss_mask: 0.0648  loss_rpn_cls: 0.0007157  loss_rpn_loc: 0.01608  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:11] d2.utils.events INFO:  eta: 1:19:43  iter: 35599  total_loss: 0.2277  loss_cls: 0.03488  loss_box_reg: 0.1066  loss_mask: 0.06124  loss_rpn_cls: 0.0004072  loss_rpn_loc: 0.01408  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:13] d2.utils.events INFO:  eta: 1:19:40  iter: 35619  total_loss: 0.2228  loss_cls: 0.03487  loss_box_reg: 0.09606  loss_mask: 0.06844  loss_rpn_cls: 0.0006783  loss_rpn_loc: 0.01379  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:15] d2.utils.events INFO:  eta: 1:19:41  iter: 35639  total_loss: 0.2466  loss_cls: 0.03287  loss_box_reg: 0.1088  loss_mask: 0.08094  loss_rpn_cls: 0.001647  loss_rpn_loc: 0.02016  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:17] d2.utils.events INFO:  eta: 1:19:39  iter: 35659  total_loss: 0.1841  loss_cls: 0.03586  loss_box_reg: 0.07814  loss_mask: 0.06826  loss_rpn_cls: 0.0005633  loss_rpn_loc: 0.009297  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:18] d2.utils.events INFO:  eta: 1:19:42  iter: 35679  total_loss: 0.2108  loss_cls: 0.03476  loss_box_reg: 0.1004  loss_mask: 0.07085  loss_rpn_cls: 0.0003924  loss_rpn_loc: 0.009079  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:20] d2.utils.events INFO:  eta: 1:19:39  iter: 35699  total_loss: 0.2137  loss_cls: 0.03223  loss_box_reg: 0.1047  loss_mask: 0.08041  loss_rpn_cls: 0.000466  loss_rpn_loc: 0.00927  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:22] d2.utils.events INFO:  eta: 1:19:39  iter: 35719  total_loss: 0.201  loss_cls: 0.03377  loss_box_reg: 0.07897  loss_mask: 0.09845  loss_rpn_cls: 0.0004946  loss_rpn_loc: 0.01174  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:24] d2.utils.events INFO:  eta: 1:19:34  iter: 35739  total_loss: 0.232  loss_cls: 0.03577  loss_box_reg: 0.1003  loss_mask: 0.07141  loss_rpn_cls: 0.0007388  loss_rpn_loc: 0.01482  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:25] d2.utils.events INFO:  eta: 1:19:31  iter: 35759  total_loss: 0.1944  loss_cls: 0.02664  loss_box_reg: 0.08229  loss_mask: 0.07574  loss_rpn_cls: 0.001118  loss_rpn_loc: 0.009584  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:27] d2.utils.events INFO:  eta: 1:19:27  iter: 35779  total_loss: 0.1395  loss_cls: 0.0193  loss_box_reg: 0.05573  loss_mask: 0.06173  loss_rpn_cls: 0.0004128  loss_rpn_loc: 0.01109  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:29] d2.utils.events INFO:  eta: 1:19:28  iter: 35799  total_loss: 0.2365  loss_cls: 0.03441  loss_box_reg: 0.1158  loss_mask: 0.05665  loss_rpn_cls: 0.0007724  loss_rpn_loc: 0.008385  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:31] d2.utils.events INFO:  eta: 1:19:32  iter: 35819  total_loss: 0.2128  loss_cls: 0.03206  loss_box_reg: 0.07508  loss_mask: 0.07936  loss_rpn_cls: 0.001233  loss_rpn_loc: 0.01123  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:32] d2.utils.events INFO:  eta: 1:19:26  iter: 35839  total_loss: 0.2377  loss_cls: 0.03015  loss_box_reg: 0.1052  loss_mask: 0.0665  loss_rpn_cls: 0.0007921  loss_rpn_loc: 0.0179  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:34] d2.utils.events INFO:  eta: 1:19:32  iter: 35859  total_loss: 0.2427  loss_cls: 0.03573  loss_box_reg: 0.104  loss_mask: 0.07801  loss_rpn_cls: 0.0009864  loss_rpn_loc: 0.01693  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:36] d2.utils.events INFO:  eta: 1:19:30  iter: 35879  total_loss: 0.1897  loss_cls: 0.02563  loss_box_reg: 0.08076  loss_mask: 0.07243  loss_rpn_cls: 0.001556  loss_rpn_loc: 0.01688  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:38] d2.utils.events INFO:  eta: 1:19:21  iter: 35899  total_loss: 0.1754  loss_cls: 0.02739  loss_box_reg: 0.06971  loss_mask: 0.06482  loss_rpn_cls: 0.0003856  loss_rpn_loc: 0.009524  time: 0.0883  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:30:39] d2.utils.events INFO:  eta: 1:19:15  iter: 35919  total_loss: 0.1759  loss_cls: 0.02391  loss_box_reg: 0.07712  loss_mask: 0.06357  loss_rpn_cls: 0.0004743  loss_rpn_loc: 0.01195  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:41] d2.utils.events INFO:  eta: 1:19:08  iter: 35939  total_loss: 0.2563  loss_cls: 0.03944  loss_box_reg: 0.1112  loss_mask: 0.08111  loss_rpn_cls: 0.001022  loss_rpn_loc: 0.01242  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:43] d2.utils.events INFO:  eta: 1:19:03  iter: 35959  total_loss: 0.1507  loss_cls: 0.01465  loss_box_reg: 0.06088  loss_mask: 0.06221  loss_rpn_cls: 0.0004629  loss_rpn_loc: 0.006576  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:45] d2.utils.events INFO:  eta: 1:19:10  iter: 35979  total_loss: 0.2482  loss_cls: 0.03834  loss_box_reg: 0.112  loss_mask: 0.07848  loss_rpn_cls: 0.0006742  loss_rpn_loc: 0.01452  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:46] d2.utils.events INFO:  eta: 1:19:07  iter: 35999  total_loss: 0.2587  loss_cls: 0.04697  loss_box_reg: 0.1247  loss_mask: 0.07914  loss_rpn_cls: 0.0007413  loss_rpn_loc: 0.01733  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:48] d2.utils.events INFO:  eta: 1:19:05  iter: 36019  total_loss: 0.2476  loss_cls: 0.03663  loss_box_reg: 0.09645  loss_mask: 0.07179  loss_rpn_cls: 0.0007559  loss_rpn_loc: 0.02157  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:50] d2.utils.events INFO:  eta: 1:19:05  iter: 36039  total_loss: 0.1618  loss_cls: 0.03055  loss_box_reg: 0.0765  loss_mask: 0.0577  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.01187  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:52] d2.utils.events INFO:  eta: 1:18:57  iter: 36059  total_loss: 0.1805  loss_cls: 0.03181  loss_box_reg: 0.08815  loss_mask: 0.06969  loss_rpn_cls: 0.0003315  loss_rpn_loc: 0.01042  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:30:53] d2.utils.events INFO:  eta: 1:18:49  iter: 36079  total_loss: 0.2691  loss_cls: 0.04093  loss_box_reg: 0.1204  loss_mask: 0.08083  loss_rpn_cls: 0.0009197  loss_rpn_loc: 0.01733  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:55] d2.utils.events INFO:  eta: 1:18:56  iter: 36099  total_loss: 0.2353  loss_cls: 0.03648  loss_box_reg: 0.1054  loss_mask: 0.06211  loss_rpn_cls: 0.001061  loss_rpn_loc: 0.02251  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:57] d2.utils.events INFO:  eta: 1:18:54  iter: 36119  total_loss: 0.2052  loss_cls: 0.02583  loss_box_reg: 0.09756  loss_mask: 0.0735  loss_rpn_cls: 0.001209  loss_rpn_loc: 0.01171  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:30:59] d2.utils.events INFO:  eta: 1:18:50  iter: 36139  total_loss: 0.1968  loss_cls: 0.02424  loss_box_reg: 0.07584  loss_mask: 0.0676  loss_rpn_cls: 0.0007125  loss_rpn_loc: 0.008038  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:00] d2.utils.events INFO:  eta: 1:18:47  iter: 36159  total_loss: 0.2433  loss_cls: 0.03231  loss_box_reg: 0.09825  loss_mask: 0.06936  loss_rpn_cls: 0.00141  loss_rpn_loc: 0.01656  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:02] d2.utils.events INFO:  eta: 1:18:45  iter: 36179  total_loss: 0.2241  loss_cls: 0.0262  loss_box_reg: 0.09518  loss_mask: 0.07107  loss_rpn_cls: 0.0005933  loss_rpn_loc: 0.01521  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:04] d2.utils.events INFO:  eta: 1:18:45  iter: 36199  total_loss: 0.2379  loss_cls: 0.03226  loss_box_reg: 0.0926  loss_mask: 0.05847  loss_rpn_cls: 0.0005707  loss_rpn_loc: 0.01098  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:06] d2.utils.events INFO:  eta: 1:18:43  iter: 36219  total_loss: 0.1628  loss_cls: 0.02878  loss_box_reg: 0.06669  loss_mask: 0.06313  loss_rpn_cls: 0.0006345  loss_rpn_loc: 0.01394  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:08] d2.utils.events INFO:  eta: 1:18:40  iter: 36239  total_loss: 0.2472  loss_cls: 0.03586  loss_box_reg: 0.09389  loss_mask: 0.06458  loss_rpn_cls: 0.0005353  loss_rpn_loc: 0.01494  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:09] d2.utils.events INFO:  eta: 1:18:34  iter: 36259  total_loss: 0.1576  loss_cls: 0.02618  loss_box_reg: 0.07121  loss_mask: 0.06426  loss_rpn_cls: 0.0002392  loss_rpn_loc: 0.005938  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:11] d2.utils.events INFO:  eta: 1:18:36  iter: 36279  total_loss: 0.3135  loss_cls: 0.04857  loss_box_reg: 0.1282  loss_mask: 0.09381  loss_rpn_cls: 0.001425  loss_rpn_loc: 0.02242  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:13] d2.utils.events INFO:  eta: 1:18:42  iter: 36299  total_loss: 0.2986  loss_cls: 0.04324  loss_box_reg: 0.1205  loss_mask: 0.1006  loss_rpn_cls: 0.001413  loss_rpn_loc: 0.02348  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:15] d2.utils.events INFO:  eta: 1:18:40  iter: 36319  total_loss: 0.1793  loss_cls: 0.03066  loss_box_reg: 0.08484  loss_mask: 0.07019  loss_rpn_cls: 0.0007006  loss_rpn_loc: 0.01482  time: 0.0883  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:31:16] d2.utils.events INFO:  eta: 1:18:37  iter: 36339  total_loss: 0.1464  loss_cls: 0.02695  loss_box_reg: 0.07197  loss_mask: 0.0558  loss_rpn_cls: 0.0004376  loss_rpn_loc: 0.005712  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:18] d2.utils.events INFO:  eta: 1:18:37  iter: 36359  total_loss: 0.2384  loss_cls: 0.03244  loss_box_reg: 0.09668  loss_mask: 0.08054  loss_rpn_cls: 0.001286  loss_rpn_loc: 0.01042  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:20] d2.utils.events INFO:  eta: 1:18:35  iter: 36379  total_loss: 0.2157  loss_cls: 0.03063  loss_box_reg: 0.0968  loss_mask: 0.07533  loss_rpn_cls: 0.0007328  loss_rpn_loc: 0.01336  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:22] d2.utils.events INFO:  eta: 1:18:38  iter: 36399  total_loss: 0.1978  loss_cls: 0.02074  loss_box_reg: 0.06959  loss_mask: 0.07045  loss_rpn_cls: 0.0008952  loss_rpn_loc: 0.01308  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:23] d2.utils.events INFO:  eta: 1:18:35  iter: 36419  total_loss: 0.2121  loss_cls: 0.02981  loss_box_reg: 0.08841  loss_mask: 0.08305  loss_rpn_cls: 0.0009972  loss_rpn_loc: 0.009002  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:25] d2.utils.events INFO:  eta: 1:18:30  iter: 36439  total_loss: 0.1524  loss_cls: 0.02411  loss_box_reg: 0.06092  loss_mask: 0.0621  loss_rpn_cls: 0.0005723  loss_rpn_loc: 0.008464  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:27] d2.utils.events INFO:  eta: 1:18:27  iter: 36459  total_loss: 0.2156  loss_cls: 0.03058  loss_box_reg: 0.1077  loss_mask: 0.06537  loss_rpn_cls: 0.0007709  loss_rpn_loc: 0.009343  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:29] d2.utils.events INFO:  eta: 1:18:17  iter: 36479  total_loss: 0.171  loss_cls: 0.03484  loss_box_reg: 0.07184  loss_mask: 0.05314  loss_rpn_cls: 0.0003907  loss_rpn_loc: 0.01045  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:30] d2.utils.events INFO:  eta: 1:18:13  iter: 36499  total_loss: 0.1595  loss_cls: 0.02893  loss_box_reg: 0.07431  loss_mask: 0.05644  loss_rpn_cls: 0.0004093  loss_rpn_loc: 0.008329  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:32] d2.utils.events INFO:  eta: 1:18:20  iter: 36519  total_loss: 0.2457  loss_cls: 0.04046  loss_box_reg: 0.1174  loss_mask: 0.07579  loss_rpn_cls: 0.0004388  loss_rpn_loc: 0.009556  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:34] d2.utils.events INFO:  eta: 1:18:22  iter: 36539  total_loss: 0.1897  loss_cls: 0.02793  loss_box_reg: 0.08122  loss_mask: 0.07162  loss_rpn_cls: 0.001561  loss_rpn_loc: 0.01297  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:36] d2.utils.events INFO:  eta: 1:18:24  iter: 36559  total_loss: 0.2105  loss_cls: 0.04251  loss_box_reg: 0.1005  loss_mask: 0.06073  loss_rpn_cls: 0.0005967  loss_rpn_loc: 0.01147  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:37] d2.utils.events INFO:  eta: 1:18:19  iter: 36579  total_loss: 0.2378  loss_cls: 0.02323  loss_box_reg: 0.09386  loss_mask: 0.07547  loss_rpn_cls: 0.001889  loss_rpn_loc: 0.01131  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:39] d2.utils.events INFO:  eta: 1:18:17  iter: 36599  total_loss: 0.1953  loss_cls: 0.02527  loss_box_reg: 0.0811  loss_mask: 0.06853  loss_rpn_cls: 0.0009729  loss_rpn_loc: 0.00757  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:41] d2.utils.events INFO:  eta: 1:18:13  iter: 36619  total_loss: 0.1471  loss_cls: 0.01829  loss_box_reg: 0.05411  loss_mask: 0.06266  loss_rpn_cls: 0.000846  loss_rpn_loc: 0.01632  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:43] d2.utils.events INFO:  eta: 1:18:15  iter: 36639  total_loss: 0.3083  loss_cls: 0.04481  loss_box_reg: 0.1321  loss_mask: 0.1068  loss_rpn_cls: 0.001888  loss_rpn_loc: 0.03297  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:45] d2.utils.events INFO:  eta: 1:18:12  iter: 36659  total_loss: 0.1656  loss_cls: 0.02776  loss_box_reg: 0.07429  loss_mask: 0.07066  loss_rpn_cls: 0.001013  loss_rpn_loc: 0.01195  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:46] d2.utils.events INFO:  eta: 1:18:01  iter: 36679  total_loss: 0.2053  loss_cls: 0.02494  loss_box_reg: 0.08284  loss_mask: 0.0765  loss_rpn_cls: 0.001017  loss_rpn_loc: 0.01556  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:48] d2.utils.events INFO:  eta: 1:18:06  iter: 36699  total_loss: 0.2655  loss_cls: 0.03302  loss_box_reg: 0.1152  loss_mask: 0.09179  loss_rpn_cls: 0.0008247  loss_rpn_loc: 0.02036  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:50] d2.utils.events INFO:  eta: 1:18:06  iter: 36719  total_loss: 0.1937  loss_cls: 0.03794  loss_box_reg: 0.07172  loss_mask: 0.07511  loss_rpn_cls: 0.0006987  loss_rpn_loc: 0.01719  time: 0.0883  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:52] d2.utils.events INFO:  eta: 1:18:10  iter: 36739  total_loss: 0.2145  loss_cls: 0.0289  loss_box_reg: 0.07947  loss_mask: 0.06529  loss_rpn_cls: 0.0008089  loss_rpn_loc: 0.01429  time: 0.0883  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:31:53] d2.utils.events INFO:  eta: 1:18:06  iter: 36759  total_loss: 0.1677  loss_cls: 0.02349  loss_box_reg: 0.06894  loss_mask: 0.07313  loss_rpn_cls: 0.0005059  loss_rpn_loc: 0.01129  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:55] d2.utils.events INFO:  eta: 1:18:15  iter: 36779  total_loss: 0.2576  loss_cls: 0.04249  loss_box_reg: 0.1136  loss_mask: 0.08132  loss_rpn_cls: 0.001376  loss_rpn_loc: 0.0205  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:57] d2.utils.events INFO:  eta: 1:18:10  iter: 36799  total_loss: 0.1602  loss_cls: 0.03125  loss_box_reg: 0.06677  loss_mask: 0.05919  loss_rpn_cls: 0.0005781  loss_rpn_loc: 0.01093  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:31:59] d2.utils.events INFO:  eta: 1:18:08  iter: 36819  total_loss: 0.1829  loss_cls: 0.02902  loss_box_reg: 0.08961  loss_mask: 0.07115  loss_rpn_cls: 0.0004854  loss_rpn_loc: 0.01034  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:32:00] d2.utils.events INFO:  eta: 1:18:09  iter: 36839  total_loss: 0.2012  loss_cls: 0.02911  loss_box_reg: 0.09329  loss_mask: 0.08  loss_rpn_cls: 0.001887  loss_rpn_loc: 0.02045  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:02] d2.utils.events INFO:  eta: 1:17:57  iter: 36859  total_loss: 0.1788  loss_cls: 0.01872  loss_box_reg: 0.09093  loss_mask: 0.06887  loss_rpn_cls: 0.0007111  loss_rpn_loc: 0.01599  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:04] d2.utils.events INFO:  eta: 1:18:04  iter: 36879  total_loss: 0.2516  loss_cls: 0.03553  loss_box_reg: 0.1195  loss_mask: 0.06527  loss_rpn_cls: 0.000828  loss_rpn_loc: 0.02372  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:06] d2.utils.events INFO:  eta: 1:18:10  iter: 36899  total_loss: 0.2792  loss_cls: 0.04848  loss_box_reg: 0.1277  loss_mask: 0.08431  loss_rpn_cls: 0.001294  loss_rpn_loc: 0.01174  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:08] d2.utils.events INFO:  eta: 1:18:09  iter: 36919  total_loss: 0.1797  loss_cls: 0.022  loss_box_reg: 0.0803  loss_mask: 0.05479  loss_rpn_cls: 0.0008028  loss_rpn_loc: 0.01225  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:32:09] d2.utils.events INFO:  eta: 1:18:08  iter: 36939  total_loss: 0.1843  loss_cls: 0.02983  loss_box_reg: 0.08491  loss_mask: 0.06482  loss_rpn_cls: 0.0005639  loss_rpn_loc: 0.0119  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:11] d2.utils.events INFO:  eta: 1:18:07  iter: 36959  total_loss: 0.2043  loss_cls: 0.02599  loss_box_reg: 0.07608  loss_mask: 0.07852  loss_rpn_cls: 0.0007056  loss_rpn_loc: 0.01262  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:32:13] d2.utils.events INFO:  eta: 1:18:04  iter: 36979  total_loss: 0.2169  loss_cls: 0.03021  loss_box_reg: 0.09555  loss_mask: 0.07669  loss_rpn_cls: 0.0007281  loss_rpn_loc: 0.0138  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:14] d2.utils.events INFO:  eta: 1:17:56  iter: 36999  total_loss: 0.1426  loss_cls: 0.01889  loss_box_reg: 0.05589  loss_mask: 0.06566  loss_rpn_cls: 0.0003137  loss_rpn_loc: 0.006245  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:16] d2.utils.events INFO:  eta: 1:18:00  iter: 37019  total_loss: 0.2639  loss_cls: 0.03983  loss_box_reg: 0.1127  loss_mask: 0.07403  loss_rpn_cls: 0.0007849  loss_rpn_loc: 0.01159  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:18] d2.utils.events INFO:  eta: 1:18:01  iter: 37039  total_loss: 0.296  loss_cls: 0.04028  loss_box_reg: 0.1284  loss_mask: 0.07836  loss_rpn_cls: 0.001323  loss_rpn_loc: 0.02265  time: 0.0882  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:32:20] d2.utils.events INFO:  eta: 1:18:06  iter: 37059  total_loss: 0.2177  loss_cls: 0.03323  loss_box_reg: 0.09919  loss_mask: 0.08026  loss_rpn_cls: 0.0006173  loss_rpn_loc: 0.01392  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:22] d2.utils.events INFO:  eta: 1:18:01  iter: 37079  total_loss: 0.1773  loss_cls: 0.02625  loss_box_reg: 0.07804  loss_mask: 0.07005  loss_rpn_cls: 0.0008702  loss_rpn_loc: 0.01649  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:23] d2.utils.events INFO:  eta: 1:17:53  iter: 37099  total_loss: 0.1943  loss_cls: 0.019  loss_box_reg: 0.07492  loss_mask: 0.06784  loss_rpn_cls: 0.0008765  loss_rpn_loc: 0.01092  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:25] d2.utils.events INFO:  eta: 1:17:45  iter: 37119  total_loss: 0.1673  loss_cls: 0.02469  loss_box_reg: 0.07924  loss_mask: 0.06105  loss_rpn_cls: 0.0004744  loss_rpn_loc: 0.007238  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:27] d2.utils.events INFO:  eta: 1:17:48  iter: 37139  total_loss: 0.2402  loss_cls: 0.04185  loss_box_reg: 0.1071  loss_mask: 0.07978  loss_rpn_cls: 0.001129  loss_rpn_loc: 0.01825  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:28] d2.utils.events INFO:  eta: 1:17:42  iter: 37159  total_loss: 0.1694  loss_cls: 0.02406  loss_box_reg: 0.06855  loss_mask: 0.06597  loss_rpn_cls: 0.0003996  loss_rpn_loc: 0.006535  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:30] d2.utils.events INFO:  eta: 1:17:46  iter: 37179  total_loss: 0.1789  loss_cls: 0.03329  loss_box_reg: 0.08032  loss_mask: 0.07247  loss_rpn_cls: 0.0004617  loss_rpn_loc: 0.01158  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:32] d2.utils.events INFO:  eta: 1:17:39  iter: 37199  total_loss: 0.2332  loss_cls: 0.03918  loss_box_reg: 0.09479  loss_mask: 0.07216  loss_rpn_cls: 0.001149  loss_rpn_loc: 0.01557  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:34] d2.utils.events INFO:  eta: 1:17:48  iter: 37219  total_loss: 0.2142  loss_cls: 0.0372  loss_box_reg: 0.114  loss_mask: 0.07751  loss_rpn_cls: 0.000794  loss_rpn_loc: 0.01341  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:32:36] d2.utils.events INFO:  eta: 1:17:46  iter: 37239  total_loss: 0.2558  loss_cls: 0.04272  loss_box_reg: 0.11  loss_mask: 0.07835  loss_rpn_cls: 0.001291  loss_rpn_loc: 0.01648  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:37] d2.utils.events INFO:  eta: 1:17:49  iter: 37259  total_loss: 0.2069  loss_cls: 0.02868  loss_box_reg: 0.08327  loss_mask: 0.06448  loss_rpn_cls: 0.0009111  loss_rpn_loc: 0.01193  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:39] d2.utils.events INFO:  eta: 1:17:45  iter: 37279  total_loss: 0.256  loss_cls: 0.03692  loss_box_reg: 0.1234  loss_mask: 0.07105  loss_rpn_cls: 0.0007799  loss_rpn_loc: 0.01752  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:41] d2.utils.events INFO:  eta: 1:17:38  iter: 37299  total_loss: 0.1901  loss_cls: 0.02873  loss_box_reg: 0.0774  loss_mask: 0.06392  loss_rpn_cls: 0.0007114  loss_rpn_loc: 0.008236  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:43] d2.utils.events INFO:  eta: 1:17:38  iter: 37319  total_loss: 0.2004  loss_cls: 0.03419  loss_box_reg: 0.08384  loss_mask: 0.07685  loss_rpn_cls: 0.0004852  loss_rpn_loc: 0.01055  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:44] d2.utils.events INFO:  eta: 1:17:37  iter: 37339  total_loss: 0.2099  loss_cls: 0.03244  loss_box_reg: 0.09205  loss_mask: 0.05633  loss_rpn_cls: 0.0008167  loss_rpn_loc: 0.01411  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:32:46] d2.utils.events INFO:  eta: 1:17:38  iter: 37359  total_loss: 0.2712  loss_cls: 0.04961  loss_box_reg: 0.1265  loss_mask: 0.06906  loss_rpn_cls: 0.001357  loss_rpn_loc: 0.02624  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:48] d2.utils.events INFO:  eta: 1:17:36  iter: 37379  total_loss: 0.2122  loss_cls: 0.02394  loss_box_reg: 0.08919  loss_mask: 0.07711  loss_rpn_cls: 0.001172  loss_rpn_loc: 0.01611  time: 0.0882  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:32:50] d2.utils.events INFO:  eta: 1:17:35  iter: 37399  total_loss: 0.1815  loss_cls: 0.02802  loss_box_reg: 0.05947  loss_mask: 0.07185  loss_rpn_cls: 0.0004662  loss_rpn_loc: 0.007995  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:52] d2.utils.events INFO:  eta: 1:17:33  iter: 37419  total_loss: 0.1991  loss_cls: 0.0397  loss_box_reg: 0.09171  loss_mask: 0.06516  loss_rpn_cls: 0.0007896  loss_rpn_loc: 0.01027  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:53] d2.utils.events INFO:  eta: 1:17:38  iter: 37439  total_loss: 0.1829  loss_cls: 0.03765  loss_box_reg: 0.07944  loss_mask: 0.0637  loss_rpn_cls: 0.0007712  loss_rpn_loc: 0.01313  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:55] d2.utils.events INFO:  eta: 1:17:41  iter: 37459  total_loss: 0.2148  loss_cls: 0.03881  loss_box_reg: 0.1007  loss_mask: 0.07364  loss_rpn_cls: 0.0007487  loss_rpn_loc: 0.01116  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:57] d2.utils.events INFO:  eta: 1:17:43  iter: 37479  total_loss: 0.2409  loss_cls: 0.03558  loss_box_reg: 0.1081  loss_mask: 0.07248  loss_rpn_cls: 0.000777  loss_rpn_loc: 0.01119  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:32:59] d2.utils.events INFO:  eta: 1:17:43  iter: 37499  total_loss: 0.2101  loss_cls: 0.03447  loss_box_reg: 0.09331  loss_mask: 0.06805  loss_rpn_cls: 0.0007594  loss_rpn_loc: 0.01181  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:00] d2.utils.events INFO:  eta: 1:17:30  iter: 37519  total_loss: 0.1688  loss_cls: 0.02583  loss_box_reg: 0.07228  loss_mask: 0.0597  loss_rpn_cls: 0.0007506  loss_rpn_loc: 0.0131  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:02] d2.utils.events INFO:  eta: 1:17:33  iter: 37539  total_loss: 0.2572  loss_cls: 0.04838  loss_box_reg: 0.1274  loss_mask: 0.07471  loss_rpn_cls: 0.001033  loss_rpn_loc: 0.02626  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:04] d2.utils.events INFO:  eta: 1:17:20  iter: 37559  total_loss: 0.1829  loss_cls: 0.02345  loss_box_reg: 0.07183  loss_mask: 0.07205  loss_rpn_cls: 0.0008833  loss_rpn_loc: 0.01249  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:06] d2.utils.events INFO:  eta: 1:17:15  iter: 37579  total_loss: 0.177  loss_cls: 0.02499  loss_box_reg: 0.06762  loss_mask: 0.06866  loss_rpn_cls: 0.0003344  loss_rpn_loc: 0.01131  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:07] d2.utils.events INFO:  eta: 1:17:17  iter: 37599  total_loss: 0.2721  loss_cls: 0.04282  loss_box_reg: 0.1047  loss_mask: 0.09014  loss_rpn_cls: 0.001225  loss_rpn_loc: 0.02847  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:09] d2.utils.events INFO:  eta: 1:17:25  iter: 37619  total_loss: 0.1677  loss_cls: 0.03054  loss_box_reg: 0.06965  loss_mask: 0.06035  loss_rpn_cls: 0.0003896  loss_rpn_loc: 0.00938  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:11] d2.utils.events INFO:  eta: 1:17:09  iter: 37639  total_loss: 0.1763  loss_cls: 0.03191  loss_box_reg: 0.07131  loss_mask: 0.06624  loss_rpn_cls: 0.0005747  loss_rpn_loc: 0.01132  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:13] d2.utils.events INFO:  eta: 1:17:08  iter: 37659  total_loss: 0.1982  loss_cls: 0.03687  loss_box_reg: 0.08286  loss_mask: 0.06964  loss_rpn_cls: 0.0009093  loss_rpn_loc: 0.01507  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:14] d2.utils.events INFO:  eta: 1:17:11  iter: 37679  total_loss: 0.2462  loss_cls: 0.03831  loss_box_reg: 0.1084  loss_mask: 0.07532  loss_rpn_cls: 0.0009982  loss_rpn_loc: 0.02045  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:16] d2.utils.events INFO:  eta: 1:17:18  iter: 37699  total_loss: 0.297  loss_cls: 0.03989  loss_box_reg: 0.1382  loss_mask: 0.08896  loss_rpn_cls: 0.0009185  loss_rpn_loc: 0.01713  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:18] d2.utils.events INFO:  eta: 1:17:07  iter: 37719  total_loss: 0.1662  loss_cls: 0.02711  loss_box_reg: 0.0708  loss_mask: 0.06554  loss_rpn_cls: 0.0004123  loss_rpn_loc: 0.006413  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:20] d2.utils.events INFO:  eta: 1:17:02  iter: 37739  total_loss: 0.1941  loss_cls: 0.02303  loss_box_reg: 0.08662  loss_mask: 0.06075  loss_rpn_cls: 0.0004931  loss_rpn_loc: 0.01162  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:21] d2.utils.events INFO:  eta: 1:17:00  iter: 37759  total_loss: 0.1701  loss_cls: 0.0306  loss_box_reg: 0.0779  loss_mask: 0.04818  loss_rpn_cls: 0.0005845  loss_rpn_loc: 0.01259  time: 0.0882  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:33:23] d2.utils.events INFO:  eta: 1:16:53  iter: 37779  total_loss: 0.1896  loss_cls: 0.02007  loss_box_reg: 0.06491  loss_mask: 0.05982  loss_rpn_cls: 0.0006301  loss_rpn_loc: 0.0129  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:25] d2.utils.events INFO:  eta: 1:16:57  iter: 37799  total_loss: 0.2152  loss_cls: 0.03321  loss_box_reg: 0.103  loss_mask: 0.0682  loss_rpn_cls: 0.001299  loss_rpn_loc: 0.009368  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:27] d2.utils.events INFO:  eta: 1:16:55  iter: 37819  total_loss: 0.1918  loss_cls: 0.02788  loss_box_reg: 0.08197  loss_mask: 0.07976  loss_rpn_cls: 0.0002233  loss_rpn_loc: 0.007031  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:28] d2.utils.events INFO:  eta: 1:16:34  iter: 37839  total_loss: 0.1698  loss_cls: 0.02453  loss_box_reg: 0.06005  loss_mask: 0.07731  loss_rpn_cls: 0.000607  loss_rpn_loc: 0.00854  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:30] d2.utils.events INFO:  eta: 1:16:48  iter: 37859  total_loss: 0.2641  loss_cls: 0.03255  loss_box_reg: 0.1138  loss_mask: 0.09016  loss_rpn_cls: 0.0008979  loss_rpn_loc: 0.01627  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:32] d2.utils.events INFO:  eta: 1:16:26  iter: 37879  total_loss: 0.2298  loss_cls: 0.03618  loss_box_reg: 0.09994  loss_mask: 0.0753  loss_rpn_cls: 0.001121  loss_rpn_loc: 0.02017  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:34] d2.utils.events INFO:  eta: 1:16:13  iter: 37899  total_loss: 0.2156  loss_cls: 0.03239  loss_box_reg: 0.07908  loss_mask: 0.07383  loss_rpn_cls: 0.0007454  loss_rpn_loc: 0.01508  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:35] d2.utils.events INFO:  eta: 1:16:29  iter: 37919  total_loss: 0.1591  loss_cls: 0.03439  loss_box_reg: 0.06791  loss_mask: 0.05649  loss_rpn_cls: 0.0005471  loss_rpn_loc: 0.0112  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:37] d2.utils.events INFO:  eta: 1:16:21  iter: 37939  total_loss: 0.1759  loss_cls: 0.02703  loss_box_reg: 0.07035  loss_mask: 0.0646  loss_rpn_cls: 0.0006389  loss_rpn_loc: 0.01385  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:39] d2.utils.events INFO:  eta: 1:16:25  iter: 37959  total_loss: 0.1933  loss_cls: 0.0243  loss_box_reg: 0.07125  loss_mask: 0.06538  loss_rpn_cls: 0.0009054  loss_rpn_loc: 0.01389  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:41] d2.utils.events INFO:  eta: 1:16:30  iter: 37979  total_loss: 0.237  loss_cls: 0.02903  loss_box_reg: 0.101  loss_mask: 0.07513  loss_rpn_cls: 0.0009368  loss_rpn_loc: 0.02075  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:42] d2.utils.events INFO:  eta: 1:16:42  iter: 37999  total_loss: 0.2212  loss_cls: 0.0357  loss_box_reg: 0.1008  loss_mask: 0.07594  loss_rpn_cls: 0.0008624  loss_rpn_loc: 0.01232  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:44] d2.utils.events INFO:  eta: 1:16:33  iter: 38019  total_loss: 0.1712  loss_cls: 0.02914  loss_box_reg: 0.07321  loss_mask: 0.06261  loss_rpn_cls: 0.0003996  loss_rpn_loc: 0.01035  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:46] d2.utils.events INFO:  eta: 1:16:21  iter: 38039  total_loss: 0.3243  loss_cls: 0.03292  loss_box_reg: 0.106  loss_mask: 0.08937  loss_rpn_cls: 0.001104  loss_rpn_loc: 0.02095  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:48] d2.utils.events INFO:  eta: 1:16:05  iter: 38059  total_loss: 0.2038  loss_cls: 0.02896  loss_box_reg: 0.09527  loss_mask: 0.06923  loss_rpn_cls: 0.0007791  loss_rpn_loc: 0.01183  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:49] d2.utils.events INFO:  eta: 1:16:28  iter: 38079  total_loss: 0.2887  loss_cls: 0.05431  loss_box_reg: 0.1337  loss_mask: 0.08445  loss_rpn_cls: 0.000864  loss_rpn_loc: 0.018  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:51] d2.utils.events INFO:  eta: 1:16:43  iter: 38099  total_loss: 0.3  loss_cls: 0.04754  loss_box_reg: 0.1205  loss_mask: 0.07844  loss_rpn_cls: 0.0009351  loss_rpn_loc: 0.02166  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:53] d2.utils.events INFO:  eta: 1:16:41  iter: 38119  total_loss: 0.1622  loss_cls: 0.01584  loss_box_reg: 0.06076  loss_mask: 0.06699  loss_rpn_cls: 0.0004956  loss_rpn_loc: 0.007345  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:33:55] d2.utils.events INFO:  eta: 1:16:25  iter: 38139  total_loss: 0.1726  loss_cls: 0.02487  loss_box_reg: 0.06724  loss_mask: 0.06959  loss_rpn_cls: 0.0004292  loss_rpn_loc: 0.009476  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:56] d2.utils.events INFO:  eta: 1:16:29  iter: 38159  total_loss: 0.2431  loss_cls: 0.04059  loss_box_reg: 0.1149  loss_mask: 0.06484  loss_rpn_cls: 0.0008564  loss_rpn_loc: 0.01436  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:33:58] d2.utils.events INFO:  eta: 1:16:19  iter: 38179  total_loss: 0.1962  loss_cls: 0.02966  loss_box_reg: 0.07772  loss_mask: 0.06109  loss_rpn_cls: 0.0009497  loss_rpn_loc: 0.01522  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:00] d2.utils.events INFO:  eta: 1:16:12  iter: 38199  total_loss: 0.1828  loss_cls: 0.03016  loss_box_reg: 0.07814  loss_mask: 0.07264  loss_rpn_cls: 0.0004424  loss_rpn_loc: 0.009015  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:02] d2.utils.events INFO:  eta: 1:16:08  iter: 38219  total_loss: 0.2269  loss_cls: 0.03613  loss_box_reg: 0.09357  loss_mask: 0.07769  loss_rpn_cls: 0.0008478  loss_rpn_loc: 0.008505  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:03] d2.utils.events INFO:  eta: 1:15:49  iter: 38239  total_loss: 0.1594  loss_cls: 0.02314  loss_box_reg: 0.06713  loss_mask: 0.06897  loss_rpn_cls: 0.0004263  loss_rpn_loc: 0.008097  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:05] d2.utils.events INFO:  eta: 1:15:43  iter: 38259  total_loss: 0.1481  loss_cls: 0.02351  loss_box_reg: 0.06305  loss_mask: 0.05217  loss_rpn_cls: 0.0003068  loss_rpn_loc: 0.008936  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:07] d2.utils.events INFO:  eta: 1:15:37  iter: 38279  total_loss: 0.1595  loss_cls: 0.02408  loss_box_reg: 0.06631  loss_mask: 0.05731  loss_rpn_cls: 0.0003505  loss_rpn_loc: 0.005148  time: 0.0882  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:09] d2.utils.events INFO:  eta: 1:15:36  iter: 38299  total_loss: 0.2266  loss_cls: 0.03732  loss_box_reg: 0.08551  loss_mask: 0.07654  loss_rpn_cls: 0.0004188  loss_rpn_loc: 0.01824  time: 0.0882  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:10] d2.utils.events INFO:  eta: 1:15:32  iter: 38319  total_loss: 0.2373  loss_cls: 0.02968  loss_box_reg: 0.07155  loss_mask: 0.07571  loss_rpn_cls: 0.001181  loss_rpn_loc: 0.01257  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:12] d2.utils.events INFO:  eta: 1:15:27  iter: 38339  total_loss: 0.1669  loss_cls: 0.02118  loss_box_reg: 0.06282  loss_mask: 0.06528  loss_rpn_cls: 0.0006237  loss_rpn_loc: 0.01314  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:14] d2.utils.events INFO:  eta: 1:15:20  iter: 38359  total_loss: 0.2247  loss_cls: 0.03303  loss_box_reg: 0.08298  loss_mask: 0.06017  loss_rpn_cls: 0.0006522  loss_rpn_loc: 0.01518  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:16] d2.utils.events INFO:  eta: 1:15:26  iter: 38379  total_loss: 0.2772  loss_cls: 0.03573  loss_box_reg: 0.1261  loss_mask: 0.07532  loss_rpn_cls: 0.0008915  loss_rpn_loc: 0.01828  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:17] d2.utils.events INFO:  eta: 1:15:29  iter: 38399  total_loss: 0.232  loss_cls: 0.03814  loss_box_reg: 0.1106  loss_mask: 0.07152  loss_rpn_cls: 0.00062  loss_rpn_loc: 0.01494  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:19] d2.utils.events INFO:  eta: 1:15:23  iter: 38419  total_loss: 0.1694  loss_cls: 0.02779  loss_box_reg: 0.08074  loss_mask: 0.05833  loss_rpn_cls: 0.0004344  loss_rpn_loc: 0.008748  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:21] d2.utils.events INFO:  eta: 1:15:25  iter: 38439  total_loss: 0.3182  loss_cls: 0.04953  loss_box_reg: 0.1487  loss_mask: 0.08899  loss_rpn_cls: 0.001132  loss_rpn_loc: 0.02388  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:23] d2.utils.events INFO:  eta: 1:15:26  iter: 38459  total_loss: 0.2151  loss_cls: 0.02838  loss_box_reg: 0.09134  loss_mask: 0.06807  loss_rpn_cls: 0.0007759  loss_rpn_loc: 0.01728  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:25] d2.utils.events INFO:  eta: 1:15:28  iter: 38479  total_loss: 0.2293  loss_cls: 0.03141  loss_box_reg: 0.1014  loss_mask: 0.06646  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.01249  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:26] d2.utils.events INFO:  eta: 1:15:29  iter: 38499  total_loss: 0.2698  loss_cls: 0.04018  loss_box_reg: 0.1049  loss_mask: 0.09217  loss_rpn_cls: 0.001501  loss_rpn_loc: 0.01995  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:28] d2.utils.events INFO:  eta: 1:15:31  iter: 38519  total_loss: 0.196  loss_cls: 0.03513  loss_box_reg: 0.09154  loss_mask: 0.06649  loss_rpn_cls: 0.001393  loss_rpn_loc: 0.01884  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:30] d2.utils.events INFO:  eta: 1:15:26  iter: 38539  total_loss: 0.1796  loss_cls: 0.02714  loss_box_reg: 0.0781  loss_mask: 0.05523  loss_rpn_cls: 0.0006061  loss_rpn_loc: 0.01163  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:32] d2.utils.events INFO:  eta: 1:15:25  iter: 38559  total_loss: 0.2481  loss_cls: 0.03598  loss_box_reg: 0.1128  loss_mask: 0.0894  loss_rpn_cls: 0.0009814  loss_rpn_loc: 0.0163  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:33] d2.utils.events INFO:  eta: 1:15:33  iter: 38579  total_loss: 0.202  loss_cls: 0.02254  loss_box_reg: 0.08889  loss_mask: 0.07904  loss_rpn_cls: 0.0006682  loss_rpn_loc: 0.01743  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:35] d2.utils.events INFO:  eta: 1:15:33  iter: 38599  total_loss: 0.3026  loss_cls: 0.0386  loss_box_reg: 0.1261  loss_mask: 0.0668  loss_rpn_cls: 0.001548  loss_rpn_loc: 0.02595  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:37] d2.utils.events INFO:  eta: 1:15:33  iter: 38619  total_loss: 0.23  loss_cls: 0.03399  loss_box_reg: 0.09632  loss_mask: 0.08838  loss_rpn_cls: 0.0005399  loss_rpn_loc: 0.01131  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:39] d2.utils.events INFO:  eta: 1:15:31  iter: 38639  total_loss: 0.1891  loss_cls: 0.03573  loss_box_reg: 0.08833  loss_mask: 0.06478  loss_rpn_cls: 0.0008594  loss_rpn_loc: 0.0123  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:40] d2.utils.events INFO:  eta: 1:15:26  iter: 38659  total_loss: 0.1731  loss_cls: 0.02559  loss_box_reg: 0.05233  loss_mask: 0.0592  loss_rpn_cls: 0.0006792  loss_rpn_loc: 0.01398  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:42] d2.utils.events INFO:  eta: 1:15:27  iter: 38679  total_loss: 0.2326  loss_cls: 0.03966  loss_box_reg: 0.09007  loss_mask: 0.08089  loss_rpn_cls: 0.0007344  loss_rpn_loc: 0.01091  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:44] d2.utils.events INFO:  eta: 1:15:19  iter: 38699  total_loss: 0.1949  loss_cls: 0.02297  loss_box_reg: 0.09209  loss_mask: 0.06751  loss_rpn_cls: 0.0006355  loss_rpn_loc: 0.01681  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:46] d2.utils.events INFO:  eta: 1:15:14  iter: 38719  total_loss: 0.2045  loss_cls: 0.03647  loss_box_reg: 0.07949  loss_mask: 0.07003  loss_rpn_cls: 0.000411  loss_rpn_loc: 0.008972  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:47] d2.utils.events INFO:  eta: 1:15:15  iter: 38739  total_loss: 0.1912  loss_cls: 0.03065  loss_box_reg: 0.07058  loss_mask: 0.0644  loss_rpn_cls: 0.0006761  loss_rpn_loc: 0.00942  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:49] d2.utils.events INFO:  eta: 1:15:18  iter: 38759  total_loss: 0.2083  loss_cls: 0.02665  loss_box_reg: 0.07609  loss_mask: 0.06697  loss_rpn_cls: 0.001048  loss_rpn_loc: 0.01566  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:51] d2.utils.events INFO:  eta: 1:15:17  iter: 38779  total_loss: 0.2282  loss_cls: 0.03949  loss_box_reg: 0.09321  loss_mask: 0.06734  loss_rpn_cls: 0.0007957  loss_rpn_loc: 0.01389  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:53] d2.utils.events INFO:  eta: 1:15:15  iter: 38799  total_loss: 0.1729  loss_cls: 0.02187  loss_box_reg: 0.06312  loss_mask: 0.05333  loss_rpn_cls: 0.0006987  loss_rpn_loc: 0.01299  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:54] d2.utils.events INFO:  eta: 1:15:13  iter: 38819  total_loss: 0.1883  loss_cls: 0.02591  loss_box_reg: 0.0906  loss_mask: 0.06049  loss_rpn_cls: 0.0005968  loss_rpn_loc: 0.01096  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:34:56] d2.utils.events INFO:  eta: 1:15:13  iter: 38839  total_loss: 0.1746  loss_cls: 0.02062  loss_box_reg: 0.07713  loss_mask: 0.06481  loss_rpn_cls: 0.0005851  loss_rpn_loc: 0.01107  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:34:58] d2.utils.events INFO:  eta: 1:15:16  iter: 38859  total_loss: 0.271  loss_cls: 0.03555  loss_box_reg: 0.1139  loss_mask: 0.07401  loss_rpn_cls: 0.0009382  loss_rpn_loc: 0.01352  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:00] d2.utils.events INFO:  eta: 1:15:15  iter: 38879  total_loss: 0.1788  loss_cls: 0.03135  loss_box_reg: 0.07483  loss_mask: 0.06053  loss_rpn_cls: 0.0006794  loss_rpn_loc: 0.01785  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:01] d2.utils.events INFO:  eta: 1:15:13  iter: 38899  total_loss: 0.1325  loss_cls: 0.0198  loss_box_reg: 0.05419  loss_mask: 0.06058  loss_rpn_cls: 0.0003776  loss_rpn_loc: 0.007766  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:03] d2.utils.events INFO:  eta: 1:15:06  iter: 38919  total_loss: 0.1413  loss_cls: 0.02115  loss_box_reg: 0.06291  loss_mask: 0.05377  loss_rpn_cls: 0.0007076  loss_rpn_loc: 0.007637  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:05] d2.utils.events INFO:  eta: 1:15:05  iter: 38939  total_loss: 0.2386  loss_cls: 0.03737  loss_box_reg: 0.1148  loss_mask: 0.07272  loss_rpn_cls: 0.0004355  loss_rpn_loc: 0.01659  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:07] d2.utils.events INFO:  eta: 1:15:01  iter: 38959  total_loss: 0.1714  loss_cls: 0.02495  loss_box_reg: 0.0834  loss_mask: 0.05322  loss_rpn_cls: 0.0003363  loss_rpn_loc: 0.0126  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:08] d2.utils.events INFO:  eta: 1:15:00  iter: 38979  total_loss: 0.1968  loss_cls: 0.03819  loss_box_reg: 0.09229  loss_mask: 0.06068  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.02023  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:10] d2.utils.events INFO:  eta: 1:14:54  iter: 38999  total_loss: 0.1449  loss_cls: 0.02508  loss_box_reg: 0.05644  loss_mask: 0.0611  loss_rpn_cls: 0.0002607  loss_rpn_loc: 0.005045  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:12] d2.utils.events INFO:  eta: 1:14:56  iter: 39019  total_loss: 0.2423  loss_cls: 0.03775  loss_box_reg: 0.1004  loss_mask: 0.07091  loss_rpn_cls: 0.001275  loss_rpn_loc: 0.01899  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:14] d2.utils.events INFO:  eta: 1:14:51  iter: 39039  total_loss: 0.1606  loss_cls: 0.02005  loss_box_reg: 0.0677  loss_mask: 0.06703  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.008663  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:15] d2.utils.events INFO:  eta: 1:14:49  iter: 39059  total_loss: 0.2413  loss_cls: 0.03706  loss_box_reg: 0.08748  loss_mask: 0.08084  loss_rpn_cls: 0.0007517  loss_rpn_loc: 0.0126  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:17] d2.utils.events INFO:  eta: 1:14:39  iter: 39079  total_loss: 0.2409  loss_cls: 0.03291  loss_box_reg: 0.1087  loss_mask: 0.08489  loss_rpn_cls: 0.0007972  loss_rpn_loc: 0.02049  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:19] d2.utils.events INFO:  eta: 1:14:36  iter: 39099  total_loss: 0.2611  loss_cls: 0.03279  loss_box_reg: 0.1221  loss_mask: 0.07526  loss_rpn_cls: 0.0009173  loss_rpn_loc: 0.01658  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:21] d2.utils.events INFO:  eta: 1:14:36  iter: 39119  total_loss: 0.2037  loss_cls: 0.03285  loss_box_reg: 0.08258  loss_mask: 0.06387  loss_rpn_cls: 0.00092  loss_rpn_loc: 0.01818  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:22] d2.utils.events INFO:  eta: 1:14:35  iter: 39139  total_loss: 0.1867  loss_cls: 0.02578  loss_box_reg: 0.07513  loss_mask: 0.06371  loss_rpn_cls: 0.0005456  loss_rpn_loc: 0.01302  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:24] d2.utils.events INFO:  eta: 1:14:38  iter: 39159  total_loss: 0.3144  loss_cls: 0.04984  loss_box_reg: 0.1358  loss_mask: 0.07018  loss_rpn_cls: 0.001343  loss_rpn_loc: 0.02137  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:26] d2.utils.events INFO:  eta: 1:14:41  iter: 39179  total_loss: 0.2668  loss_cls: 0.04807  loss_box_reg: 0.122  loss_mask: 0.08332  loss_rpn_cls: 0.001162  loss_rpn_loc: 0.02182  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:28] d2.utils.events INFO:  eta: 1:14:40  iter: 39199  total_loss: 0.1889  loss_cls: 0.02534  loss_box_reg: 0.07985  loss_mask: 0.06133  loss_rpn_cls: 0.0004716  loss_rpn_loc: 0.008545  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:30] d2.utils.events INFO:  eta: 1:14:35  iter: 39219  total_loss: 0.2115  loss_cls: 0.02968  loss_box_reg: 0.09021  loss_mask: 0.06787  loss_rpn_cls: 0.0004419  loss_rpn_loc: 0.008158  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:31] d2.utils.events INFO:  eta: 1:14:36  iter: 39239  total_loss: 0.2188  loss_cls: 0.03292  loss_box_reg: 0.09424  loss_mask: 0.08583  loss_rpn_cls: 0.001052  loss_rpn_loc: 0.0121  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:33] d2.utils.events INFO:  eta: 1:14:33  iter: 39259  total_loss: 0.1311  loss_cls: 0.01476  loss_box_reg: 0.04852  loss_mask: 0.05198  loss_rpn_cls: 0.0005686  loss_rpn_loc: 0.007109  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:35] d2.utils.events INFO:  eta: 1:14:30  iter: 39279  total_loss: 0.2215  loss_cls: 0.02928  loss_box_reg: 0.07643  loss_mask: 0.0789  loss_rpn_cls: 0.001974  loss_rpn_loc: 0.02118  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:37] d2.utils.events INFO:  eta: 1:14:23  iter: 39299  total_loss: 0.2073  loss_cls: 0.02896  loss_box_reg: 0.09258  loss_mask: 0.05703  loss_rpn_cls: 0.0006997  loss_rpn_loc: 0.01068  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:38] d2.utils.events INFO:  eta: 1:14:22  iter: 39319  total_loss: 0.1901  loss_cls: 0.0338  loss_box_reg: 0.07836  loss_mask: 0.06507  loss_rpn_cls: 0.0003711  loss_rpn_loc: 0.0118  time: 0.0881  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:35:40] d2.utils.events INFO:  eta: 1:14:27  iter: 39339  total_loss: 0.2268  loss_cls: 0.03065  loss_box_reg: 0.1138  loss_mask: 0.07464  loss_rpn_cls: 0.0005925  loss_rpn_loc: 0.01321  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:42] d2.utils.events INFO:  eta: 1:14:26  iter: 39359  total_loss: 0.1773  loss_cls: 0.02857  loss_box_reg: 0.09708  loss_mask: 0.06514  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.01506  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:44] d2.utils.events INFO:  eta: 1:14:15  iter: 39379  total_loss: 0.1755  loss_cls: 0.02652  loss_box_reg: 0.0718  loss_mask: 0.06932  loss_rpn_cls: 0.0008933  loss_rpn_loc: 0.01247  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:45] d2.utils.events INFO:  eta: 1:14:09  iter: 39399  total_loss: 0.1809  loss_cls: 0.01883  loss_box_reg: 0.0761  loss_mask: 0.06126  loss_rpn_cls: 0.0007432  loss_rpn_loc: 0.0107  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:47] d2.utils.events INFO:  eta: 1:14:09  iter: 39419  total_loss: 0.1793  loss_cls: 0.02721  loss_box_reg: 0.07629  loss_mask: 0.07074  loss_rpn_cls: 0.001225  loss_rpn_loc: 0.01832  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:49] d2.utils.events INFO:  eta: 1:14:04  iter: 39439  total_loss: 0.1745  loss_cls: 0.03048  loss_box_reg: 0.07928  loss_mask: 0.06126  loss_rpn_cls: 0.0007398  loss_rpn_loc: 0.01249  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:51] d2.utils.events INFO:  eta: 1:14:01  iter: 39459  total_loss: 0.2671  loss_cls: 0.0331  loss_box_reg: 0.1111  loss_mask: 0.09048  loss_rpn_cls: 0.0006033  loss_rpn_loc: 0.02133  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:52] d2.utils.events INFO:  eta: 1:13:43  iter: 39479  total_loss: 0.161  loss_cls: 0.01738  loss_box_reg: 0.05917  loss_mask: 0.06292  loss_rpn_cls: 0.0003902  loss_rpn_loc: 0.008044  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:35:54] d2.utils.events INFO:  eta: 1:13:41  iter: 39499  total_loss: 0.212  loss_cls: 0.02731  loss_box_reg: 0.09743  loss_mask: 0.06816  loss_rpn_cls: 0.001029  loss_rpn_loc: 0.01347  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:56] d2.utils.events INFO:  eta: 1:13:41  iter: 39519  total_loss: 0.2375  loss_cls: 0.04891  loss_box_reg: 0.08938  loss_mask: 0.06728  loss_rpn_cls: 0.0008965  loss_rpn_loc: 0.02417  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:58] d2.utils.events INFO:  eta: 1:13:44  iter: 39539  total_loss: 0.2096  loss_cls: 0.03306  loss_box_reg: 0.09136  loss_mask: 0.06965  loss_rpn_cls: 0.0004657  loss_rpn_loc: 0.01419  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:35:59] d2.utils.events INFO:  eta: 1:13:42  iter: 39559  total_loss: 0.2357  loss_cls: 0.03531  loss_box_reg: 0.09454  loss_mask: 0.08168  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.01875  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:01] d2.utils.events INFO:  eta: 1:13:40  iter: 39579  total_loss: 0.1699  loss_cls: 0.02662  loss_box_reg: 0.07583  loss_mask: 0.06783  loss_rpn_cls: 0.0004443  loss_rpn_loc: 0.008796  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:03] d2.utils.events INFO:  eta: 1:13:27  iter: 39599  total_loss: 0.1655  loss_cls: 0.02773  loss_box_reg: 0.06831  loss_mask: 0.0696  loss_rpn_cls: 0.0003802  loss_rpn_loc: 0.01129  time: 0.0881  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:36:05] d2.utils.events INFO:  eta: 1:13:28  iter: 39619  total_loss: 0.2663  loss_cls: 0.04098  loss_box_reg: 0.1204  loss_mask: 0.0644  loss_rpn_cls: 0.001002  loss_rpn_loc: 0.01665  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:06] d2.utils.events INFO:  eta: 1:13:29  iter: 39639  total_loss: 0.2126  loss_cls: 0.03308  loss_box_reg: 0.0747  loss_mask: 0.07229  loss_rpn_cls: 0.0009445  loss_rpn_loc: 0.01195  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:08] d2.utils.events INFO:  eta: 1:13:37  iter: 39659  total_loss: 0.1656  loss_cls: 0.0257  loss_box_reg: 0.07437  loss_mask: 0.05676  loss_rpn_cls: 0.0005131  loss_rpn_loc: 0.009987  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:10] d2.utils.events INFO:  eta: 1:13:25  iter: 39679  total_loss: 0.1643  loss_cls: 0.02687  loss_box_reg: 0.06931  loss_mask: 0.04911  loss_rpn_cls: 0.0006221  loss_rpn_loc: 0.01094  time: 0.0881  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:36:12] d2.utils.events INFO:  eta: 1:13:21  iter: 39699  total_loss: 0.1556  loss_cls: 0.02534  loss_box_reg: 0.0756  loss_mask: 0.0567  loss_rpn_cls: 0.0005724  loss_rpn_loc: 0.01265  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:14] d2.utils.events INFO:  eta: 1:13:22  iter: 39719  total_loss: 0.1642  loss_cls: 0.02307  loss_box_reg: 0.07398  loss_mask: 0.07003  loss_rpn_cls: 0.0004024  loss_rpn_loc: 0.007454  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:15] d2.utils.events INFO:  eta: 1:13:27  iter: 39739  total_loss: 0.1846  loss_cls: 0.0301  loss_box_reg: 0.0898  loss_mask: 0.07222  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.01475  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:17] d2.utils.events INFO:  eta: 1:13:28  iter: 39759  total_loss: 0.2556  loss_cls: 0.0431  loss_box_reg: 0.1222  loss_mask: 0.0847  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.02043  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:19] d2.utils.events INFO:  eta: 1:13:19  iter: 39779  total_loss: 0.1468  loss_cls: 0.01792  loss_box_reg: 0.05114  loss_mask: 0.05163  loss_rpn_cls: 0.000566  loss_rpn_loc: 0.01131  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:21] d2.utils.events INFO:  eta: 1:13:19  iter: 39799  total_loss: 0.2366  loss_cls: 0.03024  loss_box_reg: 0.1019  loss_mask: 0.05676  loss_rpn_cls: 0.0005764  loss_rpn_loc: 0.01282  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:22] d2.utils.events INFO:  eta: 1:13:23  iter: 39819  total_loss: 0.2113  loss_cls: 0.03328  loss_box_reg: 0.0983  loss_mask: 0.0611  loss_rpn_cls: 0.0008161  loss_rpn_loc: 0.01449  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:24] d2.utils.events INFO:  eta: 1:13:21  iter: 39839  total_loss: 0.2073  loss_cls: 0.0272  loss_box_reg: 0.08556  loss_mask: 0.0616  loss_rpn_cls: 0.0009339  loss_rpn_loc: 0.01135  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:26] d2.utils.events INFO:  eta: 1:13:19  iter: 39859  total_loss: 0.224  loss_cls: 0.03374  loss_box_reg: 0.101  loss_mask: 0.06269  loss_rpn_cls: 0.0007671  loss_rpn_loc: 0.01418  time: 0.0881  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:36:28] d2.utils.events INFO:  eta: 1:13:10  iter: 39879  total_loss: 0.1899  loss_cls: 0.02741  loss_box_reg: 0.0807  loss_mask: 0.06434  loss_rpn_cls: 0.0005707  loss_rpn_loc: 0.01256  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:29] d2.utils.events INFO:  eta: 1:13:08  iter: 39899  total_loss: 0.1863  loss_cls: 0.03087  loss_box_reg: 0.08739  loss_mask: 0.06377  loss_rpn_cls: 0.001004  loss_rpn_loc: 0.008531  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:31] d2.utils.events INFO:  eta: 1:13:06  iter: 39919  total_loss: 0.1825  loss_cls: 0.03068  loss_box_reg: 0.07073  loss_mask: 0.0703  loss_rpn_cls: 0.0004612  loss_rpn_loc: 0.007512  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:33] d2.utils.events INFO:  eta: 1:13:04  iter: 39939  total_loss: 0.1619  loss_cls: 0.02715  loss_box_reg: 0.06872  loss_mask: 0.06577  loss_rpn_cls: 0.0004088  loss_rpn_loc: 0.006679  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:35] d2.utils.events INFO:  eta: 1:13:12  iter: 39959  total_loss: 0.2513  loss_cls: 0.03574  loss_box_reg: 0.1046  loss_mask: 0.0993  loss_rpn_cls: 0.001172  loss_rpn_loc: 0.01672  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:36] d2.utils.events INFO:  eta: 1:13:08  iter: 39979  total_loss: 0.2094  loss_cls: 0.02986  loss_box_reg: 0.09304  loss_mask: 0.07678  loss_rpn_cls: 0.0005111  loss_rpn_loc: 0.01341  time: 0.0881  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:36:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0039999.pth
[10/27 19:36:39] d2.utils.events INFO:  eta: 1:13:09  iter: 39999  total_loss: 0.2061  loss_cls: 0.02538  loss_box_reg: 0.08277  loss_mask: 0.05203  loss_rpn_cls: 0.0005163  loss_rpn_loc: 0.01561  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:40] d2.utils.events INFO:  eta: 1:13:02  iter: 40019  total_loss: 0.1435  loss_cls: 0.0214  loss_box_reg: 0.05001  loss_mask: 0.06184  loss_rpn_cls: 0.0004645  loss_rpn_loc: 0.006564  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:42] d2.utils.events INFO:  eta: 1:13:09  iter: 40039  total_loss: 0.272  loss_cls: 0.05052  loss_box_reg: 0.1292  loss_mask: 0.08054  loss_rpn_cls: 0.001131  loss_rpn_loc: 0.02318  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:44] d2.utils.events INFO:  eta: 1:13:09  iter: 40059  total_loss: 0.2873  loss_cls: 0.04349  loss_box_reg: 0.1169  loss_mask: 0.08538  loss_rpn_cls: 0.0006666  loss_rpn_loc: 0.01971  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:46] d2.utils.events INFO:  eta: 1:13:17  iter: 40079  total_loss: 0.3174  loss_cls: 0.04389  loss_box_reg: 0.1313  loss_mask: 0.1032  loss_rpn_cls: 0.001578  loss_rpn_loc: 0.0298  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:47] d2.utils.events INFO:  eta: 1:13:08  iter: 40099  total_loss: 0.1369  loss_cls: 0.02007  loss_box_reg: 0.04976  loss_mask: 0.05233  loss_rpn_cls: 0.0005155  loss_rpn_loc: 0.005919  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:49] d2.utils.events INFO:  eta: 1:12:59  iter: 40119  total_loss: 0.1675  loss_cls: 0.02217  loss_box_reg: 0.06878  loss_mask: 0.06355  loss_rpn_cls: 0.0006285  loss_rpn_loc: 0.01676  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:51] d2.utils.events INFO:  eta: 1:13:00  iter: 40139  total_loss: 0.196  loss_cls: 0.02564  loss_box_reg: 0.0874  loss_mask: 0.05621  loss_rpn_cls: 0.001641  loss_rpn_loc: 0.008411  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:53] d2.utils.events INFO:  eta: 1:12:44  iter: 40159  total_loss: 0.1604  loss_cls: 0.02369  loss_box_reg: 0.06551  loss_mask: 0.06766  loss_rpn_cls: 0.0004508  loss_rpn_loc: 0.007688  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:36:54] d2.utils.events INFO:  eta: 1:12:38  iter: 40179  total_loss: 0.2118  loss_cls: 0.03461  loss_box_reg: 0.09071  loss_mask: 0.05817  loss_rpn_cls: 0.0006579  loss_rpn_loc: 0.01225  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:56] d2.utils.events INFO:  eta: 1:12:38  iter: 40199  total_loss: 0.2248  loss_cls: 0.03673  loss_box_reg: 0.09928  loss_mask: 0.07256  loss_rpn_cls: 0.001006  loss_rpn_loc: 0.01259  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:36:58] d2.utils.events INFO:  eta: 1:12:35  iter: 40219  total_loss: 0.1724  loss_cls: 0.03036  loss_box_reg: 0.07695  loss_mask: 0.06655  loss_rpn_cls: 0.0005247  loss_rpn_loc: 0.01163  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:00] d2.utils.events INFO:  eta: 1:12:36  iter: 40239  total_loss: 0.2555  loss_cls: 0.03769  loss_box_reg: 0.1118  loss_mask: 0.07665  loss_rpn_cls: 0.0008377  loss_rpn_loc: 0.01866  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:01] d2.utils.events INFO:  eta: 1:12:38  iter: 40259  total_loss: 0.1653  loss_cls: 0.02359  loss_box_reg: 0.08473  loss_mask: 0.05781  loss_rpn_cls: 0.0005292  loss_rpn_loc: 0.01065  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:03] d2.utils.events INFO:  eta: 1:12:42  iter: 40279  total_loss: 0.2371  loss_cls: 0.03529  loss_box_reg: 0.1147  loss_mask: 0.06581  loss_rpn_cls: 0.0007851  loss_rpn_loc: 0.01322  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:05] d2.utils.events INFO:  eta: 1:12:41  iter: 40299  total_loss: 0.159  loss_cls: 0.02221  loss_box_reg: 0.06691  loss_mask: 0.06925  loss_rpn_cls: 0.0005088  loss_rpn_loc: 0.01345  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:07] d2.utils.events INFO:  eta: 1:12:39  iter: 40319  total_loss: 0.1993  loss_cls: 0.03375  loss_box_reg: 0.09422  loss_mask: 0.07065  loss_rpn_cls: 0.0009514  loss_rpn_loc: 0.01299  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:08] d2.utils.events INFO:  eta: 1:12:31  iter: 40339  total_loss: 0.1542  loss_cls: 0.02387  loss_box_reg: 0.06954  loss_mask: 0.06713  loss_rpn_cls: 0.0003345  loss_rpn_loc: 0.006934  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:10] d2.utils.events INFO:  eta: 1:12:32  iter: 40359  total_loss: 0.1664  loss_cls: 0.01987  loss_box_reg: 0.07013  loss_mask: 0.05429  loss_rpn_cls: 0.001187  loss_rpn_loc: 0.01109  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:12] d2.utils.events INFO:  eta: 1:12:28  iter: 40379  total_loss: 0.15  loss_cls: 0.02064  loss_box_reg: 0.05615  loss_mask: 0.07135  loss_rpn_cls: 0.0004856  loss_rpn_loc: 0.009676  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:14] d2.utils.events INFO:  eta: 1:12:27  iter: 40399  total_loss: 0.2076  loss_cls: 0.02871  loss_box_reg: 0.09107  loss_mask: 0.07792  loss_rpn_cls: 0.0008052  loss_rpn_loc: 0.01392  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:15] d2.utils.events INFO:  eta: 1:12:25  iter: 40419  total_loss: 0.1949  loss_cls: 0.03647  loss_box_reg: 0.0889  loss_mask: 0.06009  loss_rpn_cls: 0.0003939  loss_rpn_loc: 0.01635  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:17] d2.utils.events INFO:  eta: 1:12:23  iter: 40439  total_loss: 0.1899  loss_cls: 0.02778  loss_box_reg: 0.09871  loss_mask: 0.05958  loss_rpn_cls: 0.0007152  loss_rpn_loc: 0.01225  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:19] d2.utils.events INFO:  eta: 1:12:21  iter: 40459  total_loss: 0.1886  loss_cls: 0.03396  loss_box_reg: 0.08695  loss_mask: 0.06454  loss_rpn_cls: 0.0004633  loss_rpn_loc: 0.007486  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:21] d2.utils.events INFO:  eta: 1:12:25  iter: 40479  total_loss: 0.1869  loss_cls: 0.02915  loss_box_reg: 0.0852  loss_mask: 0.07161  loss_rpn_cls: 0.0008416  loss_rpn_loc: 0.01193  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:22] d2.utils.events INFO:  eta: 1:12:18  iter: 40499  total_loss: 0.1849  loss_cls: 0.0292  loss_box_reg: 0.08151  loss_mask: 0.05688  loss_rpn_cls: 0.0004574  loss_rpn_loc: 0.009969  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:24] d2.utils.events INFO:  eta: 1:12:15  iter: 40519  total_loss: 0.1705  loss_cls: 0.02519  loss_box_reg: 0.08179  loss_mask: 0.0635  loss_rpn_cls: 0.0006739  loss_rpn_loc: 0.01475  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:26] d2.utils.events INFO:  eta: 1:12:15  iter: 40539  total_loss: 0.2433  loss_cls: 0.03696  loss_box_reg: 0.1105  loss_mask: 0.06275  loss_rpn_cls: 0.001641  loss_rpn_loc: 0.02048  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:28] d2.utils.events INFO:  eta: 1:12:13  iter: 40559  total_loss: 0.187  loss_cls: 0.0258  loss_box_reg: 0.08341  loss_mask: 0.0673  loss_rpn_cls: 0.0007575  loss_rpn_loc: 0.0107  time: 0.0881  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:30] d2.utils.events INFO:  eta: 1:12:13  iter: 40579  total_loss: 0.1814  loss_cls: 0.02963  loss_box_reg: 0.0776  loss_mask: 0.07277  loss_rpn_cls: 0.000551  loss_rpn_loc: 0.0148  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:31] d2.utils.events INFO:  eta: 1:12:14  iter: 40599  total_loss: 0.1613  loss_cls: 0.02486  loss_box_reg: 0.0534  loss_mask: 0.05328  loss_rpn_cls: 0.0005541  loss_rpn_loc: 0.009217  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:33] d2.utils.events INFO:  eta: 1:12:09  iter: 40619  total_loss: 0.2213  loss_cls: 0.04458  loss_box_reg: 0.09845  loss_mask: 0.05781  loss_rpn_cls: 0.0007861  loss_rpn_loc: 0.01699  time: 0.0881  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:35] d2.utils.events INFO:  eta: 1:12:04  iter: 40639  total_loss: 0.2182  loss_cls: 0.03507  loss_box_reg: 0.08125  loss_mask: 0.06724  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.02094  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:37] d2.utils.events INFO:  eta: 1:12:06  iter: 40659  total_loss: 0.2343  loss_cls: 0.03506  loss_box_reg: 0.1153  loss_mask: 0.06962  loss_rpn_cls: 0.0007282  loss_rpn_loc: 0.01785  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:38] d2.utils.events INFO:  eta: 1:12:03  iter: 40679  total_loss: 0.148  loss_cls: 0.02229  loss_box_reg: 0.0592  loss_mask: 0.06194  loss_rpn_cls: 0.0004473  loss_rpn_loc: 0.007355  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:40] d2.utils.events INFO:  eta: 1:11:59  iter: 40699  total_loss: 0.1718  loss_cls: 0.02419  loss_box_reg: 0.0707  loss_mask: 0.06003  loss_rpn_cls: 0.0009106  loss_rpn_loc: 0.009609  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:42] d2.utils.events INFO:  eta: 1:11:58  iter: 40719  total_loss: 0.1668  loss_cls: 0.02258  loss_box_reg: 0.06686  loss_mask: 0.0588  loss_rpn_cls: 0.0005274  loss_rpn_loc: 0.006932  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:44] d2.utils.events INFO:  eta: 1:11:55  iter: 40739  total_loss: 0.194  loss_cls: 0.02242  loss_box_reg: 0.08448  loss_mask: 0.06913  loss_rpn_cls: 0.000798  loss_rpn_loc: 0.01588  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:45] d2.utils.events INFO:  eta: 1:11:50  iter: 40759  total_loss: 0.2027  loss_cls: 0.02976  loss_box_reg: 0.09012  loss_mask: 0.06785  loss_rpn_cls: 0.0003699  loss_rpn_loc: 0.01142  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:47] d2.utils.events INFO:  eta: 1:11:52  iter: 40779  total_loss: 0.2701  loss_cls: 0.04416  loss_box_reg: 0.1201  loss_mask: 0.07922  loss_rpn_cls: 0.001231  loss_rpn_loc: 0.02319  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:49] d2.utils.events INFO:  eta: 1:11:50  iter: 40799  total_loss: 0.1924  loss_cls: 0.02547  loss_box_reg: 0.0744  loss_mask: 0.06994  loss_rpn_cls: 0.0006579  loss_rpn_loc: 0.01382  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:51] d2.utils.events INFO:  eta: 1:11:43  iter: 40819  total_loss: 0.1551  loss_cls: 0.02236  loss_box_reg: 0.07101  loss_mask: 0.05609  loss_rpn_cls: 0.0006298  loss_rpn_loc: 0.01299  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:52] d2.utils.events INFO:  eta: 1:11:37  iter: 40839  total_loss: 0.1625  loss_cls: 0.02466  loss_box_reg: 0.07657  loss_mask: 0.05672  loss_rpn_cls: 0.0007286  loss_rpn_loc: 0.0107  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:54] d2.utils.events INFO:  eta: 1:11:32  iter: 40859  total_loss: 0.1777  loss_cls: 0.02987  loss_box_reg: 0.08621  loss_mask: 0.06608  loss_rpn_cls: 0.000733  loss_rpn_loc: 0.01174  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:56] d2.utils.events INFO:  eta: 1:11:34  iter: 40879  total_loss: 0.1542  loss_cls: 0.02008  loss_box_reg: 0.06127  loss_mask: 0.05622  loss_rpn_cls: 0.0005021  loss_rpn_loc: 0.008287  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:37:58] d2.utils.events INFO:  eta: 1:11:40  iter: 40899  total_loss: 0.2558  loss_cls: 0.0305  loss_box_reg: 0.1088  loss_mask: 0.08162  loss_rpn_cls: 0.001111  loss_rpn_loc: 0.01273  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:37:59] d2.utils.events INFO:  eta: 1:11:42  iter: 40919  total_loss: 0.2274  loss_cls: 0.0352  loss_box_reg: 0.1068  loss_mask: 0.06837  loss_rpn_cls: 0.000688  loss_rpn_loc: 0.01056  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:01] d2.utils.events INFO:  eta: 1:11:42  iter: 40939  total_loss: 0.294  loss_cls: 0.02903  loss_box_reg: 0.1203  loss_mask: 0.09776  loss_rpn_cls: 0.001729  loss_rpn_loc: 0.02492  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:38:03] d2.utils.events INFO:  eta: 1:11:38  iter: 40959  total_loss: 0.2481  loss_cls: 0.03597  loss_box_reg: 0.08808  loss_mask: 0.08549  loss_rpn_cls: 0.0007785  loss_rpn_loc: 0.02471  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:05] d2.utils.events INFO:  eta: 1:11:37  iter: 40979  total_loss: 0.1762  loss_cls: 0.03175  loss_box_reg: 0.08121  loss_mask: 0.05737  loss_rpn_cls: 0.0008133  loss_rpn_loc: 0.006591  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:06] d2.utils.events INFO:  eta: 1:11:35  iter: 40999  total_loss: 0.2077  loss_cls: 0.03247  loss_box_reg: 0.08536  loss_mask: 0.0621  loss_rpn_cls: 0.0008206  loss_rpn_loc: 0.01096  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:08] d2.utils.events INFO:  eta: 1:11:40  iter: 41019  total_loss: 0.1681  loss_cls: 0.02952  loss_box_reg: 0.08165  loss_mask: 0.06487  loss_rpn_cls: 0.0005861  loss_rpn_loc: 0.01005  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:10] d2.utils.events INFO:  eta: 1:11:32  iter: 41039  total_loss: 0.2523  loss_cls: 0.03343  loss_box_reg: 0.1148  loss_mask: 0.08033  loss_rpn_cls: 0.001759  loss_rpn_loc: 0.02006  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:12] d2.utils.events INFO:  eta: 1:11:26  iter: 41059  total_loss: 0.142  loss_cls: 0.03133  loss_box_reg: 0.05672  loss_mask: 0.05899  loss_rpn_cls: 0.0004542  loss_rpn_loc: 0.008401  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:13] d2.utils.events INFO:  eta: 1:11:20  iter: 41079  total_loss: 0.2074  loss_cls: 0.0338  loss_box_reg: 0.08525  loss_mask: 0.06514  loss_rpn_cls: 0.0003669  loss_rpn_loc: 0.01197  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:15] d2.utils.events INFO:  eta: 1:11:24  iter: 41099  total_loss: 0.1958  loss_cls: 0.0233  loss_box_reg: 0.08771  loss_mask: 0.06858  loss_rpn_cls: 0.0007405  loss_rpn_loc: 0.01115  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:17] d2.utils.events INFO:  eta: 1:11:23  iter: 41119  total_loss: 0.1359  loss_cls: 0.01659  loss_box_reg: 0.04726  loss_mask: 0.06048  loss_rpn_cls: 0.0005741  loss_rpn_loc: 0.008748  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:38:19] d2.utils.events INFO:  eta: 1:11:15  iter: 41139  total_loss: 0.1485  loss_cls: 0.01649  loss_box_reg: 0.05045  loss_mask: 0.06628  loss_rpn_cls: 0.0006015  loss_rpn_loc: 0.009472  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:20] d2.utils.events INFO:  eta: 1:11:17  iter: 41159  total_loss: 0.1732  loss_cls: 0.02907  loss_box_reg: 0.09347  loss_mask: 0.06745  loss_rpn_cls: 0.001197  loss_rpn_loc: 0.01751  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:22] d2.utils.events INFO:  eta: 1:11:20  iter: 41179  total_loss: 0.1996  loss_cls: 0.03093  loss_box_reg: 0.08821  loss_mask: 0.07343  loss_rpn_cls: 0.0005317  loss_rpn_loc: 0.006959  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:24] d2.utils.events INFO:  eta: 1:11:18  iter: 41199  total_loss: 0.1888  loss_cls: 0.0242  loss_box_reg: 0.07064  loss_mask: 0.08166  loss_rpn_cls: 0.0006912  loss_rpn_loc: 0.01116  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:26] d2.utils.events INFO:  eta: 1:11:16  iter: 41219  total_loss: 0.198  loss_cls: 0.03366  loss_box_reg: 0.08238  loss_mask: 0.07434  loss_rpn_cls: 0.0009317  loss_rpn_loc: 0.01364  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:27] d2.utils.events INFO:  eta: 1:11:12  iter: 41239  total_loss: 0.2233  loss_cls: 0.02841  loss_box_reg: 0.09153  loss_mask: 0.06485  loss_rpn_cls: 0.0007203  loss_rpn_loc: 0.01532  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:29] d2.utils.events INFO:  eta: 1:11:13  iter: 41259  total_loss: 0.2085  loss_cls: 0.02935  loss_box_reg: 0.09513  loss_mask: 0.06382  loss_rpn_cls: 0.001116  loss_rpn_loc: 0.01707  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:31] d2.utils.events INFO:  eta: 1:11:08  iter: 41279  total_loss: 0.1718  loss_cls: 0.02582  loss_box_reg: 0.0765  loss_mask: 0.0594  loss_rpn_cls: 0.0002615  loss_rpn_loc: 0.008895  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:33] d2.utils.events INFO:  eta: 1:11:08  iter: 41299  total_loss: 0.2108  loss_cls: 0.02748  loss_box_reg: 0.09  loss_mask: 0.06994  loss_rpn_cls: 0.0007888  loss_rpn_loc: 0.009368  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:34] d2.utils.events INFO:  eta: 1:11:04  iter: 41319  total_loss: 0.1901  loss_cls: 0.02866  loss_box_reg: 0.07386  loss_mask: 0.06984  loss_rpn_cls: 0.0006382  loss_rpn_loc: 0.01084  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:36] d2.utils.events INFO:  eta: 1:11:05  iter: 41339  total_loss: 0.15  loss_cls: 0.02721  loss_box_reg: 0.06527  loss_mask: 0.06145  loss_rpn_cls: 0.0005914  loss_rpn_loc: 0.007026  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:38] d2.utils.events INFO:  eta: 1:11:06  iter: 41359  total_loss: 0.2353  loss_cls: 0.03891  loss_box_reg: 0.1099  loss_mask: 0.07178  loss_rpn_cls: 0.0007767  loss_rpn_loc: 0.01169  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:40] d2.utils.events INFO:  eta: 1:11:02  iter: 41379  total_loss: 0.1333  loss_cls: 0.02151  loss_box_reg: 0.05057  loss_mask: 0.05045  loss_rpn_cls: 0.0002906  loss_rpn_loc: 0.0071  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:41] d2.utils.events INFO:  eta: 1:11:05  iter: 41399  total_loss: 0.1913  loss_cls: 0.02531  loss_box_reg: 0.08263  loss_mask: 0.05726  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.01368  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:43] d2.utils.events INFO:  eta: 1:11:08  iter: 41419  total_loss: 0.2201  loss_cls: 0.03484  loss_box_reg: 0.1112  loss_mask: 0.06417  loss_rpn_cls: 0.0005821  loss_rpn_loc: 0.01496  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:45] d2.utils.events INFO:  eta: 1:11:07  iter: 41439  total_loss: 0.172  loss_cls: 0.02677  loss_box_reg: 0.07727  loss_mask: 0.06789  loss_rpn_cls: 0.0005467  loss_rpn_loc: 0.00926  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:47] d2.utils.events INFO:  eta: 1:11:04  iter: 41459  total_loss: 0.1909  loss_cls: 0.02535  loss_box_reg: 0.08585  loss_mask: 0.06014  loss_rpn_cls: 0.0004724  loss_rpn_loc: 0.008937  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:49] d2.utils.events INFO:  eta: 1:11:12  iter: 41479  total_loss: 0.297  loss_cls: 0.04737  loss_box_reg: 0.1259  loss_mask: 0.09575  loss_rpn_cls: 0.001294  loss_rpn_loc: 0.03453  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:50] d2.utils.events INFO:  eta: 1:11:19  iter: 41499  total_loss: 0.2376  loss_cls: 0.03338  loss_box_reg: 0.1095  loss_mask: 0.06828  loss_rpn_cls: 0.0007332  loss_rpn_loc: 0.01903  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:38:52] d2.utils.events INFO:  eta: 1:11:14  iter: 41519  total_loss: 0.1551  loss_cls: 0.0224  loss_box_reg: 0.06297  loss_mask: 0.06606  loss_rpn_cls: 0.0007355  loss_rpn_loc: 0.0101  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:54] d2.utils.events INFO:  eta: 1:11:11  iter: 41539  total_loss: 0.1962  loss_cls: 0.02895  loss_box_reg: 0.08604  loss_mask: 0.05678  loss_rpn_cls: 0.001379  loss_rpn_loc: 0.0234  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:56] d2.utils.events INFO:  eta: 1:11:05  iter: 41559  total_loss: 0.1828  loss_cls: 0.01866  loss_box_reg: 0.06192  loss_mask: 0.0695  loss_rpn_cls: 0.0004461  loss_rpn_loc: 0.01371  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:57] d2.utils.events INFO:  eta: 1:11:01  iter: 41579  total_loss: 0.2068  loss_cls: 0.0275  loss_box_reg: 0.07631  loss_mask: 0.06649  loss_rpn_cls: 0.0005483  loss_rpn_loc: 0.01146  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:38:59] d2.utils.events INFO:  eta: 1:10:59  iter: 41599  total_loss: 0.2241  loss_cls: 0.02834  loss_box_reg: 0.09198  loss_mask: 0.07016  loss_rpn_cls: 0.0004428  loss_rpn_loc: 0.009441  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:01] d2.utils.events INFO:  eta: 1:10:51  iter: 41619  total_loss: 0.1489  loss_cls: 0.02045  loss_box_reg: 0.06227  loss_mask: 0.06838  loss_rpn_cls: 0.0007106  loss_rpn_loc: 0.008807  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:02] d2.utils.events INFO:  eta: 1:10:48  iter: 41639  total_loss: 0.1554  loss_cls: 0.01739  loss_box_reg: 0.07017  loss_mask: 0.05641  loss_rpn_cls: 0.0003202  loss_rpn_loc: 0.009118  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:04] d2.utils.events INFO:  eta: 1:10:53  iter: 41659  total_loss: 0.3062  loss_cls: 0.04665  loss_box_reg: 0.1252  loss_mask: 0.08605  loss_rpn_cls: 0.0009235  loss_rpn_loc: 0.02733  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:39:06] d2.utils.events INFO:  eta: 1:10:55  iter: 41679  total_loss: 0.2918  loss_cls: 0.04342  loss_box_reg: 0.1224  loss_mask: 0.07998  loss_rpn_cls: 0.0008561  loss_rpn_loc: 0.0176  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:08] d2.utils.events INFO:  eta: 1:11:05  iter: 41699  total_loss: 0.2306  loss_cls: 0.033  loss_box_reg: 0.1011  loss_mask: 0.06416  loss_rpn_cls: 0.0006264  loss_rpn_loc: 0.013  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:10] d2.utils.events INFO:  eta: 1:10:55  iter: 41719  total_loss: 0.1631  loss_cls: 0.02444  loss_box_reg: 0.08227  loss_mask: 0.05467  loss_rpn_cls: 0.0004908  loss_rpn_loc: 0.0125  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:11] d2.utils.events INFO:  eta: 1:10:55  iter: 41739  total_loss: 0.1897  loss_cls: 0.03219  loss_box_reg: 0.07824  loss_mask: 0.05639  loss_rpn_cls: 0.0003883  loss_rpn_loc: 0.01376  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:13] d2.utils.events INFO:  eta: 1:10:56  iter: 41759  total_loss: 0.2107  loss_cls: 0.03125  loss_box_reg: 0.08911  loss_mask: 0.06912  loss_rpn_cls: 0.0006975  loss_rpn_loc: 0.01121  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:15] d2.utils.events INFO:  eta: 1:10:50  iter: 41779  total_loss: 0.1925  loss_cls: 0.03027  loss_box_reg: 0.07207  loss_mask: 0.06311  loss_rpn_cls: 0.0005432  loss_rpn_loc: 0.01037  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:17] d2.utils.events INFO:  eta: 1:10:49  iter: 41799  total_loss: 0.2217  loss_cls: 0.04059  loss_box_reg: 0.1096  loss_mask: 0.09167  loss_rpn_cls: 0.001142  loss_rpn_loc: 0.0166  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:18] d2.utils.events INFO:  eta: 1:10:48  iter: 41819  total_loss: 0.1604  loss_cls: 0.02142  loss_box_reg: 0.06272  loss_mask: 0.05079  loss_rpn_cls: 0.0005101  loss_rpn_loc: 0.009529  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:20] d2.utils.events INFO:  eta: 1:10:44  iter: 41839  total_loss: 0.2039  loss_cls: 0.02031  loss_box_reg: 0.08374  loss_mask: 0.06328  loss_rpn_cls: 0.0007388  loss_rpn_loc: 0.01492  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:22] d2.utils.events INFO:  eta: 1:10:39  iter: 41859  total_loss: 0.174  loss_cls: 0.01987  loss_box_reg: 0.07966  loss_mask: 0.06806  loss_rpn_cls: 0.0007853  loss_rpn_loc: 0.009859  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:24] d2.utils.events INFO:  eta: 1:10:37  iter: 41879  total_loss: 0.1744  loss_cls: 0.02382  loss_box_reg: 0.07636  loss_mask: 0.06675  loss_rpn_cls: 0.0005229  loss_rpn_loc: 0.01022  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:39:25] d2.utils.events INFO:  eta: 1:10:33  iter: 41899  total_loss: 0.1925  loss_cls: 0.02706  loss_box_reg: 0.09787  loss_mask: 0.05884  loss_rpn_cls: 0.0005362  loss_rpn_loc: 0.01187  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:27] d2.utils.events INFO:  eta: 1:10:33  iter: 41919  total_loss: 0.2154  loss_cls: 0.04004  loss_box_reg: 0.1053  loss_mask: 0.06195  loss_rpn_cls: 0.0006524  loss_rpn_loc: 0.01115  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:29] d2.utils.events INFO:  eta: 1:10:34  iter: 41939  total_loss: 0.2688  loss_cls: 0.03913  loss_box_reg: 0.1002  loss_mask: 0.0826  loss_rpn_cls: 0.0008098  loss_rpn_loc: 0.01623  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:31] d2.utils.events INFO:  eta: 1:10:32  iter: 41959  total_loss: 0.2102  loss_cls: 0.03184  loss_box_reg: 0.09367  loss_mask: 0.06519  loss_rpn_cls: 0.0005293  loss_rpn_loc: 0.01146  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:33] d2.utils.events INFO:  eta: 1:10:30  iter: 41979  total_loss: 0.1869  loss_cls: 0.03121  loss_box_reg: 0.07004  loss_mask: 0.07772  loss_rpn_cls: 0.0008851  loss_rpn_loc: 0.01407  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:34] d2.utils.events INFO:  eta: 1:10:28  iter: 41999  total_loss: 0.1624  loss_cls: 0.0241  loss_box_reg: 0.07296  loss_mask: 0.06232  loss_rpn_cls: 0.0007487  loss_rpn_loc: 0.0144  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:36] d2.utils.events INFO:  eta: 1:10:25  iter: 42019  total_loss: 0.2107  loss_cls: 0.02728  loss_box_reg: 0.08341  loss_mask: 0.06921  loss_rpn_cls: 0.0004468  loss_rpn_loc: 0.009166  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:38] d2.utils.events INFO:  eta: 1:10:20  iter: 42039  total_loss: 0.1937  loss_cls: 0.03191  loss_box_reg: 0.07389  loss_mask: 0.06899  loss_rpn_cls: 0.0003369  loss_rpn_loc: 0.01356  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:40] d2.utils.events INFO:  eta: 1:10:19  iter: 42059  total_loss: 0.1641  loss_cls: 0.02082  loss_box_reg: 0.07107  loss_mask: 0.06164  loss_rpn_cls: 0.0003711  loss_rpn_loc: 0.00425  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:41] d2.utils.events INFO:  eta: 1:10:10  iter: 42079  total_loss: 0.1234  loss_cls: 0.02275  loss_box_reg: 0.04955  loss_mask: 0.05113  loss_rpn_cls: 0.0005723  loss_rpn_loc: 0.006255  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:39:43] d2.utils.events INFO:  eta: 1:10:05  iter: 42099  total_loss: 0.1927  loss_cls: 0.02338  loss_box_reg: 0.08825  loss_mask: 0.06405  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.01282  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:45] d2.utils.events INFO:  eta: 1:10:07  iter: 42119  total_loss: 0.1755  loss_cls: 0.02379  loss_box_reg: 0.08232  loss_mask: 0.04702  loss_rpn_cls: 0.0006577  loss_rpn_loc: 0.008673  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:46] d2.utils.events INFO:  eta: 1:10:09  iter: 42139  total_loss: 0.1578  loss_cls: 0.01669  loss_box_reg: 0.05488  loss_mask: 0.06479  loss_rpn_cls: 0.0002787  loss_rpn_loc: 0.006952  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:48] d2.utils.events INFO:  eta: 1:10:11  iter: 42159  total_loss: 0.2416  loss_cls: 0.03711  loss_box_reg: 0.1168  loss_mask: 0.0697  loss_rpn_cls: 0.000715  loss_rpn_loc: 0.01032  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:50] d2.utils.events INFO:  eta: 1:10:02  iter: 42179  total_loss: 0.1267  loss_cls: 0.02142  loss_box_reg: 0.05523  loss_mask: 0.0531  loss_rpn_cls: 0.0005847  loss_rpn_loc: 0.007365  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:52] d2.utils.events INFO:  eta: 1:09:54  iter: 42199  total_loss: 0.2043  loss_cls: 0.02266  loss_box_reg: 0.08633  loss_mask: 0.088  loss_rpn_cls: 0.0005938  loss_rpn_loc: 0.01222  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:54] d2.utils.events INFO:  eta: 1:09:54  iter: 42219  total_loss: 0.2826  loss_cls: 0.04191  loss_box_reg: 0.1332  loss_mask: 0.08743  loss_rpn_cls: 0.000906  loss_rpn_loc: 0.01513  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:55] d2.utils.events INFO:  eta: 1:10:00  iter: 42239  total_loss: 0.2104  loss_cls: 0.03355  loss_box_reg: 0.08987  loss_mask: 0.06889  loss_rpn_cls: 0.0005619  loss_rpn_loc: 0.01065  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:57] d2.utils.events INFO:  eta: 1:10:00  iter: 42259  total_loss: 0.1784  loss_cls: 0.023  loss_box_reg: 0.09889  loss_mask: 0.06871  loss_rpn_cls: 0.0005874  loss_rpn_loc: 0.01185  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:39:59] d2.utils.events INFO:  eta: 1:10:03  iter: 42279  total_loss: 0.218  loss_cls: 0.02563  loss_box_reg: 0.1057  loss_mask: 0.06681  loss_rpn_cls: 0.0007139  loss_rpn_loc: 0.01478  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:01] d2.utils.events INFO:  eta: 1:09:59  iter: 42299  total_loss: 0.2017  loss_cls: 0.0242  loss_box_reg: 0.08574  loss_mask: 0.06445  loss_rpn_cls: 0.0006092  loss_rpn_loc: 0.00973  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:02] d2.utils.events INFO:  eta: 1:09:59  iter: 42319  total_loss: 0.2074  loss_cls: 0.02601  loss_box_reg: 0.07826  loss_mask: 0.05975  loss_rpn_cls: 0.0005788  loss_rpn_loc: 0.01051  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:04] d2.utils.events INFO:  eta: 1:09:57  iter: 42339  total_loss: 0.1581  loss_cls: 0.02427  loss_box_reg: 0.06296  loss_mask: 0.06063  loss_rpn_cls: 0.0003913  loss_rpn_loc: 0.01369  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:06] d2.utils.events INFO:  eta: 1:09:52  iter: 42359  total_loss: 0.1596  loss_cls: 0.0207  loss_box_reg: 0.07028  loss_mask: 0.04852  loss_rpn_cls: 0.0003888  loss_rpn_loc: 0.0047  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:08] d2.utils.events INFO:  eta: 1:09:55  iter: 42379  total_loss: 0.2755  loss_cls: 0.04824  loss_box_reg: 0.1195  loss_mask: 0.08069  loss_rpn_cls: 0.0008831  loss_rpn_loc: 0.02349  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:10] d2.utils.events INFO:  eta: 1:09:53  iter: 42399  total_loss: 0.1586  loss_cls: 0.02091  loss_box_reg: 0.06685  loss_mask: 0.06245  loss_rpn_cls: 0.0007321  loss_rpn_loc: 0.009929  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:11] d2.utils.events INFO:  eta: 1:09:47  iter: 42419  total_loss: 0.1748  loss_cls: 0.02167  loss_box_reg: 0.05625  loss_mask: 0.05946  loss_rpn_cls: 0.0005129  loss_rpn_loc: 0.01202  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:13] d2.utils.events INFO:  eta: 1:09:45  iter: 42439  total_loss: 0.2232  loss_cls: 0.02877  loss_box_reg: 0.09498  loss_mask: 0.06186  loss_rpn_cls: 0.0008539  loss_rpn_loc: 0.01507  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:15] d2.utils.events INFO:  eta: 1:09:46  iter: 42459  total_loss: 0.2077  loss_cls: 0.02471  loss_box_reg: 0.09106  loss_mask: 0.06728  loss_rpn_cls: 0.0006629  loss_rpn_loc: 0.01591  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:17] d2.utils.events INFO:  eta: 1:09:41  iter: 42479  total_loss: 0.2307  loss_cls: 0.03674  loss_box_reg: 0.09869  loss_mask: 0.07215  loss_rpn_cls: 0.0008692  loss_rpn_loc: 0.01933  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:18] d2.utils.events INFO:  eta: 1:09:40  iter: 42499  total_loss: 0.1993  loss_cls: 0.03289  loss_box_reg: 0.09059  loss_mask: 0.06867  loss_rpn_cls: 0.0007907  loss_rpn_loc: 0.01647  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:20] d2.utils.events INFO:  eta: 1:09:41  iter: 42519  total_loss: 0.1872  loss_cls: 0.02361  loss_box_reg: 0.07474  loss_mask: 0.06077  loss_rpn_cls: 0.001065  loss_rpn_loc: 0.01252  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:22] d2.utils.events INFO:  eta: 1:09:37  iter: 42539  total_loss: 0.1778  loss_cls: 0.02503  loss_box_reg: 0.07038  loss_mask: 0.07976  loss_rpn_cls: 0.0004994  loss_rpn_loc: 0.01097  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:24] d2.utils.events INFO:  eta: 1:09:40  iter: 42559  total_loss: 0.2217  loss_cls: 0.0315  loss_box_reg: 0.1042  loss_mask: 0.05954  loss_rpn_cls: 0.0006961  loss_rpn_loc: 0.01296  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:25] d2.utils.events INFO:  eta: 1:09:37  iter: 42579  total_loss: 0.1539  loss_cls: 0.01761  loss_box_reg: 0.06929  loss_mask: 0.06251  loss_rpn_cls: 0.0007069  loss_rpn_loc: 0.01216  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:27] d2.utils.events INFO:  eta: 1:09:35  iter: 42599  total_loss: 0.1733  loss_cls: 0.02705  loss_box_reg: 0.06383  loss_mask: 0.06129  loss_rpn_cls: 0.0003613  loss_rpn_loc: 0.009341  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:29] d2.utils.events INFO:  eta: 1:09:35  iter: 42619  total_loss: 0.1929  loss_cls: 0.02621  loss_box_reg: 0.08632  loss_mask: 0.06021  loss_rpn_cls: 0.0007298  loss_rpn_loc: 0.01041  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:31] d2.utils.events INFO:  eta: 1:09:41  iter: 42639  total_loss: 0.1561  loss_cls: 0.02057  loss_box_reg: 0.07211  loss_mask: 0.05649  loss_rpn_cls: 0.0004643  loss_rpn_loc: 0.00677  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:32] d2.utils.events INFO:  eta: 1:09:29  iter: 42659  total_loss: 0.2581  loss_cls: 0.03867  loss_box_reg: 0.1241  loss_mask: 0.09488  loss_rpn_cls: 0.001228  loss_rpn_loc: 0.01987  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:34] d2.utils.events INFO:  eta: 1:09:22  iter: 42679  total_loss: 0.1504  loss_cls: 0.02424  loss_box_reg: 0.06264  loss_mask: 0.04726  loss_rpn_cls: 0.0005656  loss_rpn_loc: 0.01332  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:36] d2.utils.events INFO:  eta: 1:09:19  iter: 42699  total_loss: 0.2363  loss_cls: 0.04099  loss_box_reg: 0.09944  loss_mask: 0.07058  loss_rpn_cls: 0.0007439  loss_rpn_loc: 0.01895  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:38] d2.utils.events INFO:  eta: 1:09:19  iter: 42719  total_loss: 0.1814  loss_cls: 0.01874  loss_box_reg: 0.07363  loss_mask: 0.06516  loss_rpn_cls: 0.0004518  loss_rpn_loc: 0.008446  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:40] d2.utils.events INFO:  eta: 1:09:17  iter: 42739  total_loss: 0.1996  loss_cls: 0.0292  loss_box_reg: 0.09567  loss_mask: 0.05975  loss_rpn_cls: 0.0007245  loss_rpn_loc: 0.01073  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:41] d2.utils.events INFO:  eta: 1:09:03  iter: 42759  total_loss: 0.1786  loss_cls: 0.0242  loss_box_reg: 0.07181  loss_mask: 0.06053  loss_rpn_cls: 0.0008732  loss_rpn_loc: 0.00669  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:43] d2.utils.events INFO:  eta: 1:09:04  iter: 42779  total_loss: 0.1766  loss_cls: 0.02927  loss_box_reg: 0.07918  loss_mask: 0.055  loss_rpn_cls: 0.0009037  loss_rpn_loc: 0.009223  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:45] d2.utils.events INFO:  eta: 1:08:56  iter: 42799  total_loss: 0.1514  loss_cls: 0.01746  loss_box_reg: 0.06275  loss_mask: 0.06082  loss_rpn_cls: 0.0005166  loss_rpn_loc: 0.007796  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:46] d2.utils.events INFO:  eta: 1:09:05  iter: 42819  total_loss: 0.2164  loss_cls: 0.02873  loss_box_reg: 0.09168  loss_mask: 0.07208  loss_rpn_cls: 0.0008836  loss_rpn_loc: 0.01232  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:48] d2.utils.events INFO:  eta: 1:09:08  iter: 42839  total_loss: 0.1972  loss_cls: 0.02813  loss_box_reg: 0.08518  loss_mask: 0.05813  loss_rpn_cls: 0.0009309  loss_rpn_loc: 0.01494  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:50] d2.utils.events INFO:  eta: 1:09:08  iter: 42859  total_loss: 0.1935  loss_cls: 0.02535  loss_box_reg: 0.09235  loss_mask: 0.07214  loss_rpn_cls: 0.0007082  loss_rpn_loc: 0.0138  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:52] d2.utils.events INFO:  eta: 1:09:06  iter: 42879  total_loss: 0.1883  loss_cls: 0.02884  loss_box_reg: 0.07043  loss_mask: 0.0728  loss_rpn_cls: 0.0005622  loss_rpn_loc: 0.01109  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:40:54] d2.utils.events INFO:  eta: 1:09:06  iter: 42899  total_loss: 0.1779  loss_cls: 0.02502  loss_box_reg: 0.07673  loss_mask: 0.06237  loss_rpn_cls: 0.0005934  loss_rpn_loc: 0.01004  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:55] d2.utils.events INFO:  eta: 1:09:01  iter: 42919  total_loss: 0.163  loss_cls: 0.02384  loss_box_reg: 0.06152  loss_mask: 0.05498  loss_rpn_cls: 0.0003359  loss_rpn_loc: 0.008927  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:40:57] d2.utils.events INFO:  eta: 1:08:50  iter: 42939  total_loss: 0.2212  loss_cls: 0.03119  loss_box_reg: 0.1168  loss_mask: 0.07131  loss_rpn_cls: 0.0009504  loss_rpn_loc: 0.01448  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:40:59] d2.utils.events INFO:  eta: 1:08:42  iter: 42959  total_loss: 0.1675  loss_cls: 0.02932  loss_box_reg: 0.07845  loss_mask: 0.06209  loss_rpn_cls: 0.0004885  loss_rpn_loc: 0.01078  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:01] d2.utils.events INFO:  eta: 1:08:51  iter: 42979  total_loss: 0.2216  loss_cls: 0.03234  loss_box_reg: 0.09379  loss_mask: 0.06442  loss_rpn_cls: 0.000596  loss_rpn_loc: 0.01325  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:02] d2.utils.events INFO:  eta: 1:08:54  iter: 42999  total_loss: 0.193  loss_cls: 0.02794  loss_box_reg: 0.1029  loss_mask: 0.07268  loss_rpn_cls: 0.0007548  loss_rpn_loc: 0.01802  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:04] d2.utils.events INFO:  eta: 1:08:52  iter: 43019  total_loss: 0.1757  loss_cls: 0.02088  loss_box_reg: 0.07368  loss_mask: 0.05518  loss_rpn_cls: 0.0005258  loss_rpn_loc: 0.006518  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:06] d2.utils.events INFO:  eta: 1:08:51  iter: 43039  total_loss: 0.132  loss_cls: 0.01796  loss_box_reg: 0.04917  loss_mask: 0.06383  loss_rpn_cls: 0.0004296  loss_rpn_loc: 0.009341  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:08] d2.utils.events INFO:  eta: 1:08:50  iter: 43059  total_loss: 0.2641  loss_cls: 0.03934  loss_box_reg: 0.1075  loss_mask: 0.08255  loss_rpn_cls: 0.0007237  loss_rpn_loc: 0.01585  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:09] d2.utils.events INFO:  eta: 1:08:58  iter: 43079  total_loss: 0.2417  loss_cls: 0.02731  loss_box_reg: 0.1251  loss_mask: 0.06771  loss_rpn_cls: 0.0004335  loss_rpn_loc: 0.01563  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:11] d2.utils.events INFO:  eta: 1:08:59  iter: 43099  total_loss: 0.1975  loss_cls: 0.02629  loss_box_reg: 0.09551  loss_mask: 0.06791  loss_rpn_cls: 0.0006306  loss_rpn_loc: 0.01487  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:13] d2.utils.events INFO:  eta: 1:08:59  iter: 43119  total_loss: 0.1818  loss_cls: 0.0333  loss_box_reg: 0.08105  loss_mask: 0.07113  loss_rpn_cls: 0.0004764  loss_rpn_loc: 0.007229  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:15] d2.utils.events INFO:  eta: 1:09:00  iter: 43139  total_loss: 0.2009  loss_cls: 0.03048  loss_box_reg: 0.09317  loss_mask: 0.05531  loss_rpn_cls: 0.001155  loss_rpn_loc: 0.01067  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:17] d2.utils.events INFO:  eta: 1:08:54  iter: 43159  total_loss: 0.1999  loss_cls: 0.02919  loss_box_reg: 0.08349  loss_mask: 0.06011  loss_rpn_cls: 0.0005615  loss_rpn_loc: 0.01208  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:18] d2.utils.events INFO:  eta: 1:08:56  iter: 43179  total_loss: 0.1523  loss_cls: 0.02401  loss_box_reg: 0.06699  loss_mask: 0.06075  loss_rpn_cls: 0.0004383  loss_rpn_loc: 0.01025  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:20] d2.utils.events INFO:  eta: 1:08:58  iter: 43199  total_loss: 0.1657  loss_cls: 0.03039  loss_box_reg: 0.0884  loss_mask: 0.06079  loss_rpn_cls: 0.0003338  loss_rpn_loc: 0.008503  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:22] d2.utils.events INFO:  eta: 1:08:51  iter: 43219  total_loss: 0.1506  loss_cls: 0.02903  loss_box_reg: 0.06161  loss_mask: 0.05893  loss_rpn_cls: 0.001011  loss_rpn_loc: 0.01502  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:24] d2.utils.events INFO:  eta: 1:08:48  iter: 43239  total_loss: 0.1893  loss_cls: 0.02565  loss_box_reg: 0.07342  loss_mask: 0.06557  loss_rpn_cls: 0.0003735  loss_rpn_loc: 0.01174  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:25] d2.utils.events INFO:  eta: 1:08:42  iter: 43259  total_loss: 0.1674  loss_cls: 0.02389  loss_box_reg: 0.05709  loss_mask: 0.06688  loss_rpn_cls: 0.000389  loss_rpn_loc: 0.00951  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:41:27] d2.utils.events INFO:  eta: 1:08:36  iter: 43279  total_loss: 0.1655  loss_cls: 0.02495  loss_box_reg: 0.07973  loss_mask: 0.05986  loss_rpn_cls: 0.0005434  loss_rpn_loc: 0.00817  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:29] d2.utils.events INFO:  eta: 1:08:40  iter: 43299  total_loss: 0.1902  loss_cls: 0.03527  loss_box_reg: 0.07002  loss_mask: 0.06329  loss_rpn_cls: 0.0007209  loss_rpn_loc: 0.01128  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:31] d2.utils.events INFO:  eta: 1:08:40  iter: 43319  total_loss: 0.2714  loss_cls: 0.04283  loss_box_reg: 0.1063  loss_mask: 0.08368  loss_rpn_cls: 0.001498  loss_rpn_loc: 0.03895  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:41:33] d2.utils.events INFO:  eta: 1:08:42  iter: 43339  total_loss: 0.2291  loss_cls: 0.03729  loss_box_reg: 0.09363  loss_mask: 0.07053  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.01671  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:34] d2.utils.events INFO:  eta: 1:08:47  iter: 43359  total_loss: 0.1767  loss_cls: 0.02986  loss_box_reg: 0.06926  loss_mask: 0.06712  loss_rpn_cls: 0.0007302  loss_rpn_loc: 0.01144  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:36] d2.utils.events INFO:  eta: 1:08:39  iter: 43379  total_loss: 0.1667  loss_cls: 0.03209  loss_box_reg: 0.06232  loss_mask: 0.0608  loss_rpn_cls: 0.000445  loss_rpn_loc: 0.01181  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:41:38] d2.utils.events INFO:  eta: 1:08:41  iter: 43399  total_loss: 0.1909  loss_cls: 0.02873  loss_box_reg: 0.08669  loss_mask: 0.06064  loss_rpn_cls: 0.0008878  loss_rpn_loc: 0.01478  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:40] d2.utils.events INFO:  eta: 1:08:34  iter: 43419  total_loss: 0.1521  loss_cls: 0.02304  loss_box_reg: 0.07249  loss_mask: 0.06286  loss_rpn_cls: 0.0005266  loss_rpn_loc: 0.01054  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:41] d2.utils.events INFO:  eta: 1:08:33  iter: 43439  total_loss: 0.2015  loss_cls: 0.03034  loss_box_reg: 0.1032  loss_mask: 0.06904  loss_rpn_cls: 0.0009728  loss_rpn_loc: 0.0163  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:43] d2.utils.events INFO:  eta: 1:08:36  iter: 43459  total_loss: 0.1953  loss_cls: 0.03544  loss_box_reg: 0.09587  loss_mask: 0.05277  loss_rpn_cls: 0.0008171  loss_rpn_loc: 0.01759  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:45] d2.utils.events INFO:  eta: 1:08:25  iter: 43479  total_loss: 0.1749  loss_cls: 0.02831  loss_box_reg: 0.06836  loss_mask: 0.05954  loss_rpn_cls: 0.0007095  loss_rpn_loc: 0.007151  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:47] d2.utils.events INFO:  eta: 1:08:13  iter: 43499  total_loss: 0.1947  loss_cls: 0.02656  loss_box_reg: 0.06014  loss_mask: 0.06198  loss_rpn_cls: 0.0006075  loss_rpn_loc: 0.007523  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:48] d2.utils.events INFO:  eta: 1:08:09  iter: 43519  total_loss: 0.1722  loss_cls: 0.02452  loss_box_reg: 0.07327  loss_mask: 0.0629  loss_rpn_cls: 0.0007885  loss_rpn_loc: 0.01098  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:41:50] d2.utils.events INFO:  eta: 1:08:13  iter: 43539  total_loss: 0.1885  loss_cls: 0.03061  loss_box_reg: 0.08924  loss_mask: 0.05843  loss_rpn_cls: 0.000516  loss_rpn_loc: 0.01298  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:52] d2.utils.events INFO:  eta: 1:08:11  iter: 43559  total_loss: 0.2063  loss_cls: 0.02652  loss_box_reg: 0.08958  loss_mask: 0.07058  loss_rpn_cls: 0.0007959  loss_rpn_loc: 0.01184  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:54] d2.utils.events INFO:  eta: 1:08:17  iter: 43579  total_loss: 0.1821  loss_cls: 0.02536  loss_box_reg: 0.08662  loss_mask: 0.05129  loss_rpn_cls: 0.0006498  loss_rpn_loc: 0.007668  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:56] d2.utils.events INFO:  eta: 1:08:15  iter: 43599  total_loss: 0.1888  loss_cls: 0.02433  loss_box_reg: 0.0905  loss_mask: 0.06636  loss_rpn_cls: 0.000294  loss_rpn_loc: 0.00925  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:41:57] d2.utils.events INFO:  eta: 1:08:15  iter: 43619  total_loss: 0.2061  loss_cls: 0.02954  loss_box_reg: 0.09434  loss_mask: 0.06678  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.01454  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:41:59] d2.utils.events INFO:  eta: 1:08:18  iter: 43639  total_loss: 0.2065  loss_cls: 0.03814  loss_box_reg: 0.09032  loss_mask: 0.07097  loss_rpn_cls: 0.0009301  loss_rpn_loc: 0.01306  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:01] d2.utils.events INFO:  eta: 1:08:12  iter: 43659  total_loss: 0.2339  loss_cls: 0.04255  loss_box_reg: 0.1086  loss_mask: 0.07266  loss_rpn_cls: 0.001304  loss_rpn_loc: 0.02312  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:03] d2.utils.events INFO:  eta: 1:08:10  iter: 43679  total_loss: 0.1333  loss_cls: 0.0266  loss_box_reg: 0.05446  loss_mask: 0.05613  loss_rpn_cls: 0.0003616  loss_rpn_loc: 0.008301  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:04] d2.utils.events INFO:  eta: 1:08:06  iter: 43699  total_loss: 0.1535  loss_cls: 0.02068  loss_box_reg: 0.06906  loss_mask: 0.0584  loss_rpn_cls: 0.0004548  loss_rpn_loc: 0.01067  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:06] d2.utils.events INFO:  eta: 1:07:59  iter: 43719  total_loss: 0.2096  loss_cls: 0.02781  loss_box_reg: 0.09452  loss_mask: 0.07135  loss_rpn_cls: 0.0007901  loss_rpn_loc: 0.01279  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:08] d2.utils.events INFO:  eta: 1:07:55  iter: 43739  total_loss: 0.182  loss_cls: 0.02716  loss_box_reg: 0.08452  loss_mask: 0.05491  loss_rpn_cls: 0.0002744  loss_rpn_loc: 0.006582  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:10] d2.utils.events INFO:  eta: 1:07:56  iter: 43759  total_loss: 0.1537  loss_cls: 0.01981  loss_box_reg: 0.0537  loss_mask: 0.06215  loss_rpn_cls: 0.0005973  loss_rpn_loc: 0.01155  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:11] d2.utils.events INFO:  eta: 1:07:57  iter: 43779  total_loss: 0.277  loss_cls: 0.03834  loss_box_reg: 0.1129  loss_mask: 0.08615  loss_rpn_cls: 0.0008442  loss_rpn_loc: 0.02062  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:13] d2.utils.events INFO:  eta: 1:07:58  iter: 43799  total_loss: 0.1981  loss_cls: 0.03203  loss_box_reg: 0.08714  loss_mask: 0.06486  loss_rpn_cls: 0.0005144  loss_rpn_loc: 0.0176  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:15] d2.utils.events INFO:  eta: 1:08:02  iter: 43819  total_loss: 0.2586  loss_cls: 0.0378  loss_box_reg: 0.1099  loss_mask: 0.07732  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.02058  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:17] d2.utils.events INFO:  eta: 1:08:02  iter: 43839  total_loss: 0.1977  loss_cls: 0.02998  loss_box_reg: 0.08012  loss_mask: 0.07251  loss_rpn_cls: 0.0003154  loss_rpn_loc: 0.004786  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:42:18] d2.utils.events INFO:  eta: 1:07:56  iter: 43859  total_loss: 0.1206  loss_cls: 0.01767  loss_box_reg: 0.04418  loss_mask: 0.05027  loss_rpn_cls: 0.0003639  loss_rpn_loc: 0.008345  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:20] d2.utils.events INFO:  eta: 1:07:51  iter: 43879  total_loss: 0.1914  loss_cls: 0.02292  loss_box_reg: 0.07106  loss_mask: 0.06926  loss_rpn_cls: 0.00139  loss_rpn_loc: 0.02606  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:22] d2.utils.events INFO:  eta: 1:07:56  iter: 43899  total_loss: 0.3017  loss_cls: 0.03523  loss_box_reg: 0.1208  loss_mask: 0.07906  loss_rpn_cls: 0.001443  loss_rpn_loc: 0.02966  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:24] d2.utils.events INFO:  eta: 1:08:00  iter: 43919  total_loss: 0.2042  loss_cls: 0.02726  loss_box_reg: 0.09747  loss_mask: 0.0657  loss_rpn_cls: 0.001073  loss_rpn_loc: 0.0142  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:26] d2.utils.events INFO:  eta: 1:07:53  iter: 43939  total_loss: 0.1745  loss_cls: 0.02814  loss_box_reg: 0.07495  loss_mask: 0.05802  loss_rpn_cls: 0.0007842  loss_rpn_loc: 0.01038  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:27] d2.utils.events INFO:  eta: 1:07:52  iter: 43959  total_loss: 0.1657  loss_cls: 0.0257  loss_box_reg: 0.07155  loss_mask: 0.05373  loss_rpn_cls: 0.0006626  loss_rpn_loc: 0.009717  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:29] d2.utils.events INFO:  eta: 1:07:42  iter: 43979  total_loss: 0.1727  loss_cls: 0.02907  loss_box_reg: 0.0823  loss_mask: 0.05154  loss_rpn_cls: 0.0005292  loss_rpn_loc: 0.01086  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:31] d2.utils.events INFO:  eta: 1:07:36  iter: 43999  total_loss: 0.1214  loss_cls: 0.01969  loss_box_reg: 0.05041  loss_mask: 0.05918  loss_rpn_cls: 0.0003142  loss_rpn_loc: 0.006203  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:33] d2.utils.events INFO:  eta: 1:07:39  iter: 44019  total_loss: 0.2075  loss_cls: 0.03577  loss_box_reg: 0.0996  loss_mask: 0.06945  loss_rpn_cls: 0.0007173  loss_rpn_loc: 0.01547  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:34] d2.utils.events INFO:  eta: 1:07:40  iter: 44039  total_loss: 0.1605  loss_cls: 0.02317  loss_box_reg: 0.07242  loss_mask: 0.0616  loss_rpn_cls: 0.000452  loss_rpn_loc: 0.01545  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:36] d2.utils.events INFO:  eta: 1:07:33  iter: 44059  total_loss: 0.1838  loss_cls: 0.02682  loss_box_reg: 0.06241  loss_mask: 0.06088  loss_rpn_cls: 0.0008502  loss_rpn_loc: 0.01952  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:38] d2.utils.events INFO:  eta: 1:07:29  iter: 44079  total_loss: 0.168  loss_cls: 0.03083  loss_box_reg: 0.085  loss_mask: 0.05121  loss_rpn_cls: 0.0005529  loss_rpn_loc: 0.008818  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:40] d2.utils.events INFO:  eta: 1:07:28  iter: 44099  total_loss: 0.1874  loss_cls: 0.03177  loss_box_reg: 0.0784  loss_mask: 0.06378  loss_rpn_cls: 0.0006231  loss_rpn_loc: 0.01079  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:41] d2.utils.events INFO:  eta: 1:07:19  iter: 44119  total_loss: 0.1306  loss_cls: 0.02175  loss_box_reg: 0.05566  loss_mask: 0.04796  loss_rpn_cls: 0.0002819  loss_rpn_loc: 0.006244  time: 0.0880  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:42:43] d2.utils.events INFO:  eta: 1:07:17  iter: 44139  total_loss: 0.19  loss_cls: 0.03024  loss_box_reg: 0.08991  loss_mask: 0.06285  loss_rpn_cls: 0.000571  loss_rpn_loc: 0.01134  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:45] d2.utils.events INFO:  eta: 1:07:20  iter: 44159  total_loss: 0.2137  loss_cls: 0.02557  loss_box_reg: 0.1011  loss_mask: 0.08096  loss_rpn_cls: 0.0005586  loss_rpn_loc: 0.01481  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:47] d2.utils.events INFO:  eta: 1:07:14  iter: 44179  total_loss: 0.1578  loss_cls: 0.03213  loss_box_reg: 0.0655  loss_mask: 0.05935  loss_rpn_cls: 0.0004144  loss_rpn_loc: 0.008296  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:49] d2.utils.events INFO:  eta: 1:07:20  iter: 44199  total_loss: 0.2734  loss_cls: 0.04273  loss_box_reg: 0.1119  loss_mask: 0.08822  loss_rpn_cls: 0.001118  loss_rpn_loc: 0.0228  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:50] d2.utils.events INFO:  eta: 1:07:23  iter: 44219  total_loss: 0.2576  loss_cls: 0.0371  loss_box_reg: 0.1212  loss_mask: 0.07389  loss_rpn_cls: 0.0008283  loss_rpn_loc: 0.01738  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:52] d2.utils.events INFO:  eta: 1:07:17  iter: 44239  total_loss: 0.1558  loss_cls: 0.01957  loss_box_reg: 0.05069  loss_mask: 0.06751  loss_rpn_cls: 0.0004931  loss_rpn_loc: 0.01082  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:54] d2.utils.events INFO:  eta: 1:07:13  iter: 44259  total_loss: 0.1647  loss_cls: 0.02253  loss_box_reg: 0.07036  loss_mask: 0.05406  loss_rpn_cls: 0.00072  loss_rpn_loc: 0.009071  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:56] d2.utils.events INFO:  eta: 1:07:15  iter: 44279  total_loss: 0.2057  loss_cls: 0.02211  loss_box_reg: 0.07749  loss_mask: 0.07262  loss_rpn_cls: 0.001396  loss_rpn_loc: 0.0146  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:42:57] d2.utils.events INFO:  eta: 1:07:15  iter: 44299  total_loss: 0.229  loss_cls: 0.0371  loss_box_reg: 0.1116  loss_mask: 0.07231  loss_rpn_cls: 0.001511  loss_rpn_loc: 0.01975  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:42:59] d2.utils.events INFO:  eta: 1:07:13  iter: 44319  total_loss: 0.2164  loss_cls: 0.03133  loss_box_reg: 0.1077  loss_mask: 0.07192  loss_rpn_cls: 0.0006437  loss_rpn_loc: 0.01432  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:01] d2.utils.events INFO:  eta: 1:07:10  iter: 44339  total_loss: 0.2008  loss_cls: 0.02766  loss_box_reg: 0.09319  loss_mask: 0.07183  loss_rpn_cls: 0.0008214  loss_rpn_loc: 0.01176  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:03] d2.utils.events INFO:  eta: 1:07:06  iter: 44359  total_loss: 0.158  loss_cls: 0.02202  loss_box_reg: 0.0614  loss_mask: 0.06062  loss_rpn_cls: 0.0003844  loss_rpn_loc: 0.01131  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:04] d2.utils.events INFO:  eta: 1:07:00  iter: 44379  total_loss: 0.1437  loss_cls: 0.01978  loss_box_reg: 0.05464  loss_mask: 0.05152  loss_rpn_cls: 0.0002543  loss_rpn_loc: 0.008008  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:06] d2.utils.events INFO:  eta: 1:06:46  iter: 44399  total_loss: 0.1503  loss_cls: 0.02463  loss_box_reg: 0.05716  loss_mask: 0.05081  loss_rpn_cls: 0.0006209  loss_rpn_loc: 0.01381  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:08] d2.utils.events INFO:  eta: 1:06:53  iter: 44419  total_loss: 0.1896  loss_cls: 0.03231  loss_box_reg: 0.07743  loss_mask: 0.062  loss_rpn_cls: 0.0004982  loss_rpn_loc: 0.007905  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:10] d2.utils.events INFO:  eta: 1:06:43  iter: 44439  total_loss: 0.2052  loss_cls: 0.03234  loss_box_reg: 0.09808  loss_mask: 0.06283  loss_rpn_cls: 0.0005808  loss_rpn_loc: 0.01249  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:11] d2.utils.events INFO:  eta: 1:06:38  iter: 44459  total_loss: 0.1328  loss_cls: 0.02088  loss_box_reg: 0.05506  loss_mask: 0.05721  loss_rpn_cls: 0.0008322  loss_rpn_loc: 0.00691  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:13] d2.utils.events INFO:  eta: 1:06:51  iter: 44479  total_loss: 0.2026  loss_cls: 0.03049  loss_box_reg: 0.09616  loss_mask: 0.06264  loss_rpn_cls: 0.0005459  loss_rpn_loc: 0.008253  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:15] d2.utils.events INFO:  eta: 1:06:48  iter: 44499  total_loss: 0.158  loss_cls: 0.02952  loss_box_reg: 0.0754  loss_mask: 0.05442  loss_rpn_cls: 0.0006607  loss_rpn_loc: 0.009633  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:17] d2.utils.events INFO:  eta: 1:06:47  iter: 44519  total_loss: 0.2276  loss_cls: 0.03423  loss_box_reg: 0.0972  loss_mask: 0.06843  loss_rpn_cls: 0.0009242  loss_rpn_loc: 0.01816  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:18] d2.utils.events INFO:  eta: 1:06:42  iter: 44539  total_loss: 0.1495  loss_cls: 0.02547  loss_box_reg: 0.06511  loss_mask: 0.05264  loss_rpn_cls: 0.0003707  loss_rpn_loc: 0.007115  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:20] d2.utils.events INFO:  eta: 1:06:40  iter: 44559  total_loss: 0.1783  loss_cls: 0.0269  loss_box_reg: 0.07983  loss_mask: 0.06361  loss_rpn_cls: 0.0004812  loss_rpn_loc: 0.008969  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:22] d2.utils.events INFO:  eta: 1:06:29  iter: 44579  total_loss: 0.1616  loss_cls: 0.02772  loss_box_reg: 0.06993  loss_mask: 0.05823  loss_rpn_cls: 0.0005538  loss_rpn_loc: 0.01065  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:24] d2.utils.events INFO:  eta: 1:06:26  iter: 44599  total_loss: 0.2267  loss_cls: 0.02558  loss_box_reg: 0.09218  loss_mask: 0.07169  loss_rpn_cls: 0.0005793  loss_rpn_loc: 0.009911  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:25] d2.utils.events INFO:  eta: 1:06:24  iter: 44619  total_loss: 0.1556  loss_cls: 0.02237  loss_box_reg: 0.06748  loss_mask: 0.05237  loss_rpn_cls: 0.0003057  loss_rpn_loc: 0.008693  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:27] d2.utils.events INFO:  eta: 1:06:22  iter: 44639  total_loss: 0.1804  loss_cls: 0.02887  loss_box_reg: 0.083  loss_mask: 0.06324  loss_rpn_cls: 0.0007098  loss_rpn_loc: 0.01473  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:29] d2.utils.events INFO:  eta: 1:06:20  iter: 44659  total_loss: 0.1909  loss_cls: 0.02578  loss_box_reg: 0.06963  loss_mask: 0.07361  loss_rpn_cls: 0.0005532  loss_rpn_loc: 0.009845  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:31] d2.utils.events INFO:  eta: 1:06:20  iter: 44679  total_loss: 0.1917  loss_cls: 0.0358  loss_box_reg: 0.08791  loss_mask: 0.06436  loss_rpn_cls: 0.0008261  loss_rpn_loc: 0.01762  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:33] d2.utils.events INFO:  eta: 1:06:30  iter: 44699  total_loss: 0.2003  loss_cls: 0.02899  loss_box_reg: 0.07875  loss_mask: 0.06804  loss_rpn_cls: 0.0006559  loss_rpn_loc: 0.01447  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:34] d2.utils.events INFO:  eta: 1:06:29  iter: 44719  total_loss: 0.157  loss_cls: 0.01946  loss_box_reg: 0.06872  loss_mask: 0.05282  loss_rpn_cls: 0.0004103  loss_rpn_loc: 0.007158  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:36] d2.utils.events INFO:  eta: 1:06:28  iter: 44739  total_loss: 0.1997  loss_cls: 0.0412  loss_box_reg: 0.08562  loss_mask: 0.06296  loss_rpn_cls: 0.000688  loss_rpn_loc: 0.02187  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:38] d2.utils.events INFO:  eta: 1:06:32  iter: 44759  total_loss: 0.2182  loss_cls: 0.04445  loss_box_reg: 0.08387  loss_mask: 0.0663  loss_rpn_cls: 0.0009587  loss_rpn_loc: 0.01477  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:40] d2.utils.events INFO:  eta: 1:06:30  iter: 44779  total_loss: 0.2019  loss_cls: 0.02701  loss_box_reg: 0.0826  loss_mask: 0.06454  loss_rpn_cls: 0.0006951  loss_rpn_loc: 0.01318  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:41] d2.utils.events INFO:  eta: 1:06:31  iter: 44799  total_loss: 0.2348  loss_cls: 0.03964  loss_box_reg: 0.09812  loss_mask: 0.06319  loss_rpn_cls: 0.0003879  loss_rpn_loc: 0.009957  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:43] d2.utils.events INFO:  eta: 1:06:23  iter: 44819  total_loss: 0.1276  loss_cls: 0.02016  loss_box_reg: 0.04658  loss_mask: 0.05505  loss_rpn_cls: 0.0004386  loss_rpn_loc: 0.01052  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:45] d2.utils.events INFO:  eta: 1:06:18  iter: 44839  total_loss: 0.1495  loss_cls: 0.02082  loss_box_reg: 0.06251  loss_mask: 0.05615  loss_rpn_cls: 0.0003145  loss_rpn_loc: 0.006108  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:47] d2.utils.events INFO:  eta: 1:06:17  iter: 44859  total_loss: 0.1581  loss_cls: 0.02462  loss_box_reg: 0.06402  loss_mask: 0.05595  loss_rpn_cls: 0.0006443  loss_rpn_loc: 0.008  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:48] d2.utils.events INFO:  eta: 1:06:10  iter: 44879  total_loss: 0.1548  loss_cls: 0.02091  loss_box_reg: 0.05446  loss_mask: 0.05848  loss_rpn_cls: 0.000425  loss_rpn_loc: 0.008401  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:50] d2.utils.events INFO:  eta: 1:05:59  iter: 44899  total_loss: 0.1518  loss_cls: 0.01796  loss_box_reg: 0.06962  loss_mask: 0.06617  loss_rpn_cls: 0.0003331  loss_rpn_loc: 0.007355  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:52] d2.utils.events INFO:  eta: 1:05:46  iter: 44919  total_loss: 0.1709  loss_cls: 0.03022  loss_box_reg: 0.07873  loss_mask: 0.05879  loss_rpn_cls: 0.0004527  loss_rpn_loc: 0.01031  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:43:54] d2.utils.events INFO:  eta: 1:05:50  iter: 44939  total_loss: 0.1827  loss_cls: 0.01976  loss_box_reg: 0.06282  loss_mask: 0.0537  loss_rpn_cls: 0.0002953  loss_rpn_loc: 0.007899  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:55] d2.utils.events INFO:  eta: 1:05:49  iter: 44959  total_loss: 0.2101  loss_cls: 0.0248  loss_box_reg: 0.08841  loss_mask: 0.06083  loss_rpn_cls: 0.0006284  loss_rpn_loc: 0.01412  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:57] d2.utils.events INFO:  eta: 1:05:52  iter: 44979  total_loss: 0.1743  loss_cls: 0.02599  loss_box_reg: 0.07391  loss_mask: 0.06645  loss_rpn_cls: 0.0005842  loss_rpn_loc: 0.01138  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:43:59] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0044999.pth
[10/27 19:43:59] d2.utils.events INFO:  eta: 1:05:51  iter: 44999  total_loss: 0.233  loss_cls: 0.0316  loss_box_reg: 0.1086  loss_mask: 0.07075  loss_rpn_cls: 0.0008666  loss_rpn_loc: 0.01721  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:01] d2.utils.events INFO:  eta: 1:05:49  iter: 45019  total_loss: 0.1672  loss_cls: 0.0287  loss_box_reg: 0.0747  loss_mask: 0.06209  loss_rpn_cls: 0.0004651  loss_rpn_loc: 0.01104  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:03] d2.utils.events INFO:  eta: 1:05:42  iter: 45039  total_loss: 0.1714  loss_cls: 0.02258  loss_box_reg: 0.0702  loss_mask: 0.05738  loss_rpn_cls: 0.0004245  loss_rpn_loc: 0.007417  time: 0.0880  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:44:05] d2.utils.events INFO:  eta: 1:05:46  iter: 45059  total_loss: 0.2121  loss_cls: 0.03611  loss_box_reg: 0.0894  loss_mask: 0.06769  loss_rpn_cls: 0.000834  loss_rpn_loc: 0.01356  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:06] d2.utils.events INFO:  eta: 1:05:49  iter: 45079  total_loss: 0.2342  loss_cls: 0.03944  loss_box_reg: 0.1051  loss_mask: 0.05845  loss_rpn_cls: 0.0006077  loss_rpn_loc: 0.02005  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:08] d2.utils.events INFO:  eta: 1:05:47  iter: 45099  total_loss: 0.1861  loss_cls: 0.01762  loss_box_reg: 0.05752  loss_mask: 0.06052  loss_rpn_cls: 0.0007442  loss_rpn_loc: 0.01782  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:10] d2.utils.events INFO:  eta: 1:05:55  iter: 45119  total_loss: 0.2027  loss_cls: 0.03328  loss_box_reg: 0.08744  loss_mask: 0.06587  loss_rpn_cls: 0.0006705  loss_rpn_loc: 0.01349  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:12] d2.utils.events INFO:  eta: 1:05:46  iter: 45139  total_loss: 0.1431  loss_cls: 0.01928  loss_box_reg: 0.0526  loss_mask: 0.05285  loss_rpn_cls: 0.0002863  loss_rpn_loc: 0.01099  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:13] d2.utils.events INFO:  eta: 1:05:49  iter: 45159  total_loss: 0.2146  loss_cls: 0.0402  loss_box_reg: 0.1019  loss_mask: 0.07631  loss_rpn_cls: 0.0004146  loss_rpn_loc: 0.008637  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:15] d2.utils.events INFO:  eta: 1:05:48  iter: 45179  total_loss: 0.1973  loss_cls: 0.02278  loss_box_reg: 0.07787  loss_mask: 0.05336  loss_rpn_cls: 0.0003888  loss_rpn_loc: 0.009343  time: 0.0880  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:17] d2.utils.events INFO:  eta: 1:05:34  iter: 45199  total_loss: 0.1377  loss_cls: 0.01999  loss_box_reg: 0.06009  loss_mask: 0.06726  loss_rpn_cls: 0.0003465  loss_rpn_loc: 0.003266  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:19] d2.utils.events INFO:  eta: 1:05:32  iter: 45219  total_loss: 0.1993  loss_cls: 0.02561  loss_box_reg: 0.08431  loss_mask: 0.05488  loss_rpn_cls: 0.0007954  loss_rpn_loc: 0.0188  time: 0.0880  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:20] d2.utils.events INFO:  eta: 1:05:33  iter: 45239  total_loss: 0.2167  loss_cls: 0.02765  loss_box_reg: 0.08436  loss_mask: 0.0696  loss_rpn_cls: 0.0006575  loss_rpn_loc: 0.01193  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:44:22] d2.utils.events INFO:  eta: 1:05:31  iter: 45259  total_loss: 0.1903  loss_cls: 0.02581  loss_box_reg: 0.08682  loss_mask: 0.05379  loss_rpn_cls: 0.0004553  loss_rpn_loc: 0.01134  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:24] d2.utils.events INFO:  eta: 1:05:27  iter: 45279  total_loss: 0.181  loss_cls: 0.04199  loss_box_reg: 0.07242  loss_mask: 0.07222  loss_rpn_cls: 0.0008023  loss_rpn_loc: 0.01062  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:26] d2.utils.events INFO:  eta: 1:05:20  iter: 45299  total_loss: 0.1853  loss_cls: 0.02781  loss_box_reg: 0.07138  loss_mask: 0.06534  loss_rpn_cls: 0.0003649  loss_rpn_loc: 0.01573  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:27] d2.utils.events INFO:  eta: 1:05:09  iter: 45319  total_loss: 0.1334  loss_cls: 0.02404  loss_box_reg: 0.05847  loss_mask: 0.04983  loss_rpn_cls: 0.0005567  loss_rpn_loc: 0.008175  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:29] d2.utils.events INFO:  eta: 1:05:09  iter: 45339  total_loss: 0.3138  loss_cls: 0.04993  loss_box_reg: 0.1219  loss_mask: 0.1043  loss_rpn_cls: 0.00135  loss_rpn_loc: 0.02937  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:31] d2.utils.events INFO:  eta: 1:05:08  iter: 45359  total_loss: 0.2108  loss_cls: 0.03481  loss_box_reg: 0.08955  loss_mask: 0.06626  loss_rpn_cls: 0.0009574  loss_rpn_loc: 0.0158  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:33] d2.utils.events INFO:  eta: 1:05:06  iter: 45379  total_loss: 0.1311  loss_cls: 0.02197  loss_box_reg: 0.04661  loss_mask: 0.05626  loss_rpn_cls: 0.0004267  loss_rpn_loc: 0.009367  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:34] d2.utils.events INFO:  eta: 1:05:14  iter: 45399  total_loss: 0.2314  loss_cls: 0.02901  loss_box_reg: 0.09084  loss_mask: 0.07809  loss_rpn_cls: 0.0006126  loss_rpn_loc: 0.01592  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:36] d2.utils.events INFO:  eta: 1:05:18  iter: 45419  total_loss: 0.2105  loss_cls: 0.02607  loss_box_reg: 0.09719  loss_mask: 0.06596  loss_rpn_cls: 0.0005006  loss_rpn_loc: 0.01132  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:38] d2.utils.events INFO:  eta: 1:05:15  iter: 45439  total_loss: 0.2238  loss_cls: 0.0309  loss_box_reg: 0.0831  loss_mask: 0.06761  loss_rpn_cls: 0.0004498  loss_rpn_loc: 0.01268  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:40] d2.utils.events INFO:  eta: 1:05:15  iter: 45459  total_loss: 0.1247  loss_cls: 0.0178  loss_box_reg: 0.04999  loss_mask: 0.04878  loss_rpn_cls: 0.00031  loss_rpn_loc: 0.006843  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:42] d2.utils.events INFO:  eta: 1:05:11  iter: 45479  total_loss: 0.1928  loss_cls: 0.02841  loss_box_reg: 0.08427  loss_mask: 0.06782  loss_rpn_cls: 0.0005098  loss_rpn_loc: 0.01266  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:43] d2.utils.events INFO:  eta: 1:05:09  iter: 45499  total_loss: 0.1581  loss_cls: 0.02004  loss_box_reg: 0.07086  loss_mask: 0.06269  loss_rpn_cls: 0.000337  loss_rpn_loc: 0.006825  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:45] d2.utils.events INFO:  eta: 1:05:06  iter: 45519  total_loss: 0.1152  loss_cls: 0.01189  loss_box_reg: 0.05635  loss_mask: 0.04894  loss_rpn_cls: 0.0004911  loss_rpn_loc: 0.006268  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:47] d2.utils.events INFO:  eta: 1:04:58  iter: 45539  total_loss: 0.1531  loss_cls: 0.02426  loss_box_reg: 0.05776  loss_mask: 0.06168  loss_rpn_cls: 0.000591  loss_rpn_loc: 0.01707  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:48] d2.utils.events INFO:  eta: 1:05:00  iter: 45559  total_loss: 0.2401  loss_cls: 0.03418  loss_box_reg: 0.103  loss_mask: 0.06316  loss_rpn_cls: 0.0006025  loss_rpn_loc: 0.01709  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:50] d2.utils.events INFO:  eta: 1:04:55  iter: 45579  total_loss: 0.1982  loss_cls: 0.03203  loss_box_reg: 0.07363  loss_mask: 0.07924  loss_rpn_cls: 0.0005165  loss_rpn_loc: 0.01771  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:52] d2.utils.events INFO:  eta: 1:04:52  iter: 45599  total_loss: 0.2078  loss_cls: 0.02832  loss_box_reg: 0.09963  loss_mask: 0.06841  loss_rpn_cls: 0.0007711  loss_rpn_loc: 0.01799  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:44:54] d2.utils.events INFO:  eta: 1:04:47  iter: 45619  total_loss: 0.1217  loss_cls: 0.01224  loss_box_reg: 0.04724  loss_mask: 0.04769  loss_rpn_cls: 0.0004928  loss_rpn_loc: 0.01003  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:55] d2.utils.events INFO:  eta: 1:04:46  iter: 45639  total_loss: 0.1747  loss_cls: 0.03045  loss_box_reg: 0.07431  loss_mask: 0.06884  loss_rpn_cls: 0.0005342  loss_rpn_loc: 0.009471  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:57] d2.utils.events INFO:  eta: 1:04:46  iter: 45659  total_loss: 0.2688  loss_cls: 0.04015  loss_box_reg: 0.1267  loss_mask: 0.08131  loss_rpn_cls: 0.0008483  loss_rpn_loc: 0.01362  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:44:59] d2.utils.events INFO:  eta: 1:04:50  iter: 45679  total_loss: 0.1686  loss_cls: 0.03145  loss_box_reg: 0.064  loss_mask: 0.06164  loss_rpn_cls: 0.0006622  loss_rpn_loc: 0.01268  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:01] d2.utils.events INFO:  eta: 1:04:46  iter: 45699  total_loss: 0.1969  loss_cls: 0.03181  loss_box_reg: 0.08418  loss_mask: 0.065  loss_rpn_cls: 0.0008192  loss_rpn_loc: 0.01352  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:03] d2.utils.events INFO:  eta: 1:04:50  iter: 45719  total_loss: 0.2121  loss_cls: 0.03031  loss_box_reg: 0.1015  loss_mask: 0.06052  loss_rpn_cls: 0.0005704  loss_rpn_loc: 0.01102  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:04] d2.utils.events INFO:  eta: 1:04:48  iter: 45739  total_loss: 0.1581  loss_cls: 0.02538  loss_box_reg: 0.07266  loss_mask: 0.06784  loss_rpn_cls: 0.0004628  loss_rpn_loc: 0.009641  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:06] d2.utils.events INFO:  eta: 1:04:45  iter: 45759  total_loss: 0.1489  loss_cls: 0.01761  loss_box_reg: 0.07058  loss_mask: 0.05591  loss_rpn_cls: 0.0005954  loss_rpn_loc: 0.006955  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:08] d2.utils.events INFO:  eta: 1:04:43  iter: 45779  total_loss: 0.1883  loss_cls: 0.02371  loss_box_reg: 0.08582  loss_mask: 0.06385  loss_rpn_cls: 0.001128  loss_rpn_loc: 0.01292  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:10] d2.utils.events INFO:  eta: 1:04:39  iter: 45799  total_loss: 0.1752  loss_cls: 0.02447  loss_box_reg: 0.06925  loss_mask: 0.05408  loss_rpn_cls: 0.0004532  loss_rpn_loc: 0.009403  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:11] d2.utils.events INFO:  eta: 1:04:39  iter: 45819  total_loss: 0.277  loss_cls: 0.03694  loss_box_reg: 0.1167  loss_mask: 0.09268  loss_rpn_cls: 0.000794  loss_rpn_loc: 0.01551  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:13] d2.utils.events INFO:  eta: 1:04:38  iter: 45839  total_loss: 0.1731  loss_cls: 0.02827  loss_box_reg: 0.07421  loss_mask: 0.06383  loss_rpn_cls: 0.0008508  loss_rpn_loc: 0.01548  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:15] d2.utils.events INFO:  eta: 1:04:38  iter: 45859  total_loss: 0.204  loss_cls: 0.02888  loss_box_reg: 0.08272  loss_mask: 0.0674  loss_rpn_cls: 0.0004876  loss_rpn_loc: 0.007914  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:17] d2.utils.events INFO:  eta: 1:04:40  iter: 45879  total_loss: 0.168  loss_cls: 0.0247  loss_box_reg: 0.08971  loss_mask: 0.05041  loss_rpn_cls: 0.0003595  loss_rpn_loc: 0.00653  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:19] d2.utils.events INFO:  eta: 1:04:42  iter: 45899  total_loss: 0.161  loss_cls: 0.02169  loss_box_reg: 0.07124  loss_mask: 0.06277  loss_rpn_cls: 0.0003223  loss_rpn_loc: 0.007721  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:20] d2.utils.events INFO:  eta: 1:04:52  iter: 45919  total_loss: 0.2378  loss_cls: 0.03611  loss_box_reg: 0.1056  loss_mask: 0.07341  loss_rpn_cls: 0.0007228  loss_rpn_loc: 0.01634  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:22] d2.utils.events INFO:  eta: 1:04:36  iter: 45939  total_loss: 0.1237  loss_cls: 0.0159  loss_box_reg: 0.04575  loss_mask: 0.05796  loss_rpn_cls: 0.0004033  loss_rpn_loc: 0.004863  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:24] d2.utils.events INFO:  eta: 1:04:42  iter: 45959  total_loss: 0.1985  loss_cls: 0.03349  loss_box_reg: 0.08938  loss_mask: 0.06335  loss_rpn_cls: 0.0008104  loss_rpn_loc: 0.01987  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:26] d2.utils.events INFO:  eta: 1:04:40  iter: 45979  total_loss: 0.2123  loss_cls: 0.02433  loss_box_reg: 0.1111  loss_mask: 0.06302  loss_rpn_cls: 0.000965  loss_rpn_loc: 0.01553  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:27] d2.utils.events INFO:  eta: 1:04:33  iter: 45999  total_loss: 0.1946  loss_cls: 0.02739  loss_box_reg: 0.09975  loss_mask: 0.06162  loss_rpn_cls: 0.0008514  loss_rpn_loc: 0.01693  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:29] d2.utils.events INFO:  eta: 1:04:25  iter: 46019  total_loss: 0.16  loss_cls: 0.02909  loss_box_reg: 0.06798  loss_mask: 0.05462  loss_rpn_cls: 0.0005088  loss_rpn_loc: 0.01256  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:31] d2.utils.events INFO:  eta: 1:04:30  iter: 46039  total_loss: 0.1526  loss_cls: 0.0183  loss_box_reg: 0.06693  loss_mask: 0.06178  loss_rpn_cls: 0.0007228  loss_rpn_loc: 0.008345  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:33] d2.utils.events INFO:  eta: 1:04:28  iter: 46059  total_loss: 0.2147  loss_cls: 0.03002  loss_box_reg: 0.0838  loss_mask: 0.0723  loss_rpn_cls: 0.0006403  loss_rpn_loc: 0.01033  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:34] d2.utils.events INFO:  eta: 1:04:18  iter: 46079  total_loss: 0.1451  loss_cls: 0.02245  loss_box_reg: 0.06633  loss_mask: 0.05964  loss_rpn_cls: 0.0004715  loss_rpn_loc: 0.00867  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:36] d2.utils.events INFO:  eta: 1:04:16  iter: 46099  total_loss: 0.1953  loss_cls: 0.02415  loss_box_reg: 0.09226  loss_mask: 0.05825  loss_rpn_cls: 0.0008045  loss_rpn_loc: 0.01256  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:38] d2.utils.events INFO:  eta: 1:04:13  iter: 46119  total_loss: 0.1821  loss_cls: 0.02771  loss_box_reg: 0.08292  loss_mask: 0.06241  loss_rpn_cls: 0.0004362  loss_rpn_loc: 0.00929  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:40] d2.utils.events INFO:  eta: 1:04:13  iter: 46139  total_loss: 0.167  loss_cls: 0.02687  loss_box_reg: 0.06806  loss_mask: 0.06076  loss_rpn_cls: 0.0004855  loss_rpn_loc: 0.01019  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:41] d2.utils.events INFO:  eta: 1:04:09  iter: 46159  total_loss: 0.1728  loss_cls: 0.02719  loss_box_reg: 0.08642  loss_mask: 0.06347  loss_rpn_cls: 0.0004244  loss_rpn_loc: 0.01341  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:43] d2.utils.events INFO:  eta: 1:04:15  iter: 46179  total_loss: 0.2977  loss_cls: 0.04305  loss_box_reg: 0.1178  loss_mask: 0.06997  loss_rpn_cls: 0.001785  loss_rpn_loc: 0.02687  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:45] d2.utils.events INFO:  eta: 1:04:30  iter: 46199  total_loss: 0.2395  loss_cls: 0.03255  loss_box_reg: 0.1038  loss_mask: 0.06584  loss_rpn_cls: 0.0007908  loss_rpn_loc: 0.02071  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:45:47] d2.utils.events INFO:  eta: 1:04:19  iter: 46219  total_loss: 0.1587  loss_cls: 0.01966  loss_box_reg: 0.06741  loss_mask: 0.05966  loss_rpn_cls: 0.0004486  loss_rpn_loc: 0.008329  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:49] d2.utils.events INFO:  eta: 1:04:23  iter: 46239  total_loss: 0.1916  loss_cls: 0.02547  loss_box_reg: 0.07768  loss_mask: 0.0626  loss_rpn_cls: 0.0005626  loss_rpn_loc: 0.01434  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:50] d2.utils.events INFO:  eta: 1:04:22  iter: 46259  total_loss: 0.1612  loss_cls: 0.02208  loss_box_reg: 0.06738  loss_mask: 0.05503  loss_rpn_cls: 0.0006128  loss_rpn_loc: 0.01004  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:52] d2.utils.events INFO:  eta: 1:04:16  iter: 46279  total_loss: 0.1891  loss_cls: 0.02579  loss_box_reg: 0.08255  loss_mask: 0.06341  loss_rpn_cls: 0.0004447  loss_rpn_loc: 0.01082  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:54] d2.utils.events INFO:  eta: 1:04:10  iter: 46299  total_loss: 0.1583  loss_cls: 0.02364  loss_box_reg: 0.0663  loss_mask: 0.05923  loss_rpn_cls: 0.0004731  loss_rpn_loc: 0.007582  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:55] d2.utils.events INFO:  eta: 1:04:10  iter: 46319  total_loss: 0.1363  loss_cls: 0.01892  loss_box_reg: 0.05141  loss_mask: 0.05596  loss_rpn_cls: 0.0008396  loss_rpn_loc: 0.009508  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:45:57] d2.utils.events INFO:  eta: 1:03:50  iter: 46339  total_loss: 0.1415  loss_cls: 0.01257  loss_box_reg: 0.0417  loss_mask: 0.05989  loss_rpn_cls: 0.0004066  loss_rpn_loc: 0.00648  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:45:59] d2.utils.events INFO:  eta: 1:03:51  iter: 46359  total_loss: 0.2034  loss_cls: 0.03747  loss_box_reg: 0.07658  loss_mask: 0.08131  loss_rpn_cls: 0.0007017  loss_rpn_loc: 0.01441  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:01] d2.utils.events INFO:  eta: 1:03:57  iter: 46379  total_loss: 0.1971  loss_cls: 0.03691  loss_box_reg: 0.08145  loss_mask: 0.06437  loss_rpn_cls: 0.0004761  loss_rpn_loc: 0.01205  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:03] d2.utils.events INFO:  eta: 1:03:58  iter: 46399  total_loss: 0.2575  loss_cls: 0.04881  loss_box_reg: 0.1131  loss_mask: 0.08722  loss_rpn_cls: 0.001889  loss_rpn_loc: 0.02086  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:04] d2.utils.events INFO:  eta: 1:03:53  iter: 46419  total_loss: 0.1923  loss_cls: 0.02333  loss_box_reg: 0.08039  loss_mask: 0.05825  loss_rpn_cls: 0.000781  loss_rpn_loc: 0.01064  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:46:06] d2.utils.events INFO:  eta: 1:03:49  iter: 46439  total_loss: 0.1691  loss_cls: 0.0258  loss_box_reg: 0.06572  loss_mask: 0.06265  loss_rpn_cls: 0.0003957  loss_rpn_loc: 0.009707  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:08] d2.utils.events INFO:  eta: 1:03:50  iter: 46459  total_loss: 0.1811  loss_cls: 0.03392  loss_box_reg: 0.07597  loss_mask: 0.05454  loss_rpn_cls: 0.0005525  loss_rpn_loc: 0.01333  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:10] d2.utils.events INFO:  eta: 1:03:48  iter: 46479  total_loss: 0.2127  loss_cls: 0.03718  loss_box_reg: 0.09225  loss_mask: 0.06274  loss_rpn_cls: 0.00101  loss_rpn_loc: 0.01221  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:11] d2.utils.events INFO:  eta: 1:03:43  iter: 46499  total_loss: 0.1403  loss_cls: 0.01735  loss_box_reg: 0.06033  loss_mask: 0.06268  loss_rpn_cls: 0.0003643  loss_rpn_loc: 0.01063  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:13] d2.utils.events INFO:  eta: 1:03:42  iter: 46519  total_loss: 0.172  loss_cls: 0.02778  loss_box_reg: 0.0711  loss_mask: 0.04976  loss_rpn_cls: 0.0005685  loss_rpn_loc: 0.01002  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:15] d2.utils.events INFO:  eta: 1:03:45  iter: 46539  total_loss: 0.202  loss_cls: 0.02972  loss_box_reg: 0.09591  loss_mask: 0.07219  loss_rpn_cls: 0.0007046  loss_rpn_loc: 0.01066  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:17] d2.utils.events INFO:  eta: 1:03:36  iter: 46559  total_loss: 0.1585  loss_cls: 0.02143  loss_box_reg: 0.06964  loss_mask: 0.06252  loss_rpn_cls: 0.0002886  loss_rpn_loc: 0.008967  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:18] d2.utils.events INFO:  eta: 1:03:36  iter: 46579  total_loss: 0.1799  loss_cls: 0.03009  loss_box_reg: 0.08065  loss_mask: 0.06993  loss_rpn_cls: 0.000533  loss_rpn_loc: 0.01582  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1493M
[10/27 19:46:20] d2.utils.events INFO:  eta: 1:03:35  iter: 46599  total_loss: 0.1525  loss_cls: 0.02291  loss_box_reg: 0.07258  loss_mask: 0.05305  loss_rpn_cls: 0.0004268  loss_rpn_loc: 0.008253  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:22] d2.utils.events INFO:  eta: 1:03:40  iter: 46619  total_loss: 0.1853  loss_cls: 0.03002  loss_box_reg: 0.07554  loss_mask: 0.06234  loss_rpn_cls: 0.0005911  loss_rpn_loc: 0.01541  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:24] d2.utils.events INFO:  eta: 1:03:36  iter: 46639  total_loss: 0.1572  loss_cls: 0.02332  loss_box_reg: 0.06674  loss_mask: 0.05586  loss_rpn_cls: 0.0006296  loss_rpn_loc: 0.007909  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:25] d2.utils.events INFO:  eta: 1:03:30  iter: 46659  total_loss: 0.1859  loss_cls: 0.0297  loss_box_reg: 0.0858  loss_mask: 0.07314  loss_rpn_cls: 0.000521  loss_rpn_loc: 0.01186  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:27] d2.utils.events INFO:  eta: 1:03:27  iter: 46679  total_loss: 0.2076  loss_cls: 0.02429  loss_box_reg: 0.05304  loss_mask: 0.0691  loss_rpn_cls: 0.0007614  loss_rpn_loc: 0.01419  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:29] d2.utils.events INFO:  eta: 1:03:26  iter: 46699  total_loss: 0.1866  loss_cls: 0.02402  loss_box_reg: 0.07114  loss_mask: 0.07263  loss_rpn_cls: 0.0004922  loss_rpn_loc: 0.0103  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:31] d2.utils.events INFO:  eta: 1:03:18  iter: 46719  total_loss: 0.1686  loss_cls: 0.02089  loss_box_reg: 0.0651  loss_mask: 0.05788  loss_rpn_cls: 0.0003528  loss_rpn_loc: 0.009989  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:33] d2.utils.events INFO:  eta: 1:03:23  iter: 46739  total_loss: 0.225  loss_cls: 0.03095  loss_box_reg: 0.09166  loss_mask: 0.0658  loss_rpn_cls: 0.0008106  loss_rpn_loc: 0.0119  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:34] d2.utils.events INFO:  eta: 1:03:18  iter: 46759  total_loss: 0.157  loss_cls: 0.0205  loss_box_reg: 0.05645  loss_mask: 0.05676  loss_rpn_cls: 0.000911  loss_rpn_loc: 0.008163  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:36] d2.utils.events INFO:  eta: 1:03:05  iter: 46779  total_loss: 0.1391  loss_cls: 0.01901  loss_box_reg: 0.05858  loss_mask: 0.05291  loss_rpn_cls: 0.0008621  loss_rpn_loc: 0.008715  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:46:38] d2.utils.events INFO:  eta: 1:03:06  iter: 46799  total_loss: 0.1574  loss_cls: 0.02129  loss_box_reg: 0.06471  loss_mask: 0.06061  loss_rpn_cls: 0.0006  loss_rpn_loc: 0.01535  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:40] d2.utils.events INFO:  eta: 1:03:08  iter: 46819  total_loss: 0.2809  loss_cls: 0.03142  loss_box_reg: 0.1192  loss_mask: 0.08918  loss_rpn_cls: 0.0009808  loss_rpn_loc: 0.02453  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:41] d2.utils.events INFO:  eta: 1:03:05  iter: 46839  total_loss: 0.1692  loss_cls: 0.01945  loss_box_reg: 0.07577  loss_mask: 0.05984  loss_rpn_cls: 0.0006441  loss_rpn_loc: 0.01555  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:43] d2.utils.events INFO:  eta: 1:03:03  iter: 46859  total_loss: 0.1587  loss_cls: 0.02604  loss_box_reg: 0.07495  loss_mask: 0.05351  loss_rpn_cls: 0.0006571  loss_rpn_loc: 0.009151  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:45] d2.utils.events INFO:  eta: 1:03:03  iter: 46879  total_loss: 0.1893  loss_cls: 0.03528  loss_box_reg: 0.07817  loss_mask: 0.06527  loss_rpn_cls: 0.000406  loss_rpn_loc: 0.01441  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:47] d2.utils.events INFO:  eta: 1:02:59  iter: 46899  total_loss: 0.1905  loss_cls: 0.02855  loss_box_reg: 0.07107  loss_mask: 0.06493  loss_rpn_cls: 0.000744  loss_rpn_loc: 0.008213  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:48] d2.utils.events INFO:  eta: 1:02:53  iter: 46919  total_loss: 0.1445  loss_cls: 0.02557  loss_box_reg: 0.07497  loss_mask: 0.04737  loss_rpn_cls: 0.0003905  loss_rpn_loc: 0.006445  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:50] d2.utils.events INFO:  eta: 1:03:05  iter: 46939  total_loss: 0.2471  loss_cls: 0.03055  loss_box_reg: 0.1224  loss_mask: 0.06509  loss_rpn_cls: 0.0004536  loss_rpn_loc: 0.01084  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:52] d2.utils.events INFO:  eta: 1:02:58  iter: 46959  total_loss: 0.1769  loss_cls: 0.02947  loss_box_reg: 0.07559  loss_mask: 0.0588  loss_rpn_cls: 0.0009246  loss_rpn_loc: 0.01349  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:54] d2.utils.events INFO:  eta: 1:02:58  iter: 46979  total_loss: 0.2087  loss_cls: 0.03194  loss_box_reg: 0.1022  loss_mask: 0.07307  loss_rpn_cls: 0.0008177  loss_rpn_loc: 0.01137  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:56] d2.utils.events INFO:  eta: 1:03:04  iter: 46999  total_loss: 0.2172  loss_cls: 0.02872  loss_box_reg: 0.09681  loss_mask: 0.06271  loss_rpn_cls: 0.0007278  loss_rpn_loc: 0.008458  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:46:57] d2.utils.events INFO:  eta: 1:03:03  iter: 47019  total_loss: 0.1616  loss_cls: 0.02127  loss_box_reg: 0.05956  loss_mask: 0.06183  loss_rpn_cls: 0.000408  loss_rpn_loc: 0.005405  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:46:59] d2.utils.events INFO:  eta: 1:03:03  iter: 47039  total_loss: 0.237  loss_cls: 0.02949  loss_box_reg: 0.1197  loss_mask: 0.06667  loss_rpn_cls: 0.0005357  loss_rpn_loc: 0.01279  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:01] d2.utils.events INFO:  eta: 1:02:59  iter: 47059  total_loss: 0.2003  loss_cls: 0.03995  loss_box_reg: 0.09059  loss_mask: 0.06992  loss_rpn_cls: 0.001057  loss_rpn_loc: 0.01817  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:03] d2.utils.events INFO:  eta: 1:03:02  iter: 47079  total_loss: 0.2194  loss_cls: 0.04102  loss_box_reg: 0.102  loss_mask: 0.06509  loss_rpn_cls: 0.000869  loss_rpn_loc: 0.0135  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:04] d2.utils.events INFO:  eta: 1:02:58  iter: 47099  total_loss: 0.1159  loss_cls: 0.02028  loss_box_reg: 0.0356  loss_mask: 0.04163  loss_rpn_cls: 0.0002996  loss_rpn_loc: 0.004195  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:06] d2.utils.events INFO:  eta: 1:02:56  iter: 47119  total_loss: 0.2261  loss_cls: 0.03677  loss_box_reg: 0.104  loss_mask: 0.07468  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.01876  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:08] d2.utils.events INFO:  eta: 1:02:54  iter: 47139  total_loss: 0.1735  loss_cls: 0.02186  loss_box_reg: 0.07224  loss_mask: 0.05313  loss_rpn_cls: 0.0004355  loss_rpn_loc: 0.01104  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:10] d2.utils.events INFO:  eta: 1:02:47  iter: 47159  total_loss: 0.1572  loss_cls: 0.02282  loss_box_reg: 0.0535  loss_mask: 0.05663  loss_rpn_cls: 0.0003808  loss_rpn_loc: 0.00953  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:11] d2.utils.events INFO:  eta: 1:02:37  iter: 47179  total_loss: 0.2623  loss_cls: 0.03818  loss_box_reg: 0.09943  loss_mask: 0.07281  loss_rpn_cls: 0.001149  loss_rpn_loc: 0.01855  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:13] d2.utils.events INFO:  eta: 1:02:33  iter: 47199  total_loss: 0.247  loss_cls: 0.04145  loss_box_reg: 0.101  loss_mask: 0.07478  loss_rpn_cls: 0.0007117  loss_rpn_loc: 0.02611  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:15] d2.utils.events INFO:  eta: 1:02:30  iter: 47219  total_loss: 0.1604  loss_cls: 0.026  loss_box_reg: 0.06348  loss_mask: 0.0532  loss_rpn_cls: 0.0004482  loss_rpn_loc: 0.01088  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:17] d2.utils.events INFO:  eta: 1:02:28  iter: 47239  total_loss: 0.2164  loss_cls: 0.0308  loss_box_reg: 0.1015  loss_mask: 0.07584  loss_rpn_cls: 0.0006451  loss_rpn_loc: 0.0132  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:47:19] d2.utils.events INFO:  eta: 1:02:23  iter: 47259  total_loss: 0.1413  loss_cls: 0.02474  loss_box_reg: 0.07002  loss_mask: 0.05331  loss_rpn_cls: 0.0005138  loss_rpn_loc: 0.009277  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:20] d2.utils.events INFO:  eta: 1:02:34  iter: 47279  total_loss: 0.2285  loss_cls: 0.03702  loss_box_reg: 0.08367  loss_mask: 0.06726  loss_rpn_cls: 0.0006394  loss_rpn_loc: 0.01691  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:22] d2.utils.events INFO:  eta: 1:02:37  iter: 47299  total_loss: 0.1641  loss_cls: 0.02217  loss_box_reg: 0.07308  loss_mask: 0.04731  loss_rpn_cls: 0.0005823  loss_rpn_loc: 0.008854  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:24] d2.utils.events INFO:  eta: 1:02:36  iter: 47319  total_loss: 0.2027  loss_cls: 0.02901  loss_box_reg: 0.08845  loss_mask: 0.06623  loss_rpn_cls: 0.0007045  loss_rpn_loc: 0.01459  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:25] d2.utils.events INFO:  eta: 1:02:41  iter: 47339  total_loss: 0.1297  loss_cls: 0.01414  loss_box_reg: 0.05059  loss_mask: 0.05188  loss_rpn_cls: 0.0002408  loss_rpn_loc: 0.006255  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:27] d2.utils.events INFO:  eta: 1:02:39  iter: 47359  total_loss: 0.2438  loss_cls: 0.03523  loss_box_reg: 0.1022  loss_mask: 0.07816  loss_rpn_cls: 0.0003005  loss_rpn_loc: 0.01085  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:29] d2.utils.events INFO:  eta: 1:02:30  iter: 47379  total_loss: 0.165  loss_cls: 0.02031  loss_box_reg: 0.0685  loss_mask: 0.06196  loss_rpn_cls: 0.000403  loss_rpn_loc: 0.009444  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:31] d2.utils.events INFO:  eta: 1:02:22  iter: 47399  total_loss: 0.1536  loss_cls: 0.02552  loss_box_reg: 0.06822  loss_mask: 0.05665  loss_rpn_cls: 0.0007113  loss_rpn_loc: 0.01356  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:33] d2.utils.events INFO:  eta: 1:02:20  iter: 47419  total_loss: 0.1756  loss_cls: 0.0259  loss_box_reg: 0.07321  loss_mask: 0.05959  loss_rpn_cls: 0.0009734  loss_rpn_loc: 0.01134  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:34] d2.utils.events INFO:  eta: 1:02:17  iter: 47439  total_loss: 0.1487  loss_cls: 0.02744  loss_box_reg: 0.06928  loss_mask: 0.05245  loss_rpn_cls: 0.0004145  loss_rpn_loc: 0.007298  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:36] d2.utils.events INFO:  eta: 1:02:12  iter: 47459  total_loss: 0.1357  loss_cls: 0.01307  loss_box_reg: 0.04918  loss_mask: 0.06074  loss_rpn_cls: 0.0003283  loss_rpn_loc: 0.007009  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:38] d2.utils.events INFO:  eta: 1:02:10  iter: 47479  total_loss: 0.1795  loss_cls: 0.02682  loss_box_reg: 0.08099  loss_mask: 0.05975  loss_rpn_cls: 0.0004749  loss_rpn_loc: 0.01145  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:40] d2.utils.events INFO:  eta: 1:02:11  iter: 47499  total_loss: 0.22  loss_cls: 0.03083  loss_box_reg: 0.1034  loss_mask: 0.06228  loss_rpn_cls: 0.0009727  loss_rpn_loc: 0.01729  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:41] d2.utils.events INFO:  eta: 1:02:09  iter: 47519  total_loss: 0.1953  loss_cls: 0.02542  loss_box_reg: 0.1092  loss_mask: 0.0535  loss_rpn_cls: 0.000427  loss_rpn_loc: 0.009359  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:43] d2.utils.events INFO:  eta: 1:02:11  iter: 47539  total_loss: 0.3296  loss_cls: 0.04455  loss_box_reg: 0.1476  loss_mask: 0.08132  loss_rpn_cls: 0.0008422  loss_rpn_loc: 0.02086  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:45] d2.utils.events INFO:  eta: 1:02:21  iter: 47559  total_loss: 0.2422  loss_cls: 0.03812  loss_box_reg: 0.1026  loss_mask: 0.06054  loss_rpn_cls: 0.0006436  loss_rpn_loc: 0.01778  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:47] d2.utils.events INFO:  eta: 1:02:24  iter: 47579  total_loss: 0.1965  loss_cls: 0.02355  loss_box_reg: 0.07507  loss_mask: 0.05796  loss_rpn_cls: 0.0006204  loss_rpn_loc: 0.009855  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:49] d2.utils.events INFO:  eta: 1:02:25  iter: 47599  total_loss: 0.1974  loss_cls: 0.03219  loss_box_reg: 0.08895  loss_mask: 0.06293  loss_rpn_cls: 0.0005793  loss_rpn_loc: 0.01444  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:47:50] d2.utils.events INFO:  eta: 1:02:23  iter: 47619  total_loss: 0.1645  loss_cls: 0.02372  loss_box_reg: 0.07729  loss_mask: 0.06711  loss_rpn_cls: 0.000942  loss_rpn_loc: 0.01168  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:47:52] d2.utils.events INFO:  eta: 1:02:25  iter: 47639  total_loss: 0.2126  loss_cls: 0.03287  loss_box_reg: 0.08021  loss_mask: 0.07137  loss_rpn_cls: 0.0007291  loss_rpn_loc: 0.01314  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:54] d2.utils.events INFO:  eta: 1:02:25  iter: 47659  total_loss: 0.2457  loss_cls: 0.03328  loss_box_reg: 0.09038  loss_mask: 0.05426  loss_rpn_cls: 0.0005987  loss_rpn_loc: 0.01024  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:56] d2.utils.events INFO:  eta: 1:02:21  iter: 47679  total_loss: 0.145  loss_cls: 0.02389  loss_box_reg: 0.06411  loss_mask: 0.04865  loss_rpn_cls: 0.0004323  loss_rpn_loc: 0.01234  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:47:58] d2.utils.events INFO:  eta: 1:02:17  iter: 47699  total_loss: 0.1475  loss_cls: 0.02529  loss_box_reg: 0.07312  loss_mask: 0.0503  loss_rpn_cls: 0.0003524  loss_rpn_loc: 0.006748  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:47:59] d2.utils.events INFO:  eta: 1:02:16  iter: 47719  total_loss: 0.13  loss_cls: 0.01729  loss_box_reg: 0.05723  loss_mask: 0.05615  loss_rpn_cls: 0.0004512  loss_rpn_loc: 0.005077  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:01] d2.utils.events INFO:  eta: 1:02:06  iter: 47739  total_loss: 0.1433  loss_cls: 0.02013  loss_box_reg: 0.06936  loss_mask: 0.04874  loss_rpn_cls: 0.0003889  loss_rpn_loc: 0.009104  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:03] d2.utils.events INFO:  eta: 1:02:06  iter: 47759  total_loss: 0.1704  loss_cls: 0.02315  loss_box_reg: 0.08248  loss_mask: 0.0631  loss_rpn_cls: 0.0008019  loss_rpn_loc: 0.0088  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:05] d2.utils.events INFO:  eta: 1:02:12  iter: 47779  total_loss: 0.2113  loss_cls: 0.03748  loss_box_reg: 0.08702  loss_mask: 0.05717  loss_rpn_cls: 0.0007207  loss_rpn_loc: 0.01604  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:48:06] d2.utils.events INFO:  eta: 1:02:07  iter: 47799  total_loss: 0.1824  loss_cls: 0.02652  loss_box_reg: 0.0834  loss_mask: 0.06628  loss_rpn_cls: 0.0005349  loss_rpn_loc: 0.01437  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:08] d2.utils.events INFO:  eta: 1:02:02  iter: 47819  total_loss: 0.2086  loss_cls: 0.03388  loss_box_reg: 0.09355  loss_mask: 0.07922  loss_rpn_cls: 0.0007178  loss_rpn_loc: 0.009354  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:10] d2.utils.events INFO:  eta: 1:02:08  iter: 47839  total_loss: 0.2373  loss_cls: 0.02932  loss_box_reg: 0.09458  loss_mask: 0.06334  loss_rpn_cls: 0.0008414  loss_rpn_loc: 0.01632  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:12] d2.utils.events INFO:  eta: 1:02:08  iter: 47859  total_loss: 0.2812  loss_cls: 0.0373  loss_box_reg: 0.1013  loss_mask: 0.09798  loss_rpn_cls: 0.001167  loss_rpn_loc: 0.02342  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:13] d2.utils.events INFO:  eta: 1:02:04  iter: 47879  total_loss: 0.1325  loss_cls: 0.01703  loss_box_reg: 0.05488  loss_mask: 0.04768  loss_rpn_cls: 0.0004627  loss_rpn_loc: 0.005457  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:15] d2.utils.events INFO:  eta: 1:02:03  iter: 47899  total_loss: 0.2025  loss_cls: 0.03503  loss_box_reg: 0.1031  loss_mask: 0.06568  loss_rpn_cls: 0.0009247  loss_rpn_loc: 0.01065  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:17] d2.utils.events INFO:  eta: 1:02:02  iter: 47919  total_loss: 0.1983  loss_cls: 0.02756  loss_box_reg: 0.07753  loss_mask: 0.06394  loss_rpn_cls: 0.0009044  loss_rpn_loc: 0.01513  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:19] d2.utils.events INFO:  eta: 1:01:59  iter: 47939  total_loss: 0.1895  loss_cls: 0.0294  loss_box_reg: 0.08419  loss_mask: 0.06074  loss_rpn_cls: 0.0008003  loss_rpn_loc: 0.01193  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:20] d2.utils.events INFO:  eta: 1:01:54  iter: 47959  total_loss: 0.0982  loss_cls: 0.01305  loss_box_reg: 0.03708  loss_mask: 0.05065  loss_rpn_cls: 0.0005483  loss_rpn_loc: 0.008666  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:22] d2.utils.events INFO:  eta: 1:01:54  iter: 47979  total_loss: 0.1545  loss_cls: 0.02072  loss_box_reg: 0.0687  loss_mask: 0.05411  loss_rpn_cls: 0.0004909  loss_rpn_loc: 0.009324  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:24] d2.utils.events INFO:  eta: 1:01:38  iter: 47999  total_loss: 0.1207  loss_cls: 0.01601  loss_box_reg: 0.03969  loss_mask: 0.06063  loss_rpn_cls: 0.0006576  loss_rpn_loc: 0.008951  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:26] d2.utils.events INFO:  eta: 1:01:43  iter: 48019  total_loss: 0.2283  loss_cls: 0.0299  loss_box_reg: 0.07081  loss_mask: 0.06719  loss_rpn_cls: 0.0006348  loss_rpn_loc: 0.01007  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:27] d2.utils.events INFO:  eta: 1:01:39  iter: 48039  total_loss: 0.1608  loss_cls: 0.02718  loss_box_reg: 0.06986  loss_mask: 0.05872  loss_rpn_cls: 0.0006046  loss_rpn_loc: 0.01271  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:29] d2.utils.events INFO:  eta: 1:01:40  iter: 48059  total_loss: 0.2347  loss_cls: 0.03732  loss_box_reg: 0.09378  loss_mask: 0.07373  loss_rpn_cls: 0.0006944  loss_rpn_loc: 0.01586  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:31] d2.utils.events INFO:  eta: 1:01:40  iter: 48079  total_loss: 0.2206  loss_cls: 0.03447  loss_box_reg: 0.08804  loss_mask: 0.06507  loss_rpn_cls: 0.0009085  loss_rpn_loc: 0.02115  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:33] d2.utils.events INFO:  eta: 1:01:43  iter: 48099  total_loss: 0.1774  loss_cls: 0.0263  loss_box_reg: 0.08131  loss_mask: 0.05742  loss_rpn_cls: 0.0005132  loss_rpn_loc: 0.01046  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:35] d2.utils.events INFO:  eta: 1:01:40  iter: 48119  total_loss: 0.2737  loss_cls: 0.0489  loss_box_reg: 0.1147  loss_mask: 0.08178  loss_rpn_cls: 0.001249  loss_rpn_loc: 0.01809  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:36] d2.utils.events INFO:  eta: 1:01:40  iter: 48139  total_loss: 0.2314  loss_cls: 0.0396  loss_box_reg: 0.08893  loss_mask: 0.07546  loss_rpn_cls: 0.0007071  loss_rpn_loc: 0.02332  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:48:38] d2.utils.events INFO:  eta: 1:01:34  iter: 48159  total_loss: 0.1204  loss_cls: 0.01506  loss_box_reg: 0.04193  loss_mask: 0.04138  loss_rpn_cls: 0.0002779  loss_rpn_loc: 0.005799  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:40] d2.utils.events INFO:  eta: 1:01:29  iter: 48179  total_loss: 0.1746  loss_cls: 0.02485  loss_box_reg: 0.07367  loss_mask: 0.05769  loss_rpn_cls: 0.0006674  loss_rpn_loc: 0.01472  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:42] d2.utils.events INFO:  eta: 1:01:26  iter: 48199  total_loss: 0.1645  loss_cls: 0.02556  loss_box_reg: 0.07432  loss_mask: 0.05427  loss_rpn_cls: 0.0007064  loss_rpn_loc: 0.01661  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:43] d2.utils.events INFO:  eta: 1:01:30  iter: 48219  total_loss: 0.2634  loss_cls: 0.04248  loss_box_reg: 0.1181  loss_mask: 0.0688  loss_rpn_cls: 0.001052  loss_rpn_loc: 0.02344  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:45] d2.utils.events INFO:  eta: 1:01:23  iter: 48239  total_loss: 0.1776  loss_cls: 0.03271  loss_box_reg: 0.08754  loss_mask: 0.0553  loss_rpn_cls: 0.000778  loss_rpn_loc: 0.01193  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:47] d2.utils.events INFO:  eta: 1:01:30  iter: 48259  total_loss: 0.1672  loss_cls: 0.02233  loss_box_reg: 0.0728  loss_mask: 0.05941  loss_rpn_cls: 0.0006592  loss_rpn_loc: 0.01242  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:49] d2.utils.events INFO:  eta: 1:01:18  iter: 48279  total_loss: 0.1813  loss_cls: 0.01661  loss_box_reg: 0.05901  loss_mask: 0.06081  loss_rpn_cls: 0.0004575  loss_rpn_loc: 0.009395  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:50] d2.utils.events INFO:  eta: 1:01:17  iter: 48299  total_loss: 0.2028  loss_cls: 0.02932  loss_box_reg: 0.09272  loss_mask: 0.06073  loss_rpn_cls: 0.0007558  loss_rpn_loc: 0.01299  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:48:52] d2.utils.events INFO:  eta: 1:01:24  iter: 48319  total_loss: 0.1823  loss_cls: 0.0258  loss_box_reg: 0.08564  loss_mask: 0.06996  loss_rpn_cls: 0.0009102  loss_rpn_loc: 0.01322  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:54] d2.utils.events INFO:  eta: 1:01:26  iter: 48339  total_loss: 0.2059  loss_cls: 0.03944  loss_box_reg: 0.08409  loss_mask: 0.07608  loss_rpn_cls: 0.0007685  loss_rpn_loc: 0.01382  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:56] d2.utils.events INFO:  eta: 1:01:25  iter: 48359  total_loss: 0.2182  loss_cls: 0.02975  loss_box_reg: 0.1022  loss_mask: 0.06887  loss_rpn_cls: 0.0008259  loss_rpn_loc: 0.01234  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:48:58] d2.utils.events INFO:  eta: 1:01:22  iter: 48379  total_loss: 0.1576  loss_cls: 0.02024  loss_box_reg: 0.05162  loss_mask: 0.05943  loss_rpn_cls: 0.0004078  loss_rpn_loc: 0.007462  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:48:59] d2.utils.events INFO:  eta: 1:01:20  iter: 48399  total_loss: 0.1912  loss_cls: 0.02364  loss_box_reg: 0.0826  loss_mask: 0.06931  loss_rpn_cls: 0.0006353  loss_rpn_loc: 0.01424  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:01] d2.utils.events INFO:  eta: 1:01:19  iter: 48419  total_loss: 0.2217  loss_cls: 0.03837  loss_box_reg: 0.1001  loss_mask: 0.05583  loss_rpn_cls: 0.0007479  loss_rpn_loc: 0.01839  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:03] d2.utils.events INFO:  eta: 1:01:17  iter: 48439  total_loss: 0.1303  loss_cls: 0.01336  loss_box_reg: 0.0409  loss_mask: 0.05334  loss_rpn_cls: 0.0003298  loss_rpn_loc: 0.005477  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:05] d2.utils.events INFO:  eta: 1:01:15  iter: 48459  total_loss: 0.1214  loss_cls: 0.01761  loss_box_reg: 0.05736  loss_mask: 0.04922  loss_rpn_cls: 0.0002366  loss_rpn_loc: 0.006524  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:06] d2.utils.events INFO:  eta: 1:01:13  iter: 48479  total_loss: 0.1456  loss_cls: 0.01676  loss_box_reg: 0.05274  loss_mask: 0.05989  loss_rpn_cls: 0.000731  loss_rpn_loc: 0.009609  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:08] d2.utils.events INFO:  eta: 1:01:12  iter: 48499  total_loss: 0.2157  loss_cls: 0.03428  loss_box_reg: 0.09578  loss_mask: 0.06929  loss_rpn_cls: 0.0006472  loss_rpn_loc: 0.01395  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:10] d2.utils.events INFO:  eta: 1:01:10  iter: 48519  total_loss: 0.2041  loss_cls: 0.03249  loss_box_reg: 0.08449  loss_mask: 0.07154  loss_rpn_cls: 0.0005521  loss_rpn_loc: 0.009797  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:12] d2.utils.events INFO:  eta: 1:01:07  iter: 48539  total_loss: 0.1403  loss_cls: 0.01959  loss_box_reg: 0.06645  loss_mask: 0.05127  loss_rpn_cls: 0.0006559  loss_rpn_loc: 0.00872  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:13] d2.utils.events INFO:  eta: 1:01:03  iter: 48559  total_loss: 0.1924  loss_cls: 0.03086  loss_box_reg: 0.08236  loss_mask: 0.06164  loss_rpn_cls: 0.0004481  loss_rpn_loc: 0.01056  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:15] d2.utils.events INFO:  eta: 1:00:53  iter: 48579  total_loss: 0.1705  loss_cls: 0.02781  loss_box_reg: 0.0719  loss_mask: 0.06845  loss_rpn_cls: 0.0009279  loss_rpn_loc: 0.007972  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:17] d2.utils.events INFO:  eta: 1:00:48  iter: 48599  total_loss: 0.1535  loss_cls: 0.01709  loss_box_reg: 0.05906  loss_mask: 0.05369  loss_rpn_cls: 0.0005052  loss_rpn_loc: 0.01069  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:19] d2.utils.events INFO:  eta: 1:00:42  iter: 48619  total_loss: 0.1176  loss_cls: 0.01533  loss_box_reg: 0.0432  loss_mask: 0.05842  loss_rpn_cls: 0.0002768  loss_rpn_loc: 0.004937  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:20] d2.utils.events INFO:  eta: 1:00:38  iter: 48639  total_loss: 0.1949  loss_cls: 0.03111  loss_box_reg: 0.07453  loss_mask: 0.06384  loss_rpn_cls: 0.0005381  loss_rpn_loc: 0.01791  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:22] d2.utils.events INFO:  eta: 1:00:39  iter: 48659  total_loss: 0.3046  loss_cls: 0.05307  loss_box_reg: 0.1174  loss_mask: 0.09741  loss_rpn_cls: 0.0007157  loss_rpn_loc: 0.01808  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:49:24] d2.utils.events INFO:  eta: 1:00:41  iter: 48679  total_loss: 0.2408  loss_cls: 0.03547  loss_box_reg: 0.102  loss_mask: 0.07411  loss_rpn_cls: 0.0007244  loss_rpn_loc: 0.01944  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:26] d2.utils.events INFO:  eta: 1:00:43  iter: 48699  total_loss: 0.2332  loss_cls: 0.03905  loss_box_reg: 0.1134  loss_mask: 0.06412  loss_rpn_cls: 0.0006724  loss_rpn_loc: 0.01199  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:28] d2.utils.events INFO:  eta: 1:00:40  iter: 48719  total_loss: 0.1857  loss_cls: 0.02507  loss_box_reg: 0.09011  loss_mask: 0.06084  loss_rpn_cls: 0.000787  loss_rpn_loc: 0.01915  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:29] d2.utils.events INFO:  eta: 1:00:40  iter: 48739  total_loss: 0.1799  loss_cls: 0.02658  loss_box_reg: 0.07817  loss_mask: 0.05788  loss_rpn_cls: 0.0002374  loss_rpn_loc: 0.007545  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:31] d2.utils.events INFO:  eta: 1:00:44  iter: 48759  total_loss: 0.1489  loss_cls: 0.02253  loss_box_reg: 0.05966  loss_mask: 0.05486  loss_rpn_cls: 0.0004704  loss_rpn_loc: 0.008307  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:33] d2.utils.events INFO:  eta: 1:00:34  iter: 48779  total_loss: 0.1579  loss_cls: 0.02272  loss_box_reg: 0.08247  loss_mask: 0.0461  loss_rpn_cls: 0.0003996  loss_rpn_loc: 0.008228  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:35] d2.utils.events INFO:  eta: 1:00:35  iter: 48799  total_loss: 0.1939  loss_cls: 0.02975  loss_box_reg: 0.09466  loss_mask: 0.06489  loss_rpn_cls: 0.0006473  loss_rpn_loc: 0.01528  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:36] d2.utils.events INFO:  eta: 1:00:31  iter: 48819  total_loss: 0.1547  loss_cls: 0.02304  loss_box_reg: 0.06449  loss_mask: 0.05564  loss_rpn_cls: 0.0007564  loss_rpn_loc: 0.01304  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:38] d2.utils.events INFO:  eta: 1:00:29  iter: 48839  total_loss: 0.155  loss_cls: 0.01993  loss_box_reg: 0.07163  loss_mask: 0.06118  loss_rpn_cls: 0.0004419  loss_rpn_loc: 0.009035  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:40] d2.utils.events INFO:  eta: 1:00:25  iter: 48859  total_loss: 0.2692  loss_cls: 0.04342  loss_box_reg: 0.1113  loss_mask: 0.07268  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.031  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:42] d2.utils.events INFO:  eta: 1:00:30  iter: 48879  total_loss: 0.1977  loss_cls: 0.03232  loss_box_reg: 0.08208  loss_mask: 0.05772  loss_rpn_cls: 0.0004268  loss_rpn_loc: 0.01207  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:44] d2.utils.events INFO:  eta: 1:00:24  iter: 48899  total_loss: 0.1666  loss_cls: 0.02045  loss_box_reg: 0.06903  loss_mask: 0.05341  loss_rpn_cls: 0.0004406  loss_rpn_loc: 0.007131  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:45] d2.utils.events INFO:  eta: 1:00:23  iter: 48919  total_loss: 0.1755  loss_cls: 0.0233  loss_box_reg: 0.08186  loss_mask: 0.06222  loss_rpn_cls: 0.0004044  loss_rpn_loc: 0.01002  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:47] d2.utils.events INFO:  eta: 1:00:15  iter: 48939  total_loss: 0.1346  loss_cls: 0.0184  loss_box_reg: 0.06056  loss_mask: 0.04795  loss_rpn_cls: 0.0003245  loss_rpn_loc: 0.008812  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:49:49] d2.utils.events INFO:  eta: 1:00:16  iter: 48959  total_loss: 0.1398  loss_cls: 0.02321  loss_box_reg: 0.06791  loss_mask: 0.06585  loss_rpn_cls: 0.0005561  loss_rpn_loc: 0.01079  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:50] d2.utils.events INFO:  eta: 1:00:11  iter: 48979  total_loss: 0.1071  loss_cls: 0.0177  loss_box_reg: 0.04403  loss_mask: 0.05509  loss_rpn_cls: 0.0002566  loss_rpn_loc: 0.003059  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:52] d2.utils.events INFO:  eta: 1:00:15  iter: 48999  total_loss: 0.3368  loss_cls: 0.04235  loss_box_reg: 0.1177  loss_mask: 0.1045  loss_rpn_cls: 0.001556  loss_rpn_loc: 0.02937  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:54] d2.utils.events INFO:  eta: 1:00:14  iter: 49019  total_loss: 0.2278  loss_cls: 0.03868  loss_box_reg: 0.102  loss_mask: 0.05856  loss_rpn_cls: 0.001296  loss_rpn_loc: 0.01961  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:56] d2.utils.events INFO:  eta: 1:00:13  iter: 49039  total_loss: 0.2274  loss_cls: 0.02938  loss_box_reg: 0.08918  loss_mask: 0.06696  loss_rpn_cls: 0.0008373  loss_rpn_loc: 0.01162  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:58] d2.utils.events INFO:  eta: 1:00:09  iter: 49059  total_loss: 0.1695  loss_cls: 0.0331  loss_box_reg: 0.07234  loss_mask: 0.05023  loss_rpn_cls: 0.0002487  loss_rpn_loc: 0.005635  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:49:59] d2.utils.events INFO:  eta: 1:00:06  iter: 49079  total_loss: 0.2192  loss_cls: 0.04226  loss_box_reg: 0.09155  loss_mask: 0.06814  loss_rpn_cls: 0.0009553  loss_rpn_loc: 0.01739  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:01] d2.utils.events INFO:  eta: 1:00:01  iter: 49099  total_loss: 0.1575  loss_cls: 0.0267  loss_box_reg: 0.07383  loss_mask: 0.05751  loss_rpn_cls: 0.0003436  loss_rpn_loc: 0.008874  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:03] d2.utils.events INFO:  eta: 0:59:56  iter: 49119  total_loss: 0.136  loss_cls: 0.01836  loss_box_reg: 0.04937  loss_mask: 0.04492  loss_rpn_cls: 0.0002679  loss_rpn_loc: 0.006345  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:05] d2.utils.events INFO:  eta: 0:59:48  iter: 49139  total_loss: 0.1444  loss_cls: 0.01855  loss_box_reg: 0.06711  loss_mask: 0.04725  loss_rpn_cls: 0.000638  loss_rpn_loc: 0.01581  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:06] d2.utils.events INFO:  eta: 0:59:54  iter: 49159  total_loss: 0.2013  loss_cls: 0.03251  loss_box_reg: 0.09145  loss_mask: 0.07051  loss_rpn_cls: 0.0006539  loss_rpn_loc: 0.01516  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:08] d2.utils.events INFO:  eta: 0:59:56  iter: 49179  total_loss: 0.2822  loss_cls: 0.04159  loss_box_reg: 0.1205  loss_mask: 0.08702  loss_rpn_cls: 0.00112  loss_rpn_loc: 0.01939  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:10] d2.utils.events INFO:  eta: 0:59:56  iter: 49199  total_loss: 0.1973  loss_cls: 0.03146  loss_box_reg: 0.07181  loss_mask: 0.06562  loss_rpn_cls: 0.0006665  loss_rpn_loc: 0.008551  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:12] d2.utils.events INFO:  eta: 0:59:52  iter: 49219  total_loss: 0.1478  loss_cls: 0.02217  loss_box_reg: 0.0584  loss_mask: 0.05118  loss_rpn_cls: 0.0004744  loss_rpn_loc: 0.007193  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:13] d2.utils.events INFO:  eta: 0:59:51  iter: 49239  total_loss: 0.1822  loss_cls: 0.02682  loss_box_reg: 0.07266  loss_mask: 0.05824  loss_rpn_cls: 0.0005928  loss_rpn_loc: 0.01118  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:50:15] d2.utils.events INFO:  eta: 0:59:49  iter: 49259  total_loss: 0.1794  loss_cls: 0.03131  loss_box_reg: 0.08376  loss_mask: 0.07038  loss_rpn_cls: 0.001129  loss_rpn_loc: 0.01396  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:17] d2.utils.events INFO:  eta: 0:59:45  iter: 49279  total_loss: 0.1356  loss_cls: 0.01866  loss_box_reg: 0.05242  loss_mask: 0.04919  loss_rpn_cls: 0.0003994  loss_rpn_loc: 0.005635  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:19] d2.utils.events INFO:  eta: 0:59:46  iter: 49299  total_loss: 0.215  loss_cls: 0.03185  loss_box_reg: 0.1025  loss_mask: 0.06241  loss_rpn_cls: 0.0004296  loss_rpn_loc: 0.01336  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:21] d2.utils.events INFO:  eta: 0:59:45  iter: 49319  total_loss: 0.1972  loss_cls: 0.02639  loss_box_reg: 0.08413  loss_mask: 0.07191  loss_rpn_cls: 0.0008648  loss_rpn_loc: 0.01679  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:22] d2.utils.events INFO:  eta: 0:59:41  iter: 49339  total_loss: 0.156  loss_cls: 0.02305  loss_box_reg: 0.05812  loss_mask: 0.0585  loss_rpn_cls: 0.0005449  loss_rpn_loc: 0.009493  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:24] d2.utils.events INFO:  eta: 0:59:38  iter: 49359  total_loss: 0.152  loss_cls: 0.02633  loss_box_reg: 0.06863  loss_mask: 0.05109  loss_rpn_cls: 0.0002897  loss_rpn_loc: 0.008163  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:26] d2.utils.events INFO:  eta: 0:59:38  iter: 49379  total_loss: 0.1952  loss_cls: 0.02595  loss_box_reg: 0.06925  loss_mask: 0.06084  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.0104  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:28] d2.utils.events INFO:  eta: 0:59:36  iter: 49399  total_loss: 0.1747  loss_cls: 0.02064  loss_box_reg: 0.09139  loss_mask: 0.05516  loss_rpn_cls: 0.0007396  loss_rpn_loc: 0.009751  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:50:30] d2.utils.events INFO:  eta: 0:59:37  iter: 49419  total_loss: 0.2246  loss_cls: 0.04259  loss_box_reg: 0.1073  loss_mask: 0.07427  loss_rpn_cls: 0.0008386  loss_rpn_loc: 0.01642  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:31] d2.utils.events INFO:  eta: 0:59:34  iter: 49439  total_loss: 0.1667  loss_cls: 0.0244  loss_box_reg: 0.06832  loss_mask: 0.05465  loss_rpn_cls: 0.0005658  loss_rpn_loc: 0.008053  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:33] d2.utils.events INFO:  eta: 0:59:40  iter: 49459  total_loss: 0.2128  loss_cls: 0.03254  loss_box_reg: 0.1092  loss_mask: 0.07335  loss_rpn_cls: 0.0006234  loss_rpn_loc: 0.02128  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:35] d2.utils.events INFO:  eta: 0:59:41  iter: 49479  total_loss: 0.2102  loss_cls: 0.02662  loss_box_reg: 0.09037  loss_mask: 0.07161  loss_rpn_cls: 0.0008552  loss_rpn_loc: 0.01483  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:37] d2.utils.events INFO:  eta: 0:59:38  iter: 49499  total_loss: 0.1599  loss_cls: 0.01945  loss_box_reg: 0.04298  loss_mask: 0.05013  loss_rpn_cls: 0.0003486  loss_rpn_loc: 0.009017  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:38] d2.utils.events INFO:  eta: 0:59:36  iter: 49519  total_loss: 0.1556  loss_cls: 0.0177  loss_box_reg: 0.07573  loss_mask: 0.05371  loss_rpn_cls: 0.0002702  loss_rpn_loc: 0.006815  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:40] d2.utils.events INFO:  eta: 0:59:35  iter: 49539  total_loss: 0.1977  loss_cls: 0.02699  loss_box_reg: 0.08045  loss_mask: 0.06204  loss_rpn_cls: 0.0004083  loss_rpn_loc: 0.0103  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:42] d2.utils.events INFO:  eta: 0:59:33  iter: 49559  total_loss: 0.2159  loss_cls: 0.03316  loss_box_reg: 0.0866  loss_mask: 0.07434  loss_rpn_cls: 0.00112  loss_rpn_loc: 0.02037  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:50:44] d2.utils.events INFO:  eta: 0:59:31  iter: 49579  total_loss: 0.2052  loss_cls: 0.02683  loss_box_reg: 0.08856  loss_mask: 0.0621  loss_rpn_cls: 0.0006358  loss_rpn_loc: 0.01898  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:46] d2.utils.events INFO:  eta: 0:59:31  iter: 49599  total_loss: 0.1955  loss_cls: 0.0334  loss_box_reg: 0.09085  loss_mask: 0.06401  loss_rpn_cls: 0.0008669  loss_rpn_loc: 0.01541  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:47] d2.utils.events INFO:  eta: 0:59:42  iter: 49619  total_loss: 0.221  loss_cls: 0.03415  loss_box_reg: 0.1083  loss_mask: 0.06943  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.01446  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:49] d2.utils.events INFO:  eta: 0:59:38  iter: 49639  total_loss: 0.1449  loss_cls: 0.02049  loss_box_reg: 0.05664  loss_mask: 0.0576  loss_rpn_cls: 0.0004007  loss_rpn_loc: 0.006533  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:51] d2.utils.events INFO:  eta: 0:59:26  iter: 49659  total_loss: 0.1371  loss_cls: 0.02383  loss_box_reg: 0.06141  loss_mask: 0.04436  loss_rpn_cls: 0.0006975  loss_rpn_loc: 0.009331  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:52] d2.utils.events INFO:  eta: 0:59:21  iter: 49679  total_loss: 0.1479  loss_cls: 0.01738  loss_box_reg: 0.06106  loss_mask: 0.05551  loss_rpn_cls: 0.0004693  loss_rpn_loc: 0.00851  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:54] d2.utils.events INFO:  eta: 0:59:14  iter: 49699  total_loss: 0.2488  loss_cls: 0.01764  loss_box_reg: 0.06836  loss_mask: 0.08687  loss_rpn_cls: 0.001318  loss_rpn_loc: 0.01791  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:56] d2.utils.events INFO:  eta: 0:59:14  iter: 49719  total_loss: 0.175  loss_cls: 0.02816  loss_box_reg: 0.07684  loss_mask: 0.04777  loss_rpn_cls: 0.0004404  loss_rpn_loc: 0.009744  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:50:58] d2.utils.events INFO:  eta: 0:59:10  iter: 49739  total_loss: 0.1839  loss_cls: 0.02663  loss_box_reg: 0.06444  loss_mask: 0.06474  loss_rpn_cls: 0.0006922  loss_rpn_loc: 0.01186  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:50:59] d2.utils.events INFO:  eta: 0:59:04  iter: 49759  total_loss: 0.1356  loss_cls: 0.01873  loss_box_reg: 0.05632  loss_mask: 0.05765  loss_rpn_cls: 0.0004866  loss_rpn_loc: 0.008417  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:01] d2.utils.events INFO:  eta: 0:59:05  iter: 49779  total_loss: 0.1614  loss_cls: 0.02331  loss_box_reg: 0.07012  loss_mask: 0.05755  loss_rpn_cls: 0.0002634  loss_rpn_loc: 0.007678  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:03] d2.utils.events INFO:  eta: 0:59:02  iter: 49799  total_loss: 0.2635  loss_cls: 0.04141  loss_box_reg: 0.1156  loss_mask: 0.08377  loss_rpn_cls: 0.0008412  loss_rpn_loc: 0.0224  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:05] d2.utils.events INFO:  eta: 0:59:03  iter: 49819  total_loss: 0.1239  loss_cls: 0.02341  loss_box_reg: 0.05002  loss_mask: 0.04806  loss_rpn_cls: 0.0008093  loss_rpn_loc: 0.01109  time: 0.0879  data_time: 0.0023  lr: 0.0025  max_mem: 1493M
[10/27 19:51:07] d2.utils.events INFO:  eta: 0:59:01  iter: 49839  total_loss: 0.2163  loss_cls: 0.02572  loss_box_reg: 0.08386  loss_mask: 0.06721  loss_rpn_cls: 0.0009623  loss_rpn_loc: 0.01595  time: 0.0879  data_time: 0.0023  lr: 0.0025  max_mem: 1493M
[10/27 19:51:08] d2.utils.events INFO:  eta: 0:58:58  iter: 49859  total_loss: 0.1546  loss_cls: 0.02298  loss_box_reg: 0.08193  loss_mask: 0.04939  loss_rpn_cls: 0.0004078  loss_rpn_loc: 0.009466  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:51:10] d2.utils.events INFO:  eta: 0:58:53  iter: 49879  total_loss: 0.1302  loss_cls: 0.02148  loss_box_reg: 0.05592  loss_mask: 0.0477  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.00834  time: 0.0879  data_time: 0.0023  lr: 0.0025  max_mem: 1493M
[10/27 19:51:12] d2.utils.events INFO:  eta: 0:58:53  iter: 49899  total_loss: 0.1815  loss_cls: 0.03059  loss_box_reg: 0.08069  loss_mask: 0.06047  loss_rpn_cls: 0.0004163  loss_rpn_loc: 0.01126  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:51:14] d2.utils.events INFO:  eta: 0:58:54  iter: 49919  total_loss: 0.2314  loss_cls: 0.03632  loss_box_reg: 0.1097  loss_mask: 0.05121  loss_rpn_cls: 0.0007125  loss_rpn_loc: 0.016  time: 0.0879  data_time: 0.0025  lr: 0.0025  max_mem: 1493M
[10/27 19:51:15] d2.utils.events INFO:  eta: 0:58:59  iter: 49939  total_loss: 0.1642  loss_cls: 0.02511  loss_box_reg: 0.07197  loss_mask: 0.06707  loss_rpn_cls: 0.0005579  loss_rpn_loc: 0.01078  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:51:17] d2.utils.events INFO:  eta: 0:58:59  iter: 49959  total_loss: 0.2202  loss_cls: 0.03287  loss_box_reg: 0.08765  loss_mask: 0.06535  loss_rpn_cls: 0.0008247  loss_rpn_loc: 0.01282  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:51:19] d2.utils.events INFO:  eta: 0:59:06  iter: 49979  total_loss: 0.1879  loss_cls: 0.02795  loss_box_reg: 0.0936  loss_mask: 0.05906  loss_rpn_cls: 0.0005674  loss_rpn_loc: 0.009924  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:21] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0049999.pth
[10/27 19:51:21] d2.utils.events INFO:  eta: 0:59:16  iter: 49999  total_loss: 0.2521  loss_cls: 0.03613  loss_box_reg: 0.1263  loss_mask: 0.07668  loss_rpn_cls: 0.0005566  loss_rpn_loc: 0.01194  time: 0.0879  data_time: 0.0023  lr: 0.0025  max_mem: 1493M
[10/27 19:51:23] d2.utils.events INFO:  eta: 0:59:16  iter: 50019  total_loss: 0.213  loss_cls: 0.0409  loss_box_reg: 0.1106  loss_mask: 0.06528  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.008616  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:25] d2.utils.events INFO:  eta: 0:59:16  iter: 50039  total_loss: 0.2068  loss_cls: 0.03049  loss_box_reg: 0.08752  loss_mask: 0.06037  loss_rpn_cls: 0.0005406  loss_rpn_loc: 0.009233  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:51:27] d2.utils.events INFO:  eta: 0:59:13  iter: 50059  total_loss: 0.1615  loss_cls: 0.02481  loss_box_reg: 0.06735  loss_mask: 0.05691  loss_rpn_cls: 0.000461  loss_rpn_loc: 0.009902  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:51:28] d2.utils.events INFO:  eta: 0:59:12  iter: 50079  total_loss: 0.2243  loss_cls: 0.03727  loss_box_reg: 0.1097  loss_mask: 0.0602  loss_rpn_cls: 0.0008353  loss_rpn_loc: 0.01872  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:30] d2.utils.events INFO:  eta: 0:59:16  iter: 50099  total_loss: 0.2404  loss_cls: 0.03148  loss_box_reg: 0.1029  loss_mask: 0.07381  loss_rpn_cls: 0.0006694  loss_rpn_loc: 0.01833  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:32] d2.utils.events INFO:  eta: 0:59:11  iter: 50119  total_loss: 0.1205  loss_cls: 0.01857  loss_box_reg: 0.04633  loss_mask: 0.04104  loss_rpn_cls: 0.0002756  loss_rpn_loc: 0.006607  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:34] d2.utils.events INFO:  eta: 0:59:12  iter: 50139  total_loss: 0.162  loss_cls: 0.02491  loss_box_reg: 0.06909  loss_mask: 0.05412  loss_rpn_cls: 0.0005318  loss_rpn_loc: 0.009019  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:51:35] d2.utils.events INFO:  eta: 0:59:05  iter: 50159  total_loss: 0.1048  loss_cls: 0.0116  loss_box_reg: 0.03968  loss_mask: 0.05966  loss_rpn_cls: 0.0006423  loss_rpn_loc: 0.006739  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:37] d2.utils.events INFO:  eta: 0:59:00  iter: 50179  total_loss: 0.2371  loss_cls: 0.02915  loss_box_reg: 0.1049  loss_mask: 0.07033  loss_rpn_cls: 0.001446  loss_rpn_loc: 0.01878  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:39] d2.utils.events INFO:  eta: 0:58:50  iter: 50199  total_loss: 0.117  loss_cls: 0.01567  loss_box_reg: 0.04878  loss_mask: 0.05113  loss_rpn_cls: 0.0003763  loss_rpn_loc: 0.01122  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:41] d2.utils.events INFO:  eta: 0:58:40  iter: 50219  total_loss: 0.09377  loss_cls: 0.01408  loss_box_reg: 0.03944  loss_mask: 0.0449  loss_rpn_cls: 0.0002265  loss_rpn_loc: 0.00593  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:42] d2.utils.events INFO:  eta: 0:58:37  iter: 50239  total_loss: 0.169  loss_cls: 0.02173  loss_box_reg: 0.07437  loss_mask: 0.06352  loss_rpn_cls: 0.0006054  loss_rpn_loc: 0.01084  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:51:44] d2.utils.events INFO:  eta: 0:58:37  iter: 50259  total_loss: 0.1698  loss_cls: 0.02356  loss_box_reg: 0.06266  loss_mask: 0.06575  loss_rpn_cls: 0.0006566  loss_rpn_loc: 0.007492  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:46] d2.utils.events INFO:  eta: 0:58:36  iter: 50279  total_loss: 0.1819  loss_cls: 0.02716  loss_box_reg: 0.07882  loss_mask: 0.06479  loss_rpn_cls: 0.0009592  loss_rpn_loc: 0.01521  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:48] d2.utils.events INFO:  eta: 0:58:29  iter: 50299  total_loss: 0.1925  loss_cls: 0.02828  loss_box_reg: 0.08469  loss_mask: 0.06963  loss_rpn_cls: 0.0005362  loss_rpn_loc: 0.01488  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:50] d2.utils.events INFO:  eta: 0:58:32  iter: 50319  total_loss: 0.2295  loss_cls: 0.03353  loss_box_reg: 0.08835  loss_mask: 0.06559  loss_rpn_cls: 0.001503  loss_rpn_loc: 0.02394  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:51] d2.utils.events INFO:  eta: 0:58:28  iter: 50339  total_loss: 0.1705  loss_cls: 0.03278  loss_box_reg: 0.07792  loss_mask: 0.05721  loss_rpn_cls: 0.0007239  loss_rpn_loc: 0.01242  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:53] d2.utils.events INFO:  eta: 0:58:26  iter: 50359  total_loss: 0.2274  loss_cls: 0.03559  loss_box_reg: 0.1192  loss_mask: 0.06548  loss_rpn_cls: 0.0004581  loss_rpn_loc: 0.01262  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:55] d2.utils.events INFO:  eta: 0:58:33  iter: 50379  total_loss: 0.2657  loss_cls: 0.04445  loss_box_reg: 0.1199  loss_mask: 0.0725  loss_rpn_cls: 0.0005328  loss_rpn_loc: 0.0143  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:57] d2.utils.events INFO:  eta: 0:58:32  iter: 50399  total_loss: 0.1645  loss_cls: 0.02941  loss_box_reg: 0.07312  loss_mask: 0.05083  loss_rpn_cls: 0.0004051  loss_rpn_loc: 0.008314  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:51:59] d2.utils.events INFO:  eta: 0:58:19  iter: 50419  total_loss: 0.1679  loss_cls: 0.02413  loss_box_reg: 0.07128  loss_mask: 0.04995  loss_rpn_cls: 0.0002944  loss_rpn_loc: 0.008704  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:00] d2.utils.events INFO:  eta: 0:58:17  iter: 50439  total_loss: 0.152  loss_cls: 0.02217  loss_box_reg: 0.06697  loss_mask: 0.0498  loss_rpn_cls: 0.000404  loss_rpn_loc: 0.006882  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:02] d2.utils.events INFO:  eta: 0:58:11  iter: 50459  total_loss: 0.1707  loss_cls: 0.02531  loss_box_reg: 0.08556  loss_mask: 0.0595  loss_rpn_cls: 0.0009735  loss_rpn_loc: 0.009829  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:04] d2.utils.events INFO:  eta: 0:58:03  iter: 50479  total_loss: 0.1152  loss_cls: 0.01591  loss_box_reg: 0.04862  loss_mask: 0.0468  loss_rpn_cls: 0.000389  loss_rpn_loc: 0.004299  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:06] d2.utils.events INFO:  eta: 0:58:02  iter: 50499  total_loss: 0.1293  loss_cls: 0.01813  loss_box_reg: 0.05902  loss_mask: 0.04677  loss_rpn_cls: 0.0003808  loss_rpn_loc: 0.006783  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:07] d2.utils.events INFO:  eta: 0:57:58  iter: 50519  total_loss: 0.134  loss_cls: 0.02235  loss_box_reg: 0.04809  loss_mask: 0.0527  loss_rpn_cls: 0.0007055  loss_rpn_loc: 0.008158  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:09] d2.utils.events INFO:  eta: 0:57:56  iter: 50539  total_loss: 0.1721  loss_cls: 0.02485  loss_box_reg: 0.06289  loss_mask: 0.06169  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.01372  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:11] d2.utils.events INFO:  eta: 0:57:53  iter: 50559  total_loss: 0.1695  loss_cls: 0.02271  loss_box_reg: 0.08166  loss_mask: 0.0467  loss_rpn_cls: 0.0005208  loss_rpn_loc: 0.01294  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:13] d2.utils.events INFO:  eta: 0:57:52  iter: 50579  total_loss: 0.204  loss_cls: 0.03166  loss_box_reg: 0.08886  loss_mask: 0.06307  loss_rpn_cls: 0.0008956  loss_rpn_loc: 0.01455  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:14] d2.utils.events INFO:  eta: 0:57:51  iter: 50599  total_loss: 0.2382  loss_cls: 0.03257  loss_box_reg: 0.1124  loss_mask: 0.06136  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.01742  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:52:16] d2.utils.events INFO:  eta: 0:57:47  iter: 50619  total_loss: 0.1337  loss_cls: 0.01561  loss_box_reg: 0.0541  loss_mask: 0.05364  loss_rpn_cls: 0.0003025  loss_rpn_loc: 0.006383  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:18] d2.utils.events INFO:  eta: 0:57:47  iter: 50639  total_loss: 0.1509  loss_cls: 0.02298  loss_box_reg: 0.06912  loss_mask: 0.0533  loss_rpn_cls: 0.0003583  loss_rpn_loc: 0.007131  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:20] d2.utils.events INFO:  eta: 0:57:47  iter: 50659  total_loss: 0.1892  loss_cls: 0.02255  loss_box_reg: 0.09691  loss_mask: 0.05496  loss_rpn_cls: 0.0009581  loss_rpn_loc: 0.01688  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:21] d2.utils.events INFO:  eta: 0:57:46  iter: 50679  total_loss: 0.1675  loss_cls: 0.03031  loss_box_reg: 0.08839  loss_mask: 0.05248  loss_rpn_cls: 0.0005818  loss_rpn_loc: 0.01327  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:23] d2.utils.events INFO:  eta: 0:57:43  iter: 50699  total_loss: 0.1517  loss_cls: 0.02511  loss_box_reg: 0.05889  loss_mask: 0.05558  loss_rpn_cls: 0.0003939  loss_rpn_loc: 0.006208  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:25] d2.utils.events INFO:  eta: 0:57:39  iter: 50719  total_loss: 0.1267  loss_cls: 0.01174  loss_box_reg: 0.05  loss_mask: 0.05791  loss_rpn_cls: 0.0005217  loss_rpn_loc: 0.008537  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:52:27] d2.utils.events INFO:  eta: 0:57:40  iter: 50739  total_loss: 0.2413  loss_cls: 0.03862  loss_box_reg: 0.1195  loss_mask: 0.07015  loss_rpn_cls: 0.0007438  loss_rpn_loc: 0.01809  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:28] d2.utils.events INFO:  eta: 0:57:41  iter: 50759  total_loss: 0.1428  loss_cls: 0.02155  loss_box_reg: 0.0722  loss_mask: 0.05707  loss_rpn_cls: 0.0004116  loss_rpn_loc: 0.01164  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:30] d2.utils.events INFO:  eta: 0:57:45  iter: 50779  total_loss: 0.1704  loss_cls: 0.02152  loss_box_reg: 0.06633  loss_mask: 0.06429  loss_rpn_cls: 0.0007064  loss_rpn_loc: 0.01443  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:32] d2.utils.events INFO:  eta: 0:57:48  iter: 50799  total_loss: 0.2357  loss_cls: 0.03681  loss_box_reg: 0.1056  loss_mask: 0.0683  loss_rpn_cls: 0.0007677  loss_rpn_loc: 0.0172  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:34] d2.utils.events INFO:  eta: 0:57:41  iter: 50819  total_loss: 0.1659  loss_cls: 0.02549  loss_box_reg: 0.08061  loss_mask: 0.05476  loss_rpn_cls: 0.0007792  loss_rpn_loc: 0.01056  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:36] d2.utils.events INFO:  eta: 0:57:35  iter: 50839  total_loss: 0.1677  loss_cls: 0.02506  loss_box_reg: 0.06607  loss_mask: 0.05116  loss_rpn_cls: 0.0005922  loss_rpn_loc: 0.01211  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:37] d2.utils.events INFO:  eta: 0:57:38  iter: 50859  total_loss: 0.1757  loss_cls: 0.02563  loss_box_reg: 0.0715  loss_mask: 0.04841  loss_rpn_cls: 0.000583  loss_rpn_loc: 0.008705  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:39] d2.utils.events INFO:  eta: 0:57:39  iter: 50879  total_loss: 0.271  loss_cls: 0.03599  loss_box_reg: 0.1019  loss_mask: 0.08225  loss_rpn_cls: 0.0007038  loss_rpn_loc: 0.02289  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:41] d2.utils.events INFO:  eta: 0:57:30  iter: 50899  total_loss: 0.1595  loss_cls: 0.02229  loss_box_reg: 0.06813  loss_mask: 0.05707  loss_rpn_cls: 0.0005741  loss_rpn_loc: 0.008629  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:43] d2.utils.events INFO:  eta: 0:57:27  iter: 50919  total_loss: 0.1568  loss_cls: 0.0239  loss_box_reg: 0.06727  loss_mask: 0.04859  loss_rpn_cls: 0.0004145  loss_rpn_loc: 0.006552  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:44] d2.utils.events INFO:  eta: 0:57:23  iter: 50939  total_loss: 0.2404  loss_cls: 0.04083  loss_box_reg: 0.1061  loss_mask: 0.06942  loss_rpn_cls: 0.0006086  loss_rpn_loc: 0.01161  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:46] d2.utils.events INFO:  eta: 0:57:20  iter: 50959  total_loss: 0.181  loss_cls: 0.02711  loss_box_reg: 0.08192  loss_mask: 0.06113  loss_rpn_cls: 0.0006667  loss_rpn_loc: 0.0112  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:48] d2.utils.events INFO:  eta: 0:57:17  iter: 50979  total_loss: 0.1467  loss_cls: 0.02488  loss_box_reg: 0.06697  loss_mask: 0.05144  loss_rpn_cls: 0.0003409  loss_rpn_loc: 0.00713  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:50] d2.utils.events INFO:  eta: 0:57:10  iter: 50999  total_loss: 0.2293  loss_cls: 0.02964  loss_box_reg: 0.1031  loss_mask: 0.06267  loss_rpn_cls: 0.0008424  loss_rpn_loc: 0.01221  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:51] d2.utils.events INFO:  eta: 0:56:58  iter: 51019  total_loss: 0.1929  loss_cls: 0.02537  loss_box_reg: 0.09037  loss_mask: 0.05737  loss_rpn_cls: 0.0006451  loss_rpn_loc: 0.01318  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:53] d2.utils.events INFO:  eta: 0:56:54  iter: 51039  total_loss: 0.2088  loss_cls: 0.02661  loss_box_reg: 0.08915  loss_mask: 0.06406  loss_rpn_cls: 0.0006281  loss_rpn_loc: 0.01371  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:52:55] d2.utils.events INFO:  eta: 0:57:00  iter: 51059  total_loss: 0.2222  loss_cls: 0.03424  loss_box_reg: 0.08888  loss_mask: 0.06633  loss_rpn_cls: 0.0006294  loss_rpn_loc: 0.02008  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:57] d2.utils.events INFO:  eta: 0:56:52  iter: 51079  total_loss: 0.142  loss_cls: 0.01722  loss_box_reg: 0.05179  loss_mask: 0.052  loss_rpn_cls: 0.0003944  loss_rpn_loc: 0.009727  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:52:58] d2.utils.events INFO:  eta: 0:56:49  iter: 51099  total_loss: 0.1635  loss_cls: 0.02664  loss_box_reg: 0.07194  loss_mask: 0.05928  loss_rpn_cls: 0.0006662  loss_rpn_loc: 0.01474  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:00] d2.utils.events INFO:  eta: 0:56:54  iter: 51119  total_loss: 0.1584  loss_cls: 0.02171  loss_box_reg: 0.06569  loss_mask: 0.05652  loss_rpn_cls: 0.0004113  loss_rpn_loc: 0.009436  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:02] d2.utils.events INFO:  eta: 0:56:56  iter: 51139  total_loss: 0.1736  loss_cls: 0.0274  loss_box_reg: 0.08469  loss_mask: 0.05299  loss_rpn_cls: 0.0005743  loss_rpn_loc: 0.01361  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:04] d2.utils.events INFO:  eta: 0:57:01  iter: 51159  total_loss: 0.1473  loss_cls: 0.02559  loss_box_reg: 0.07229  loss_mask: 0.05259  loss_rpn_cls: 0.0007525  loss_rpn_loc: 0.01006  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:06] d2.utils.events INFO:  eta: 0:57:00  iter: 51179  total_loss: 0.2388  loss_cls: 0.03763  loss_box_reg: 0.09381  loss_mask: 0.06738  loss_rpn_cls: 0.0008532  loss_rpn_loc: 0.01262  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:07] d2.utils.events INFO:  eta: 0:57:00  iter: 51199  total_loss: 0.2131  loss_cls: 0.03476  loss_box_reg: 0.08752  loss_mask: 0.05586  loss_rpn_cls: 0.0004593  loss_rpn_loc: 0.01356  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:09] d2.utils.events INFO:  eta: 0:57:01  iter: 51219  total_loss: 0.1438  loss_cls: 0.0222  loss_box_reg: 0.06732  loss_mask: 0.05166  loss_rpn_cls: 0.0003842  loss_rpn_loc: 0.007911  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:11] d2.utils.events INFO:  eta: 0:57:01  iter: 51239  total_loss: 0.2089  loss_cls: 0.03715  loss_box_reg: 0.09696  loss_mask: 0.05693  loss_rpn_cls: 0.0007396  loss_rpn_loc: 0.01727  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:13] d2.utils.events INFO:  eta: 0:56:57  iter: 51259  total_loss: 0.1304  loss_cls: 0.01481  loss_box_reg: 0.04555  loss_mask: 0.06139  loss_rpn_cls: 0.0003332  loss_rpn_loc: 0.007372  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:15] d2.utils.events INFO:  eta: 0:56:58  iter: 51279  total_loss: 0.1913  loss_cls: 0.02077  loss_box_reg: 0.08972  loss_mask: 0.06011  loss_rpn_cls: 0.0006794  loss_rpn_loc: 0.01498  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:16] d2.utils.events INFO:  eta: 0:56:58  iter: 51299  total_loss: 0.1867  loss_cls: 0.03642  loss_box_reg: 0.07127  loss_mask: 0.06604  loss_rpn_cls: 0.0009264  loss_rpn_loc: 0.0197  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:18] d2.utils.events INFO:  eta: 0:56:55  iter: 51319  total_loss: 0.1656  loss_cls: 0.02561  loss_box_reg: 0.08161  loss_mask: 0.05423  loss_rpn_cls: 0.0009474  loss_rpn_loc: 0.009958  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:20] d2.utils.events INFO:  eta: 0:56:52  iter: 51339  total_loss: 0.1684  loss_cls: 0.02246  loss_box_reg: 0.06216  loss_mask: 0.05786  loss_rpn_cls: 0.0007809  loss_rpn_loc: 0.01075  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:22] d2.utils.events INFO:  eta: 0:56:51  iter: 51359  total_loss: 0.1879  loss_cls: 0.02774  loss_box_reg: 0.07795  loss_mask: 0.0562  loss_rpn_cls: 0.0005205  loss_rpn_loc: 0.009449  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:24] d2.utils.events INFO:  eta: 0:56:49  iter: 51379  total_loss: 0.2735  loss_cls: 0.041  loss_box_reg: 0.1106  loss_mask: 0.08127  loss_rpn_cls: 0.001206  loss_rpn_loc: 0.02438  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:25] d2.utils.events INFO:  eta: 0:56:41  iter: 51399  total_loss: 0.1616  loss_cls: 0.02277  loss_box_reg: 0.06546  loss_mask: 0.05544  loss_rpn_cls: 0.0005447  loss_rpn_loc: 0.009996  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:27] d2.utils.events INFO:  eta: 0:56:37  iter: 51419  total_loss: 0.1583  loss_cls: 0.02179  loss_box_reg: 0.07535  loss_mask: 0.04973  loss_rpn_cls: 0.000549  loss_rpn_loc: 0.01198  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:29] d2.utils.events INFO:  eta: 0:56:41  iter: 51439  total_loss: 0.1896  loss_cls: 0.02526  loss_box_reg: 0.08267  loss_mask: 0.06416  loss_rpn_cls: 0.0004452  loss_rpn_loc: 0.0139  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:30] d2.utils.events INFO:  eta: 0:56:40  iter: 51459  total_loss: 0.168  loss_cls: 0.02801  loss_box_reg: 0.06603  loss_mask: 0.06295  loss_rpn_cls: 0.0004322  loss_rpn_loc: 0.009922  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:32] d2.utils.events INFO:  eta: 0:56:40  iter: 51479  total_loss: 0.1098  loss_cls: 0.01861  loss_box_reg: 0.05999  loss_mask: 0.04625  loss_rpn_cls: 0.0002608  loss_rpn_loc: 0.006458  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:34] d2.utils.events INFO:  eta: 0:56:36  iter: 51499  total_loss: 0.1236  loss_cls: 0.01973  loss_box_reg: 0.04263  loss_mask: 0.05835  loss_rpn_cls: 0.0008467  loss_rpn_loc: 0.008123  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:36] d2.utils.events INFO:  eta: 0:56:39  iter: 51519  total_loss: 0.207  loss_cls: 0.03432  loss_box_reg: 0.09178  loss_mask: 0.06734  loss_rpn_cls: 0.0009008  loss_rpn_loc: 0.01552  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:37] d2.utils.events INFO:  eta: 0:56:35  iter: 51539  total_loss: 0.1483  loss_cls: 0.02182  loss_box_reg: 0.05939  loss_mask: 0.0535  loss_rpn_cls: 0.0006169  loss_rpn_loc: 0.009074  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:39] d2.utils.events INFO:  eta: 0:56:33  iter: 51559  total_loss: 0.1439  loss_cls: 0.02025  loss_box_reg: 0.05032  loss_mask: 0.04742  loss_rpn_cls: 0.0003773  loss_rpn_loc: 0.01074  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:41] d2.utils.events INFO:  eta: 0:56:31  iter: 51579  total_loss: 0.1996  loss_cls: 0.02663  loss_box_reg: 0.08743  loss_mask: 0.06293  loss_rpn_cls: 0.001007  loss_rpn_loc: 0.01437  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:43] d2.utils.events INFO:  eta: 0:56:29  iter: 51599  total_loss: 0.2143  loss_cls: 0.02774  loss_box_reg: 0.0991  loss_mask: 0.06871  loss_rpn_cls: 0.0006812  loss_rpn_loc: 0.01249  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:44] d2.utils.events INFO:  eta: 0:56:28  iter: 51619  total_loss: 0.1375  loss_cls: 0.01953  loss_box_reg: 0.04549  loss_mask: 0.05108  loss_rpn_cls: 0.0003471  loss_rpn_loc: 0.006051  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:46] d2.utils.events INFO:  eta: 0:56:24  iter: 51639  total_loss: 0.1136  loss_cls: 0.02418  loss_box_reg: 0.05632  loss_mask: 0.0506  loss_rpn_cls: 0.0006152  loss_rpn_loc: 0.0132  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:48] d2.utils.events INFO:  eta: 0:56:25  iter: 51659  total_loss: 0.2216  loss_cls: 0.03168  loss_box_reg: 0.1101  loss_mask: 0.07119  loss_rpn_cls: 0.0005227  loss_rpn_loc: 0.01314  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:50] d2.utils.events INFO:  eta: 0:56:20  iter: 51679  total_loss: 0.1633  loss_cls: 0.01987  loss_box_reg: 0.05733  loss_mask: 0.05329  loss_rpn_cls: 0.0005331  loss_rpn_loc: 0.007831  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:51] d2.utils.events INFO:  eta: 0:56:21  iter: 51699  total_loss: 0.2529  loss_cls: 0.03516  loss_box_reg: 0.1106  loss_mask: 0.07581  loss_rpn_cls: 0.001038  loss_rpn_loc: 0.01672  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:53] d2.utils.events INFO:  eta: 0:56:26  iter: 51719  total_loss: 0.2441  loss_cls: 0.03196  loss_box_reg: 0.1056  loss_mask: 0.07119  loss_rpn_cls: 0.000694  loss_rpn_loc: 0.01326  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:53:55] d2.utils.events INFO:  eta: 0:56:19  iter: 51739  total_loss: 0.1394  loss_cls: 0.02127  loss_box_reg: 0.05195  loss_mask: 0.04937  loss_rpn_cls: 0.000339  loss_rpn_loc: 0.00751  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:57] d2.utils.events INFO:  eta: 0:56:18  iter: 51759  total_loss: 0.223  loss_cls: 0.03982  loss_box_reg: 0.08536  loss_mask: 0.07697  loss_rpn_cls: 0.0007417  loss_rpn_loc: 0.01283  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:53:59] d2.utils.events INFO:  eta: 0:56:15  iter: 51779  total_loss: 0.1585  loss_cls: 0.01889  loss_box_reg: 0.06133  loss_mask: 0.05025  loss_rpn_cls: 0.0006689  loss_rpn_loc: 0.01355  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:00] d2.utils.events INFO:  eta: 0:56:10  iter: 51799  total_loss: 0.1932  loss_cls: 0.02591  loss_box_reg: 0.08313  loss_mask: 0.06762  loss_rpn_cls: 0.0006045  loss_rpn_loc: 0.009064  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:02] d2.utils.events INFO:  eta: 0:56:10  iter: 51819  total_loss: 0.1962  loss_cls: 0.02881  loss_box_reg: 0.1087  loss_mask: 0.06212  loss_rpn_cls: 0.0005626  loss_rpn_loc: 0.009457  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:04] d2.utils.events INFO:  eta: 0:56:09  iter: 51839  total_loss: 0.1158  loss_cls: 0.01904  loss_box_reg: 0.05354  loss_mask: 0.05362  loss_rpn_cls: 0.0004635  loss_rpn_loc: 0.004602  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:06] d2.utils.events INFO:  eta: 0:56:00  iter: 51859  total_loss: 0.1338  loss_cls: 0.01957  loss_box_reg: 0.05841  loss_mask: 0.05734  loss_rpn_cls: 0.0005347  loss_rpn_loc: 0.006989  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:07] d2.utils.events INFO:  eta: 0:55:54  iter: 51879  total_loss: 0.1706  loss_cls: 0.0265  loss_box_reg: 0.06739  loss_mask: 0.0511  loss_rpn_cls: 0.0005552  loss_rpn_loc: 0.007456  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:09] d2.utils.events INFO:  eta: 0:55:56  iter: 51899  total_loss: 0.1813  loss_cls: 0.02454  loss_box_reg: 0.06682  loss_mask: 0.05576  loss_rpn_cls: 0.0004134  loss_rpn_loc: 0.01115  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:11] d2.utils.events INFO:  eta: 0:55:58  iter: 51919  total_loss: 0.1717  loss_cls: 0.0224  loss_box_reg: 0.08243  loss_mask: 0.05747  loss_rpn_cls: 0.0005768  loss_rpn_loc: 0.01147  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:13] d2.utils.events INFO:  eta: 0:55:56  iter: 51939  total_loss: 0.1499  loss_cls: 0.01816  loss_box_reg: 0.04298  loss_mask: 0.05432  loss_rpn_cls: 0.0005075  loss_rpn_loc: 0.00985  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:14] d2.utils.events INFO:  eta: 0:55:59  iter: 51959  total_loss: 0.2581  loss_cls: 0.03744  loss_box_reg: 0.1108  loss_mask: 0.06653  loss_rpn_cls: 0.001008  loss_rpn_loc: 0.02287  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:16] d2.utils.events INFO:  eta: 0:55:58  iter: 51979  total_loss: 0.2293  loss_cls: 0.03363  loss_box_reg: 0.1155  loss_mask: 0.06221  loss_rpn_cls: 0.0006941  loss_rpn_loc: 0.01347  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:18] d2.utils.events INFO:  eta: 0:55:56  iter: 51999  total_loss: 0.1674  loss_cls: 0.02591  loss_box_reg: 0.07644  loss_mask: 0.0488  loss_rpn_cls: 0.0004106  loss_rpn_loc: 0.01287  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:20] d2.utils.events INFO:  eta: 0:55:53  iter: 52019  total_loss: 0.1381  loss_cls: 0.02436  loss_box_reg: 0.05963  loss_mask: 0.05178  loss_rpn_cls: 0.0004681  loss_rpn_loc: 0.009573  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:22] d2.utils.events INFO:  eta: 0:55:52  iter: 52039  total_loss: 0.2491  loss_cls: 0.0376  loss_box_reg: 0.1058  loss_mask: 0.08525  loss_rpn_cls: 0.0008848  loss_rpn_loc: 0.01518  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:23] d2.utils.events INFO:  eta: 0:55:52  iter: 52059  total_loss: 0.2289  loss_cls: 0.03455  loss_box_reg: 0.09546  loss_mask: 0.06057  loss_rpn_cls: 0.001217  loss_rpn_loc: 0.01966  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:25] d2.utils.events INFO:  eta: 0:55:49  iter: 52079  total_loss: 0.1497  loss_cls: 0.01813  loss_box_reg: 0.0539  loss_mask: 0.06474  loss_rpn_cls: 0.000547  loss_rpn_loc: 0.007801  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:27] d2.utils.events INFO:  eta: 0:55:46  iter: 52099  total_loss: 0.1777  loss_cls: 0.03209  loss_box_reg: 0.08377  loss_mask: 0.0616  loss_rpn_cls: 0.000464  loss_rpn_loc: 0.008287  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:29] d2.utils.events INFO:  eta: 0:55:43  iter: 52119  total_loss: 0.1208  loss_cls: 0.02504  loss_box_reg: 0.04876  loss_mask: 0.04903  loss_rpn_cls: 0.0003607  loss_rpn_loc: 0.006143  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:30] d2.utils.events INFO:  eta: 0:55:40  iter: 52139  total_loss: 0.1543  loss_cls: 0.02194  loss_box_reg: 0.05982  loss_mask: 0.05213  loss_rpn_cls: 0.0004161  loss_rpn_loc: 0.006638  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:32] d2.utils.events INFO:  eta: 0:55:33  iter: 52159  total_loss: 0.1431  loss_cls: 0.02718  loss_box_reg: 0.05452  loss_mask: 0.06273  loss_rpn_cls: 0.0004157  loss_rpn_loc: 0.007114  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:34] d2.utils.events INFO:  eta: 0:55:31  iter: 52179  total_loss: 0.2038  loss_cls: 0.03427  loss_box_reg: 0.09514  loss_mask: 0.06539  loss_rpn_cls: 0.0009249  loss_rpn_loc: 0.01196  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:36] d2.utils.events INFO:  eta: 0:55:33  iter: 52199  total_loss: 0.2524  loss_cls: 0.03396  loss_box_reg: 0.1091  loss_mask: 0.07248  loss_rpn_cls: 0.001223  loss_rpn_loc: 0.01204  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:37] d2.utils.events INFO:  eta: 0:55:30  iter: 52219  total_loss: 0.1531  loss_cls: 0.02439  loss_box_reg: 0.07819  loss_mask: 0.05164  loss_rpn_cls: 0.0009463  loss_rpn_loc: 0.01255  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:39] d2.utils.events INFO:  eta: 0:55:22  iter: 52239  total_loss: 0.157  loss_cls: 0.02239  loss_box_reg: 0.06491  loss_mask: 0.05718  loss_rpn_cls: 0.0007427  loss_rpn_loc: 0.01044  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:41] d2.utils.events INFO:  eta: 0:55:21  iter: 52259  total_loss: 0.1795  loss_cls: 0.02498  loss_box_reg: 0.08401  loss_mask: 0.0672  loss_rpn_cls: 0.0005593  loss_rpn_loc: 0.01407  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:43] d2.utils.events INFO:  eta: 0:55:08  iter: 52279  total_loss: 0.1199  loss_cls: 0.01788  loss_box_reg: 0.05193  loss_mask: 0.0435  loss_rpn_cls: 0.0002788  loss_rpn_loc: 0.005176  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:44] d2.utils.events INFO:  eta: 0:55:06  iter: 52299  total_loss: 0.2104  loss_cls: 0.02972  loss_box_reg: 0.1001  loss_mask: 0.05795  loss_rpn_cls: 0.0004668  loss_rpn_loc: 0.01023  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:46] d2.utils.events INFO:  eta: 0:55:02  iter: 52319  total_loss: 0.1975  loss_cls: 0.03016  loss_box_reg: 0.08486  loss_mask: 0.06493  loss_rpn_cls: 0.0004763  loss_rpn_loc: 0.01138  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:48] d2.utils.events INFO:  eta: 0:55:10  iter: 52339  total_loss: 0.2507  loss_cls: 0.03637  loss_box_reg: 0.1111  loss_mask: 0.08533  loss_rpn_cls: 0.001203  loss_rpn_loc: 0.02777  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:50] d2.utils.events INFO:  eta: 0:55:07  iter: 52359  total_loss: 0.1926  loss_cls: 0.03192  loss_box_reg: 0.08194  loss_mask: 0.06414  loss_rpn_cls: 0.000588  loss_rpn_loc: 0.00928  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:52] d2.utils.events INFO:  eta: 0:54:57  iter: 52379  total_loss: 0.1929  loss_cls: 0.02988  loss_box_reg: 0.0711  loss_mask: 0.04571  loss_rpn_cls: 0.0005913  loss_rpn_loc: 0.01768  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:53] d2.utils.events INFO:  eta: 0:55:03  iter: 52399  total_loss: 0.1772  loss_cls: 0.02359  loss_box_reg: 0.06589  loss_mask: 0.05735  loss_rpn_cls: 0.0005154  loss_rpn_loc: 0.007883  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:55] d2.utils.events INFO:  eta: 0:55:07  iter: 52419  total_loss: 0.1948  loss_cls: 0.02275  loss_box_reg: 0.0841  loss_mask: 0.06622  loss_rpn_cls: 0.0004836  loss_rpn_loc: 0.01376  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:54:57] d2.utils.events INFO:  eta: 0:55:01  iter: 52439  total_loss: 0.1325  loss_cls: 0.02018  loss_box_reg: 0.05665  loss_mask: 0.05331  loss_rpn_cls: 0.0003732  loss_rpn_loc: 0.01041  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:54:59] d2.utils.events INFO:  eta: 0:55:09  iter: 52459  total_loss: 0.2383  loss_cls: 0.03264  loss_box_reg: 0.1187  loss_mask: 0.07229  loss_rpn_cls: 0.0008937  loss_rpn_loc: 0.01994  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:00] d2.utils.events INFO:  eta: 0:55:12  iter: 52479  total_loss: 0.181  loss_cls: 0.02921  loss_box_reg: 0.08862  loss_mask: 0.05853  loss_rpn_cls: 0.0005183  loss_rpn_loc: 0.01109  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:02] d2.utils.events INFO:  eta: 0:55:11  iter: 52499  total_loss: 0.1795  loss_cls: 0.02162  loss_box_reg: 0.0799  loss_mask: 0.05488  loss_rpn_cls: 0.0004482  loss_rpn_loc: 0.008689  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:04] d2.utils.events INFO:  eta: 0:55:09  iter: 52519  total_loss: 0.2019  loss_cls: 0.02985  loss_box_reg: 0.08606  loss_mask: 0.05911  loss_rpn_cls: 0.0009117  loss_rpn_loc: 0.01197  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:06] d2.utils.events INFO:  eta: 0:55:09  iter: 52539  total_loss: 0.1371  loss_cls: 0.01912  loss_box_reg: 0.05921  loss_mask: 0.05105  loss_rpn_cls: 0.0006577  loss_rpn_loc: 0.007968  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:07] d2.utils.events INFO:  eta: 0:55:14  iter: 52559  total_loss: 0.2085  loss_cls: 0.02868  loss_box_reg: 0.07831  loss_mask: 0.06946  loss_rpn_cls: 0.001155  loss_rpn_loc: 0.01343  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:09] d2.utils.events INFO:  eta: 0:55:09  iter: 52579  total_loss: 0.1351  loss_cls: 0.0158  loss_box_reg: 0.06026  loss_mask: 0.05448  loss_rpn_cls: 0.0007052  loss_rpn_loc: 0.009834  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:11] d2.utils.events INFO:  eta: 0:55:07  iter: 52599  total_loss: 0.2718  loss_cls: 0.04005  loss_box_reg: 0.1211  loss_mask: 0.07523  loss_rpn_cls: 0.0006524  loss_rpn_loc: 0.02263  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:13] d2.utils.events INFO:  eta: 0:55:03  iter: 52619  total_loss: 0.1233  loss_cls: 0.01636  loss_box_reg: 0.05104  loss_mask: 0.0497  loss_rpn_cls: 0.0003271  loss_rpn_loc: 0.007496  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:14] d2.utils.events INFO:  eta: 0:55:03  iter: 52639  total_loss: 0.1634  loss_cls: 0.02294  loss_box_reg: 0.06905  loss_mask: 0.05492  loss_rpn_cls: 0.001229  loss_rpn_loc: 0.01419  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:16] d2.utils.events INFO:  eta: 0:54:57  iter: 52659  total_loss: 0.2399  loss_cls: 0.02411  loss_box_reg: 0.07946  loss_mask: 0.06406  loss_rpn_cls: 0.0006245  loss_rpn_loc: 0.01835  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:18] d2.utils.events INFO:  eta: 0:54:58  iter: 52679  total_loss: 0.1575  loss_cls: 0.02496  loss_box_reg: 0.07968  loss_mask: 0.0601  loss_rpn_cls: 0.0003352  loss_rpn_loc: 0.01143  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:20] d2.utils.events INFO:  eta: 0:54:50  iter: 52699  total_loss: 0.1126  loss_cls: 0.02085  loss_box_reg: 0.0422  loss_mask: 0.04828  loss_rpn_cls: 0.0003149  loss_rpn_loc: 0.005854  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:22] d2.utils.events INFO:  eta: 0:54:42  iter: 52719  total_loss: 0.2476  loss_cls: 0.03352  loss_box_reg: 0.09383  loss_mask: 0.07474  loss_rpn_cls: 0.000851  loss_rpn_loc: 0.01633  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:23] d2.utils.events INFO:  eta: 0:54:44  iter: 52739  total_loss: 0.2211  loss_cls: 0.02366  loss_box_reg: 0.09822  loss_mask: 0.06363  loss_rpn_cls: 0.001196  loss_rpn_loc: 0.01281  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:55:25] d2.utils.events INFO:  eta: 0:54:40  iter: 52759  total_loss: 0.1716  loss_cls: 0.03092  loss_box_reg: 0.07153  loss_mask: 0.05939  loss_rpn_cls: 0.0002913  loss_rpn_loc: 0.007734  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:27] d2.utils.events INFO:  eta: 0:54:43  iter: 52779  total_loss: 0.1609  loss_cls: 0.02469  loss_box_reg: 0.07592  loss_mask: 0.06463  loss_rpn_cls: 0.0006706  loss_rpn_loc: 0.01003  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:29] d2.utils.events INFO:  eta: 0:54:42  iter: 52799  total_loss: 0.1577  loss_cls: 0.02548  loss_box_reg: 0.07259  loss_mask: 0.04601  loss_rpn_cls: 0.0004811  loss_rpn_loc: 0.009183  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:30] d2.utils.events INFO:  eta: 0:54:30  iter: 52819  total_loss: 0.1458  loss_cls: 0.02528  loss_box_reg: 0.06343  loss_mask: 0.05574  loss_rpn_cls: 0.000433  loss_rpn_loc: 0.00786  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:32] d2.utils.events INFO:  eta: 0:54:29  iter: 52839  total_loss: 0.1564  loss_cls: 0.02524  loss_box_reg: 0.06617  loss_mask: 0.05817  loss_rpn_cls: 0.0004664  loss_rpn_loc: 0.008909  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:34] d2.utils.events INFO:  eta: 0:54:38  iter: 52859  total_loss: 0.2404  loss_cls: 0.03908  loss_box_reg: 0.1013  loss_mask: 0.08285  loss_rpn_cls: 0.0009483  loss_rpn_loc: 0.01924  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:36] d2.utils.events INFO:  eta: 0:54:37  iter: 52879  total_loss: 0.1464  loss_cls: 0.02037  loss_box_reg: 0.04764  loss_mask: 0.05629  loss_rpn_cls: 0.0006085  loss_rpn_loc: 0.007131  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:37] d2.utils.events INFO:  eta: 0:54:38  iter: 52899  total_loss: 0.1973  loss_cls: 0.02851  loss_box_reg: 0.089  loss_mask: 0.05734  loss_rpn_cls: 0.0005496  loss_rpn_loc: 0.009524  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:39] d2.utils.events INFO:  eta: 0:54:34  iter: 52919  total_loss: 0.1847  loss_cls: 0.0254  loss_box_reg: 0.08851  loss_mask: 0.04943  loss_rpn_cls: 0.0005759  loss_rpn_loc: 0.00936  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:55:41] d2.utils.events INFO:  eta: 0:54:32  iter: 52939  total_loss: 0.1681  loss_cls: 0.02693  loss_box_reg: 0.07694  loss_mask: 0.05956  loss_rpn_cls: 0.0007406  loss_rpn_loc: 0.01113  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:43] d2.utils.events INFO:  eta: 0:54:29  iter: 52959  total_loss: 0.2214  loss_cls: 0.02783  loss_box_reg: 0.1023  loss_mask: 0.06514  loss_rpn_cls: 0.0006815  loss_rpn_loc: 0.01572  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:45] d2.utils.events INFO:  eta: 0:54:16  iter: 52979  total_loss: 0.1017  loss_cls: 0.01631  loss_box_reg: 0.0337  loss_mask: 0.05621  loss_rpn_cls: 0.0002901  loss_rpn_loc: 0.00536  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:46] d2.utils.events INFO:  eta: 0:54:14  iter: 52999  total_loss: 0.1849  loss_cls: 0.02698  loss_box_reg: 0.07432  loss_mask: 0.05835  loss_rpn_cls: 0.0006499  loss_rpn_loc: 0.01335  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:48] d2.utils.events INFO:  eta: 0:54:16  iter: 53019  total_loss: 0.2387  loss_cls: 0.03202  loss_box_reg: 0.1127  loss_mask: 0.07455  loss_rpn_cls: 0.0007676  loss_rpn_loc: 0.01457  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:50] d2.utils.events INFO:  eta: 0:54:09  iter: 53039  total_loss: 0.1622  loss_cls: 0.02262  loss_box_reg: 0.0715  loss_mask: 0.05183  loss_rpn_cls: 0.0004406  loss_rpn_loc: 0.00753  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:52] d2.utils.events INFO:  eta: 0:54:02  iter: 53059  total_loss: 0.1329  loss_cls: 0.02098  loss_box_reg: 0.06205  loss_mask: 0.05221  loss_rpn_cls: 0.0004578  loss_rpn_loc: 0.007261  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:53] d2.utils.events INFO:  eta: 0:54:04  iter: 53079  total_loss: 0.1526  loss_cls: 0.02243  loss_box_reg: 0.06321  loss_mask: 0.05952  loss_rpn_cls: 0.0007682  loss_rpn_loc: 0.01366  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:55] d2.utils.events INFO:  eta: 0:54:02  iter: 53099  total_loss: 0.1966  loss_cls: 0.02866  loss_box_reg: 0.1045  loss_mask: 0.06177  loss_rpn_cls: 0.0008176  loss_rpn_loc: 0.01592  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:55:57] d2.utils.events INFO:  eta: 0:54:02  iter: 53119  total_loss: 0.1652  loss_cls: 0.02633  loss_box_reg: 0.0648  loss_mask: 0.06057  loss_rpn_cls: 0.0005805  loss_rpn_loc: 0.01454  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:55:59] d2.utils.events INFO:  eta: 0:54:01  iter: 53139  total_loss: 0.171  loss_cls: 0.02095  loss_box_reg: 0.07337  loss_mask: 0.06329  loss_rpn_cls: 0.0004245  loss_rpn_loc: 0.00859  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:00] d2.utils.events INFO:  eta: 0:54:00  iter: 53159  total_loss: 0.1601  loss_cls: 0.02185  loss_box_reg: 0.07187  loss_mask: 0.04752  loss_rpn_cls: 0.0005132  loss_rpn_loc: 0.007822  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:02] d2.utils.events INFO:  eta: 0:53:55  iter: 53179  total_loss: 0.1736  loss_cls: 0.02661  loss_box_reg: 0.06827  loss_mask: 0.0606  loss_rpn_cls: 0.0007925  loss_rpn_loc: 0.01193  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:04] d2.utils.events INFO:  eta: 0:53:50  iter: 53199  total_loss: 0.1629  loss_cls: 0.02213  loss_box_reg: 0.06399  loss_mask: 0.06038  loss_rpn_cls: 0.0005671  loss_rpn_loc: 0.008167  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:06] d2.utils.events INFO:  eta: 0:53:53  iter: 53219  total_loss: 0.227  loss_cls: 0.03345  loss_box_reg: 0.1021  loss_mask: 0.06516  loss_rpn_cls: 0.0008683  loss_rpn_loc: 0.01539  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:56:07] d2.utils.events INFO:  eta: 0:53:48  iter: 53239  total_loss: 0.1525  loss_cls: 0.02112  loss_box_reg: 0.06028  loss_mask: 0.04983  loss_rpn_cls: 0.0004146  loss_rpn_loc: 0.009554  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:09] d2.utils.events INFO:  eta: 0:53:50  iter: 53259  total_loss: 0.2001  loss_cls: 0.02915  loss_box_reg: 0.08306  loss_mask: 0.06757  loss_rpn_cls: 0.0008094  loss_rpn_loc: 0.01769  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:11] d2.utils.events INFO:  eta: 0:54:03  iter: 53279  total_loss: 0.2194  loss_cls: 0.04267  loss_box_reg: 0.08822  loss_mask: 0.06637  loss_rpn_cls: 0.000801  loss_rpn_loc: 0.01328  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:13] d2.utils.events INFO:  eta: 0:53:57  iter: 53299  total_loss: 0.1481  loss_cls: 0.02067  loss_box_reg: 0.06095  loss_mask: 0.05483  loss_rpn_cls: 0.0007174  loss_rpn_loc: 0.008224  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:15] d2.utils.events INFO:  eta: 0:53:51  iter: 53319  total_loss: 0.1591  loss_cls: 0.02213  loss_box_reg: 0.05955  loss_mask: 0.04686  loss_rpn_cls: 0.0003066  loss_rpn_loc: 0.005925  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:16] d2.utils.events INFO:  eta: 0:53:37  iter: 53339  total_loss: 0.1423  loss_cls: 0.02392  loss_box_reg: 0.05773  loss_mask: 0.05614  loss_rpn_cls: 0.0004106  loss_rpn_loc: 0.004871  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:18] d2.utils.events INFO:  eta: 0:53:36  iter: 53359  total_loss: 0.1462  loss_cls: 0.02935  loss_box_reg: 0.07087  loss_mask: 0.05768  loss_rpn_cls: 0.000404  loss_rpn_loc: 0.007169  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:20] d2.utils.events INFO:  eta: 0:53:34  iter: 53379  total_loss: 0.1432  loss_cls: 0.01811  loss_box_reg: 0.06215  loss_mask: 0.05104  loss_rpn_cls: 0.0004466  loss_rpn_loc: 0.008669  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:56:22] d2.utils.events INFO:  eta: 0:53:32  iter: 53399  total_loss: 0.1734  loss_cls: 0.02794  loss_box_reg: 0.07445  loss_mask: 0.05553  loss_rpn_cls: 0.0008632  loss_rpn_loc: 0.01638  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:23] d2.utils.events INFO:  eta: 0:53:31  iter: 53419  total_loss: 0.2259  loss_cls: 0.03352  loss_box_reg: 0.1  loss_mask: 0.06218  loss_rpn_cls: 0.0005842  loss_rpn_loc: 0.01426  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:25] d2.utils.events INFO:  eta: 0:53:33  iter: 53439  total_loss: 0.2176  loss_cls: 0.02456  loss_box_reg: 0.1041  loss_mask: 0.07163  loss_rpn_cls: 0.001547  loss_rpn_loc: 0.01422  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:27] d2.utils.events INFO:  eta: 0:53:26  iter: 53459  total_loss: 0.1859  loss_cls: 0.02711  loss_box_reg: 0.08511  loss_mask: 0.06597  loss_rpn_cls: 0.0005321  loss_rpn_loc: 0.01696  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:56:29] d2.utils.events INFO:  eta: 0:53:25  iter: 53479  total_loss: 0.1992  loss_cls: 0.03032  loss_box_reg: 0.08852  loss_mask: 0.07253  loss_rpn_cls: 0.0009248  loss_rpn_loc: 0.01408  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:30] d2.utils.events INFO:  eta: 0:53:24  iter: 53499  total_loss: 0.1741  loss_cls: 0.02473  loss_box_reg: 0.07625  loss_mask: 0.0571  loss_rpn_cls: 0.00072  loss_rpn_loc: 0.01322  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:32] d2.utils.events INFO:  eta: 0:53:19  iter: 53519  total_loss: 0.169  loss_cls: 0.02547  loss_box_reg: 0.07955  loss_mask: 0.05681  loss_rpn_cls: 0.0003963  loss_rpn_loc: 0.009451  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:34] d2.utils.events INFO:  eta: 0:53:23  iter: 53539  total_loss: 0.2246  loss_cls: 0.02801  loss_box_reg: 0.1059  loss_mask: 0.06378  loss_rpn_cls: 0.0005523  loss_rpn_loc: 0.01186  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:36] d2.utils.events INFO:  eta: 0:53:19  iter: 53559  total_loss: 0.1944  loss_cls: 0.01737  loss_box_reg: 0.07129  loss_mask: 0.06659  loss_rpn_cls: 0.0006281  loss_rpn_loc: 0.01092  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:38] d2.utils.events INFO:  eta: 0:53:21  iter: 53579  total_loss: 0.1642  loss_cls: 0.02463  loss_box_reg: 0.07332  loss_mask: 0.05919  loss_rpn_cls: 0.0003658  loss_rpn_loc: 0.007927  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:39] d2.utils.events INFO:  eta: 0:53:17  iter: 53599  total_loss: 0.1046  loss_cls: 0.01933  loss_box_reg: 0.04504  loss_mask: 0.0531  loss_rpn_cls: 0.000361  loss_rpn_loc: 0.007236  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:56:41] d2.utils.events INFO:  eta: 0:53:20  iter: 53619  total_loss: 0.2055  loss_cls: 0.02734  loss_box_reg: 0.09653  loss_mask: 0.05421  loss_rpn_cls: 0.0006451  loss_rpn_loc: 0.01205  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:43] d2.utils.events INFO:  eta: 0:53:17  iter: 53639  total_loss: 0.1457  loss_cls: 0.02069  loss_box_reg: 0.07119  loss_mask: 0.05689  loss_rpn_cls: 0.0003028  loss_rpn_loc: 0.005747  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:45] d2.utils.events INFO:  eta: 0:53:16  iter: 53659  total_loss: 0.1752  loss_cls: 0.03074  loss_box_reg: 0.07964  loss_mask: 0.05159  loss_rpn_cls: 0.0008211  loss_rpn_loc: 0.008618  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:46] d2.utils.events INFO:  eta: 0:53:13  iter: 53679  total_loss: 0.1527  loss_cls: 0.03409  loss_box_reg: 0.05648  loss_mask: 0.04762  loss_rpn_cls: 0.00048  loss_rpn_loc: 0.007164  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:48] d2.utils.events INFO:  eta: 0:53:13  iter: 53699  total_loss: 0.1362  loss_cls: 0.02098  loss_box_reg: 0.05946  loss_mask: 0.0475  loss_rpn_cls: 0.0004677  loss_rpn_loc: 0.007055  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:50] d2.utils.events INFO:  eta: 0:53:12  iter: 53719  total_loss: 0.1794  loss_cls: 0.02575  loss_box_reg: 0.07658  loss_mask: 0.06203  loss_rpn_cls: 0.0007002  loss_rpn_loc: 0.01509  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:52] d2.utils.events INFO:  eta: 0:53:05  iter: 53739  total_loss: 0.1617  loss_cls: 0.02758  loss_box_reg: 0.06476  loss_mask: 0.06104  loss_rpn_cls: 0.0004537  loss_rpn_loc: 0.008344  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:53] d2.utils.events INFO:  eta: 0:53:01  iter: 53759  total_loss: 0.1681  loss_cls: 0.02361  loss_box_reg: 0.05621  loss_mask: 0.0556  loss_rpn_cls: 0.0005505  loss_rpn_loc: 0.0102  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:55] d2.utils.events INFO:  eta: 0:53:02  iter: 53779  total_loss: 0.1858  loss_cls: 0.02489  loss_box_reg: 0.07273  loss_mask: 0.05938  loss_rpn_cls: 0.0003747  loss_rpn_loc: 0.01153  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:56:57] d2.utils.events INFO:  eta: 0:53:01  iter: 53799  total_loss: 0.206  loss_cls: 0.03258  loss_box_reg: 0.08323  loss_mask: 0.06954  loss_rpn_cls: 0.0009705  loss_rpn_loc: 0.01663  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:56:59] d2.utils.events INFO:  eta: 0:53:09  iter: 53819  total_loss: 0.1705  loss_cls: 0.02772  loss_box_reg: 0.06404  loss_mask: 0.0575  loss_rpn_cls: 0.0006349  loss_rpn_loc: 0.01124  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:01] d2.utils.events INFO:  eta: 0:53:11  iter: 53839  total_loss: 0.2545  loss_cls: 0.0318  loss_box_reg: 0.1223  loss_mask: 0.06738  loss_rpn_cls: 0.0008691  loss_rpn_loc: 0.01818  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:02] d2.utils.events INFO:  eta: 0:53:11  iter: 53859  total_loss: 0.2619  loss_cls: 0.04725  loss_box_reg: 0.1019  loss_mask: 0.08505  loss_rpn_cls: 0.001053  loss_rpn_loc: 0.0218  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:04] d2.utils.events INFO:  eta: 0:53:07  iter: 53879  total_loss: 0.1066  loss_cls: 0.01695  loss_box_reg: 0.04814  loss_mask: 0.04648  loss_rpn_cls: 0.0005562  loss_rpn_loc: 0.009887  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:06] d2.utils.events INFO:  eta: 0:53:05  iter: 53899  total_loss: 0.184  loss_cls: 0.02633  loss_box_reg: 0.09013  loss_mask: 0.05657  loss_rpn_cls: 0.0003975  loss_rpn_loc: 0.01168  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:08] d2.utils.events INFO:  eta: 0:53:04  iter: 53919  total_loss: 0.1975  loss_cls: 0.0317  loss_box_reg: 0.08305  loss_mask: 0.05811  loss_rpn_cls: 0.0005444  loss_rpn_loc: 0.01006  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:09] d2.utils.events INFO:  eta: 0:53:06  iter: 53939  total_loss: 0.1698  loss_cls: 0.01524  loss_box_reg: 0.07186  loss_mask: 0.05737  loss_rpn_cls: 0.0006251  loss_rpn_loc: 0.01285  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:11] d2.utils.events INFO:  eta: 0:53:00  iter: 53959  total_loss: 0.1502  loss_cls: 0.027  loss_box_reg: 0.07337  loss_mask: 0.05578  loss_rpn_cls: 0.0003585  loss_rpn_loc: 0.007574  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:13] d2.utils.events INFO:  eta: 0:52:58  iter: 53979  total_loss: 0.08373  loss_cls: 0.01455  loss_box_reg: 0.03714  loss_mask: 0.04436  loss_rpn_cls: 0.0002207  loss_rpn_loc: 0.002604  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:15] d2.utils.events INFO:  eta: 0:52:53  iter: 53999  total_loss: 0.1451  loss_cls: 0.02033  loss_box_reg: 0.0524  loss_mask: 0.04913  loss_rpn_cls: 0.0004414  loss_rpn_loc: 0.008716  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:16] d2.utils.events INFO:  eta: 0:52:45  iter: 54019  total_loss: 0.1541  loss_cls: 0.02538  loss_box_reg: 0.07628  loss_mask: 0.04943  loss_rpn_cls: 0.0006055  loss_rpn_loc: 0.008865  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:18] d2.utils.events INFO:  eta: 0:52:49  iter: 54039  total_loss: 0.1615  loss_cls: 0.02322  loss_box_reg: 0.07208  loss_mask: 0.05166  loss_rpn_cls: 0.00043  loss_rpn_loc: 0.01122  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:20] d2.utils.events INFO:  eta: 0:52:51  iter: 54059  total_loss: 0.2304  loss_cls: 0.0334  loss_box_reg: 0.1015  loss_mask: 0.06902  loss_rpn_cls: 0.0006571  loss_rpn_loc: 0.01375  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:22] d2.utils.events INFO:  eta: 0:52:55  iter: 54079  total_loss: 0.1592  loss_cls: 0.02755  loss_box_reg: 0.06706  loss_mask: 0.05874  loss_rpn_cls: 0.000609  loss_rpn_loc: 0.01347  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:24] d2.utils.events INFO:  eta: 0:52:54  iter: 54099  total_loss: 0.1711  loss_cls: 0.03339  loss_box_reg: 0.0699  loss_mask: 0.05548  loss_rpn_cls: 0.0005496  loss_rpn_loc: 0.01075  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:25] d2.utils.events INFO:  eta: 0:52:55  iter: 54119  total_loss: 0.2138  loss_cls: 0.03243  loss_box_reg: 0.09532  loss_mask: 0.06159  loss_rpn_cls: 0.0006247  loss_rpn_loc: 0.01573  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:27] d2.utils.events INFO:  eta: 0:52:54  iter: 54139  total_loss: 0.1641  loss_cls: 0.03019  loss_box_reg: 0.06099  loss_mask: 0.06281  loss_rpn_cls: 0.00071  loss_rpn_loc: 0.01176  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:29] d2.utils.events INFO:  eta: 0:52:54  iter: 54159  total_loss: 0.1533  loss_cls: 0.02977  loss_box_reg: 0.07192  loss_mask: 0.05236  loss_rpn_cls: 0.0005257  loss_rpn_loc: 0.009181  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:57:31] d2.utils.events INFO:  eta: 0:52:53  iter: 54179  total_loss: 0.2255  loss_cls: 0.02457  loss_box_reg: 0.1103  loss_mask: 0.06255  loss_rpn_cls: 0.0006284  loss_rpn_loc: 0.01781  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:32] d2.utils.events INFO:  eta: 0:52:54  iter: 54199  total_loss: 0.2006  loss_cls: 0.03183  loss_box_reg: 0.08824  loss_mask: 0.0633  loss_rpn_cls: 0.0008963  loss_rpn_loc: 0.01209  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:34] d2.utils.events INFO:  eta: 0:52:54  iter: 54219  total_loss: 0.2775  loss_cls: 0.0308  loss_box_reg: 0.09808  loss_mask: 0.06539  loss_rpn_cls: 0.000975  loss_rpn_loc: 0.01654  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:36] d2.utils.events INFO:  eta: 0:52:51  iter: 54239  total_loss: 0.136  loss_cls: 0.01923  loss_box_reg: 0.05343  loss_mask: 0.0467  loss_rpn_cls: 0.0005786  loss_rpn_loc: 0.007417  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:38] d2.utils.events INFO:  eta: 0:52:48  iter: 54259  total_loss: 0.1162  loss_cls: 0.01755  loss_box_reg: 0.04471  loss_mask: 0.05136  loss_rpn_cls: 0.0003048  loss_rpn_loc: 0.005359  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:39] d2.utils.events INFO:  eta: 0:52:41  iter: 54279  total_loss: 0.1674  loss_cls: 0.02996  loss_box_reg: 0.0838  loss_mask: 0.05778  loss_rpn_cls: 0.0004382  loss_rpn_loc: 0.004846  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1493M
[10/27 19:57:41] d2.utils.events INFO:  eta: 0:52:42  iter: 54299  total_loss: 0.1723  loss_cls: 0.02654  loss_box_reg: 0.08225  loss_mask: 0.05186  loss_rpn_cls: 0.0004556  loss_rpn_loc: 0.01039  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:43] d2.utils.events INFO:  eta: 0:52:41  iter: 54319  total_loss: 0.1585  loss_cls: 0.02635  loss_box_reg: 0.07719  loss_mask: 0.05452  loss_rpn_cls: 0.0004591  loss_rpn_loc: 0.008328  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:45] d2.utils.events INFO:  eta: 0:52:41  iter: 54339  total_loss: 0.2172  loss_cls: 0.03468  loss_box_reg: 0.1103  loss_mask: 0.05957  loss_rpn_cls: 0.000604  loss_rpn_loc: 0.0108  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:57:47] d2.utils.events INFO:  eta: 0:52:40  iter: 54359  total_loss: 0.181  loss_cls: 0.02474  loss_box_reg: 0.1068  loss_mask: 0.07034  loss_rpn_cls: 0.0007595  loss_rpn_loc: 0.01451  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:48] d2.utils.events INFO:  eta: 0:52:39  iter: 54379  total_loss: 0.151  loss_cls: 0.02415  loss_box_reg: 0.06404  loss_mask: 0.05488  loss_rpn_cls: 0.0004619  loss_rpn_loc: 0.008938  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1493M
[10/27 19:57:50] d2.utils.events INFO:  eta: 0:52:42  iter: 54399  total_loss: 0.2397  loss_cls: 0.04389  loss_box_reg: 0.1046  loss_mask: 0.06211  loss_rpn_cls: 0.0007573  loss_rpn_loc: 0.01614  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1493M
[10/27 19:57:52] d2.utils.events INFO:  eta: 0:52:34  iter: 54419  total_loss: 0.09509  loss_cls: 0.01245  loss_box_reg: 0.03413  loss_mask: 0.04443  loss_rpn_cls: 0.0002781  loss_rpn_loc: 0.004162  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:57:54] d2.utils.events INFO:  eta: 0:52:32  iter: 54439  total_loss: 0.1735  loss_cls: 0.02589  loss_box_reg: 0.07638  loss_mask: 0.05728  loss_rpn_cls: 0.0005248  loss_rpn_loc: 0.01376  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:57:55] d2.utils.events INFO:  eta: 0:52:31  iter: 54459  total_loss: 0.2129  loss_cls: 0.03514  loss_box_reg: 0.09348  loss_mask: 0.06876  loss_rpn_cls: 0.001257  loss_rpn_loc: 0.01716  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:57:57] d2.utils.events INFO:  eta: 0:52:27  iter: 54479  total_loss: 0.1885  loss_cls: 0.02427  loss_box_reg: 0.08534  loss_mask: 0.05765  loss_rpn_cls: 0.0005721  loss_rpn_loc: 0.01206  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:57:59] d2.utils.events INFO:  eta: 0:52:27  iter: 54499  total_loss: 0.2233  loss_cls: 0.02953  loss_box_reg: 0.09062  loss_mask: 0.06123  loss_rpn_cls: 0.0006769  loss_rpn_loc: 0.01212  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:01] d2.utils.events INFO:  eta: 0:52:29  iter: 54519  total_loss: 0.1979  loss_cls: 0.03544  loss_box_reg: 0.09441  loss_mask: 0.06718  loss_rpn_cls: 0.0009961  loss_rpn_loc: 0.01341  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:03] d2.utils.events INFO:  eta: 0:52:27  iter: 54539  total_loss: 0.1866  loss_cls: 0.03145  loss_box_reg: 0.09121  loss_mask: 0.056  loss_rpn_cls: 0.0004481  loss_rpn_loc: 0.009045  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:04] d2.utils.events INFO:  eta: 0:52:28  iter: 54559  total_loss: 0.219  loss_cls: 0.02151  loss_box_reg: 0.08191  loss_mask: 0.06471  loss_rpn_cls: 0.00129  loss_rpn_loc: 0.02419  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:06] d2.utils.events INFO:  eta: 0:52:22  iter: 54579  total_loss: 0.1666  loss_cls: 0.02826  loss_box_reg: 0.0728  loss_mask: 0.04804  loss_rpn_cls: 0.0007611  loss_rpn_loc: 0.008902  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:08] d2.utils.events INFO:  eta: 0:52:21  iter: 54599  total_loss: 0.1813  loss_cls: 0.02509  loss_box_reg: 0.09025  loss_mask: 0.05134  loss_rpn_cls: 0.0004681  loss_rpn_loc: 0.009319  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:10] d2.utils.events INFO:  eta: 0:52:17  iter: 54619  total_loss: 0.2021  loss_cls: 0.03205  loss_box_reg: 0.09135  loss_mask: 0.06207  loss_rpn_cls: 0.0004203  loss_rpn_loc: 0.008149  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:11] d2.utils.events INFO:  eta: 0:52:16  iter: 54639  total_loss: 0.1528  loss_cls: 0.02818  loss_box_reg: 0.06918  loss_mask: 0.05521  loss_rpn_cls: 0.0006535  loss_rpn_loc: 0.01103  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:13] d2.utils.events INFO:  eta: 0:52:14  iter: 54659  total_loss: 0.1976  loss_cls: 0.03546  loss_box_reg: 0.09549  loss_mask: 0.05847  loss_rpn_cls: 0.0005927  loss_rpn_loc: 0.01367  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:15] d2.utils.events INFO:  eta: 0:52:13  iter: 54679  total_loss: 0.1648  loss_cls: 0.02521  loss_box_reg: 0.07301  loss_mask: 0.05674  loss_rpn_cls: 0.000733  loss_rpn_loc: 0.00815  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:58:17] d2.utils.events INFO:  eta: 0:52:10  iter: 54699  total_loss: 0.1411  loss_cls: 0.01756  loss_box_reg: 0.05886  loss_mask: 0.04985  loss_rpn_cls: 0.0002829  loss_rpn_loc: 0.006903  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:58:19] d2.utils.events INFO:  eta: 0:52:10  iter: 54719  total_loss: 0.1767  loss_cls: 0.02097  loss_box_reg: 0.08249  loss_mask: 0.05582  loss_rpn_cls: 0.0008067  loss_rpn_loc: 0.01122  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:20] d2.utils.events INFO:  eta: 0:52:16  iter: 54739  total_loss: 0.211  loss_cls: 0.02176  loss_box_reg: 0.09136  loss_mask: 0.07131  loss_rpn_cls: 0.002039  loss_rpn_loc: 0.01624  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:22] d2.utils.events INFO:  eta: 0:52:17  iter: 54759  total_loss: 0.1842  loss_cls: 0.02015  loss_box_reg: 0.08248  loss_mask: 0.06376  loss_rpn_cls: 0.0005149  loss_rpn_loc: 0.008787  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:24] d2.utils.events INFO:  eta: 0:52:13  iter: 54779  total_loss: 0.1518  loss_cls: 0.025  loss_box_reg: 0.06398  loss_mask: 0.0534  loss_rpn_cls: 0.0007099  loss_rpn_loc: 0.01008  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:26] d2.utils.events INFO:  eta: 0:52:12  iter: 54799  total_loss: 0.147  loss_cls: 0.02065  loss_box_reg: 0.06377  loss_mask: 0.05464  loss_rpn_cls: 0.000346  loss_rpn_loc: 0.007199  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:27] d2.utils.events INFO:  eta: 0:52:09  iter: 54819  total_loss: 0.2125  loss_cls: 0.0321  loss_box_reg: 0.08372  loss_mask: 0.07065  loss_rpn_cls: 0.0004619  loss_rpn_loc: 0.01248  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:29] d2.utils.events INFO:  eta: 0:52:01  iter: 54839  total_loss: 0.1362  loss_cls: 0.01749  loss_box_reg: 0.04894  loss_mask: 0.06036  loss_rpn_cls: 0.0003626  loss_rpn_loc: 0.008138  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:31] d2.utils.events INFO:  eta: 0:51:54  iter: 54859  total_loss: 0.1649  loss_cls: 0.02321  loss_box_reg: 0.06504  loss_mask: 0.05387  loss_rpn_cls: 0.0005202  loss_rpn_loc: 0.007074  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:33] d2.utils.events INFO:  eta: 0:51:56  iter: 54879  total_loss: 0.1766  loss_cls: 0.02556  loss_box_reg: 0.06859  loss_mask: 0.06347  loss_rpn_cls: 0.0007431  loss_rpn_loc: 0.01012  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:34] d2.utils.events INFO:  eta: 0:51:54  iter: 54899  total_loss: 0.1935  loss_cls: 0.02917  loss_box_reg: 0.08456  loss_mask: 0.05926  loss_rpn_cls: 0.0005223  loss_rpn_loc: 0.01231  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:36] d2.utils.events INFO:  eta: 0:51:51  iter: 54919  total_loss: 0.1554  loss_cls: 0.02632  loss_box_reg: 0.06829  loss_mask: 0.05813  loss_rpn_cls: 0.0006555  loss_rpn_loc: 0.0157  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:38] d2.utils.events INFO:  eta: 0:51:49  iter: 54939  total_loss: 0.2208  loss_cls: 0.03585  loss_box_reg: 0.0824  loss_mask: 0.07118  loss_rpn_cls: 0.000397  loss_rpn_loc: 0.01625  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:58:40] d2.utils.events INFO:  eta: 0:51:51  iter: 54959  total_loss: 0.1961  loss_cls: 0.03345  loss_box_reg: 0.07812  loss_mask: 0.05832  loss_rpn_cls: 0.0006151  loss_rpn_loc: 0.01395  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:42] d2.utils.events INFO:  eta: 0:51:57  iter: 54979  total_loss: 0.1881  loss_cls: 0.0198  loss_box_reg: 0.07281  loss_mask: 0.06212  loss_rpn_cls: 0.0008989  loss_rpn_loc: 0.01092  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:43] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0054999.pth
[10/27 19:58:44] d2.utils.events INFO:  eta: 0:51:59  iter: 54999  total_loss: 0.1605  loss_cls: 0.02329  loss_box_reg: 0.06612  loss_mask: 0.04598  loss_rpn_cls: 0.0004069  loss_rpn_loc: 0.01215  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:45] d2.utils.events INFO:  eta: 0:51:59  iter: 55019  total_loss: 0.148  loss_cls: 0.02271  loss_box_reg: 0.06948  loss_mask: 0.04253  loss_rpn_cls: 0.0004076  loss_rpn_loc: 0.00822  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:47] d2.utils.events INFO:  eta: 0:51:59  iter: 55039  total_loss: 0.184  loss_cls: 0.02019  loss_box_reg: 0.0794  loss_mask: 0.05785  loss_rpn_cls: 0.0006217  loss_rpn_loc: 0.01061  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:49] d2.utils.events INFO:  eta: 0:51:55  iter: 55059  total_loss: 0.182  loss_cls: 0.03091  loss_box_reg: 0.07214  loss_mask: 0.05101  loss_rpn_cls: 0.001249  loss_rpn_loc: 0.0147  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:58:51] d2.utils.events INFO:  eta: 0:51:41  iter: 55079  total_loss: 0.1186  loss_cls: 0.01485  loss_box_reg: 0.04005  loss_mask: 0.05423  loss_rpn_cls: 0.0004636  loss_rpn_loc: 0.00612  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:53] d2.utils.events INFO:  eta: 0:51:37  iter: 55099  total_loss: 0.1999  loss_cls: 0.02899  loss_box_reg: 0.1027  loss_mask: 0.05313  loss_rpn_cls: 0.0007569  loss_rpn_loc: 0.009365  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:54] d2.utils.events INFO:  eta: 0:51:31  iter: 55119  total_loss: 0.1616  loss_cls: 0.02733  loss_box_reg: 0.07667  loss_mask: 0.0496  loss_rpn_cls: 0.0006652  loss_rpn_loc: 0.01062  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:56] d2.utils.events INFO:  eta: 0:51:26  iter: 55139  total_loss: 0.1592  loss_cls: 0.02024  loss_box_reg: 0.0608  loss_mask: 0.06231  loss_rpn_cls: 0.0007452  loss_rpn_loc: 0.01084  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:58:58] d2.utils.events INFO:  eta: 0:51:22  iter: 55159  total_loss: 0.1173  loss_cls: 0.01478  loss_box_reg: 0.04101  loss_mask: 0.04714  loss_rpn_cls: 0.0003837  loss_rpn_loc: 0.00619  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:00] d2.utils.events INFO:  eta: 0:51:20  iter: 55179  total_loss: 0.216  loss_cls: 0.03646  loss_box_reg: 0.09564  loss_mask: 0.05437  loss_rpn_cls: 0.0007189  loss_rpn_loc: 0.01111  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:01] d2.utils.events INFO:  eta: 0:51:14  iter: 55199  total_loss: 0.1757  loss_cls: 0.02749  loss_box_reg: 0.08459  loss_mask: 0.05901  loss_rpn_cls: 0.0005763  loss_rpn_loc: 0.008947  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:03] d2.utils.events INFO:  eta: 0:51:09  iter: 55219  total_loss: 0.154  loss_cls: 0.02779  loss_box_reg: 0.06533  loss_mask: 0.04453  loss_rpn_cls: 0.0007522  loss_rpn_loc: 0.01263  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:59:05] d2.utils.events INFO:  eta: 0:51:09  iter: 55239  total_loss: 0.18  loss_cls: 0.02639  loss_box_reg: 0.07434  loss_mask: 0.06553  loss_rpn_cls: 0.0004078  loss_rpn_loc: 0.009473  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:07] d2.utils.events INFO:  eta: 0:51:12  iter: 55259  total_loss: 0.2088  loss_cls: 0.03004  loss_box_reg: 0.09017  loss_mask: 0.06026  loss_rpn_cls: 0.0004429  loss_rpn_loc: 0.01376  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:08] d2.utils.events INFO:  eta: 0:51:11  iter: 55279  total_loss: 0.2158  loss_cls: 0.03057  loss_box_reg: 0.09028  loss_mask: 0.07115  loss_rpn_cls: 0.000622  loss_rpn_loc: 0.009058  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:10] d2.utils.events INFO:  eta: 0:51:06  iter: 55299  total_loss: 0.1499  loss_cls: 0.02391  loss_box_reg: 0.06181  loss_mask: 0.05344  loss_rpn_cls: 0.0008043  loss_rpn_loc: 0.00812  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:12] d2.utils.events INFO:  eta: 0:51:03  iter: 55319  total_loss: 0.09282  loss_cls: 0.01576  loss_box_reg: 0.03357  loss_mask: 0.04506  loss_rpn_cls: 0.0002612  loss_rpn_loc: 0.004916  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:13] d2.utils.events INFO:  eta: 0:51:01  iter: 55339  total_loss: 0.1985  loss_cls: 0.03263  loss_box_reg: 0.08316  loss_mask: 0.06374  loss_rpn_cls: 0.0005278  loss_rpn_loc: 0.02009  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:15] d2.utils.events INFO:  eta: 0:50:59  iter: 55359  total_loss: 0.2821  loss_cls: 0.03788  loss_box_reg: 0.1018  loss_mask: 0.07932  loss_rpn_cls: 0.0007348  loss_rpn_loc: 0.01745  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:17] d2.utils.events INFO:  eta: 0:50:59  iter: 55379  total_loss: 0.1704  loss_cls: 0.02515  loss_box_reg: 0.08724  loss_mask: 0.06046  loss_rpn_cls: 0.0005819  loss_rpn_loc: 0.008668  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:19] d2.utils.events INFO:  eta: 0:50:55  iter: 55399  total_loss: 0.1781  loss_cls: 0.02738  loss_box_reg: 0.07982  loss_mask: 0.05719  loss_rpn_cls: 0.000652  loss_rpn_loc: 0.01002  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:21] d2.utils.events INFO:  eta: 0:50:55  iter: 55419  total_loss: 0.1932  loss_cls: 0.03114  loss_box_reg: 0.08479  loss_mask: 0.0659  loss_rpn_cls: 0.0007437  loss_rpn_loc: 0.01752  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:22] d2.utils.events INFO:  eta: 0:50:54  iter: 55439  total_loss: 0.1743  loss_cls: 0.02856  loss_box_reg: 0.07548  loss_mask: 0.05451  loss_rpn_cls: 0.0005818  loss_rpn_loc: 0.01524  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:24] d2.utils.events INFO:  eta: 0:50:47  iter: 55459  total_loss: 0.1539  loss_cls: 0.02296  loss_box_reg: 0.06787  loss_mask: 0.04942  loss_rpn_cls: 0.0006134  loss_rpn_loc: 0.01128  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:26] d2.utils.events INFO:  eta: 0:50:45  iter: 55479  total_loss: 0.1532  loss_cls: 0.01636  loss_box_reg: 0.05976  loss_mask: 0.05105  loss_rpn_cls: 0.0005229  loss_rpn_loc: 0.009191  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:28] d2.utils.events INFO:  eta: 0:50:42  iter: 55499  total_loss: 0.2106  loss_cls: 0.03563  loss_box_reg: 0.1033  loss_mask: 0.06381  loss_rpn_cls: 0.001166  loss_rpn_loc: 0.01156  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:29] d2.utils.events INFO:  eta: 0:50:38  iter: 55519  total_loss: 0.1208  loss_cls: 0.01794  loss_box_reg: 0.05199  loss_mask: 0.05186  loss_rpn_cls: 0.0004218  loss_rpn_loc: 0.009966  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:59:31] d2.utils.events INFO:  eta: 0:50:36  iter: 55539  total_loss: 0.1997  loss_cls: 0.02606  loss_box_reg: 0.09  loss_mask: 0.06196  loss_rpn_cls: 0.0005082  loss_rpn_loc: 0.0134  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:33] d2.utils.events INFO:  eta: 0:50:33  iter: 55559  total_loss: 0.1979  loss_cls: 0.02638  loss_box_reg: 0.09034  loss_mask: 0.05358  loss_rpn_cls: 0.0004723  loss_rpn_loc: 0.007632  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:35] d2.utils.events INFO:  eta: 0:50:32  iter: 55579  total_loss: 0.156  loss_cls: 0.01864  loss_box_reg: 0.06588  loss_mask: 0.04562  loss_rpn_cls: 0.0002112  loss_rpn_loc: 0.006236  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:37] d2.utils.events INFO:  eta: 0:50:30  iter: 55599  total_loss: 0.1736  loss_cls: 0.03024  loss_box_reg: 0.07239  loss_mask: 0.0579  loss_rpn_cls: 0.0005748  loss_rpn_loc: 0.01496  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:38] d2.utils.events INFO:  eta: 0:50:26  iter: 55619  total_loss: 0.1792  loss_cls: 0.02715  loss_box_reg: 0.07238  loss_mask: 0.06286  loss_rpn_cls: 0.0005232  loss_rpn_loc: 0.008887  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:59:40] d2.utils.events INFO:  eta: 0:50:26  iter: 55639  total_loss: 0.161  loss_cls: 0.01747  loss_box_reg: 0.05951  loss_mask: 0.06118  loss_rpn_cls: 0.0005431  loss_rpn_loc: 0.009807  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:42] d2.utils.events INFO:  eta: 0:50:25  iter: 55659  total_loss: 0.226  loss_cls: 0.03665  loss_box_reg: 0.1061  loss_mask: 0.06117  loss_rpn_cls: 0.0006751  loss_rpn_loc: 0.009711  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:59:44] d2.utils.events INFO:  eta: 0:50:24  iter: 55679  total_loss: 0.1723  loss_cls: 0.02909  loss_box_reg: 0.0855  loss_mask: 0.05497  loss_rpn_cls: 0.001301  loss_rpn_loc: 0.01883  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:45] d2.utils.events INFO:  eta: 0:50:24  iter: 55699  total_loss: 0.1317  loss_cls: 0.01748  loss_box_reg: 0.06919  loss_mask: 0.04647  loss_rpn_cls: 0.0003523  loss_rpn_loc: 0.007709  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:47] d2.utils.events INFO:  eta: 0:50:19  iter: 55719  total_loss: 0.1558  loss_cls: 0.01796  loss_box_reg: 0.06097  loss_mask: 0.05858  loss_rpn_cls: 0.0006697  loss_rpn_loc: 0.007766  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:49] d2.utils.events INFO:  eta: 0:50:13  iter: 55739  total_loss: 0.1573  loss_cls: 0.02027  loss_box_reg: 0.06904  loss_mask: 0.05232  loss_rpn_cls: 0.0005442  loss_rpn_loc: 0.01048  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:51] d2.utils.events INFO:  eta: 0:50:17  iter: 55759  total_loss: 0.2412  loss_cls: 0.03579  loss_box_reg: 0.1072  loss_mask: 0.06899  loss_rpn_cls: 0.0005287  loss_rpn_loc: 0.01002  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:52] d2.utils.events INFO:  eta: 0:50:12  iter: 55779  total_loss: 0.1198  loss_cls: 0.01739  loss_box_reg: 0.05335  loss_mask: 0.04413  loss_rpn_cls: 0.0004455  loss_rpn_loc: 0.008691  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:54] d2.utils.events INFO:  eta: 0:50:07  iter: 55799  total_loss: 0.1496  loss_cls: 0.02535  loss_box_reg: 0.06556  loss_mask: 0.05531  loss_rpn_cls: 0.0005183  loss_rpn_loc: 0.008549  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 19:59:56] d2.utils.events INFO:  eta: 0:50:10  iter: 55819  total_loss: 0.1982  loss_cls: 0.03244  loss_box_reg: 0.09516  loss_mask: 0.0614  loss_rpn_cls: 0.0005832  loss_rpn_loc: 0.01052  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 19:59:58] d2.utils.events INFO:  eta: 0:50:07  iter: 55839  total_loss: 0.1795  loss_cls: 0.02855  loss_box_reg: 0.07744  loss_mask: 0.05032  loss_rpn_cls: 0.0006537  loss_rpn_loc: 0.01237  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 19:59:59] d2.utils.events INFO:  eta: 0:50:01  iter: 55859  total_loss: 0.1399  loss_cls: 0.02918  loss_box_reg: 0.06778  loss_mask: 0.0483  loss_rpn_cls: 0.0006584  loss_rpn_loc: 0.00757  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:01] d2.utils.events INFO:  eta: 0:49:53  iter: 55879  total_loss: 0.1428  loss_cls: 0.01637  loss_box_reg: 0.05482  loss_mask: 0.04906  loss_rpn_cls: 0.0006724  loss_rpn_loc: 0.009394  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 20:00:03] d2.utils.events INFO:  eta: 0:49:46  iter: 55899  total_loss: 0.1726  loss_cls: 0.02924  loss_box_reg: 0.07299  loss_mask: 0.0431  loss_rpn_cls: 0.0006662  loss_rpn_loc: 0.008215  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:05] d2.utils.events INFO:  eta: 0:49:44  iter: 55919  total_loss: 0.1535  loss_cls: 0.02191  loss_box_reg: 0.07435  loss_mask: 0.0615  loss_rpn_cls: 0.0004231  loss_rpn_loc: 0.01348  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:06] d2.utils.events INFO:  eta: 0:49:43  iter: 55939  total_loss: 0.1552  loss_cls: 0.02447  loss_box_reg: 0.0671  loss_mask: 0.06277  loss_rpn_cls: 0.0004102  loss_rpn_loc: 0.009213  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:08] d2.utils.events INFO:  eta: 0:49:41  iter: 55959  total_loss: 0.1674  loss_cls: 0.02236  loss_box_reg: 0.07849  loss_mask: 0.05616  loss_rpn_cls: 0.0003423  loss_rpn_loc: 0.008198  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:10] d2.utils.events INFO:  eta: 0:49:49  iter: 55979  total_loss: 0.2376  loss_cls: 0.04417  loss_box_reg: 0.1011  loss_mask: 0.06139  loss_rpn_cls: 0.001068  loss_rpn_loc: 0.01612  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:12] d2.utils.events INFO:  eta: 0:49:48  iter: 55999  total_loss: 0.2211  loss_cls: 0.02222  loss_box_reg: 0.07677  loss_mask: 0.07792  loss_rpn_cls: 0.0006829  loss_rpn_loc: 0.01194  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:13] d2.utils.events INFO:  eta: 0:49:49  iter: 56019  total_loss: 0.2234  loss_cls: 0.02726  loss_box_reg: 0.07331  loss_mask: 0.07247  loss_rpn_cls: 0.0006578  loss_rpn_loc: 0.01119  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:15] d2.utils.events INFO:  eta: 0:49:45  iter: 56039  total_loss: 0.1708  loss_cls: 0.02426  loss_box_reg: 0.07693  loss_mask: 0.05264  loss_rpn_cls: 0.0004458  loss_rpn_loc: 0.00955  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:17] d2.utils.events INFO:  eta: 0:49:43  iter: 56059  total_loss: 0.1844  loss_cls: 0.02482  loss_box_reg: 0.06704  loss_mask: 0.06924  loss_rpn_cls: 0.0004223  loss_rpn_loc: 0.006433  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:19] d2.utils.events INFO:  eta: 0:49:41  iter: 56079  total_loss: 0.1251  loss_cls: 0.017  loss_box_reg: 0.05512  loss_mask: 0.05567  loss_rpn_cls: 0.0001775  loss_rpn_loc: 0.004369  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:21] d2.utils.events INFO:  eta: 0:49:41  iter: 56099  total_loss: 0.2448  loss_cls: 0.03583  loss_box_reg: 0.1141  loss_mask: 0.06174  loss_rpn_cls: 0.000678  loss_rpn_loc: 0.01455  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:22] d2.utils.events INFO:  eta: 0:49:40  iter: 56119  total_loss: 0.2  loss_cls: 0.026  loss_box_reg: 0.06991  loss_mask: 0.0537  loss_rpn_cls: 0.0005713  loss_rpn_loc: 0.01428  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:24] d2.utils.events INFO:  eta: 0:49:42  iter: 56139  total_loss: 0.1578  loss_cls: 0.02559  loss_box_reg: 0.06839  loss_mask: 0.0509  loss_rpn_cls: 0.0004548  loss_rpn_loc: 0.01117  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:26] d2.utils.events INFO:  eta: 0:49:42  iter: 56159  total_loss: 0.1267  loss_cls: 0.01949  loss_box_reg: 0.04855  loss_mask: 0.04959  loss_rpn_cls: 0.0004241  loss_rpn_loc: 0.00847  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:28] d2.utils.events INFO:  eta: 0:49:37  iter: 56179  total_loss: 0.1516  loss_cls: 0.02431  loss_box_reg: 0.06822  loss_mask: 0.04557  loss_rpn_cls: 0.0006996  loss_rpn_loc: 0.009108  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:29] d2.utils.events INFO:  eta: 0:49:33  iter: 56199  total_loss: 0.0932  loss_cls: 0.01446  loss_box_reg: 0.03326  loss_mask: 0.04447  loss_rpn_cls: 0.0003301  loss_rpn_loc: 0.005114  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:31] d2.utils.events INFO:  eta: 0:49:29  iter: 56219  total_loss: 0.1637  loss_cls: 0.01934  loss_box_reg: 0.0563  loss_mask: 0.06292  loss_rpn_cls: 0.0009409  loss_rpn_loc: 0.01092  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:33] d2.utils.events INFO:  eta: 0:49:27  iter: 56239  total_loss: 0.1738  loss_cls: 0.02783  loss_box_reg: 0.08187  loss_mask: 0.05788  loss_rpn_cls: 0.0005391  loss_rpn_loc: 0.009648  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:34] d2.utils.events INFO:  eta: 0:49:23  iter: 56259  total_loss: 0.1921  loss_cls: 0.03275  loss_box_reg: 0.08558  loss_mask: 0.05341  loss_rpn_cls: 0.0007141  loss_rpn_loc: 0.01461  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:36] d2.utils.events INFO:  eta: 0:49:24  iter: 56279  total_loss: 0.2338  loss_cls: 0.02958  loss_box_reg: 0.1148  loss_mask: 0.07306  loss_rpn_cls: 0.0008611  loss_rpn_loc: 0.01861  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:38] d2.utils.events INFO:  eta: 0:49:22  iter: 56299  total_loss: 0.1331  loss_cls: 0.01807  loss_box_reg: 0.05235  loss_mask: 0.06184  loss_rpn_cls: 0.0005085  loss_rpn_loc: 0.009201  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:40] d2.utils.events INFO:  eta: 0:49:23  iter: 56319  total_loss: 0.1619  loss_cls: 0.02569  loss_box_reg: 0.08024  loss_mask: 0.05942  loss_rpn_cls: 0.0008835  loss_rpn_loc: 0.01017  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:41] d2.utils.events INFO:  eta: 0:49:18  iter: 56339  total_loss: 0.1177  loss_cls: 0.01809  loss_box_reg: 0.04691  loss_mask: 0.04793  loss_rpn_cls: 0.0004363  loss_rpn_loc: 0.01  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:43] d2.utils.events INFO:  eta: 0:49:11  iter: 56359  total_loss: 0.1658  loss_cls: 0.02187  loss_box_reg: 0.07746  loss_mask: 0.0465  loss_rpn_cls: 0.0003764  loss_rpn_loc: 0.01666  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:45] d2.utils.events INFO:  eta: 0:49:04  iter: 56379  total_loss: 0.1512  loss_cls: 0.02785  loss_box_reg: 0.0742  loss_mask: 0.0489  loss_rpn_cls: 0.0004569  loss_rpn_loc: 0.009357  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:47] d2.utils.events INFO:  eta: 0:49:02  iter: 56399  total_loss: 0.2225  loss_cls: 0.03026  loss_box_reg: 0.1083  loss_mask: 0.0753  loss_rpn_cls: 0.00087  loss_rpn_loc: 0.01436  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:48] d2.utils.events INFO:  eta: 0:49:06  iter: 56419  total_loss: 0.2143  loss_cls: 0.03735  loss_box_reg: 0.09981  loss_mask: 0.06299  loss_rpn_cls: 0.0004539  loss_rpn_loc: 0.0109  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:50] d2.utils.events INFO:  eta: 0:48:59  iter: 56439  total_loss: 0.2215  loss_cls: 0.0245  loss_box_reg: 0.07243  loss_mask: 0.05758  loss_rpn_cls: 0.0004046  loss_rpn_loc: 0.006172  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:52] d2.utils.events INFO:  eta: 0:49:06  iter: 56459  total_loss: 0.1914  loss_cls: 0.0266  loss_box_reg: 0.1027  loss_mask: 0.05824  loss_rpn_cls: 0.001105  loss_rpn_loc: 0.01226  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:54] d2.utils.events INFO:  eta: 0:49:00  iter: 56479  total_loss: 0.1244  loss_cls: 0.02183  loss_box_reg: 0.06288  loss_mask: 0.04987  loss_rpn_cls: 0.0004974  loss_rpn_loc: 0.008637  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:00:56] d2.utils.events INFO:  eta: 0:48:56  iter: 56499  total_loss: 0.1337  loss_cls: 0.01846  loss_box_reg: 0.05835  loss_mask: 0.0497  loss_rpn_cls: 0.0003597  loss_rpn_loc: 0.008348  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:57] d2.utils.events INFO:  eta: 0:48:57  iter: 56519  total_loss: 0.1526  loss_cls: 0.02145  loss_box_reg: 0.06714  loss_mask: 0.06006  loss_rpn_cls: 0.000401  loss_rpn_loc: 0.01283  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:00:59] d2.utils.events INFO:  eta: 0:48:51  iter: 56539  total_loss: 0.1535  loss_cls: 0.02649  loss_box_reg: 0.06565  loss_mask: 0.06475  loss_rpn_cls: 0.0008122  loss_rpn_loc: 0.009962  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:01] d2.utils.events INFO:  eta: 0:48:51  iter: 56559  total_loss: 0.182  loss_cls: 0.02797  loss_box_reg: 0.08099  loss_mask: 0.05672  loss_rpn_cls: 0.0007423  loss_rpn_loc: 0.01289  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:03] d2.utils.events INFO:  eta: 0:48:54  iter: 56579  total_loss: 0.1647  loss_cls: 0.02407  loss_box_reg: 0.06929  loss_mask: 0.05668  loss_rpn_cls: 0.0004136  loss_rpn_loc: 0.009083  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:04] d2.utils.events INFO:  eta: 0:48:52  iter: 56599  total_loss: 0.1516  loss_cls: 0.01542  loss_box_reg: 0.0591  loss_mask: 0.06138  loss_rpn_cls: 0.0007418  loss_rpn_loc: 0.01503  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:06] d2.utils.events INFO:  eta: 0:48:51  iter: 56619  total_loss: 0.1781  loss_cls: 0.01896  loss_box_reg: 0.07146  loss_mask: 0.06966  loss_rpn_cls: 0.0007353  loss_rpn_loc: 0.01178  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:08] d2.utils.events INFO:  eta: 0:48:49  iter: 56639  total_loss: 0.1571  loss_cls: 0.02655  loss_box_reg: 0.07895  loss_mask: 0.04626  loss_rpn_cls: 0.0006582  loss_rpn_loc: 0.01019  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:10] d2.utils.events INFO:  eta: 0:48:38  iter: 56659  total_loss: 0.1573  loss_cls: 0.02215  loss_box_reg: 0.06711  loss_mask: 0.06211  loss_rpn_cls: 0.000568  loss_rpn_loc: 0.01191  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:11] d2.utils.events INFO:  eta: 0:48:35  iter: 56679  total_loss: 0.2078  loss_cls: 0.03017  loss_box_reg: 0.08421  loss_mask: 0.06603  loss_rpn_cls: 0.001006  loss_rpn_loc: 0.01672  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:13] d2.utils.events INFO:  eta: 0:48:34  iter: 56699  total_loss: 0.1628  loss_cls: 0.01855  loss_box_reg: 0.08849  loss_mask: 0.05498  loss_rpn_cls: 0.0006142  loss_rpn_loc: 0.01061  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:15] d2.utils.events INFO:  eta: 0:48:32  iter: 56719  total_loss: 0.1254  loss_cls: 0.01899  loss_box_reg: 0.05374  loss_mask: 0.04984  loss_rpn_cls: 0.0002334  loss_rpn_loc: 0.005684  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:17] d2.utils.events INFO:  eta: 0:48:31  iter: 56739  total_loss: 0.1761  loss_cls: 0.02794  loss_box_reg: 0.08075  loss_mask: 0.06138  loss_rpn_cls: 0.000691  loss_rpn_loc: 0.007369  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:18] d2.utils.events INFO:  eta: 0:48:24  iter: 56759  total_loss: 0.1434  loss_cls: 0.02314  loss_box_reg: 0.06028  loss_mask: 0.05471  loss_rpn_cls: 0.0003902  loss_rpn_loc: 0.007053  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:20] d2.utils.events INFO:  eta: 0:48:26  iter: 56779  total_loss: 0.1938  loss_cls: 0.02912  loss_box_reg: 0.08879  loss_mask: 0.04856  loss_rpn_cls: 0.0007163  loss_rpn_loc: 0.01273  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:22] d2.utils.events INFO:  eta: 0:48:21  iter: 56799  total_loss: 0.1268  loss_cls: 0.01973  loss_box_reg: 0.06222  loss_mask: 0.05051  loss_rpn_cls: 0.0004913  loss_rpn_loc: 0.006632  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:24] d2.utils.events INFO:  eta: 0:48:18  iter: 56819  total_loss: 0.1687  loss_cls: 0.02342  loss_box_reg: 0.07203  loss_mask: 0.06069  loss_rpn_cls: 0.0004622  loss_rpn_loc: 0.01535  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:25] d2.utils.events INFO:  eta: 0:48:21  iter: 56839  total_loss: 0.1814  loss_cls: 0.02566  loss_box_reg: 0.07076  loss_mask: 0.06137  loss_rpn_cls: 0.0005955  loss_rpn_loc: 0.01584  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:27] d2.utils.events INFO:  eta: 0:48:19  iter: 56859  total_loss: 0.1723  loss_cls: 0.02428  loss_box_reg: 0.07226  loss_mask: 0.05619  loss_rpn_cls: 0.0003089  loss_rpn_loc: 0.00967  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:29] d2.utils.events INFO:  eta: 0:48:29  iter: 56879  total_loss: 0.245  loss_cls: 0.04146  loss_box_reg: 0.09377  loss_mask: 0.07375  loss_rpn_cls: 0.0009497  loss_rpn_loc: 0.02953  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:31] d2.utils.events INFO:  eta: 0:48:21  iter: 56899  total_loss: 0.1374  loss_cls: 0.01894  loss_box_reg: 0.06689  loss_mask: 0.04586  loss_rpn_cls: 0.0004358  loss_rpn_loc: 0.007304  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:32] d2.utils.events INFO:  eta: 0:48:14  iter: 56919  total_loss: 0.1693  loss_cls: 0.01941  loss_box_reg: 0.06512  loss_mask: 0.0578  loss_rpn_cls: 0.0002973  loss_rpn_loc: 0.008781  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:34] d2.utils.events INFO:  eta: 0:48:15  iter: 56939  total_loss: 0.2343  loss_cls: 0.0352  loss_box_reg: 0.1094  loss_mask: 0.07696  loss_rpn_cls: 0.0006592  loss_rpn_loc: 0.01337  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:36] d2.utils.events INFO:  eta: 0:48:16  iter: 56959  total_loss: 0.2233  loss_cls: 0.03474  loss_box_reg: 0.08607  loss_mask: 0.07331  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.01815  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:38] d2.utils.events INFO:  eta: 0:48:08  iter: 56979  total_loss: 0.1915  loss_cls: 0.02741  loss_box_reg: 0.07293  loss_mask: 0.06594  loss_rpn_cls: 0.0005631  loss_rpn_loc: 0.008498  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:39] d2.utils.events INFO:  eta: 0:48:02  iter: 56999  total_loss: 0.08271  loss_cls: 0.0132  loss_box_reg: 0.02946  loss_mask: 0.04306  loss_rpn_cls: 0.0003979  loss_rpn_loc: 0.006288  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:41] d2.utils.events INFO:  eta: 0:47:58  iter: 57019  total_loss: 0.161  loss_cls: 0.02939  loss_box_reg: 0.07549  loss_mask: 0.04394  loss_rpn_cls: 0.0003089  loss_rpn_loc: 0.006347  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 20:01:43] d2.utils.events INFO:  eta: 0:47:57  iter: 57039  total_loss: 0.1406  loss_cls: 0.03027  loss_box_reg: 0.07103  loss_mask: 0.04717  loss_rpn_cls: 0.000721  loss_rpn_loc: 0.009137  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:45] d2.utils.events INFO:  eta: 0:47:55  iter: 57059  total_loss: 0.1848  loss_cls: 0.02658  loss_box_reg: 0.08366  loss_mask: 0.05589  loss_rpn_cls: 0.00059  loss_rpn_loc: 0.006555  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:46] d2.utils.events INFO:  eta: 0:47:56  iter: 57079  total_loss: 0.2808  loss_cls: 0.04172  loss_box_reg: 0.1216  loss_mask: 0.07951  loss_rpn_cls: 0.0008454  loss_rpn_loc: 0.02122  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:48] d2.utils.events INFO:  eta: 0:47:52  iter: 57099  total_loss: 0.1594  loss_cls: 0.02272  loss_box_reg: 0.06983  loss_mask: 0.0637  loss_rpn_cls: 0.0008154  loss_rpn_loc: 0.01101  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:50] d2.utils.events INFO:  eta: 0:47:50  iter: 57119  total_loss: 0.1606  loss_cls: 0.02574  loss_box_reg: 0.05169  loss_mask: 0.0616  loss_rpn_cls: 0.0003358  loss_rpn_loc: 0.01164  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:52] d2.utils.events INFO:  eta: 0:47:51  iter: 57139  total_loss: 0.2402  loss_cls: 0.02613  loss_box_reg: 0.1039  loss_mask: 0.07514  loss_rpn_cls: 0.0009155  loss_rpn_loc: 0.01451  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:53] d2.utils.events INFO:  eta: 0:47:50  iter: 57159  total_loss: 0.1662  loss_cls: 0.02562  loss_box_reg: 0.07264  loss_mask: 0.06022  loss_rpn_cls: 0.0005479  loss_rpn_loc: 0.015  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:55] d2.utils.events INFO:  eta: 0:47:47  iter: 57179  total_loss: 0.1288  loss_cls: 0.0169  loss_box_reg: 0.05836  loss_mask: 0.05047  loss_rpn_cls: 0.0003004  loss_rpn_loc: 0.006912  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:01:57] d2.utils.events INFO:  eta: 0:47:48  iter: 57199  total_loss: 0.1832  loss_cls: 0.02462  loss_box_reg: 0.09738  loss_mask: 0.06263  loss_rpn_cls: 0.001118  loss_rpn_loc: 0.01314  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:01:59] d2.utils.events INFO:  eta: 0:47:49  iter: 57219  total_loss: 0.1945  loss_cls: 0.03247  loss_box_reg: 0.09059  loss_mask: 0.05642  loss_rpn_cls: 0.0006961  loss_rpn_loc: 0.02003  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:00] d2.utils.events INFO:  eta: 0:47:46  iter: 57239  total_loss: 0.177  loss_cls: 0.02788  loss_box_reg: 0.07515  loss_mask: 0.05377  loss_rpn_cls: 0.0006976  loss_rpn_loc: 0.013  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:02] d2.utils.events INFO:  eta: 0:47:42  iter: 57259  total_loss: 0.147  loss_cls: 0.02293  loss_box_reg: 0.06428  loss_mask: 0.05624  loss_rpn_cls: 0.0007323  loss_rpn_loc: 0.008335  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:04] d2.utils.events INFO:  eta: 0:47:39  iter: 57279  total_loss: 0.165  loss_cls: 0.02306  loss_box_reg: 0.06817  loss_mask: 0.0601  loss_rpn_cls: 0.0008706  loss_rpn_loc: 0.01596  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:06] d2.utils.events INFO:  eta: 0:47:38  iter: 57299  total_loss: 0.183  loss_cls: 0.03611  loss_box_reg: 0.08267  loss_mask: 0.06862  loss_rpn_cls: 0.0009476  loss_rpn_loc: 0.01716  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:07] d2.utils.events INFO:  eta: 0:47:35  iter: 57319  total_loss: 0.1204  loss_cls: 0.01713  loss_box_reg: 0.05891  loss_mask: 0.04833  loss_rpn_cls: 0.0004593  loss_rpn_loc: 0.004989  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:09] d2.utils.events INFO:  eta: 0:47:35  iter: 57339  total_loss: 0.1326  loss_cls: 0.01705  loss_box_reg: 0.05805  loss_mask: 0.05405  loss_rpn_cls: 0.0003752  loss_rpn_loc: 0.007703  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:11] d2.utils.events INFO:  eta: 0:47:33  iter: 57359  total_loss: 0.1312  loss_cls: 0.01888  loss_box_reg: 0.059  loss_mask: 0.05968  loss_rpn_cls: 0.0008179  loss_rpn_loc: 0.01288  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:13] d2.utils.events INFO:  eta: 0:47:32  iter: 57379  total_loss: 0.1825  loss_cls: 0.03274  loss_box_reg: 0.08228  loss_mask: 0.06012  loss_rpn_cls: 0.0008525  loss_rpn_loc: 0.01618  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:15] d2.utils.events INFO:  eta: 0:47:30  iter: 57399  total_loss: 0.216  loss_cls: 0.02547  loss_box_reg: 0.08516  loss_mask: 0.05544  loss_rpn_cls: 0.0004747  loss_rpn_loc: 0.01476  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:16] d2.utils.events INFO:  eta: 0:47:28  iter: 57419  total_loss: 0.1524  loss_cls: 0.02481  loss_box_reg: 0.079  loss_mask: 0.05428  loss_rpn_cls: 0.0007224  loss_rpn_loc: 0.01079  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:18] d2.utils.events INFO:  eta: 0:47:26  iter: 57439  total_loss: 0.202  loss_cls: 0.02763  loss_box_reg: 0.09866  loss_mask: 0.05606  loss_rpn_cls: 0.0005004  loss_rpn_loc: 0.01165  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:20] d2.utils.events INFO:  eta: 0:47:25  iter: 57459  total_loss: 0.1856  loss_cls: 0.02423  loss_box_reg: 0.07944  loss_mask: 0.05589  loss_rpn_cls: 0.0005975  loss_rpn_loc: 0.008883  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:22] d2.utils.events INFO:  eta: 0:47:28  iter: 57479  total_loss: 0.1738  loss_cls: 0.0231  loss_box_reg: 0.08685  loss_mask: 0.06144  loss_rpn_cls: 0.0005059  loss_rpn_loc: 0.01209  time: 0.0879  data_time: 0.0022  lr: 0.0025  max_mem: 1494M
[10/27 20:02:23] d2.utils.events INFO:  eta: 0:47:21  iter: 57499  total_loss: 0.1405  loss_cls: 0.01687  loss_box_reg: 0.05418  loss_mask: 0.04363  loss_rpn_cls: 0.0005103  loss_rpn_loc: 0.007741  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:25] d2.utils.events INFO:  eta: 0:47:19  iter: 57519  total_loss: 0.1334  loss_cls: 0.01763  loss_box_reg: 0.06017  loss_mask: 0.04725  loss_rpn_cls: 0.0003995  loss_rpn_loc: 0.005588  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:27] d2.utils.events INFO:  eta: 0:47:18  iter: 57539  total_loss: 0.2004  loss_cls: 0.03123  loss_box_reg: 0.1036  loss_mask: 0.07107  loss_rpn_cls: 0.0008919  loss_rpn_loc: 0.0214  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:29] d2.utils.events INFO:  eta: 0:47:16  iter: 57559  total_loss: 0.1168  loss_cls: 0.01498  loss_box_reg: 0.05373  loss_mask: 0.04879  loss_rpn_cls: 0.0002386  loss_rpn_loc: 0.004288  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:30] d2.utils.events INFO:  eta: 0:47:11  iter: 57579  total_loss: 0.1374  loss_cls: 0.0154  loss_box_reg: 0.05397  loss_mask: 0.04551  loss_rpn_cls: 0.0003928  loss_rpn_loc: 0.009786  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:32] d2.utils.events INFO:  eta: 0:47:12  iter: 57599  total_loss: 0.2004  loss_cls: 0.02615  loss_box_reg: 0.08225  loss_mask: 0.06799  loss_rpn_cls: 0.0007906  loss_rpn_loc: 0.0117  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:34] d2.utils.events INFO:  eta: 0:47:10  iter: 57619  total_loss: 0.186  loss_cls: 0.03171  loss_box_reg: 0.08083  loss_mask: 0.05756  loss_rpn_cls: 0.0005192  loss_rpn_loc: 0.01223  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:36] d2.utils.events INFO:  eta: 0:47:07  iter: 57639  total_loss: 0.1484  loss_cls: 0.02406  loss_box_reg: 0.08117  loss_mask: 0.06028  loss_rpn_cls: 0.000376  loss_rpn_loc: 0.004945  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:37] d2.utils.events INFO:  eta: 0:47:06  iter: 57659  total_loss: 0.1428  loss_cls: 0.01772  loss_box_reg: 0.05686  loss_mask: 0.04786  loss_rpn_cls: 0.0005445  loss_rpn_loc: 0.008378  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:39] d2.utils.events INFO:  eta: 0:47:04  iter: 57679  total_loss: 0.176  loss_cls: 0.02358  loss_box_reg: 0.07377  loss_mask: 0.05327  loss_rpn_cls: 0.0006368  loss_rpn_loc: 0.008617  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:41] d2.utils.events INFO:  eta: 0:47:03  iter: 57699  total_loss: 0.196  loss_cls: 0.0352  loss_box_reg: 0.08538  loss_mask: 0.0686  loss_rpn_cls: 0.0006429  loss_rpn_loc: 0.01688  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:42] d2.utils.events INFO:  eta: 0:47:02  iter: 57719  total_loss: 0.2325  loss_cls: 0.03051  loss_box_reg: 0.07986  loss_mask: 0.06761  loss_rpn_cls: 0.0003989  loss_rpn_loc: 0.009999  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:44] d2.utils.events INFO:  eta: 0:47:00  iter: 57739  total_loss: 0.1322  loss_cls: 0.01977  loss_box_reg: 0.06378  loss_mask: 0.04611  loss_rpn_cls: 0.0003374  loss_rpn_loc: 0.00765  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:46] d2.utils.events INFO:  eta: 0:46:58  iter: 57759  total_loss: 0.1688  loss_cls: 0.02814  loss_box_reg: 0.06775  loss_mask: 0.06122  loss_rpn_cls: 0.000536  loss_rpn_loc: 0.01102  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:48] d2.utils.events INFO:  eta: 0:46:55  iter: 57779  total_loss: 0.1602  loss_cls: 0.02375  loss_box_reg: 0.07184  loss_mask: 0.05427  loss_rpn_cls: 0.0003453  loss_rpn_loc: 0.008564  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:49] d2.utils.events INFO:  eta: 0:46:55  iter: 57799  total_loss: 0.2252  loss_cls: 0.03024  loss_box_reg: 0.08231  loss_mask: 0.05622  loss_rpn_cls: 0.0007849  loss_rpn_loc: 0.02134  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:51] d2.utils.events INFO:  eta: 0:46:52  iter: 57819  total_loss: 0.1308  loss_cls: 0.01496  loss_box_reg: 0.04825  loss_mask: 0.0498  loss_rpn_cls: 0.0008359  loss_rpn_loc: 0.006167  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:53] d2.utils.events INFO:  eta: 0:46:50  iter: 57839  total_loss: 0.1864  loss_cls: 0.02746  loss_box_reg: 0.09631  loss_mask: 0.05735  loss_rpn_cls: 0.0008012  loss_rpn_loc: 0.01486  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:02:54] d2.utils.events INFO:  eta: 0:46:42  iter: 57859  total_loss: 0.1384  loss_cls: 0.02049  loss_box_reg: 0.06158  loss_mask: 0.05353  loss_rpn_cls: 0.0006815  loss_rpn_loc: 0.01146  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:02:56] d2.utils.events INFO:  eta: 0:46:38  iter: 57879  total_loss: 0.1995  loss_cls: 0.03017  loss_box_reg: 0.08779  loss_mask: 0.04846  loss_rpn_cls: 0.0007047  loss_rpn_loc: 0.01204  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:02:58] d2.utils.events INFO:  eta: 0:46:39  iter: 57899  total_loss: 0.1742  loss_cls: 0.03088  loss_box_reg: 0.08183  loss_mask: 0.05853  loss_rpn_cls: 0.0005416  loss_rpn_loc: 0.009149  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:00] d2.utils.events INFO:  eta: 0:46:37  iter: 57919  total_loss: 0.1731  loss_cls: 0.01795  loss_box_reg: 0.06785  loss_mask: 0.05559  loss_rpn_cls: 0.0005773  loss_rpn_loc: 0.01113  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:01] d2.utils.events INFO:  eta: 0:46:33  iter: 57939  total_loss: 0.1634  loss_cls: 0.02994  loss_box_reg: 0.06611  loss_mask: 0.05846  loss_rpn_cls: 0.0006478  loss_rpn_loc: 0.01272  time: 0.0879  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:03:03] d2.utils.events INFO:  eta: 0:46:31  iter: 57959  total_loss: 0.1781  loss_cls: 0.03256  loss_box_reg: 0.1069  loss_mask: 0.05704  loss_rpn_cls: 0.0009866  loss_rpn_loc: 0.01035  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:05] d2.utils.events INFO:  eta: 0:46:31  iter: 57979  total_loss: 0.1964  loss_cls: 0.0282  loss_box_reg: 0.08359  loss_mask: 0.06603  loss_rpn_cls: 0.001102  loss_rpn_loc: 0.02605  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:07] d2.utils.events INFO:  eta: 0:46:30  iter: 57999  total_loss: 0.151  loss_cls: 0.02466  loss_box_reg: 0.06262  loss_mask: 0.05866  loss_rpn_cls: 0.0004139  loss_rpn_loc: 0.01007  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:08] d2.utils.events INFO:  eta: 0:46:34  iter: 58019  total_loss: 0.2069  loss_cls: 0.03405  loss_box_reg: 0.08502  loss_mask: 0.06259  loss_rpn_cls: 0.0008192  loss_rpn_loc: 0.008818  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:10] d2.utils.events INFO:  eta: 0:46:30  iter: 58039  total_loss: 0.1703  loss_cls: 0.02117  loss_box_reg: 0.07944  loss_mask: 0.06888  loss_rpn_cls: 0.0005734  loss_rpn_loc: 0.01084  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:12] d2.utils.events INFO:  eta: 0:46:25  iter: 58059  total_loss: 0.1426  loss_cls: 0.02314  loss_box_reg: 0.05848  loss_mask: 0.05108  loss_rpn_cls: 0.0003249  loss_rpn_loc: 0.005228  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:13] d2.utils.events INFO:  eta: 0:46:21  iter: 58079  total_loss: 0.1138  loss_cls: 0.01974  loss_box_reg: 0.04887  loss_mask: 0.04953  loss_rpn_cls: 0.0004673  loss_rpn_loc: 0.007758  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:15] d2.utils.events INFO:  eta: 0:46:19  iter: 58099  total_loss: 0.1794  loss_cls: 0.02128  loss_box_reg: 0.08255  loss_mask: 0.05326  loss_rpn_cls: 0.0004977  loss_rpn_loc: 0.006357  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:17] d2.utils.events INFO:  eta: 0:46:17  iter: 58119  total_loss: 0.119  loss_cls: 0.01735  loss_box_reg: 0.04126  loss_mask: 0.05456  loss_rpn_cls: 0.0004412  loss_rpn_loc: 0.007894  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:19] d2.utils.events INFO:  eta: 0:46:07  iter: 58139  total_loss: 0.09862  loss_cls: 0.01759  loss_box_reg: 0.0451  loss_mask: 0.04174  loss_rpn_cls: 0.0002959  loss_rpn_loc: 0.004208  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:20] d2.utils.events INFO:  eta: 0:46:02  iter: 58159  total_loss: 0.1877  loss_cls: 0.02077  loss_box_reg: 0.0658  loss_mask: 0.06633  loss_rpn_cls: 0.0007297  loss_rpn_loc: 0.008822  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:22] d2.utils.events INFO:  eta: 0:46:08  iter: 58179  total_loss: 0.2018  loss_cls: 0.02744  loss_box_reg: 0.09901  loss_mask: 0.06979  loss_rpn_cls: 0.0009484  loss_rpn_loc: 0.01295  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:24] d2.utils.events INFO:  eta: 0:46:06  iter: 58199  total_loss: 0.2062  loss_cls: 0.03167  loss_box_reg: 0.09585  loss_mask: 0.07163  loss_rpn_cls: 0.001022  loss_rpn_loc: 0.02217  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:26] d2.utils.events INFO:  eta: 0:45:57  iter: 58219  total_loss: 0.115  loss_cls: 0.01727  loss_box_reg: 0.04181  loss_mask: 0.04462  loss_rpn_cls: 0.0002631  loss_rpn_loc: 0.006887  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:27] d2.utils.events INFO:  eta: 0:45:55  iter: 58239  total_loss: 0.1725  loss_cls: 0.02511  loss_box_reg: 0.07435  loss_mask: 0.0607  loss_rpn_cls: 0.0006362  loss_rpn_loc: 0.00873  time: 0.0879  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:29] d2.utils.events INFO:  eta: 0:46:00  iter: 58259  total_loss: 0.1757  loss_cls: 0.041  loss_box_reg: 0.07587  loss_mask: 0.06662  loss_rpn_cls: 0.0009884  loss_rpn_loc: 0.01506  time: 0.0879  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:31] d2.utils.events INFO:  eta: 0:45:56  iter: 58279  total_loss: 0.1573  loss_cls: 0.01801  loss_box_reg: 0.05881  loss_mask: 0.05814  loss_rpn_cls: 0.0005557  loss_rpn_loc: 0.01075  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:33] d2.utils.events INFO:  eta: 0:45:57  iter: 58299  total_loss: 0.271  loss_cls: 0.04339  loss_box_reg: 0.1124  loss_mask: 0.08028  loss_rpn_cls: 0.002092  loss_rpn_loc: 0.02682  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:34] d2.utils.events INFO:  eta: 0:46:00  iter: 58319  total_loss: 0.1429  loss_cls: 0.02367  loss_box_reg: 0.06017  loss_mask: 0.05333  loss_rpn_cls: 0.0002971  loss_rpn_loc: 0.009298  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:36] d2.utils.events INFO:  eta: 0:45:58  iter: 58339  total_loss: 0.1717  loss_cls: 0.02508  loss_box_reg: 0.0613  loss_mask: 0.04886  loss_rpn_cls: 0.0009275  loss_rpn_loc: 0.01572  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:38] d2.utils.events INFO:  eta: 0:45:58  iter: 58359  total_loss: 0.1794  loss_cls: 0.02973  loss_box_reg: 0.07964  loss_mask: 0.05108  loss_rpn_cls: 0.0004278  loss_rpn_loc: 0.01093  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:40] d2.utils.events INFO:  eta: 0:45:50  iter: 58379  total_loss: 0.1563  loss_cls: 0.0174  loss_box_reg: 0.06211  loss_mask: 0.05181  loss_rpn_cls: 0.00065  loss_rpn_loc: 0.01029  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:41] d2.utils.events INFO:  eta: 0:45:41  iter: 58399  total_loss: 0.1198  loss_cls: 0.01546  loss_box_reg: 0.05348  loss_mask: 0.04515  loss_rpn_cls: 0.0003702  loss_rpn_loc: 0.006597  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:43] d2.utils.events INFO:  eta: 0:45:41  iter: 58419  total_loss: 0.1994  loss_cls: 0.02846  loss_box_reg: 0.1008  loss_mask: 0.05969  loss_rpn_cls: 0.0006622  loss_rpn_loc: 0.01495  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:45] d2.utils.events INFO:  eta: 0:45:37  iter: 58439  total_loss: 0.1785  loss_cls: 0.02817  loss_box_reg: 0.08692  loss_mask: 0.05823  loss_rpn_cls: 0.0003874  loss_rpn_loc: 0.01048  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:46] d2.utils.events INFO:  eta: 0:45:31  iter: 58459  total_loss: 0.1778  loss_cls: 0.02979  loss_box_reg: 0.07951  loss_mask: 0.05658  loss_rpn_cls: 0.0007312  loss_rpn_loc: 0.0161  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:48] d2.utils.events INFO:  eta: 0:45:28  iter: 58479  total_loss: 0.1351  loss_cls: 0.01596  loss_box_reg: 0.05908  loss_mask: 0.05205  loss_rpn_cls: 0.0003837  loss_rpn_loc: 0.007227  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:50] d2.utils.events INFO:  eta: 0:45:27  iter: 58499  total_loss: 0.1448  loss_cls: 0.01616  loss_box_reg: 0.05331  loss_mask: 0.05083  loss_rpn_cls: 0.0003054  loss_rpn_loc: 0.006564  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:52] d2.utils.events INFO:  eta: 0:45:28  iter: 58519  total_loss: 0.17  loss_cls: 0.02361  loss_box_reg: 0.07507  loss_mask: 0.05952  loss_rpn_cls: 0.000483  loss_rpn_loc: 0.01014  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:53] d2.utils.events INFO:  eta: 0:45:27  iter: 58539  total_loss: 0.2113  loss_cls: 0.02682  loss_box_reg: 0.0932  loss_mask: 0.07018  loss_rpn_cls: 0.0006079  loss_rpn_loc: 0.01101  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:55] d2.utils.events INFO:  eta: 0:45:25  iter: 58559  total_loss: 0.1624  loss_cls: 0.0229  loss_box_reg: 0.0846  loss_mask: 0.05369  loss_rpn_cls: 0.0004894  loss_rpn_loc: 0.009859  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:03:57] d2.utils.events INFO:  eta: 0:45:30  iter: 58579  total_loss: 0.1643  loss_cls: 0.02621  loss_box_reg: 0.06998  loss_mask: 0.05514  loss_rpn_cls: 0.0005783  loss_rpn_loc: 0.006486  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:03:58] d2.utils.events INFO:  eta: 0:45:18  iter: 58599  total_loss: 0.1191  loss_cls: 0.01422  loss_box_reg: 0.04999  loss_mask: 0.04918  loss_rpn_cls: 0.0003294  loss_rpn_loc: 0.006888  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:00] d2.utils.events INFO:  eta: 0:45:14  iter: 58619  total_loss: 0.2008  loss_cls: 0.03086  loss_box_reg: 0.08563  loss_mask: 0.06009  loss_rpn_cls: 0.0009863  loss_rpn_loc: 0.01551  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:02] d2.utils.events INFO:  eta: 0:45:13  iter: 58639  total_loss: 0.1385  loss_cls: 0.02206  loss_box_reg: 0.05099  loss_mask: 0.05312  loss_rpn_cls: 0.0007231  loss_rpn_loc: 0.006596  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:04] d2.utils.events INFO:  eta: 0:45:11  iter: 58659  total_loss: 0.1158  loss_cls: 0.01823  loss_box_reg: 0.05685  loss_mask: 0.04762  loss_rpn_cls: 0.0006796  loss_rpn_loc: 0.008532  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:05] d2.utils.events INFO:  eta: 0:45:08  iter: 58679  total_loss: 0.1586  loss_cls: 0.02686  loss_box_reg: 0.06368  loss_mask: 0.05392  loss_rpn_cls: 0.0005099  loss_rpn_loc: 0.007484  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:07] d2.utils.events INFO:  eta: 0:45:05  iter: 58699  total_loss: 0.1766  loss_cls: 0.02268  loss_box_reg: 0.08204  loss_mask: 0.05568  loss_rpn_cls: 0.0006102  loss_rpn_loc: 0.01337  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:09] d2.utils.events INFO:  eta: 0:45:01  iter: 58719  total_loss: 0.1283  loss_cls: 0.02041  loss_box_reg: 0.06418  loss_mask: 0.04824  loss_rpn_cls: 0.0005208  loss_rpn_loc: 0.008607  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:11] d2.utils.events INFO:  eta: 0:45:07  iter: 58739  total_loss: 0.2136  loss_cls: 0.03318  loss_box_reg: 0.1027  loss_mask: 0.0541  loss_rpn_cls: 0.0006655  loss_rpn_loc: 0.01464  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:12] d2.utils.events INFO:  eta: 0:45:06  iter: 58759  total_loss: 0.1705  loss_cls: 0.02079  loss_box_reg: 0.07503  loss_mask: 0.04575  loss_rpn_cls: 0.0007729  loss_rpn_loc: 0.01315  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:14] d2.utils.events INFO:  eta: 0:45:10  iter: 58779  total_loss: 0.1575  loss_cls: 0.02129  loss_box_reg: 0.06874  loss_mask: 0.04968  loss_rpn_cls: 0.0006788  loss_rpn_loc: 0.007417  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:16] d2.utils.events INFO:  eta: 0:45:07  iter: 58799  total_loss: 0.2059  loss_cls: 0.03017  loss_box_reg: 0.08837  loss_mask: 0.07086  loss_rpn_cls: 0.000662  loss_rpn_loc: 0.01233  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:18] d2.utils.events INFO:  eta: 0:45:12  iter: 58819  total_loss: 0.1967  loss_cls: 0.02819  loss_box_reg: 0.09952  loss_mask: 0.06112  loss_rpn_cls: 0.001348  loss_rpn_loc: 0.0147  time: 0.0878  data_time: 0.0021  lr: 0.0025  max_mem: 1494M
[10/27 20:04:19] d2.utils.events INFO:  eta: 0:45:03  iter: 58839  total_loss: 0.1073  loss_cls: 0.02056  loss_box_reg: 0.03803  loss_mask: 0.04962  loss_rpn_cls: 0.0005468  loss_rpn_loc: 0.006347  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:21] d2.utils.events INFO:  eta: 0:45:02  iter: 58859  total_loss: 0.1186  loss_cls: 0.01641  loss_box_reg: 0.05663  loss_mask: 0.05143  loss_rpn_cls: 0.0003522  loss_rpn_loc: 0.007704  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:23] d2.utils.events INFO:  eta: 0:44:55  iter: 58879  total_loss: 0.1308  loss_cls: 0.01766  loss_box_reg: 0.05417  loss_mask: 0.05734  loss_rpn_cls: 0.0003776  loss_rpn_loc: 0.007183  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:24] d2.utils.events INFO:  eta: 0:44:53  iter: 58899  total_loss: 0.1397  loss_cls: 0.01632  loss_box_reg: 0.04867  loss_mask: 0.05304  loss_rpn_cls: 0.0004062  loss_rpn_loc: 0.006926  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:26] d2.utils.events INFO:  eta: 0:44:51  iter: 58919  total_loss: 0.1509  loss_cls: 0.01953  loss_box_reg: 0.06618  loss_mask: 0.05508  loss_rpn_cls: 0.0003664  loss_rpn_loc: 0.008928  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:28] d2.utils.events INFO:  eta: 0:44:48  iter: 58939  total_loss: 0.1612  loss_cls: 0.01836  loss_box_reg: 0.06188  loss_mask: 0.05488  loss_rpn_cls: 0.0006132  loss_rpn_loc: 0.01629  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:29] d2.utils.events INFO:  eta: 0:44:44  iter: 58959  total_loss: 0.178  loss_cls: 0.02685  loss_box_reg: 0.07475  loss_mask: 0.05874  loss_rpn_cls: 0.0007674  loss_rpn_loc: 0.01255  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:31] d2.utils.events INFO:  eta: 0:44:45  iter: 58979  total_loss: 0.2076  loss_cls: 0.03608  loss_box_reg: 0.1042  loss_mask: 0.06573  loss_rpn_cls: 0.0008465  loss_rpn_loc: 0.0157  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:33] d2.utils.events INFO:  eta: 0:44:42  iter: 58999  total_loss: 0.143  loss_cls: 0.01544  loss_box_reg: 0.05546  loss_mask: 0.05936  loss_rpn_cls: 0.0002566  loss_rpn_loc: 0.005311  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:04:35] d2.utils.events INFO:  eta: 0:44:40  iter: 59019  total_loss: 0.2063  loss_cls: 0.03038  loss_box_reg: 0.09612  loss_mask: 0.05902  loss_rpn_cls: 0.0006592  loss_rpn_loc: 0.01758  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:36] d2.utils.events INFO:  eta: 0:44:39  iter: 59039  total_loss: 0.1533  loss_cls: 0.03262  loss_box_reg: 0.06564  loss_mask: 0.05995  loss_rpn_cls: 0.0006589  loss_rpn_loc: 0.01354  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:38] d2.utils.events INFO:  eta: 0:44:40  iter: 59059  total_loss: 0.2297  loss_cls: 0.03453  loss_box_reg: 0.1086  loss_mask: 0.07301  loss_rpn_cls: 0.001099  loss_rpn_loc: 0.01946  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:40] d2.utils.events INFO:  eta: 0:44:39  iter: 59079  total_loss: 0.1221  loss_cls: 0.02321  loss_box_reg: 0.05107  loss_mask: 0.05736  loss_rpn_cls: 0.0006303  loss_rpn_loc: 0.00801  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:42] d2.utils.events INFO:  eta: 0:44:34  iter: 59099  total_loss: 0.1303  loss_cls: 0.01235  loss_box_reg: 0.04405  loss_mask: 0.05432  loss_rpn_cls: 0.0006394  loss_rpn_loc: 0.01207  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:43] d2.utils.events INFO:  eta: 0:44:30  iter: 59119  total_loss: 0.1467  loss_cls: 0.02715  loss_box_reg: 0.06683  loss_mask: 0.05835  loss_rpn_cls: 0.0003506  loss_rpn_loc: 0.008895  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:45] d2.utils.events INFO:  eta: 0:44:30  iter: 59139  total_loss: 0.1808  loss_cls: 0.02502  loss_box_reg: 0.07476  loss_mask: 0.0602  loss_rpn_cls: 0.0002813  loss_rpn_loc: 0.007599  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:47] d2.utils.events INFO:  eta: 0:44:33  iter: 59159  total_loss: 0.1672  loss_cls: 0.02624  loss_box_reg: 0.07703  loss_mask: 0.0541  loss_rpn_cls: 0.0004723  loss_rpn_loc: 0.006982  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:49] d2.utils.events INFO:  eta: 0:44:30  iter: 59179  total_loss: 0.1696  loss_cls: 0.02333  loss_box_reg: 0.07154  loss_mask: 0.05818  loss_rpn_cls: 0.0005242  loss_rpn_loc: 0.01314  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:50] d2.utils.events INFO:  eta: 0:44:25  iter: 59199  total_loss: 0.1267  loss_cls: 0.02065  loss_box_reg: 0.04607  loss_mask: 0.04764  loss_rpn_cls: 0.0005208  loss_rpn_loc: 0.009161  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:52] d2.utils.events INFO:  eta: 0:44:26  iter: 59219  total_loss: 0.1921  loss_cls: 0.02763  loss_box_reg: 0.1101  loss_mask: 0.05173  loss_rpn_cls: 0.0004187  loss_rpn_loc: 0.01013  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:04:54] d2.utils.events INFO:  eta: 0:44:25  iter: 59239  total_loss: 0.1266  loss_cls: 0.02717  loss_box_reg: 0.05512  loss_mask: 0.05154  loss_rpn_cls: 0.0002914  loss_rpn_loc: 0.006373  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:56] d2.utils.events INFO:  eta: 0:44:24  iter: 59259  total_loss: 0.1967  loss_cls: 0.03003  loss_box_reg: 0.092  loss_mask: 0.05123  loss_rpn_cls: 0.0004625  loss_rpn_loc: 0.009375  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:57] d2.utils.events INFO:  eta: 0:44:24  iter: 59279  total_loss: 0.1584  loss_cls: 0.02426  loss_box_reg: 0.07027  loss_mask: 0.05102  loss_rpn_cls: 0.0004645  loss_rpn_loc: 0.01071  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:04:59] d2.utils.events INFO:  eta: 0:44:21  iter: 59299  total_loss: 0.2798  loss_cls: 0.04103  loss_box_reg: 0.1119  loss_mask: 0.08358  loss_rpn_cls: 0.0007028  loss_rpn_loc: 0.02585  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:05:01] d2.utils.events INFO:  eta: 0:44:20  iter: 59319  total_loss: 0.1295  loss_cls: 0.02438  loss_box_reg: 0.06847  loss_mask: 0.04758  loss_rpn_cls: 0.0004386  loss_rpn_loc: 0.007851  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:03] d2.utils.events INFO:  eta: 0:44:18  iter: 59339  total_loss: 0.1838  loss_cls: 0.03919  loss_box_reg: 0.08019  loss_mask: 0.05922  loss_rpn_cls: 0.0006649  loss_rpn_loc: 0.01337  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:04] d2.utils.events INFO:  eta: 0:44:11  iter: 59359  total_loss: 0.1418  loss_cls: 0.01481  loss_box_reg: 0.05436  loss_mask: 0.04449  loss_rpn_cls: 0.0003605  loss_rpn_loc: 0.009993  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:06] d2.utils.events INFO:  eta: 0:44:12  iter: 59379  total_loss: 0.1689  loss_cls: 0.03037  loss_box_reg: 0.07632  loss_mask: 0.06116  loss_rpn_cls: 0.001323  loss_rpn_loc: 0.01527  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:05:08] d2.utils.events INFO:  eta: 0:44:12  iter: 59399  total_loss: 0.2746  loss_cls: 0.04173  loss_box_reg: 0.1059  loss_mask: 0.08531  loss_rpn_cls: 0.001162  loss_rpn_loc: 0.02553  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:09] d2.utils.events INFO:  eta: 0:44:10  iter: 59419  total_loss: 0.2269  loss_cls: 0.03379  loss_box_reg: 0.1041  loss_mask: 0.05925  loss_rpn_cls: 0.0005986  loss_rpn_loc: 0.01585  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:11] d2.utils.events INFO:  eta: 0:44:08  iter: 59439  total_loss: 0.1504  loss_cls: 0.02887  loss_box_reg: 0.06596  loss_mask: 0.06105  loss_rpn_cls: 0.000626  loss_rpn_loc: 0.01892  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:13] d2.utils.events INFO:  eta: 0:44:07  iter: 59459  total_loss: 0.1752  loss_cls: 0.02207  loss_box_reg: 0.06786  loss_mask: 0.05425  loss_rpn_cls: 0.0006576  loss_rpn_loc: 0.01463  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:15] d2.utils.events INFO:  eta: 0:44:06  iter: 59479  total_loss: 0.168  loss_cls: 0.02208  loss_box_reg: 0.08371  loss_mask: 0.05015  loss_rpn_cls: 0.0004451  loss_rpn_loc: 0.01112  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:16] d2.utils.events INFO:  eta: 0:44:04  iter: 59499  total_loss: 0.1596  loss_cls: 0.02333  loss_box_reg: 0.07085  loss_mask: 0.05386  loss_rpn_cls: 0.0008069  loss_rpn_loc: 0.009818  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:18] d2.utils.events INFO:  eta: 0:44:02  iter: 59519  total_loss: 0.1753  loss_cls: 0.0219  loss_box_reg: 0.08566  loss_mask: 0.06376  loss_rpn_cls: 0.0006717  loss_rpn_loc: 0.01076  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:20] d2.utils.events INFO:  eta: 0:43:57  iter: 59539  total_loss: 0.1238  loss_cls: 0.02044  loss_box_reg: 0.0541  loss_mask: 0.05398  loss_rpn_cls: 0.0004643  loss_rpn_loc: 0.007492  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:21] d2.utils.events INFO:  eta: 0:43:48  iter: 59559  total_loss: 0.09014  loss_cls: 0.01408  loss_box_reg: 0.043  loss_mask: 0.04193  loss_rpn_cls: 0.0003522  loss_rpn_loc: 0.007584  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:23] d2.utils.events INFO:  eta: 0:43:45  iter: 59579  total_loss: 0.1408  loss_cls: 0.01615  loss_box_reg: 0.05804  loss_mask: 0.05075  loss_rpn_cls: 0.000297  loss_rpn_loc: 0.006745  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:25] d2.utils.events INFO:  eta: 0:43:45  iter: 59599  total_loss: 0.1575  loss_cls: 0.02558  loss_box_reg: 0.0678  loss_mask: 0.05534  loss_rpn_cls: 0.0003004  loss_rpn_loc: 0.008001  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:27] d2.utils.events INFO:  eta: 0:43:43  iter: 59619  total_loss: 0.1888  loss_cls: 0.02755  loss_box_reg: 0.07331  loss_mask: 0.05501  loss_rpn_cls: 0.0007884  loss_rpn_loc: 0.01543  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:28] d2.utils.events INFO:  eta: 0:43:40  iter: 59639  total_loss: 0.1388  loss_cls: 0.01638  loss_box_reg: 0.05749  loss_mask: 0.05547  loss_rpn_cls: 0.0003543  loss_rpn_loc: 0.006497  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:30] d2.utils.events INFO:  eta: 0:43:39  iter: 59659  total_loss: 0.1649  loss_cls: 0.02499  loss_box_reg: 0.06718  loss_mask: 0.05345  loss_rpn_cls: 0.0005848  loss_rpn_loc: 0.007936  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:05:32] d2.utils.events INFO:  eta: 0:43:41  iter: 59679  total_loss: 0.1883  loss_cls: 0.02559  loss_box_reg: 0.07969  loss_mask: 0.05385  loss_rpn_cls: 0.00054  loss_rpn_loc: 0.009233  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:33] d2.utils.events INFO:  eta: 0:43:34  iter: 59699  total_loss: 0.1919  loss_cls: 0.01994  loss_box_reg: 0.06951  loss_mask: 0.06648  loss_rpn_cls: 0.0006672  loss_rpn_loc: 0.01268  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:35] d2.utils.events INFO:  eta: 0:43:35  iter: 59719  total_loss: 0.2585  loss_cls: 0.03281  loss_box_reg: 0.1112  loss_mask: 0.07816  loss_rpn_cls: 0.001011  loss_rpn_loc: 0.02509  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:37] d2.utils.events INFO:  eta: 0:43:33  iter: 59739  total_loss: 0.1424  loss_cls: 0.0242  loss_box_reg: 0.06088  loss_mask: 0.05584  loss_rpn_cls: 0.0004593  loss_rpn_loc: 0.004834  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:39] d2.utils.events INFO:  eta: 0:43:28  iter: 59759  total_loss: 0.1404  loss_cls: 0.02261  loss_box_reg: 0.05861  loss_mask: 0.04909  loss_rpn_cls: 0.000498  loss_rpn_loc: 0.007069  time: 0.0878  data_time: 0.0020  lr: 0.0025  max_mem: 1494M
[10/27 20:05:40] d2.utils.events INFO:  eta: 0:43:25  iter: 59779  total_loss: 0.1419  loss_cls: 0.01991  loss_box_reg: 0.06253  loss_mask: 0.04837  loss_rpn_cls: 0.0003426  loss_rpn_loc: 0.009283  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:42] d2.utils.events INFO:  eta: 0:43:23  iter: 59799  total_loss: 0.1474  loss_cls: 0.02376  loss_box_reg: 0.06019  loss_mask: 0.05985  loss_rpn_cls: 0.0004376  loss_rpn_loc: 0.0106  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:44] d2.utils.events INFO:  eta: 0:43:20  iter: 59819  total_loss: 0.1862  loss_cls: 0.0268  loss_box_reg: 0.07537  loss_mask: 0.05751  loss_rpn_cls: 0.0004315  loss_rpn_loc: 0.007455  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:45] d2.utils.events INFO:  eta: 0:43:19  iter: 59839  total_loss: 0.1582  loss_cls: 0.0199  loss_box_reg: 0.06978  loss_mask: 0.06175  loss_rpn_cls: 0.0005991  loss_rpn_loc: 0.01359  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:47] d2.utils.events INFO:  eta: 0:43:16  iter: 59859  total_loss: 0.1183  loss_cls: 0.02011  loss_box_reg: 0.05418  loss_mask: 0.0475  loss_rpn_cls: 0.0004456  loss_rpn_loc: 0.009589  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:49] d2.utils.events INFO:  eta: 0:43:16  iter: 59879  total_loss: 0.1878  loss_cls: 0.02788  loss_box_reg: 0.08624  loss_mask: 0.0545  loss_rpn_cls: 0.0004065  loss_rpn_loc: 0.01075  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:51] d2.utils.events INFO:  eta: 0:43:15  iter: 59899  total_loss: 0.1809  loss_cls: 0.03238  loss_box_reg: 0.09388  loss_mask: 0.04681  loss_rpn_cls: 0.0003372  loss_rpn_loc: 0.0146  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:52] d2.utils.events INFO:  eta: 0:43:14  iter: 59919  total_loss: 0.145  loss_cls: 0.02764  loss_box_reg: 0.07127  loss_mask: 0.04841  loss_rpn_cls: 0.0007366  loss_rpn_loc: 0.01101  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:54] d2.utils.events INFO:  eta: 0:43:13  iter: 59939  total_loss: 0.2242  loss_cls: 0.02409  loss_box_reg: 0.09716  loss_mask: 0.0589  loss_rpn_cls: 0.0007953  loss_rpn_loc: 0.01345  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:56] d2.utils.events INFO:  eta: 0:43:11  iter: 59959  total_loss: 0.2081  loss_cls: 0.02864  loss_box_reg: 0.08778  loss_mask: 0.06014  loss_rpn_cls: 0.0006242  loss_rpn_loc: 0.01182  time: 0.0878  data_time: 0.0018  lr: 0.0025  max_mem: 1494M
[10/27 20:05:58] d2.utils.events INFO:  eta: 0:43:08  iter: 59979  total_loss: 0.196  loss_cls: 0.03294  loss_box_reg: 0.09489  loss_mask: 0.07299  loss_rpn_cls: 0.001266  loss_rpn_loc: 0.02066  time: 0.0878  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:05:59] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0059999.pth
[10/27 20:06:00] d2.utils.events INFO:  eta: 0:43:07  iter: 59999  total_loss: 0.1512  loss_cls: 0.02688  loss_box_reg: 0.06196  loss_mask: 0.05073  loss_rpn_cls: 0.000454  loss_rpn_loc: 0.01182  time: 0.0877  data_time: 0.0019  lr: 0.0025  max_mem: 1494M
[10/27 20:06:01] d2.utils.events INFO:  eta: 0:43:05  iter: 60019  total_loss: 0.1427  loss_cls: 0.02026  loss_box_reg: 0.0587  loss_mask: 0.04517  loss_rpn_cls: 0.0004349  loss_rpn_loc: 0.009394  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:03] d2.utils.events INFO:  eta: 0:43:02  iter: 60039  total_loss: 0.1235  loss_cls: 0.0196  loss_box_reg: 0.05105  loss_mask: 0.03567  loss_rpn_cls: 0.0004126  loss_rpn_loc: 0.006977  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:05] d2.utils.events INFO:  eta: 0:42:57  iter: 60059  total_loss: 0.1321  loss_cls: 0.02224  loss_box_reg: 0.04702  loss_mask: 0.04984  loss_rpn_cls: 0.0006776  loss_rpn_loc: 0.00992  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:07] d2.utils.events INFO:  eta: 0:42:54  iter: 60079  total_loss: 0.1285  loss_cls: 0.01879  loss_box_reg: 0.04749  loss_mask: 0.05066  loss_rpn_cls: 0.0004692  loss_rpn_loc: 0.004454  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:08] d2.utils.events INFO:  eta: 0:42:56  iter: 60099  total_loss: 0.1756  loss_cls: 0.03162  loss_box_reg: 0.0773  loss_mask: 0.06019  loss_rpn_cls: 0.0007538  loss_rpn_loc: 0.01538  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:10] d2.utils.events INFO:  eta: 0:42:54  iter: 60119  total_loss: 0.1099  loss_cls: 0.01725  loss_box_reg: 0.04399  loss_mask: 0.04376  loss_rpn_cls: 0.0003045  loss_rpn_loc: 0.005616  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:12] d2.utils.events INFO:  eta: 0:42:53  iter: 60139  total_loss: 0.1443  loss_cls: 0.02851  loss_box_reg: 0.06342  loss_mask: 0.05868  loss_rpn_cls: 0.0007298  loss_rpn_loc: 0.007125  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:13] d2.utils.events INFO:  eta: 0:42:47  iter: 60159  total_loss: 0.1457  loss_cls: 0.02308  loss_box_reg: 0.04565  loss_mask: 0.0614  loss_rpn_cls: 0.0007255  loss_rpn_loc: 0.008881  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:15] d2.utils.events INFO:  eta: 0:42:46  iter: 60179  total_loss: 0.1324  loss_cls: 0.02107  loss_box_reg: 0.05111  loss_mask: 0.05101  loss_rpn_cls: 0.000445  loss_rpn_loc: 0.008063  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:17] d2.utils.events INFO:  eta: 0:42:46  iter: 60199  total_loss: 0.1814  loss_cls: 0.02676  loss_box_reg: 0.0672  loss_mask: 0.06355  loss_rpn_cls: 0.000533  loss_rpn_loc: 0.01056  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:19] d2.utils.events INFO:  eta: 0:42:46  iter: 60219  total_loss: 0.3011  loss_cls: 0.04281  loss_box_reg: 0.1046  loss_mask: 0.06985  loss_rpn_cls: 0.001224  loss_rpn_loc: 0.01552  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:20] d2.utils.events INFO:  eta: 0:42:45  iter: 60239  total_loss: 0.134  loss_cls: 0.01712  loss_box_reg: 0.05758  loss_mask: 0.04381  loss_rpn_cls: 0.000549  loss_rpn_loc: 0.01055  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:22] d2.utils.events INFO:  eta: 0:42:41  iter: 60259  total_loss: 0.1148  loss_cls: 0.01822  loss_box_reg: 0.04301  loss_mask: 0.05646  loss_rpn_cls: 0.0003572  loss_rpn_loc: 0.005872  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:24] d2.utils.events INFO:  eta: 0:42:40  iter: 60279  total_loss: 0.1313  loss_cls: 0.02156  loss_box_reg: 0.06048  loss_mask: 0.04646  loss_rpn_cls: 0.0006493  loss_rpn_loc: 0.004981  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:26] d2.utils.events INFO:  eta: 0:42:36  iter: 60299  total_loss: 0.1086  loss_cls: 0.02134  loss_box_reg: 0.04285  loss_mask: 0.05415  loss_rpn_cls: 0.0003202  loss_rpn_loc: 0.007788  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:27] d2.utils.events INFO:  eta: 0:42:36  iter: 60319  total_loss: 0.1229  loss_cls: 0.01964  loss_box_reg: 0.04845  loss_mask: 0.05023  loss_rpn_cls: 0.0003488  loss_rpn_loc: 0.008104  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:29] d2.utils.events INFO:  eta: 0:42:32  iter: 60339  total_loss: 0.1213  loss_cls: 0.01844  loss_box_reg: 0.03802  loss_mask: 0.04949  loss_rpn_cls: 0.00032  loss_rpn_loc: 0.005169  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:31] d2.utils.events INFO:  eta: 0:42:35  iter: 60359  total_loss: 0.1649  loss_cls: 0.02323  loss_box_reg: 0.06917  loss_mask: 0.05559  loss_rpn_cls: 0.00082  loss_rpn_loc: 0.00847  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:32] d2.utils.events INFO:  eta: 0:42:33  iter: 60379  total_loss: 0.123  loss_cls: 0.01936  loss_box_reg: 0.04792  loss_mask: 0.04881  loss_rpn_cls: 0.0004737  loss_rpn_loc: 0.006193  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:34] d2.utils.events INFO:  eta: 0:42:29  iter: 60399  total_loss: 0.132  loss_cls: 0.01771  loss_box_reg: 0.04947  loss_mask: 0.05586  loss_rpn_cls: 0.0005122  loss_rpn_loc: 0.007703  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:36] d2.utils.events INFO:  eta: 0:42:25  iter: 60419  total_loss: 0.1314  loss_cls: 0.01712  loss_box_reg: 0.04737  loss_mask: 0.05685  loss_rpn_cls: 0.0003661  loss_rpn_loc: 0.004319  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:38] d2.utils.events INFO:  eta: 0:42:24  iter: 60439  total_loss: 0.153  loss_cls: 0.02371  loss_box_reg: 0.06343  loss_mask: 0.04823  loss_rpn_cls: 0.0006645  loss_rpn_loc: 0.007172  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:39] d2.utils.events INFO:  eta: 0:42:22  iter: 60459  total_loss: 0.1308  loss_cls: 0.02262  loss_box_reg: 0.05223  loss_mask: 0.04443  loss_rpn_cls: 0.0005144  loss_rpn_loc: 0.006678  time: 0.0877  data_time: 0.0018  lr: 0.00025  max_mem: 1494M
[10/27 20:06:41] d2.utils.events INFO:  eta: 0:42:22  iter: 60479  total_loss: 0.126  loss_cls: 0.02091  loss_box_reg: 0.05054  loss_mask: 0.04843  loss_rpn_cls: 0.0004584  loss_rpn_loc: 0.006234  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:43] d2.utils.events INFO:  eta: 0:42:20  iter: 60499  total_loss: 0.1216  loss_cls: 0.02518  loss_box_reg: 0.04668  loss_mask: 0.04726  loss_rpn_cls: 0.0002931  loss_rpn_loc: 0.005835  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:45] d2.utils.events INFO:  eta: 0:42:19  iter: 60519  total_loss: 0.149  loss_cls: 0.02367  loss_box_reg: 0.05136  loss_mask: 0.05638  loss_rpn_cls: 0.0007194  loss_rpn_loc: 0.012  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:46] d2.utils.events INFO:  eta: 0:42:18  iter: 60539  total_loss: 0.09478  loss_cls: 0.01632  loss_box_reg: 0.02278  loss_mask: 0.05145  loss_rpn_cls: 0.0004571  loss_rpn_loc: 0.00831  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:48] d2.utils.events INFO:  eta: 0:42:20  iter: 60559  total_loss: 0.1138  loss_cls: 0.01721  loss_box_reg: 0.03928  loss_mask: 0.0503  loss_rpn_cls: 0.0003177  loss_rpn_loc: 0.004792  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:50] d2.utils.events INFO:  eta: 0:42:22  iter: 60579  total_loss: 0.09823  loss_cls: 0.01557  loss_box_reg: 0.03862  loss_mask: 0.04137  loss_rpn_cls: 0.0002424  loss_rpn_loc: 0.00466  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:52] d2.utils.events INFO:  eta: 0:42:21  iter: 60599  total_loss: 0.1381  loss_cls: 0.02371  loss_box_reg: 0.05824  loss_mask: 0.0549  loss_rpn_cls: 0.0007178  loss_rpn_loc: 0.008149  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:53] d2.utils.events INFO:  eta: 0:42:11  iter: 60619  total_loss: 0.08662  loss_cls: 0.01133  loss_box_reg: 0.02656  loss_mask: 0.03896  loss_rpn_cls: 0.0003899  loss_rpn_loc: 0.004234  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:55] d2.utils.events INFO:  eta: 0:42:13  iter: 60639  total_loss: 0.1077  loss_cls: 0.01722  loss_box_reg: 0.04514  loss_mask: 0.04797  loss_rpn_cls: 0.0003493  loss_rpn_loc: 0.005124  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:06:57] d2.utils.events INFO:  eta: 0:42:16  iter: 60659  total_loss: 0.1929  loss_cls: 0.03522  loss_box_reg: 0.07689  loss_mask: 0.06808  loss_rpn_cls: 0.0009884  loss_rpn_loc: 0.0145  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:06:59] d2.utils.events INFO:  eta: 0:42:13  iter: 60679  total_loss: 0.1527  loss_cls: 0.02214  loss_box_reg: 0.0607  loss_mask: 0.0584  loss_rpn_cls: 0.0008259  loss_rpn_loc: 0.008898  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:00] d2.utils.events INFO:  eta: 0:42:13  iter: 60699  total_loss: 0.0958  loss_cls: 0.01291  loss_box_reg: 0.03475  loss_mask: 0.04406  loss_rpn_cls: 0.0003055  loss_rpn_loc: 0.004106  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:02] d2.utils.events INFO:  eta: 0:42:10  iter: 60719  total_loss: 0.1335  loss_cls: 0.02303  loss_box_reg: 0.04388  loss_mask: 0.04383  loss_rpn_cls: 0.0003679  loss_rpn_loc: 0.00804  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:04] d2.utils.events INFO:  eta: 0:42:08  iter: 60739  total_loss: 0.1353  loss_cls: 0.02047  loss_box_reg: 0.05446  loss_mask: 0.04702  loss_rpn_cls: 0.0002675  loss_rpn_loc: 0.004464  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:06] d2.utils.events INFO:  eta: 0:42:12  iter: 60759  total_loss: 0.1181  loss_cls: 0.01733  loss_box_reg: 0.04248  loss_mask: 0.05416  loss_rpn_cls: 0.0003839  loss_rpn_loc: 0.005202  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:07] d2.utils.events INFO:  eta: 0:42:13  iter: 60779  total_loss: 0.1201  loss_cls: 0.02232  loss_box_reg: 0.04414  loss_mask: 0.05004  loss_rpn_cls: 0.0003512  loss_rpn_loc: 0.005568  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:09] d2.utils.events INFO:  eta: 0:42:18  iter: 60799  total_loss: 0.1721  loss_cls: 0.02056  loss_box_reg: 0.06225  loss_mask: 0.06052  loss_rpn_cls: 0.0006241  loss_rpn_loc: 0.01033  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:11] d2.utils.events INFO:  eta: 0:42:19  iter: 60819  total_loss: 0.1744  loss_cls: 0.02016  loss_box_reg: 0.06257  loss_mask: 0.07283  loss_rpn_cls: 0.0005262  loss_rpn_loc: 0.008606  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:13] d2.utils.events INFO:  eta: 0:42:17  iter: 60839  total_loss: 0.1056  loss_cls: 0.01296  loss_box_reg: 0.0383  loss_mask: 0.04034  loss_rpn_cls: 0.0005164  loss_rpn_loc: 0.006452  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:14] d2.utils.events INFO:  eta: 0:42:20  iter: 60859  total_loss: 0.1387  loss_cls: 0.02432  loss_box_reg: 0.04652  loss_mask: 0.05383  loss_rpn_cls: 0.0007629  loss_rpn_loc: 0.01119  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:16] d2.utils.events INFO:  eta: 0:42:17  iter: 60879  total_loss: 0.1115  loss_cls: 0.01674  loss_box_reg: 0.04012  loss_mask: 0.04477  loss_rpn_cls: 0.000305  loss_rpn_loc: 0.005027  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:18] d2.utils.events INFO:  eta: 0:42:14  iter: 60899  total_loss: 0.07241  loss_cls: 0.01242  loss_box_reg: 0.02723  loss_mask: 0.04204  loss_rpn_cls: 0.0003067  loss_rpn_loc: 0.005481  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:07:20] d2.utils.events INFO:  eta: 0:42:11  iter: 60919  total_loss: 0.09033  loss_cls: 0.009732  loss_box_reg: 0.02473  loss_mask: 0.04478  loss_rpn_cls: 0.0002496  loss_rpn_loc: 0.002899  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:21] d2.utils.events INFO:  eta: 0:42:09  iter: 60939  total_loss: 0.117  loss_cls: 0.02103  loss_box_reg: 0.05069  loss_mask: 0.04895  loss_rpn_cls: 0.0003796  loss_rpn_loc: 0.005159  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:23] d2.utils.events INFO:  eta: 0:42:07  iter: 60959  total_loss: 0.1432  loss_cls: 0.02565  loss_box_reg: 0.05055  loss_mask: 0.05264  loss_rpn_cls: 0.0005329  loss_rpn_loc: 0.007062  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:07:25] d2.utils.events INFO:  eta: 0:42:07  iter: 60979  total_loss: 0.1423  loss_cls: 0.02636  loss_box_reg: 0.05336  loss_mask: 0.05184  loss_rpn_cls: 0.0004018  loss_rpn_loc: 0.007148  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:27] d2.utils.events INFO:  eta: 0:42:05  iter: 60999  total_loss: 0.1261  loss_cls: 0.02086  loss_box_reg: 0.04021  loss_mask: 0.05464  loss_rpn_cls: 0.0003168  loss_rpn_loc: 0.007046  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:29] d2.utils.events INFO:  eta: 0:42:03  iter: 61019  total_loss: 0.1032  loss_cls: 0.0183  loss_box_reg: 0.03267  loss_mask: 0.04645  loss_rpn_cls: 0.0003344  loss_rpn_loc: 0.003368  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:30] d2.utils.events INFO:  eta: 0:42:03  iter: 61039  total_loss: 0.1267  loss_cls: 0.02238  loss_box_reg: 0.05309  loss_mask: 0.04574  loss_rpn_cls: 0.0008113  loss_rpn_loc: 0.007718  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:32] d2.utils.events INFO:  eta: 0:42:04  iter: 61059  total_loss: 0.1376  loss_cls: 0.01861  loss_box_reg: 0.05647  loss_mask: 0.04841  loss_rpn_cls: 0.0002644  loss_rpn_loc: 0.004778  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:34] d2.utils.events INFO:  eta: 0:42:06  iter: 61079  total_loss: 0.1007  loss_cls: 0.0118  loss_box_reg: 0.03207  loss_mask: 0.04495  loss_rpn_cls: 0.0003684  loss_rpn_loc: 0.003282  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:36] d2.utils.events INFO:  eta: 0:42:01  iter: 61099  total_loss: 0.09195  loss_cls: 0.01813  loss_box_reg: 0.03172  loss_mask: 0.04328  loss_rpn_cls: 0.0004916  loss_rpn_loc: 0.008485  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:37] d2.utils.events INFO:  eta: 0:42:04  iter: 61119  total_loss: 0.1129  loss_cls: 0.02047  loss_box_reg: 0.0348  loss_mask: 0.05133  loss_rpn_cls: 0.0002966  loss_rpn_loc: 0.00569  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:39] d2.utils.events INFO:  eta: 0:42:02  iter: 61139  total_loss: 0.1166  loss_cls: 0.01734  loss_box_reg: 0.04309  loss_mask: 0.04914  loss_rpn_cls: 0.0002641  loss_rpn_loc: 0.003511  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:07:41] d2.utils.events INFO:  eta: 0:41:56  iter: 61159  total_loss: 0.1075  loss_cls: 0.01433  loss_box_reg: 0.03154  loss_mask: 0.05245  loss_rpn_cls: 0.0003418  loss_rpn_loc: 0.006152  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:43] d2.utils.events INFO:  eta: 0:41:57  iter: 61179  total_loss: 0.1339  loss_cls: 0.02068  loss_box_reg: 0.05206  loss_mask: 0.0496  loss_rpn_cls: 0.000331  loss_rpn_loc: 0.006871  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:44] d2.utils.events INFO:  eta: 0:41:52  iter: 61199  total_loss: 0.08974  loss_cls: 0.01221  loss_box_reg: 0.0322  loss_mask: 0.03996  loss_rpn_cls: 0.000324  loss_rpn_loc: 0.00352  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:46] d2.utils.events INFO:  eta: 0:41:46  iter: 61219  total_loss: 0.09706  loss_cls: 0.01399  loss_box_reg: 0.02851  loss_mask: 0.04685  loss_rpn_cls: 0.0003006  loss_rpn_loc: 0.006078  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:48] d2.utils.events INFO:  eta: 0:41:49  iter: 61239  total_loss: 0.1266  loss_cls: 0.02299  loss_box_reg: 0.04222  loss_mask: 0.05328  loss_rpn_cls: 0.0002892  loss_rpn_loc: 0.004826  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:50] d2.utils.events INFO:  eta: 0:41:50  iter: 61259  total_loss: 0.1284  loss_cls: 0.02054  loss_box_reg: 0.05677  loss_mask: 0.04922  loss_rpn_cls: 0.0006753  loss_rpn_loc: 0.008296  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:51] d2.utils.events INFO:  eta: 0:41:46  iter: 61279  total_loss: 0.1478  loss_cls: 0.0256  loss_box_reg: 0.05523  loss_mask: 0.05414  loss_rpn_cls: 0.0006241  loss_rpn_loc: 0.005541  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:53] d2.utils.events INFO:  eta: 0:41:49  iter: 61299  total_loss: 0.1469  loss_cls: 0.02043  loss_box_reg: 0.04997  loss_mask: 0.04999  loss_rpn_cls: 0.0006819  loss_rpn_loc: 0.009297  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:55] d2.utils.events INFO:  eta: 0:41:47  iter: 61319  total_loss: 0.1368  loss_cls: 0.01669  loss_box_reg: 0.04569  loss_mask: 0.06936  loss_rpn_cls: 0.0005318  loss_rpn_loc: 0.006283  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:07:57] d2.utils.events INFO:  eta: 0:41:47  iter: 61339  total_loss: 0.1098  loss_cls: 0.01787  loss_box_reg: 0.04382  loss_mask: 0.04203  loss_rpn_cls: 0.0003487  loss_rpn_loc: 0.003465  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:07:58] d2.utils.events INFO:  eta: 0:41:45  iter: 61359  total_loss: 0.121  loss_cls: 0.02164  loss_box_reg: 0.04803  loss_mask: 0.0484  loss_rpn_cls: 0.0005514  loss_rpn_loc: 0.006237  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:08:00] d2.utils.events INFO:  eta: 0:41:43  iter: 61379  total_loss: 0.09504  loss_cls: 0.01314  loss_box_reg: 0.03539  loss_mask: 0.04409  loss_rpn_cls: 0.0005195  loss_rpn_loc: 0.005726  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:02] d2.utils.events INFO:  eta: 0:41:43  iter: 61399  total_loss: 0.1168  loss_cls: 0.01981  loss_box_reg: 0.04216  loss_mask: 0.04386  loss_rpn_cls: 0.0002652  loss_rpn_loc: 0.003969  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:08:04] d2.utils.events INFO:  eta: 0:41:42  iter: 61419  total_loss: 0.1015  loss_cls: 0.01672  loss_box_reg: 0.03123  loss_mask: 0.04202  loss_rpn_cls: 0.0002778  loss_rpn_loc: 0.004336  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:05] d2.utils.events INFO:  eta: 0:41:39  iter: 61439  total_loss: 0.1097  loss_cls: 0.01271  loss_box_reg: 0.03803  loss_mask: 0.05638  loss_rpn_cls: 0.0002829  loss_rpn_loc: 0.005699  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:07] d2.utils.events INFO:  eta: 0:41:35  iter: 61459  total_loss: 0.0988  loss_cls: 0.01686  loss_box_reg: 0.03122  loss_mask: 0.04453  loss_rpn_cls: 0.0002474  loss_rpn_loc: 0.006501  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:09] d2.utils.events INFO:  eta: 0:41:33  iter: 61479  total_loss: 0.08236  loss_cls: 0.01214  loss_box_reg: 0.02797  loss_mask: 0.03879  loss_rpn_cls: 0.0003791  loss_rpn_loc: 0.003808  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:11] d2.utils.events INFO:  eta: 0:41:31  iter: 61499  total_loss: 0.09092  loss_cls: 0.01215  loss_box_reg: 0.03425  loss_mask: 0.04284  loss_rpn_cls: 0.0004752  loss_rpn_loc: 0.004348  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:12] d2.utils.events INFO:  eta: 0:41:30  iter: 61519  total_loss: 0.1489  loss_cls: 0.01527  loss_box_reg: 0.04364  loss_mask: 0.05959  loss_rpn_cls: 0.0007648  loss_rpn_loc: 0.008803  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:08:14] d2.utils.events INFO:  eta: 0:41:29  iter: 61539  total_loss: 0.125  loss_cls: 0.01906  loss_box_reg: 0.04121  loss_mask: 0.05574  loss_rpn_cls: 0.000303  loss_rpn_loc: 0.006868  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:16] d2.utils.events INFO:  eta: 0:41:38  iter: 61559  total_loss: 0.1259  loss_cls: 0.01862  loss_box_reg: 0.04819  loss_mask: 0.04896  loss_rpn_cls: 0.0006912  loss_rpn_loc: 0.006845  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:18] d2.utils.events INFO:  eta: 0:41:38  iter: 61579  total_loss: 0.07103  loss_cls: 0.01396  loss_box_reg: 0.02862  loss_mask: 0.04093  loss_rpn_cls: 0.000457  loss_rpn_loc: 0.004827  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:08:19] d2.utils.events INFO:  eta: 0:41:28  iter: 61599  total_loss: 0.09401  loss_cls: 0.0142  loss_box_reg: 0.03092  loss_mask: 0.04379  loss_rpn_cls: 0.0001724  loss_rpn_loc: 0.003791  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:21] d2.utils.events INFO:  eta: 0:41:37  iter: 61619  total_loss: 0.1599  loss_cls: 0.03211  loss_box_reg: 0.05697  loss_mask: 0.06117  loss_rpn_cls: 0.000422  loss_rpn_loc: 0.008059  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:23] d2.utils.events INFO:  eta: 0:41:34  iter: 61639  total_loss: 0.07948  loss_cls: 0.01201  loss_box_reg: 0.02529  loss_mask: 0.04419  loss_rpn_cls: 0.0002483  loss_rpn_loc: 0.003816  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:25] d2.utils.events INFO:  eta: 0:41:29  iter: 61659  total_loss: 0.08957  loss_cls: 0.01126  loss_box_reg: 0.02958  loss_mask: 0.04091  loss_rpn_cls: 0.0002802  loss_rpn_loc: 0.00365  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:26] d2.utils.events INFO:  eta: 0:41:31  iter: 61679  total_loss: 0.1447  loss_cls: 0.0242  loss_box_reg: 0.05686  loss_mask: 0.05417  loss_rpn_cls: 0.0005294  loss_rpn_loc: 0.00667  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:28] d2.utils.events INFO:  eta: 0:41:31  iter: 61699  total_loss: 0.1021  loss_cls: 0.01807  loss_box_reg: 0.03338  loss_mask: 0.04157  loss_rpn_cls: 0.000425  loss_rpn_loc: 0.004087  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:30] d2.utils.events INFO:  eta: 0:41:27  iter: 61719  total_loss: 0.1016  loss_cls: 0.0158  loss_box_reg: 0.03636  loss_mask: 0.04808  loss_rpn_cls: 0.0004306  loss_rpn_loc: 0.005718  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:32] d2.utils.events INFO:  eta: 0:41:26  iter: 61739  total_loss: 0.1376  loss_cls: 0.02532  loss_box_reg: 0.05512  loss_mask: 0.05385  loss_rpn_cls: 0.0004846  loss_rpn_loc: 0.006352  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:08:33] d2.utils.events INFO:  eta: 0:41:23  iter: 61759  total_loss: 0.09838  loss_cls: 0.01268  loss_box_reg: 0.03129  loss_mask: 0.04587  loss_rpn_cls: 0.0002339  loss_rpn_loc: 0.002998  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:35] d2.utils.events INFO:  eta: 0:41:26  iter: 61779  total_loss: 0.1476  loss_cls: 0.02831  loss_box_reg: 0.059  loss_mask: 0.05444  loss_rpn_cls: 0.000838  loss_rpn_loc: 0.00862  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:37] d2.utils.events INFO:  eta: 0:41:25  iter: 61799  total_loss: 0.1832  loss_cls: 0.031  loss_box_reg: 0.0668  loss_mask: 0.075  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.01414  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:39] d2.utils.events INFO:  eta: 0:41:22  iter: 61819  total_loss: 0.1252  loss_cls: 0.01403  loss_box_reg: 0.04189  loss_mask: 0.05  loss_rpn_cls: 0.0002278  loss_rpn_loc: 0.003767  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:41] d2.utils.events INFO:  eta: 0:41:20  iter: 61839  total_loss: 0.1414  loss_cls: 0.02226  loss_box_reg: 0.0433  loss_mask: 0.06109  loss_rpn_cls: 0.0004991  loss_rpn_loc: 0.009329  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:42] d2.utils.events INFO:  eta: 0:41:15  iter: 61859  total_loss: 0.1114  loss_cls: 0.01804  loss_box_reg: 0.03381  loss_mask: 0.04278  loss_rpn_cls: 0.0005118  loss_rpn_loc: 0.004782  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:44] d2.utils.events INFO:  eta: 0:41:11  iter: 61879  total_loss: 0.09669  loss_cls: 0.01375  loss_box_reg: 0.0337  loss_mask: 0.04201  loss_rpn_cls: 0.0003387  loss_rpn_loc: 0.003318  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:46] d2.utils.events INFO:  eta: 0:41:11  iter: 61899  total_loss: 0.1181  loss_cls: 0.01973  loss_box_reg: 0.03951  loss_mask: 0.05975  loss_rpn_cls: 0.0004911  loss_rpn_loc: 0.006277  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:48] d2.utils.events INFO:  eta: 0:41:12  iter: 61919  total_loss: 0.1059  loss_cls: 0.01523  loss_box_reg: 0.03712  loss_mask: 0.04369  loss_rpn_cls: 0.000402  loss_rpn_loc: 0.005187  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:49] d2.utils.events INFO:  eta: 0:41:12  iter: 61939  total_loss: 0.1421  loss_cls: 0.01668  loss_box_reg: 0.03917  loss_mask: 0.06136  loss_rpn_cls: 0.0005345  loss_rpn_loc: 0.006285  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:51] d2.utils.events INFO:  eta: 0:41:08  iter: 61959  total_loss: 0.1044  loss_cls: 0.01509  loss_box_reg: 0.03265  loss_mask: 0.04866  loss_rpn_cls: 0.0003529  loss_rpn_loc: 0.004894  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:53] d2.utils.events INFO:  eta: 0:41:04  iter: 61979  total_loss: 0.08394  loss_cls: 0.01658  loss_box_reg: 0.02743  loss_mask: 0.04231  loss_rpn_cls: 0.000352  loss_rpn_loc: 0.004866  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:55] d2.utils.events INFO:  eta: 0:41:03  iter: 61999  total_loss: 0.09127  loss_cls: 0.01399  loss_box_reg: 0.03214  loss_mask: 0.04037  loss_rpn_cls: 0.0003026  loss_rpn_loc: 0.005483  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:08:56] d2.utils.events INFO:  eta: 0:41:00  iter: 62019  total_loss: 0.08714  loss_cls: 0.01233  loss_box_reg: 0.02547  loss_mask: 0.04024  loss_rpn_cls: 0.0001712  loss_rpn_loc: 0.002265  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:08:58] d2.utils.events INFO:  eta: 0:40:53  iter: 62039  total_loss: 0.09076  loss_cls: 0.01136  loss_box_reg: 0.02521  loss_mask: 0.04654  loss_rpn_cls: 0.0003038  loss_rpn_loc: 0.002838  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:00] d2.utils.events INFO:  eta: 0:40:46  iter: 62059  total_loss: 0.08328  loss_cls: 0.009481  loss_box_reg: 0.02761  loss_mask: 0.03955  loss_rpn_cls: 0.0003194  loss_rpn_loc: 0.00482  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:01] d2.utils.events INFO:  eta: 0:40:44  iter: 62079  total_loss: 0.08808  loss_cls: 0.01451  loss_box_reg: 0.02538  loss_mask: 0.05047  loss_rpn_cls: 0.0003294  loss_rpn_loc: 0.00471  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:03] d2.utils.events INFO:  eta: 0:40:46  iter: 62099  total_loss: 0.1008  loss_cls: 0.0166  loss_box_reg: 0.03358  loss_mask: 0.0471  loss_rpn_cls: 0.0002415  loss_rpn_loc: 0.004734  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:05] d2.utils.events INFO:  eta: 0:40:42  iter: 62119  total_loss: 0.1025  loss_cls: 0.0143  loss_box_reg: 0.0358  loss_mask: 0.04274  loss_rpn_cls: 0.000303  loss_rpn_loc: 0.0037  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:07] d2.utils.events INFO:  eta: 0:40:39  iter: 62139  total_loss: 0.1051  loss_cls: 0.01626  loss_box_reg: 0.03162  loss_mask: 0.04169  loss_rpn_cls: 0.0003712  loss_rpn_loc: 0.003676  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:08] d2.utils.events INFO:  eta: 0:40:41  iter: 62159  total_loss: 0.1029  loss_cls: 0.01393  loss_box_reg: 0.03411  loss_mask: 0.04599  loss_rpn_cls: 0.0003465  loss_rpn_loc: 0.005106  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:10] d2.utils.events INFO:  eta: 0:40:40  iter: 62179  total_loss: 0.1165  loss_cls: 0.01845  loss_box_reg: 0.04758  loss_mask: 0.04054  loss_rpn_cls: 0.0004178  loss_rpn_loc: 0.008137  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:12] d2.utils.events INFO:  eta: 0:40:41  iter: 62199  total_loss: 0.1139  loss_cls: 0.01967  loss_box_reg: 0.04595  loss_mask: 0.04641  loss_rpn_cls: 0.0003596  loss_rpn_loc: 0.005547  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:14] d2.utils.events INFO:  eta: 0:40:40  iter: 62219  total_loss: 0.0943  loss_cls: 0.01292  loss_box_reg: 0.03398  loss_mask: 0.0476  loss_rpn_cls: 0.0003326  loss_rpn_loc: 0.003229  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:16] d2.utils.events INFO:  eta: 0:40:35  iter: 62239  total_loss: 0.1079  loss_cls: 0.01052  loss_box_reg: 0.03167  loss_mask: 0.047  loss_rpn_cls: 0.0002809  loss_rpn_loc: 0.003722  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:09:17] d2.utils.events INFO:  eta: 0:40:32  iter: 62259  total_loss: 0.1032  loss_cls: 0.01466  loss_box_reg: 0.03468  loss_mask: 0.05548  loss_rpn_cls: 0.0005431  loss_rpn_loc: 0.00526  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:19] d2.utils.events INFO:  eta: 0:40:32  iter: 62279  total_loss: 0.1325  loss_cls: 0.0207  loss_box_reg: 0.05678  loss_mask: 0.05828  loss_rpn_cls: 0.0004992  loss_rpn_loc: 0.007357  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:21] d2.utils.events INFO:  eta: 0:40:31  iter: 62299  total_loss: 0.1672  loss_cls: 0.02669  loss_box_reg: 0.06124  loss_mask: 0.06541  loss_rpn_cls: 0.000746  loss_rpn_loc: 0.009599  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:09:23] d2.utils.events INFO:  eta: 0:40:32  iter: 62319  total_loss: 0.1079  loss_cls: 0.0159  loss_box_reg: 0.03539  loss_mask: 0.04455  loss_rpn_cls: 0.0002991  loss_rpn_loc: 0.004481  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:09:24] d2.utils.events INFO:  eta: 0:40:28  iter: 62339  total_loss: 0.1161  loss_cls: 0.01534  loss_box_reg: 0.03401  loss_mask: 0.0581  loss_rpn_cls: 0.0003417  loss_rpn_loc: 0.005973  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:26] d2.utils.events INFO:  eta: 0:40:26  iter: 62359  total_loss: 0.09195  loss_cls: 0.01366  loss_box_reg: 0.02749  loss_mask: 0.04423  loss_rpn_cls: 0.0003096  loss_rpn_loc: 0.004556  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:28] d2.utils.events INFO:  eta: 0:40:25  iter: 62379  total_loss: 0.09979  loss_cls: 0.01633  loss_box_reg: 0.03412  loss_mask: 0.05019  loss_rpn_cls: 0.0004384  loss_rpn_loc: 0.0059  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:30] d2.utils.events INFO:  eta: 0:40:20  iter: 62399  total_loss: 0.07659  loss_cls: 0.01266  loss_box_reg: 0.02133  loss_mask: 0.03031  loss_rpn_cls: 0.0001767  loss_rpn_loc: 0.002213  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:31] d2.utils.events INFO:  eta: 0:40:22  iter: 62419  total_loss: 0.1073  loss_cls: 0.0185  loss_box_reg: 0.02975  loss_mask: 0.04356  loss_rpn_cls: 0.0004746  loss_rpn_loc: 0.006579  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:33] d2.utils.events INFO:  eta: 0:40:24  iter: 62439  total_loss: 0.1065  loss_cls: 0.01974  loss_box_reg: 0.03983  loss_mask: 0.04207  loss_rpn_cls: 0.0003265  loss_rpn_loc: 0.003352  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:35] d2.utils.events INFO:  eta: 0:40:22  iter: 62459  total_loss: 0.08435  loss_cls: 0.0169  loss_box_reg: 0.02964  loss_mask: 0.04292  loss_rpn_cls: 0.0005038  loss_rpn_loc: 0.003576  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:37] d2.utils.events INFO:  eta: 0:40:20  iter: 62479  total_loss: 0.08309  loss_cls: 0.008286  loss_box_reg: 0.0193  loss_mask: 0.04592  loss_rpn_cls: 0.0002318  loss_rpn_loc: 0.003858  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:09:38] d2.utils.events INFO:  eta: 0:40:20  iter: 62499  total_loss: 0.09766  loss_cls: 0.01286  loss_box_reg: 0.03111  loss_mask: 0.05053  loss_rpn_cls: 0.000287  loss_rpn_loc: 0.004276  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:40] d2.utils.events INFO:  eta: 0:40:17  iter: 62519  total_loss: 0.1056  loss_cls: 0.01755  loss_box_reg: 0.03641  loss_mask: 0.05183  loss_rpn_cls: 0.000233  loss_rpn_loc: 0.004209  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:42] d2.utils.events INFO:  eta: 0:40:16  iter: 62539  total_loss: 0.1136  loss_cls: 0.02045  loss_box_reg: 0.03806  loss_mask: 0.05595  loss_rpn_cls: 0.0002895  loss_rpn_loc: 0.004682  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:44] d2.utils.events INFO:  eta: 0:40:10  iter: 62559  total_loss: 0.09306  loss_cls: 0.01351  loss_box_reg: 0.03269  loss_mask: 0.04534  loss_rpn_cls: 0.0005326  loss_rpn_loc: 0.005032  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:45] d2.utils.events INFO:  eta: 0:40:12  iter: 62579  total_loss: 0.1324  loss_cls: 0.02132  loss_box_reg: 0.05884  loss_mask: 0.05772  loss_rpn_cls: 0.0004719  loss_rpn_loc: 0.007346  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:09:47] d2.utils.events INFO:  eta: 0:40:10  iter: 62599  total_loss: 0.08648  loss_cls: 0.01219  loss_box_reg: 0.02523  loss_mask: 0.03878  loss_rpn_cls: 0.0004901  loss_rpn_loc: 0.00555  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:49] d2.utils.events INFO:  eta: 0:40:08  iter: 62619  total_loss: 0.1015  loss_cls: 0.01519  loss_box_reg: 0.02983  loss_mask: 0.04582  loss_rpn_cls: 0.0003023  loss_rpn_loc: 0.005004  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:51] d2.utils.events INFO:  eta: 0:40:07  iter: 62639  total_loss: 0.09404  loss_cls: 0.01344  loss_box_reg: 0.03149  loss_mask: 0.04284  loss_rpn_cls: 0.0002157  loss_rpn_loc: 0.003425  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:52] d2.utils.events INFO:  eta: 0:40:05  iter: 62659  total_loss: 0.07834  loss_cls: 0.01074  loss_box_reg: 0.0253  loss_mask: 0.04584  loss_rpn_cls: 0.0001916  loss_rpn_loc: 0.003819  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:54] d2.utils.events INFO:  eta: 0:40:00  iter: 62679  total_loss: 0.07757  loss_cls: 0.01428  loss_box_reg: 0.02363  loss_mask: 0.04574  loss_rpn_cls: 0.0001711  loss_rpn_loc: 0.003424  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:09:56] d2.utils.events INFO:  eta: 0:39:54  iter: 62699  total_loss: 0.05992  loss_cls: 0.01116  loss_box_reg: 0.01515  loss_mask: 0.03414  loss_rpn_cls: 0.0003672  loss_rpn_loc: 0.003199  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:58] d2.utils.events INFO:  eta: 0:39:55  iter: 62719  total_loss: 0.1042  loss_cls: 0.01497  loss_box_reg: 0.03891  loss_mask: 0.04217  loss_rpn_cls: 0.000296  loss_rpn_loc: 0.004133  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:09:59] d2.utils.events INFO:  eta: 0:39:49  iter: 62739  total_loss: 0.09474  loss_cls: 0.01587  loss_box_reg: 0.02858  loss_mask: 0.0471  loss_rpn_cls: 0.0002145  loss_rpn_loc: 0.003544  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:01] d2.utils.events INFO:  eta: 0:39:47  iter: 62759  total_loss: 0.09873  loss_cls: 0.01661  loss_box_reg: 0.03283  loss_mask: 0.05201  loss_rpn_cls: 0.0002579  loss_rpn_loc: 0.003364  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:03] d2.utils.events INFO:  eta: 0:39:39  iter: 62779  total_loss: 0.1048  loss_cls: 0.01605  loss_box_reg: 0.03651  loss_mask: 0.04522  loss_rpn_cls: 0.0002335  loss_rpn_loc: 0.004294  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:05] d2.utils.events INFO:  eta: 0:39:37  iter: 62799  total_loss: 0.1065  loss_cls: 0.0169  loss_box_reg: 0.03391  loss_mask: 0.05311  loss_rpn_cls: 0.0003388  loss_rpn_loc: 0.004283  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:10:07] d2.utils.events INFO:  eta: 0:39:36  iter: 62819  total_loss: 0.1075  loss_cls: 0.01797  loss_box_reg: 0.03551  loss_mask: 0.05209  loss_rpn_cls: 0.0003096  loss_rpn_loc: 0.005968  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:08] d2.utils.events INFO:  eta: 0:39:34  iter: 62839  total_loss: 0.1015  loss_cls: 0.01242  loss_box_reg: 0.03431  loss_mask: 0.0432  loss_rpn_cls: 0.0003156  loss_rpn_loc: 0.004443  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:10] d2.utils.events INFO:  eta: 0:39:32  iter: 62859  total_loss: 0.101  loss_cls: 0.01553  loss_box_reg: 0.03045  loss_mask: 0.04661  loss_rpn_cls: 0.0005229  loss_rpn_loc: 0.004999  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:12] d2.utils.events INFO:  eta: 0:39:37  iter: 62879  total_loss: 0.1359  loss_cls: 0.02921  loss_box_reg: 0.05423  loss_mask: 0.05453  loss_rpn_cls: 0.0003553  loss_rpn_loc: 0.008887  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:14] d2.utils.events INFO:  eta: 0:39:31  iter: 62899  total_loss: 0.1107  loss_cls: 0.01964  loss_box_reg: 0.03601  loss_mask: 0.05419  loss_rpn_cls: 0.0003301  loss_rpn_loc: 0.003542  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:15] d2.utils.events INFO:  eta: 0:39:36  iter: 62919  total_loss: 0.1323  loss_cls: 0.02  loss_box_reg: 0.05312  loss_mask: 0.05766  loss_rpn_cls: 0.0006253  loss_rpn_loc: 0.00815  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:17] d2.utils.events INFO:  eta: 0:39:33  iter: 62939  total_loss: 0.1195  loss_cls: 0.01351  loss_box_reg: 0.03813  loss_mask: 0.04664  loss_rpn_cls: 0.0002418  loss_rpn_loc: 0.003718  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:19] d2.utils.events INFO:  eta: 0:39:31  iter: 62959  total_loss: 0.08922  loss_cls: 0.01438  loss_box_reg: 0.02732  loss_mask: 0.03941  loss_rpn_cls: 0.0004739  loss_rpn_loc: 0.005603  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:21] d2.utils.events INFO:  eta: 0:39:33  iter: 62979  total_loss: 0.1305  loss_cls: 0.01941  loss_box_reg: 0.05123  loss_mask: 0.05892  loss_rpn_cls: 0.0004181  loss_rpn_loc: 0.005928  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:22] d2.utils.events INFO:  eta: 0:39:32  iter: 62999  total_loss: 0.09548  loss_cls: 0.01388  loss_box_reg: 0.03398  loss_mask: 0.04237  loss_rpn_cls: 0.0004471  loss_rpn_loc: 0.004749  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:24] d2.utils.events INFO:  eta: 0:39:33  iter: 63019  total_loss: 0.08589  loss_cls: 0.01087  loss_box_reg: 0.02634  loss_mask: 0.04878  loss_rpn_cls: 0.0002257  loss_rpn_loc: 0.002972  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:26] d2.utils.events INFO:  eta: 0:39:32  iter: 63039  total_loss: 0.082  loss_cls: 0.01118  loss_box_reg: 0.02657  loss_mask: 0.05346  loss_rpn_cls: 0.0001231  loss_rpn_loc: 0.002315  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:28] d2.utils.events INFO:  eta: 0:39:31  iter: 63059  total_loss: 0.08402  loss_cls: 0.01146  loss_box_reg: 0.02921  loss_mask: 0.04319  loss_rpn_cls: 0.0003383  loss_rpn_loc: 0.004156  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:10:29] d2.utils.events INFO:  eta: 0:39:31  iter: 63079  total_loss: 0.09158  loss_cls: 0.01307  loss_box_reg: 0.03154  loss_mask: 0.05167  loss_rpn_cls: 0.0002246  loss_rpn_loc: 0.003438  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:31] d2.utils.events INFO:  eta: 0:39:30  iter: 63099  total_loss: 0.1083  loss_cls: 0.01825  loss_box_reg: 0.03964  loss_mask: 0.05174  loss_rpn_cls: 0.0004085  loss_rpn_loc: 0.005668  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:33] d2.utils.events INFO:  eta: 0:39:29  iter: 63119  total_loss: 0.09506  loss_cls: 0.01355  loss_box_reg: 0.02871  loss_mask: 0.04522  loss_rpn_cls: 0.0002378  loss_rpn_loc: 0.003493  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:35] d2.utils.events INFO:  eta: 0:39:28  iter: 63139  total_loss: 0.09343  loss_cls: 0.01358  loss_box_reg: 0.03107  loss_mask: 0.04668  loss_rpn_cls: 0.0002073  loss_rpn_loc: 0.00315  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:36] d2.utils.events INFO:  eta: 0:39:30  iter: 63159  total_loss: 0.1125  loss_cls: 0.02021  loss_box_reg: 0.04487  loss_mask: 0.04741  loss_rpn_cls: 0.0003329  loss_rpn_loc: 0.005569  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:38] d2.utils.events INFO:  eta: 0:39:28  iter: 63179  total_loss: 0.1078  loss_cls: 0.01997  loss_box_reg: 0.0419  loss_mask: 0.04842  loss_rpn_cls: 0.0003507  loss_rpn_loc: 0.006358  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:40] d2.utils.events INFO:  eta: 0:39:26  iter: 63199  total_loss: 0.1125  loss_cls: 0.0203  loss_box_reg: 0.03722  loss_mask: 0.04836  loss_rpn_cls: 0.0004343  loss_rpn_loc: 0.004261  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:42] d2.utils.events INFO:  eta: 0:39:23  iter: 63219  total_loss: 0.08861  loss_cls: 0.01237  loss_box_reg: 0.0263  loss_mask: 0.04794  loss_rpn_cls: 0.0004667  loss_rpn_loc: 0.004307  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:43] d2.utils.events INFO:  eta: 0:39:20  iter: 63239  total_loss: 0.0732  loss_cls: 0.01142  loss_box_reg: 0.01927  loss_mask: 0.04403  loss_rpn_cls: 0.0002809  loss_rpn_loc: 0.004507  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:45] d2.utils.events INFO:  eta: 0:39:18  iter: 63259  total_loss: 0.09382  loss_cls: 0.01403  loss_box_reg: 0.02688  loss_mask: 0.05236  loss_rpn_cls: 0.0002659  loss_rpn_loc: 0.003683  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:47] d2.utils.events INFO:  eta: 0:39:11  iter: 63279  total_loss: 0.08043  loss_cls: 0.01235  loss_box_reg: 0.02814  loss_mask: 0.04329  loss_rpn_cls: 0.000305  loss_rpn_loc: 0.003569  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:49] d2.utils.events INFO:  eta: 0:39:08  iter: 63299  total_loss: 0.1096  loss_cls: 0.01536  loss_box_reg: 0.0336  loss_mask: 0.0516  loss_rpn_cls: 0.0003462  loss_rpn_loc: 0.004088  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:50] d2.utils.events INFO:  eta: 0:39:05  iter: 63319  total_loss: 0.08536  loss_cls: 0.01362  loss_box_reg: 0.0266  loss_mask: 0.04856  loss_rpn_cls: 0.0002879  loss_rpn_loc: 0.002895  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:10:52] d2.utils.events INFO:  eta: 0:39:06  iter: 63339  total_loss: 0.1132  loss_cls: 0.01991  loss_box_reg: 0.04618  loss_mask: 0.05058  loss_rpn_cls: 0.0002726  loss_rpn_loc: 0.003829  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:54] d2.utils.events INFO:  eta: 0:39:05  iter: 63359  total_loss: 0.1071  loss_cls: 0.01886  loss_box_reg: 0.03448  loss_mask: 0.04744  loss_rpn_cls: 0.0002847  loss_rpn_loc: 0.003306  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:10:56] d2.utils.events INFO:  eta: 0:39:04  iter: 63379  total_loss: 0.119  loss_cls: 0.01899  loss_box_reg: 0.04322  loss_mask: 0.05158  loss_rpn_cls: 0.0003508  loss_rpn_loc: 0.005393  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:58] d2.utils.events INFO:  eta: 0:39:05  iter: 63399  total_loss: 0.08411  loss_cls: 0.01201  loss_box_reg: 0.02787  loss_mask: 0.04129  loss_rpn_cls: 0.0002865  loss_rpn_loc: 0.003177  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:10:59] d2.utils.events INFO:  eta: 0:39:04  iter: 63419  total_loss: 0.1249  loss_cls: 0.02261  loss_box_reg: 0.04901  loss_mask: 0.05763  loss_rpn_cls: 0.0003293  loss_rpn_loc: 0.004132  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:01] d2.utils.events INFO:  eta: 0:39:02  iter: 63439  total_loss: 0.1323  loss_cls: 0.02628  loss_box_reg: 0.05227  loss_mask: 0.05424  loss_rpn_cls: 0.00045  loss_rpn_loc: 0.004917  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:03] d2.utils.events INFO:  eta: 0:39:01  iter: 63459  total_loss: 0.07788  loss_cls: 0.01349  loss_box_reg: 0.02438  loss_mask: 0.03869  loss_rpn_cls: 0.0002949  loss_rpn_loc: 0.004748  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:05] d2.utils.events INFO:  eta: 0:38:58  iter: 63479  total_loss: 0.08763  loss_cls: 0.01163  loss_box_reg: 0.03164  loss_mask: 0.03723  loss_rpn_cls: 0.0003315  loss_rpn_loc: 0.005626  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:06] d2.utils.events INFO:  eta: 0:38:54  iter: 63499  total_loss: 0.1159  loss_cls: 0.01593  loss_box_reg: 0.03818  loss_mask: 0.04413  loss_rpn_cls: 0.0001925  loss_rpn_loc: 0.00465  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:08] d2.utils.events INFO:  eta: 0:38:52  iter: 63519  total_loss: 0.07036  loss_cls: 0.01047  loss_box_reg: 0.0184  loss_mask: 0.0432  loss_rpn_cls: 0.0002108  loss_rpn_loc: 0.001108  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:10] d2.utils.events INFO:  eta: 0:38:48  iter: 63539  total_loss: 0.08244  loss_cls: 0.01272  loss_box_reg: 0.02709  loss_mask: 0.03809  loss_rpn_cls: 0.0002893  loss_rpn_loc: 0.004443  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:12] d2.utils.events INFO:  eta: 0:38:48  iter: 63559  total_loss: 0.1032  loss_cls: 0.01366  loss_box_reg: 0.04121  loss_mask: 0.04426  loss_rpn_cls: 0.0003326  loss_rpn_loc: 0.004219  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:14] d2.utils.events INFO:  eta: 0:38:48  iter: 63579  total_loss: 0.1552  loss_cls: 0.02339  loss_box_reg: 0.05348  loss_mask: 0.06838  loss_rpn_cls: 0.0009471  loss_rpn_loc: 0.008098  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:15] d2.utils.events INFO:  eta: 0:38:49  iter: 63599  total_loss: 0.0928  loss_cls: 0.01511  loss_box_reg: 0.03054  loss_mask: 0.0552  loss_rpn_cls: 0.0002839  loss_rpn_loc: 0.004185  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:17] d2.utils.events INFO:  eta: 0:38:46  iter: 63619  total_loss: 0.1129  loss_cls: 0.01989  loss_box_reg: 0.03693  loss_mask: 0.0466  loss_rpn_cls: 0.0003418  loss_rpn_loc: 0.006971  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:19] d2.utils.events INFO:  eta: 0:38:44  iter: 63639  total_loss: 0.09591  loss_cls: 0.01426  loss_box_reg: 0.0323  loss_mask: 0.04057  loss_rpn_cls: 0.0003802  loss_rpn_loc: 0.003543  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:21] d2.utils.events INFO:  eta: 0:38:43  iter: 63659  total_loss: 0.1051  loss_cls: 0.01209  loss_box_reg: 0.03311  loss_mask: 0.05127  loss_rpn_cls: 0.0003656  loss_rpn_loc: 0.005359  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:23] d2.utils.events INFO:  eta: 0:38:47  iter: 63679  total_loss: 0.1085  loss_cls: 0.01903  loss_box_reg: 0.04175  loss_mask: 0.04686  loss_rpn_cls: 0.0003799  loss_rpn_loc: 0.005069  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:24] d2.utils.events INFO:  eta: 0:38:49  iter: 63699  total_loss: 0.06844  loss_cls: 0.0132  loss_box_reg: 0.02174  loss_mask: 0.03567  loss_rpn_cls: 0.0003323  loss_rpn_loc: 0.004078  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:26] d2.utils.events INFO:  eta: 0:38:45  iter: 63719  total_loss: 0.08477  loss_cls: 0.01476  loss_box_reg: 0.02393  loss_mask: 0.04428  loss_rpn_cls: 0.0004155  loss_rpn_loc: 0.003375  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:28] d2.utils.events INFO:  eta: 0:38:44  iter: 63739  total_loss: 0.1016  loss_cls: 0.012  loss_box_reg: 0.02953  loss_mask: 0.04847  loss_rpn_cls: 0.0002513  loss_rpn_loc: 0.003353  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:29] d2.utils.events INFO:  eta: 0:38:43  iter: 63759  total_loss: 0.08377  loss_cls: 0.01345  loss_box_reg: 0.02773  loss_mask: 0.04498  loss_rpn_cls: 0.0001956  loss_rpn_loc: 0.002568  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:31] d2.utils.events INFO:  eta: 0:38:34  iter: 63779  total_loss: 0.07541  loss_cls: 0.007268  loss_box_reg: 0.02206  loss_mask: 0.03772  loss_rpn_cls: 0.0001595  loss_rpn_loc: 0.002406  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:33] d2.utils.events INFO:  eta: 0:38:30  iter: 63799  total_loss: 0.1163  loss_cls: 0.01234  loss_box_reg: 0.03337  loss_mask: 0.05482  loss_rpn_cls: 0.0004465  loss_rpn_loc: 0.005033  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:35] d2.utils.events INFO:  eta: 0:38:33  iter: 63819  total_loss: 0.1016  loss_cls: 0.01484  loss_box_reg: 0.03609  loss_mask: 0.05153  loss_rpn_cls: 0.0003297  loss_rpn_loc: 0.005202  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:36] d2.utils.events INFO:  eta: 0:38:25  iter: 63839  total_loss: 0.08537  loss_cls: 0.01031  loss_box_reg: 0.02431  loss_mask: 0.04285  loss_rpn_cls: 0.0002039  loss_rpn_loc: 0.003708  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:38] d2.utils.events INFO:  eta: 0:38:26  iter: 63859  total_loss: 0.08983  loss_cls: 0.01545  loss_box_reg: 0.03313  loss_mask: 0.03876  loss_rpn_cls: 0.0002371  loss_rpn_loc: 0.002956  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:40] d2.utils.events INFO:  eta: 0:38:23  iter: 63879  total_loss: 0.1135  loss_cls: 0.02244  loss_box_reg: 0.03388  loss_mask: 0.04799  loss_rpn_cls: 0.0005039  loss_rpn_loc: 0.00759  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:42] d2.utils.events INFO:  eta: 0:38:25  iter: 63899  total_loss: 0.1706  loss_cls: 0.02046  loss_box_reg: 0.0508  loss_mask: 0.07864  loss_rpn_cls: 0.0006677  loss_rpn_loc: 0.00833  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:44] d2.utils.events INFO:  eta: 0:38:18  iter: 63919  total_loss: 0.1082  loss_cls: 0.01722  loss_box_reg: 0.03502  loss_mask: 0.04838  loss_rpn_cls: 0.0003469  loss_rpn_loc: 0.003856  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:45] d2.utils.events INFO:  eta: 0:38:14  iter: 63939  total_loss: 0.09533  loss_cls: 0.01353  loss_box_reg: 0.02422  loss_mask: 0.05428  loss_rpn_cls: 0.000207  loss_rpn_loc: 0.002679  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:47] d2.utils.events INFO:  eta: 0:38:17  iter: 63959  total_loss: 0.1102  loss_cls: 0.01695  loss_box_reg: 0.03599  loss_mask: 0.05079  loss_rpn_cls: 0.0002909  loss_rpn_loc: 0.004827  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:49] d2.utils.events INFO:  eta: 0:38:14  iter: 63979  total_loss: 0.1054  loss_cls: 0.01374  loss_box_reg: 0.04003  loss_mask: 0.04714  loss_rpn_cls: 0.0004569  loss_rpn_loc: 0.004689  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:51] d2.utils.events INFO:  eta: 0:38:13  iter: 63999  total_loss: 0.1228  loss_cls: 0.0245  loss_box_reg: 0.04702  loss_mask: 0.05759  loss_rpn_cls: 0.000378  loss_rpn_loc: 0.005783  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:52] d2.utils.events INFO:  eta: 0:38:16  iter: 64019  total_loss: 0.08569  loss_cls: 0.009174  loss_box_reg: 0.02729  loss_mask: 0.04031  loss_rpn_cls: 0.0001999  loss_rpn_loc: 0.003313  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:11:54] d2.utils.events INFO:  eta: 0:38:19  iter: 64039  total_loss: 0.09017  loss_cls: 0.01458  loss_box_reg: 0.03319  loss_mask: 0.03637  loss_rpn_cls: 0.0003027  loss_rpn_loc: 0.003611  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:56] d2.utils.events INFO:  eta: 0:38:13  iter: 64059  total_loss: 0.07479  loss_cls: 0.009852  loss_box_reg: 0.01767  loss_mask: 0.04031  loss_rpn_cls: 0.0001849  loss_rpn_loc: 0.001589  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:11:58] d2.utils.events INFO:  eta: 0:38:07  iter: 64079  total_loss: 0.07415  loss_cls: 0.009502  loss_box_reg: 0.02187  loss_mask: 0.04237  loss_rpn_cls: 0.0002561  loss_rpn_loc: 0.00274  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:11:59] d2.utils.events INFO:  eta: 0:38:07  iter: 64099  total_loss: 0.1055  loss_cls: 0.01636  loss_box_reg: 0.03165  loss_mask: 0.05045  loss_rpn_cls: 0.0004279  loss_rpn_loc: 0.005621  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:01] d2.utils.events INFO:  eta: 0:38:09  iter: 64119  total_loss: 0.0871  loss_cls: 0.01709  loss_box_reg: 0.03482  loss_mask: 0.04067  loss_rpn_cls: 0.0002737  loss_rpn_loc: 0.004837  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:03] d2.utils.events INFO:  eta: 0:38:05  iter: 64139  total_loss: 0.07045  loss_cls: 0.009342  loss_box_reg: 0.02405  loss_mask: 0.03486  loss_rpn_cls: 0.0001947  loss_rpn_loc: 0.002478  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:12:05] d2.utils.events INFO:  eta: 0:37:56  iter: 64159  total_loss: 0.07938  loss_cls: 0.009261  loss_box_reg: 0.02513  loss_mask: 0.04366  loss_rpn_cls: 0.0002616  loss_rpn_loc: 0.00436  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:06] d2.utils.events INFO:  eta: 0:37:55  iter: 64179  total_loss: 0.09552  loss_cls: 0.01243  loss_box_reg: 0.03119  loss_mask: 0.04635  loss_rpn_cls: 0.0004301  loss_rpn_loc: 0.00519  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:08] d2.utils.events INFO:  eta: 0:37:54  iter: 64199  total_loss: 0.1503  loss_cls: 0.01947  loss_box_reg: 0.05169  loss_mask: 0.06545  loss_rpn_cls: 0.0003987  loss_rpn_loc: 0.00584  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:10] d2.utils.events INFO:  eta: 0:37:55  iter: 64219  total_loss: 0.09604  loss_cls: 0.01667  loss_box_reg: 0.03188  loss_mask: 0.04082  loss_rpn_cls: 0.0002314  loss_rpn_loc: 0.003556  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:12] d2.utils.events INFO:  eta: 0:37:52  iter: 64239  total_loss: 0.08411  loss_cls: 0.01066  loss_box_reg: 0.02193  loss_mask: 0.04068  loss_rpn_cls: 0.0002559  loss_rpn_loc: 0.002671  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:13] d2.utils.events INFO:  eta: 0:37:51  iter: 64259  total_loss: 0.1028  loss_cls: 0.01255  loss_box_reg: 0.03682  loss_mask: 0.05745  loss_rpn_cls: 0.0004811  loss_rpn_loc: 0.006196  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:15] d2.utils.events INFO:  eta: 0:37:55  iter: 64279  total_loss: 0.1111  loss_cls: 0.01349  loss_box_reg: 0.03351  loss_mask: 0.04478  loss_rpn_cls: 0.0004842  loss_rpn_loc: 0.00556  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:17] d2.utils.events INFO:  eta: 0:37:54  iter: 64299  total_loss: 0.09511  loss_cls: 0.01526  loss_box_reg: 0.03424  loss_mask: 0.04215  loss_rpn_cls: 0.0003557  loss_rpn_loc: 0.004841  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:19] d2.utils.events INFO:  eta: 0:37:55  iter: 64319  total_loss: 0.1127  loss_cls: 0.0184  loss_box_reg: 0.04051  loss_mask: 0.0543  loss_rpn_cls: 0.0002939  loss_rpn_loc: 0.004005  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:21] d2.utils.events INFO:  eta: 0:37:46  iter: 64339  total_loss: 0.08379  loss_cls: 0.01377  loss_box_reg: 0.02008  loss_mask: 0.04564  loss_rpn_cls: 0.0004049  loss_rpn_loc: 0.003806  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:22] d2.utils.events INFO:  eta: 0:37:44  iter: 64359  total_loss: 0.1654  loss_cls: 0.02478  loss_box_reg: 0.04836  loss_mask: 0.06579  loss_rpn_cls: 0.0004945  loss_rpn_loc: 0.006261  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:24] d2.utils.events INFO:  eta: 0:37:38  iter: 64379  total_loss: 0.08212  loss_cls: 0.008964  loss_box_reg: 0.0251  loss_mask: 0.04255  loss_rpn_cls: 0.0001682  loss_rpn_loc: 0.002837  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:26] d2.utils.events INFO:  eta: 0:37:41  iter: 64399  total_loss: 0.1147  loss_cls: 0.02055  loss_box_reg: 0.03646  loss_mask: 0.04734  loss_rpn_cls: 0.0001838  loss_rpn_loc: 0.004876  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:28] d2.utils.events INFO:  eta: 0:37:34  iter: 64419  total_loss: 0.08116  loss_cls: 0.01305  loss_box_reg: 0.02423  loss_mask: 0.03739  loss_rpn_cls: 0.0001911  loss_rpn_loc: 0.003336  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:29] d2.utils.events INFO:  eta: 0:37:33  iter: 64439  total_loss: 0.09524  loss_cls: 0.01453  loss_box_reg: 0.03035  loss_mask: 0.04479  loss_rpn_cls: 0.0002055  loss_rpn_loc: 0.002957  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:31] d2.utils.events INFO:  eta: 0:37:33  iter: 64459  total_loss: 0.1135  loss_cls: 0.01456  loss_box_reg: 0.0353  loss_mask: 0.06158  loss_rpn_cls: 0.000542  loss_rpn_loc: 0.005896  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:12:33] d2.utils.events INFO:  eta: 0:37:33  iter: 64479  total_loss: 0.07059  loss_cls: 0.008392  loss_box_reg: 0.02135  loss_mask: 0.03884  loss_rpn_cls: 0.0003179  loss_rpn_loc: 0.002973  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:35] d2.utils.events INFO:  eta: 0:37:29  iter: 64499  total_loss: 0.08841  loss_cls: 0.01397  loss_box_reg: 0.02824  loss_mask: 0.04219  loss_rpn_cls: 0.0002331  loss_rpn_loc: 0.004247  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:36] d2.utils.events INFO:  eta: 0:37:29  iter: 64519  total_loss: 0.08722  loss_cls: 0.01324  loss_box_reg: 0.02858  loss_mask: 0.04254  loss_rpn_cls: 0.0003232  loss_rpn_loc: 0.002859  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:12:38] d2.utils.events INFO:  eta: 0:37:24  iter: 64539  total_loss: 0.08744  loss_cls: 0.009767  loss_box_reg: 0.02701  loss_mask: 0.04153  loss_rpn_cls: 0.0003433  loss_rpn_loc: 0.003978  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:40] d2.utils.events INFO:  eta: 0:37:21  iter: 64559  total_loss: 0.105  loss_cls: 0.01493  loss_box_reg: 0.03689  loss_mask: 0.04971  loss_rpn_cls: 0.0002444  loss_rpn_loc: 0.004742  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:42] d2.utils.events INFO:  eta: 0:37:13  iter: 64579  total_loss: 0.08254  loss_cls: 0.01442  loss_box_reg: 0.02701  loss_mask: 0.03874  loss_rpn_cls: 0.0002952  loss_rpn_loc: 0.004777  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:12:43] d2.utils.events INFO:  eta: 0:37:07  iter: 64599  total_loss: 0.06917  loss_cls: 0.007778  loss_box_reg: 0.01316  loss_mask: 0.04247  loss_rpn_cls: 0.0002114  loss_rpn_loc: 0.001957  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:45] d2.utils.events INFO:  eta: 0:37:11  iter: 64619  total_loss: 0.1562  loss_cls: 0.01842  loss_box_reg: 0.04301  loss_mask: 0.05796  loss_rpn_cls: 0.0002814  loss_rpn_loc: 0.006681  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:47] d2.utils.events INFO:  eta: 0:37:05  iter: 64639  total_loss: 0.07057  loss_cls: 0.01194  loss_box_reg: 0.01716  loss_mask: 0.03196  loss_rpn_cls: 0.0001749  loss_rpn_loc: 0.001984  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:49] d2.utils.events INFO:  eta: 0:37:02  iter: 64659  total_loss: 0.08751  loss_cls: 0.01007  loss_box_reg: 0.02503  loss_mask: 0.05375  loss_rpn_cls: 0.0003407  loss_rpn_loc: 0.003183  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:50] d2.utils.events INFO:  eta: 0:37:02  iter: 64679  total_loss: 0.1315  loss_cls: 0.02279  loss_box_reg: 0.04827  loss_mask: 0.05804  loss_rpn_cls: 0.00037  loss_rpn_loc: 0.006255  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:52] d2.utils.events INFO:  eta: 0:37:05  iter: 64699  total_loss: 0.1253  loss_cls: 0.01673  loss_box_reg: 0.03467  loss_mask: 0.06249  loss_rpn_cls: 0.0004525  loss_rpn_loc: 0.006877  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:54] d2.utils.events INFO:  eta: 0:37:04  iter: 64719  total_loss: 0.1168  loss_cls: 0.01873  loss_box_reg: 0.03441  loss_mask: 0.04873  loss_rpn_cls: 0.0003704  loss_rpn_loc: 0.00552  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:12:56] d2.utils.events INFO:  eta: 0:37:03  iter: 64739  total_loss: 0.08054  loss_cls: 0.01011  loss_box_reg: 0.02257  loss_mask: 0.03775  loss_rpn_cls: 0.0002224  loss_rpn_loc: 0.003384  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:12:57] d2.utils.events INFO:  eta: 0:36:59  iter: 64759  total_loss: 0.09395  loss_cls: 0.01415  loss_box_reg: 0.03053  loss_mask: 0.04243  loss_rpn_cls: 0.0002287  loss_rpn_loc: 0.004676  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:12:59] d2.utils.events INFO:  eta: 0:37:05  iter: 64779  total_loss: 0.101  loss_cls: 0.01452  loss_box_reg: 0.0332  loss_mask: 0.04577  loss_rpn_cls: 0.0002265  loss_rpn_loc: 0.004805  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:01] d2.utils.events INFO:  eta: 0:37:00  iter: 64799  total_loss: 0.1052  loss_cls: 0.01117  loss_box_reg: 0.02312  loss_mask: 0.04924  loss_rpn_cls: 0.0002046  loss_rpn_loc: 0.002753  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:03] d2.utils.events INFO:  eta: 0:36:58  iter: 64819  total_loss: 0.1267  loss_cls: 0.01948  loss_box_reg: 0.05026  loss_mask: 0.04562  loss_rpn_cls: 0.000343  loss_rpn_loc: 0.006062  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:05] d2.utils.events INFO:  eta: 0:36:58  iter: 64839  total_loss: 0.09516  loss_cls: 0.01167  loss_box_reg: 0.03197  loss_mask: 0.04738  loss_rpn_cls: 0.000128  loss_rpn_loc: 0.00214  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:06] d2.utils.events INFO:  eta: 0:36:58  iter: 64859  total_loss: 0.09539  loss_cls: 0.01508  loss_box_reg: 0.03297  loss_mask: 0.05265  loss_rpn_cls: 0.0002604  loss_rpn_loc: 0.004196  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:13:08] d2.utils.events INFO:  eta: 0:36:53  iter: 64879  total_loss: 0.07795  loss_cls: 0.008665  loss_box_reg: 0.02583  loss_mask: 0.044  loss_rpn_cls: 0.0001425  loss_rpn_loc: 0.003033  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:10] d2.utils.events INFO:  eta: 0:36:51  iter: 64899  total_loss: 0.1038  loss_cls: 0.01817  loss_box_reg: 0.04489  loss_mask: 0.04491  loss_rpn_cls: 0.0006462  loss_rpn_loc: 0.006328  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:12] d2.utils.events INFO:  eta: 0:36:46  iter: 64919  total_loss: 0.08179  loss_cls: 0.01151  loss_box_reg: 0.02513  loss_mask: 0.04602  loss_rpn_cls: 0.0003321  loss_rpn_loc: 0.003361  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:13] d2.utils.events INFO:  eta: 0:36:47  iter: 64939  total_loss: 0.08939  loss_cls: 0.01244  loss_box_reg: 0.03257  loss_mask: 0.04265  loss_rpn_cls: 0.0004705  loss_rpn_loc: 0.006946  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:13:15] d2.utils.events INFO:  eta: 0:36:42  iter: 64959  total_loss: 0.06672  loss_cls: 0.01189  loss_box_reg: 0.01886  loss_mask: 0.03873  loss_rpn_cls: 0.0002217  loss_rpn_loc: 0.003689  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:17] d2.utils.events INFO:  eta: 0:36:40  iter: 64979  total_loss: 0.1185  loss_cls: 0.02075  loss_box_reg: 0.048  loss_mask: 0.05109  loss_rpn_cls: 0.0002982  loss_rpn_loc: 0.003414  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:19] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0064999.pth
[10/27 20:13:19] d2.utils.events INFO:  eta: 0:36:38  iter: 64999  total_loss: 0.0834  loss_cls: 0.01393  loss_box_reg: 0.02475  loss_mask: 0.0455  loss_rpn_cls: 0.0001793  loss_rpn_loc: 0.003264  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:21] d2.utils.events INFO:  eta: 0:36:36  iter: 65019  total_loss: 0.09641  loss_cls: 0.01325  loss_box_reg: 0.03099  loss_mask: 0.04528  loss_rpn_cls: 0.0003462  loss_rpn_loc: 0.004158  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:23] d2.utils.events INFO:  eta: 0:36:34  iter: 65039  total_loss: 0.1068  loss_cls: 0.009359  loss_box_reg: 0.0338  loss_mask: 0.05204  loss_rpn_cls: 0.0002808  loss_rpn_loc: 0.00426  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:24] d2.utils.events INFO:  eta: 0:36:34  iter: 65059  total_loss: 0.1118  loss_cls: 0.01305  loss_box_reg: 0.02968  loss_mask: 0.05229  loss_rpn_cls: 0.0003065  loss_rpn_loc: 0.005562  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:13:26] d2.utils.events INFO:  eta: 0:36:33  iter: 65079  total_loss: 0.06253  loss_cls: 0.01077  loss_box_reg: 0.01927  loss_mask: 0.03447  loss_rpn_cls: 0.0002332  loss_rpn_loc: 0.002743  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:28] d2.utils.events INFO:  eta: 0:36:30  iter: 65099  total_loss: 0.1027  loss_cls: 0.01472  loss_box_reg: 0.02934  loss_mask: 0.05024  loss_rpn_cls: 0.0003058  loss_rpn_loc: 0.004644  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:13:30] d2.utils.events INFO:  eta: 0:36:27  iter: 65119  total_loss: 0.08595  loss_cls: 0.01068  loss_box_reg: 0.02739  loss_mask: 0.05171  loss_rpn_cls: 0.0002563  loss_rpn_loc: 0.003446  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:31] d2.utils.events INFO:  eta: 0:36:27  iter: 65139  total_loss: 0.1028  loss_cls: 0.01675  loss_box_reg: 0.03915  loss_mask: 0.0456  loss_rpn_cls: 0.0002446  loss_rpn_loc: 0.003925  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:33] d2.utils.events INFO:  eta: 0:36:25  iter: 65159  total_loss: 0.07771  loss_cls: 0.0108  loss_box_reg: 0.0171  loss_mask: 0.04445  loss_rpn_cls: 0.0002284  loss_rpn_loc: 0.003138  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:35] d2.utils.events INFO:  eta: 0:36:22  iter: 65179  total_loss: 0.0977  loss_cls: 0.01451  loss_box_reg: 0.02887  loss_mask: 0.03944  loss_rpn_cls: 0.0002254  loss_rpn_loc: 0.003969  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:37] d2.utils.events INFO:  eta: 0:36:21  iter: 65199  total_loss: 0.1376  loss_cls: 0.01686  loss_box_reg: 0.04409  loss_mask: 0.06609  loss_rpn_cls: 0.0005633  loss_rpn_loc: 0.006735  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:38] d2.utils.events INFO:  eta: 0:36:18  iter: 65219  total_loss: 0.06915  loss_cls: 0.01143  loss_box_reg: 0.02134  loss_mask: 0.04044  loss_rpn_cls: 0.0004219  loss_rpn_loc: 0.00318  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:40] d2.utils.events INFO:  eta: 0:36:17  iter: 65239  total_loss: 0.07883  loss_cls: 0.01118  loss_box_reg: 0.023  loss_mask: 0.04189  loss_rpn_cls: 0.000199  loss_rpn_loc: 0.003081  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:42] d2.utils.events INFO:  eta: 0:36:16  iter: 65259  total_loss: 0.08026  loss_cls: 0.01369  loss_box_reg: 0.02812  loss_mask: 0.04651  loss_rpn_cls: 0.0003422  loss_rpn_loc: 0.002928  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:44] d2.utils.events INFO:  eta: 0:36:15  iter: 65279  total_loss: 0.1112  loss_cls: 0.01904  loss_box_reg: 0.0349  loss_mask: 0.06247  loss_rpn_cls: 0.0003662  loss_rpn_loc: 0.004856  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:46] d2.utils.events INFO:  eta: 0:36:13  iter: 65299  total_loss: 0.09884  loss_cls: 0.01551  loss_box_reg: 0.03957  loss_mask: 0.04193  loss_rpn_cls: 0.0002722  loss_rpn_loc: 0.004611  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:47] d2.utils.events INFO:  eta: 0:36:10  iter: 65319  total_loss: 0.07856  loss_cls: 0.0098  loss_box_reg: 0.02566  loss_mask: 0.04243  loss_rpn_cls: 0.0002624  loss_rpn_loc: 0.003322  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:49] d2.utils.events INFO:  eta: 0:36:10  iter: 65339  total_loss: 0.08203  loss_cls: 0.009597  loss_box_reg: 0.0205  loss_mask: 0.05131  loss_rpn_cls: 0.0003057  loss_rpn_loc: 0.00264  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:51] d2.utils.events INFO:  eta: 0:36:08  iter: 65359  total_loss: 0.0983  loss_cls: 0.01671  loss_box_reg: 0.02804  loss_mask: 0.04366  loss_rpn_cls: 0.0002857  loss_rpn_loc: 0.003643  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:53] d2.utils.events INFO:  eta: 0:36:08  iter: 65379  total_loss: 0.1098  loss_cls: 0.01813  loss_box_reg: 0.0434  loss_mask: 0.05261  loss_rpn_cls: 0.0003495  loss_rpn_loc: 0.008252  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:13:55] d2.utils.events INFO:  eta: 0:36:11  iter: 65399  total_loss: 0.1453  loss_cls: 0.02635  loss_box_reg: 0.05347  loss_mask: 0.05568  loss_rpn_cls: 0.000774  loss_rpn_loc: 0.01479  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:13:56] d2.utils.events INFO:  eta: 0:36:09  iter: 65419  total_loss: 0.1097  loss_cls: 0.01473  loss_box_reg: 0.02873  loss_mask: 0.05198  loss_rpn_cls: 0.0004985  loss_rpn_loc: 0.005736  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:13:58] d2.utils.events INFO:  eta: 0:36:01  iter: 65439  total_loss: 0.06989  loss_cls: 0.007677  loss_box_reg: 0.02174  loss_mask: 0.04496  loss_rpn_cls: 0.0001625  loss_rpn_loc: 0.002842  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:00] d2.utils.events INFO:  eta: 0:35:59  iter: 65459  total_loss: 0.09197  loss_cls: 0.01277  loss_box_reg: 0.03359  loss_mask: 0.04509  loss_rpn_cls: 0.0002613  loss_rpn_loc: 0.003096  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:01] d2.utils.events INFO:  eta: 0:35:56  iter: 65479  total_loss: 0.06129  loss_cls: 0.007213  loss_box_reg: 0.01774  loss_mask: 0.03429  loss_rpn_cls: 0.0001848  loss_rpn_loc: 0.002005  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:03] d2.utils.events INFO:  eta: 0:35:53  iter: 65499  total_loss: 0.0713  loss_cls: 0.009796  loss_box_reg: 0.02147  loss_mask: 0.0425  loss_rpn_cls: 0.0001525  loss_rpn_loc: 0.002287  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:05] d2.utils.events INFO:  eta: 0:35:52  iter: 65519  total_loss: 0.09177  loss_cls: 0.01203  loss_box_reg: 0.02324  loss_mask: 0.05507  loss_rpn_cls: 0.000254  loss_rpn_loc: 0.003015  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:07] d2.utils.events INFO:  eta: 0:35:52  iter: 65539  total_loss: 0.09329  loss_cls: 0.01309  loss_box_reg: 0.02899  loss_mask: 0.04318  loss_rpn_cls: 0.0002948  loss_rpn_loc: 0.004256  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:08] d2.utils.events INFO:  eta: 0:35:50  iter: 65559  total_loss: 0.1057  loss_cls: 0.01883  loss_box_reg: 0.0341  loss_mask: 0.04366  loss_rpn_cls: 0.0003764  loss_rpn_loc: 0.005307  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:10] d2.utils.events INFO:  eta: 0:35:48  iter: 65579  total_loss: 0.08153  loss_cls: 0.01351  loss_box_reg: 0.02991  loss_mask: 0.0423  loss_rpn_cls: 0.0002233  loss_rpn_loc: 0.003349  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:12] d2.utils.events INFO:  eta: 0:35:55  iter: 65599  total_loss: 0.1475  loss_cls: 0.02674  loss_box_reg: 0.04995  loss_mask: 0.06344  loss_rpn_cls: 0.0003513  loss_rpn_loc: 0.007001  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:14] d2.utils.events INFO:  eta: 0:35:52  iter: 65619  total_loss: 0.09939  loss_cls: 0.01349  loss_box_reg: 0.0352  loss_mask: 0.04827  loss_rpn_cls: 0.0002227  loss_rpn_loc: 0.003612  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:16] d2.utils.events INFO:  eta: 0:35:52  iter: 65639  total_loss: 0.08423  loss_cls: 0.01289  loss_box_reg: 0.02719  loss_mask: 0.03971  loss_rpn_cls: 0.0004348  loss_rpn_loc: 0.003104  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:17] d2.utils.events INFO:  eta: 0:35:50  iter: 65659  total_loss: 0.07477  loss_cls: 0.011  loss_box_reg: 0.0257  loss_mask: 0.03861  loss_rpn_cls: 0.0002881  loss_rpn_loc: 0.002997  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:14:19] d2.utils.events INFO:  eta: 0:35:42  iter: 65679  total_loss: 0.07768  loss_cls: 0.01235  loss_box_reg: 0.02536  loss_mask: 0.03835  loss_rpn_cls: 0.000639  loss_rpn_loc: 0.002981  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:21] d2.utils.events INFO:  eta: 0:35:37  iter: 65699  total_loss: 0.0724  loss_cls: 0.01081  loss_box_reg: 0.02246  loss_mask: 0.04215  loss_rpn_cls: 0.0003114  loss_rpn_loc: 0.002596  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:23] d2.utils.events INFO:  eta: 0:35:36  iter: 65719  total_loss: 0.07926  loss_cls: 0.01487  loss_box_reg: 0.02525  loss_mask: 0.0406  loss_rpn_cls: 0.0002644  loss_rpn_loc: 0.004057  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:24] d2.utils.events INFO:  eta: 0:35:33  iter: 65739  total_loss: 0.08386  loss_cls: 0.00988  loss_box_reg: 0.02584  loss_mask: 0.04672  loss_rpn_cls: 0.0002247  loss_rpn_loc: 0.003036  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:26] d2.utils.events INFO:  eta: 0:35:31  iter: 65759  total_loss: 0.07112  loss_cls: 0.008316  loss_box_reg: 0.01875  loss_mask: 0.04847  loss_rpn_cls: 0.0001734  loss_rpn_loc: 0.001859  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:28] d2.utils.events INFO:  eta: 0:35:28  iter: 65779  total_loss: 0.09886  loss_cls: 0.01549  loss_box_reg: 0.03718  loss_mask: 0.04224  loss_rpn_cls: 0.0002589  loss_rpn_loc: 0.005392  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:29] d2.utils.events INFO:  eta: 0:35:28  iter: 65799  total_loss: 0.09763  loss_cls: 0.01229  loss_box_reg: 0.03542  loss_mask: 0.04867  loss_rpn_cls: 0.0003375  loss_rpn_loc: 0.00397  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:31] d2.utils.events INFO:  eta: 0:35:27  iter: 65819  total_loss: 0.1133  loss_cls: 0.01705  loss_box_reg: 0.03613  loss_mask: 0.04959  loss_rpn_cls: 0.000397  loss_rpn_loc: 0.005662  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:33] d2.utils.events INFO:  eta: 0:35:24  iter: 65839  total_loss: 0.09464  loss_cls: 0.00956  loss_box_reg: 0.02855  loss_mask: 0.0504  loss_rpn_cls: 0.0002347  loss_rpn_loc: 0.002719  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:35] d2.utils.events INFO:  eta: 0:35:23  iter: 65859  total_loss: 0.1066  loss_cls: 0.01405  loss_box_reg: 0.03467  loss_mask: 0.05267  loss_rpn_cls: 0.0002716  loss_rpn_loc: 0.003561  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:37] d2.utils.events INFO:  eta: 0:35:24  iter: 65879  total_loss: 0.1442  loss_cls: 0.02524  loss_box_reg: 0.04881  loss_mask: 0.06515  loss_rpn_cls: 0.0004129  loss_rpn_loc: 0.006051  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:38] d2.utils.events INFO:  eta: 0:35:22  iter: 65899  total_loss: 0.1139  loss_cls: 0.01814  loss_box_reg: 0.03575  loss_mask: 0.05843  loss_rpn_cls: 0.0004779  loss_rpn_loc: 0.005595  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:40] d2.utils.events INFO:  eta: 0:35:23  iter: 65919  total_loss: 0.07315  loss_cls: 0.01211  loss_box_reg: 0.01806  loss_mask: 0.03464  loss_rpn_cls: 0.0001538  loss_rpn_loc: 0.001544  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:14:42] d2.utils.events INFO:  eta: 0:35:18  iter: 65939  total_loss: 0.08535  loss_cls: 0.01039  loss_box_reg: 0.02646  loss_mask: 0.04146  loss_rpn_cls: 0.0005926  loss_rpn_loc: 0.003116  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:14:44] d2.utils.events INFO:  eta: 0:35:25  iter: 65959  total_loss: 0.1692  loss_cls: 0.02245  loss_box_reg: 0.05488  loss_mask: 0.07204  loss_rpn_cls: 0.0008323  loss_rpn_loc: 0.00842  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:45] d2.utils.events INFO:  eta: 0:35:18  iter: 65979  total_loss: 0.07664  loss_cls: 0.01254  loss_box_reg: 0.02341  loss_mask: 0.03836  loss_rpn_cls: 0.0002215  loss_rpn_loc: 0.002959  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:47] d2.utils.events INFO:  eta: 0:35:18  iter: 65999  total_loss: 0.07439  loss_cls: 0.01049  loss_box_reg: 0.02261  loss_mask: 0.04294  loss_rpn_cls: 0.0001245  loss_rpn_loc: 0.001467  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:49] d2.utils.events INFO:  eta: 0:35:16  iter: 66019  total_loss: 0.0864  loss_cls: 0.01264  loss_box_reg: 0.02848  loss_mask: 0.04787  loss_rpn_cls: 0.0003159  loss_rpn_loc: 0.004032  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:51] d2.utils.events INFO:  eta: 0:35:13  iter: 66039  total_loss: 0.08799  loss_cls: 0.01324  loss_box_reg: 0.02535  loss_mask: 0.04871  loss_rpn_cls: 0.0004476  loss_rpn_loc: 0.003301  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:52] d2.utils.events INFO:  eta: 0:35:09  iter: 66059  total_loss: 0.09043  loss_cls: 0.0129  loss_box_reg: 0.028  loss_mask: 0.04633  loss_rpn_cls: 0.0002191  loss_rpn_loc: 0.002852  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:54] d2.utils.events INFO:  eta: 0:35:10  iter: 66079  total_loss: 0.08492  loss_cls: 0.01416  loss_box_reg: 0.03688  loss_mask: 0.04074  loss_rpn_cls: 0.0002824  loss_rpn_loc: 0.003977  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:56] d2.utils.events INFO:  eta: 0:35:09  iter: 66099  total_loss: 0.101  loss_cls: 0.01299  loss_box_reg: 0.02829  loss_mask: 0.05513  loss_rpn_cls: 0.0002373  loss_rpn_loc: 0.004376  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:14:58] d2.utils.events INFO:  eta: 0:35:06  iter: 66119  total_loss: 0.07389  loss_cls: 0.00722  loss_box_reg: 0.02291  loss_mask: 0.04707  loss_rpn_cls: 0.0001767  loss_rpn_loc: 0.002104  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:14:59] d2.utils.events INFO:  eta: 0:35:01  iter: 66139  total_loss: 0.09116  loss_cls: 0.01133  loss_box_reg: 0.02524  loss_mask: 0.04427  loss_rpn_cls: 0.0002285  loss_rpn_loc: 0.003529  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:01] d2.utils.events INFO:  eta: 0:35:00  iter: 66159  total_loss: 0.07769  loss_cls: 0.008276  loss_box_reg: 0.01734  loss_mask: 0.03816  loss_rpn_cls: 0.0002851  loss_rpn_loc: 0.003494  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:03] d2.utils.events INFO:  eta: 0:34:59  iter: 66179  total_loss: 0.1056  loss_cls: 0.01852  loss_box_reg: 0.02882  loss_mask: 0.04829  loss_rpn_cls: 0.0004559  loss_rpn_loc: 0.005947  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:15:05] d2.utils.events INFO:  eta: 0:34:56  iter: 66199  total_loss: 0.1043  loss_cls: 0.01301  loss_box_reg: 0.03904  loss_mask: 0.0506  loss_rpn_cls: 0.0003574  loss_rpn_loc: 0.004681  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:07] d2.utils.events INFO:  eta: 0:34:59  iter: 66219  total_loss: 0.103  loss_cls: 0.01532  loss_box_reg: 0.0366  loss_mask: 0.04492  loss_rpn_cls: 0.0003384  loss_rpn_loc: 0.004471  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:08] d2.utils.events INFO:  eta: 0:34:57  iter: 66239  total_loss: 0.09294  loss_cls: 0.01414  loss_box_reg: 0.02696  loss_mask: 0.04204  loss_rpn_cls: 0.0004147  loss_rpn_loc: 0.003667  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:10] d2.utils.events INFO:  eta: 0:34:56  iter: 66259  total_loss: 0.1554  loss_cls: 0.02061  loss_box_reg: 0.04573  loss_mask: 0.06827  loss_rpn_cls: 0.0004575  loss_rpn_loc: 0.007196  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:15:12] d2.utils.events INFO:  eta: 0:34:54  iter: 66279  total_loss: 0.08929  loss_cls: 0.01147  loss_box_reg: 0.02871  loss_mask: 0.04485  loss_rpn_cls: 0.0002469  loss_rpn_loc: 0.00333  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:14] d2.utils.events INFO:  eta: 0:34:48  iter: 66299  total_loss: 0.06411  loss_cls: 0.008145  loss_box_reg: 0.02026  loss_mask: 0.0331  loss_rpn_cls: 0.0001038  loss_rpn_loc: 0.001159  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:15] d2.utils.events INFO:  eta: 0:34:46  iter: 66319  total_loss: 0.08526  loss_cls: 0.01375  loss_box_reg: 0.02975  loss_mask: 0.04606  loss_rpn_cls: 0.0003534  loss_rpn_loc: 0.004092  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:17] d2.utils.events INFO:  eta: 0:34:43  iter: 66339  total_loss: 0.07013  loss_cls: 0.006141  loss_box_reg: 0.0201  loss_mask: 0.04766  loss_rpn_cls: 0.0003101  loss_rpn_loc: 0.002635  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:19] d2.utils.events INFO:  eta: 0:34:42  iter: 66359  total_loss: 0.09882  loss_cls: 0.01854  loss_box_reg: 0.03356  loss_mask: 0.04164  loss_rpn_cls: 0.000331  loss_rpn_loc: 0.004308  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:21] d2.utils.events INFO:  eta: 0:34:39  iter: 66379  total_loss: 0.08855  loss_cls: 0.0128  loss_box_reg: 0.02724  loss_mask: 0.04527  loss_rpn_cls: 0.0002514  loss_rpn_loc: 0.002963  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:22] d2.utils.events INFO:  eta: 0:34:30  iter: 66399  total_loss: 0.08475  loss_cls: 0.0135  loss_box_reg: 0.02563  loss_mask: 0.03968  loss_rpn_cls: 0.0005221  loss_rpn_loc: 0.00492  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:24] d2.utils.events INFO:  eta: 0:34:33  iter: 66419  total_loss: 0.111  loss_cls: 0.01708  loss_box_reg: 0.04357  loss_mask: 0.04552  loss_rpn_cls: 0.0004435  loss_rpn_loc: 0.005575  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:26] d2.utils.events INFO:  eta: 0:34:33  iter: 66439  total_loss: 0.1075  loss_cls: 0.01148  loss_box_reg: 0.02607  loss_mask: 0.05951  loss_rpn_cls: 0.0003932  loss_rpn_loc: 0.003746  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:28] d2.utils.events INFO:  eta: 0:34:31  iter: 66459  total_loss: 0.09437  loss_cls: 0.01041  loss_box_reg: 0.0276  loss_mask: 0.04657  loss_rpn_cls: 0.0003203  loss_rpn_loc: 0.003517  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:30] d2.utils.events INFO:  eta: 0:34:34  iter: 66479  total_loss: 0.09685  loss_cls: 0.01638  loss_box_reg: 0.03932  loss_mask: 0.05144  loss_rpn_cls: 0.0004299  loss_rpn_loc: 0.005379  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:31] d2.utils.events INFO:  eta: 0:34:33  iter: 66499  total_loss: 0.08718  loss_cls: 0.01461  loss_box_reg: 0.02274  loss_mask: 0.04503  loss_rpn_cls: 0.0001502  loss_rpn_loc: 0.003357  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:33] d2.utils.events INFO:  eta: 0:34:32  iter: 66519  total_loss: 0.08002  loss_cls: 0.01205  loss_box_reg: 0.02728  loss_mask: 0.03858  loss_rpn_cls: 0.0003553  loss_rpn_loc: 0.003358  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:35] d2.utils.events INFO:  eta: 0:34:29  iter: 66539  total_loss: 0.075  loss_cls: 0.009328  loss_box_reg: 0.01769  loss_mask: 0.04427  loss_rpn_cls: 0.0001785  loss_rpn_loc: 0.002415  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:37] d2.utils.events INFO:  eta: 0:34:26  iter: 66559  total_loss: 0.06451  loss_cls: 0.0103  loss_box_reg: 0.02294  loss_mask: 0.03825  loss_rpn_cls: 0.0001062  loss_rpn_loc: 0.002369  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:38] d2.utils.events INFO:  eta: 0:34:25  iter: 66579  total_loss: 0.07983  loss_cls: 0.009391  loss_box_reg: 0.02667  loss_mask: 0.04326  loss_rpn_cls: 0.0002823  loss_rpn_loc: 0.002533  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:40] d2.utils.events INFO:  eta: 0:34:18  iter: 66599  total_loss: 0.09808  loss_cls: 0.01287  loss_box_reg: 0.02653  loss_mask: 0.05032  loss_rpn_cls: 0.0003848  loss_rpn_loc: 0.004039  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:42] d2.utils.events INFO:  eta: 0:34:20  iter: 66619  total_loss: 0.09714  loss_cls: 0.01056  loss_box_reg: 0.03257  loss_mask: 0.04509  loss_rpn_cls: 0.000225  loss_rpn_loc: 0.004131  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:44] d2.utils.events INFO:  eta: 0:34:18  iter: 66639  total_loss: 0.09378  loss_cls: 0.01634  loss_box_reg: 0.0315  loss_mask: 0.04108  loss_rpn_cls: 0.0004912  loss_rpn_loc: 0.006901  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:45] d2.utils.events INFO:  eta: 0:34:17  iter: 66659  total_loss: 0.08305  loss_cls: 0.009803  loss_box_reg: 0.02621  loss_mask: 0.03976  loss_rpn_cls: 0.0001957  loss_rpn_loc: 0.002156  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:47] d2.utils.events INFO:  eta: 0:34:17  iter: 66679  total_loss: 0.0993  loss_cls: 0.01266  loss_box_reg: 0.0332  loss_mask: 0.03747  loss_rpn_cls: 0.0003687  loss_rpn_loc: 0.003057  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:49] d2.utils.events INFO:  eta: 0:34:17  iter: 66699  total_loss: 0.0983  loss_cls: 0.01222  loss_box_reg: 0.02797  loss_mask: 0.05699  loss_rpn_cls: 0.000332  loss_rpn_loc: 0.004648  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:15:51] d2.utils.events INFO:  eta: 0:34:15  iter: 66719  total_loss: 0.08089  loss_cls: 0.01055  loss_box_reg: 0.02635  loss_mask: 0.04297  loss_rpn_cls: 0.0003738  loss_rpn_loc: 0.005462  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:53] d2.utils.events INFO:  eta: 0:34:16  iter: 66739  total_loss: 0.07873  loss_cls: 0.01081  loss_box_reg: 0.02213  loss_mask: 0.04579  loss_rpn_cls: 0.0002154  loss_rpn_loc: 0.004614  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:54] d2.utils.events INFO:  eta: 0:34:14  iter: 66759  total_loss: 0.07817  loss_cls: 0.009341  loss_box_reg: 0.02361  loss_mask: 0.04173  loss_rpn_cls: 0.0001626  loss_rpn_loc: 0.002833  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:56] d2.utils.events INFO:  eta: 0:34:10  iter: 66779  total_loss: 0.09015  loss_cls: 0.008925  loss_box_reg: 0.0238  loss_mask: 0.05669  loss_rpn_cls: 0.0001911  loss_rpn_loc: 0.002251  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:15:58] d2.utils.events INFO:  eta: 0:34:08  iter: 66799  total_loss: 0.1051  loss_cls: 0.01687  loss_box_reg: 0.02824  loss_mask: 0.04232  loss_rpn_cls: 0.0002762  loss_rpn_loc: 0.003761  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:15:59] d2.utils.events INFO:  eta: 0:34:06  iter: 66819  total_loss: 0.1004  loss_cls: 0.01546  loss_box_reg: 0.02942  loss_mask: 0.0524  loss_rpn_cls: 0.0005378  loss_rpn_loc: 0.004596  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:01] d2.utils.events INFO:  eta: 0:34:04  iter: 66839  total_loss: 0.07764  loss_cls: 0.01197  loss_box_reg: 0.02615  loss_mask: 0.03937  loss_rpn_cls: 0.000282  loss_rpn_loc: 0.002612  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:03] d2.utils.events INFO:  eta: 0:34:02  iter: 66859  total_loss: 0.104  loss_cls: 0.01459  loss_box_reg: 0.0326  loss_mask: 0.05823  loss_rpn_cls: 0.0002802  loss_rpn_loc: 0.00536  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:05] d2.utils.events INFO:  eta: 0:34:00  iter: 66879  total_loss: 0.1034  loss_cls: 0.01276  loss_box_reg: 0.03838  loss_mask: 0.04091  loss_rpn_cls: 0.0004441  loss_rpn_loc: 0.005188  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:07] d2.utils.events INFO:  eta: 0:33:59  iter: 66899  total_loss: 0.1282  loss_cls: 0.01638  loss_box_reg: 0.04239  loss_mask: 0.06192  loss_rpn_cls: 0.0003911  loss_rpn_loc: 0.004847  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:08] d2.utils.events INFO:  eta: 0:33:57  iter: 66919  total_loss: 0.07067  loss_cls: 0.007788  loss_box_reg: 0.01932  loss_mask: 0.0395  loss_rpn_cls: 0.0002078  loss_rpn_loc: 0.002607  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:10] d2.utils.events INFO:  eta: 0:33:55  iter: 66939  total_loss: 0.1025  loss_cls: 0.01299  loss_box_reg: 0.02274  loss_mask: 0.05916  loss_rpn_cls: 0.0002588  loss_rpn_loc: 0.005585  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:12] d2.utils.events INFO:  eta: 0:33:51  iter: 66959  total_loss: 0.08731  loss_cls: 0.01096  loss_box_reg: 0.0289  loss_mask: 0.04433  loss_rpn_cls: 0.0002642  loss_rpn_loc: 0.003467  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:14] d2.utils.events INFO:  eta: 0:33:50  iter: 66979  total_loss: 0.08105  loss_cls: 0.009118  loss_box_reg: 0.0244  loss_mask: 0.04378  loss_rpn_cls: 0.0002293  loss_rpn_loc: 0.002703  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:15] d2.utils.events INFO:  eta: 0:33:48  iter: 66999  total_loss: 0.06663  loss_cls: 0.008643  loss_box_reg: 0.01714  loss_mask: 0.041  loss_rpn_cls: 0.000155  loss_rpn_loc: 0.001913  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:16:17] d2.utils.events INFO:  eta: 0:33:47  iter: 67019  total_loss: 0.09794  loss_cls: 0.01574  loss_box_reg: 0.03185  loss_mask: 0.0518  loss_rpn_cls: 0.0001749  loss_rpn_loc: 0.004431  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:19] d2.utils.events INFO:  eta: 0:33:46  iter: 67039  total_loss: 0.1117  loss_cls: 0.0161  loss_box_reg: 0.0302  loss_mask: 0.0503  loss_rpn_cls: 0.0004162  loss_rpn_loc: 0.004976  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:21] d2.utils.events INFO:  eta: 0:33:44  iter: 67059  total_loss: 0.08808  loss_cls: 0.01101  loss_box_reg: 0.0268  loss_mask: 0.04977  loss_rpn_cls: 0.0003024  loss_rpn_loc: 0.004266  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:23] d2.utils.events INFO:  eta: 0:33:43  iter: 67079  total_loss: 0.06859  loss_cls: 0.01344  loss_box_reg: 0.02342  loss_mask: 0.04176  loss_rpn_cls: 0.0003376  loss_rpn_loc: 0.002587  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:24] d2.utils.events INFO:  eta: 0:33:41  iter: 67099  total_loss: 0.09999  loss_cls: 0.01498  loss_box_reg: 0.02724  loss_mask: 0.04663  loss_rpn_cls: 0.0002741  loss_rpn_loc: 0.003735  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:26] d2.utils.events INFO:  eta: 0:33:40  iter: 67119  total_loss: 0.09031  loss_cls: 0.01133  loss_box_reg: 0.02923  loss_mask: 0.04556  loss_rpn_cls: 0.0005925  loss_rpn_loc: 0.002791  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:28] d2.utils.events INFO:  eta: 0:33:38  iter: 67139  total_loss: 0.07477  loss_cls: 0.01262  loss_box_reg: 0.02591  loss_mask: 0.03831  loss_rpn_cls: 9.214e-05  loss_rpn_loc: 0.001711  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:30] d2.utils.events INFO:  eta: 0:33:41  iter: 67159  total_loss: 0.1105  loss_cls: 0.01731  loss_box_reg: 0.03329  loss_mask: 0.05217  loss_rpn_cls: 0.0005852  loss_rpn_loc: 0.005424  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:31] d2.utils.events INFO:  eta: 0:33:38  iter: 67179  total_loss: 0.08867  loss_cls: 0.01147  loss_box_reg: 0.02459  loss_mask: 0.04491  loss_rpn_cls: 0.0001941  loss_rpn_loc: 0.003789  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:33] d2.utils.events INFO:  eta: 0:33:33  iter: 67199  total_loss: 0.1046  loss_cls: 0.01268  loss_box_reg: 0.0299  loss_mask: 0.05378  loss_rpn_cls: 0.0002645  loss_rpn_loc: 0.004015  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:35] d2.utils.events INFO:  eta: 0:33:29  iter: 67219  total_loss: 0.09156  loss_cls: 0.01204  loss_box_reg: 0.02534  loss_mask: 0.03791  loss_rpn_cls: 0.0002262  loss_rpn_loc: 0.002761  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:37] d2.utils.events INFO:  eta: 0:33:31  iter: 67239  total_loss: 0.1104  loss_cls: 0.01426  loss_box_reg: 0.03075  loss_mask: 0.04778  loss_rpn_cls: 0.0002115  loss_rpn_loc: 0.003313  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:38] d2.utils.events INFO:  eta: 0:33:28  iter: 67259  total_loss: 0.06695  loss_cls: 0.01027  loss_box_reg: 0.01771  loss_mask: 0.03403  loss_rpn_cls: 0.0004788  loss_rpn_loc: 0.00333  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:40] d2.utils.events INFO:  eta: 0:33:25  iter: 67279  total_loss: 0.09034  loss_cls: 0.01517  loss_box_reg: 0.02252  loss_mask: 0.04841  loss_rpn_cls: 0.0002512  loss_rpn_loc: 0.003593  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:42] d2.utils.events INFO:  eta: 0:33:25  iter: 67299  total_loss: 0.0686  loss_cls: 0.008195  loss_box_reg: 0.0205  loss_mask: 0.04009  loss_rpn_cls: 0.000206  loss_rpn_loc: 0.003017  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:44] d2.utils.events INFO:  eta: 0:33:26  iter: 67319  total_loss: 0.08797  loss_cls: 0.0109  loss_box_reg: 0.02672  loss_mask: 0.04826  loss_rpn_cls: 0.0002074  loss_rpn_loc: 0.002602  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:46] d2.utils.events INFO:  eta: 0:33:27  iter: 67339  total_loss: 0.09497  loss_cls: 0.0148  loss_box_reg: 0.03801  loss_mask: 0.0419  loss_rpn_cls: 0.000373  loss_rpn_loc: 0.006813  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:47] d2.utils.events INFO:  eta: 0:33:27  iter: 67359  total_loss: 0.09678  loss_cls: 0.01348  loss_box_reg: 0.03282  loss_mask: 0.04905  loss_rpn_cls: 0.0005168  loss_rpn_loc: 0.00378  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:49] d2.utils.events INFO:  eta: 0:33:24  iter: 67379  total_loss: 0.09497  loss_cls: 0.0137  loss_box_reg: 0.02778  loss_mask: 0.04138  loss_rpn_cls: 0.000261  loss_rpn_loc: 0.003747  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:16:51] d2.utils.events INFO:  eta: 0:33:25  iter: 67399  total_loss: 0.09361  loss_cls: 0.01416  loss_box_reg: 0.02926  loss_mask: 0.04302  loss_rpn_cls: 0.0002634  loss_rpn_loc: 0.004348  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:53] d2.utils.events INFO:  eta: 0:33:22  iter: 67419  total_loss: 0.06873  loss_cls: 0.01043  loss_box_reg: 0.02324  loss_mask: 0.03887  loss_rpn_cls: 0.0001638  loss_rpn_loc: 0.002792  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:55] d2.utils.events INFO:  eta: 0:33:21  iter: 67439  total_loss: 0.09378  loss_cls: 0.0093  loss_box_reg: 0.02382  loss_mask: 0.05179  loss_rpn_cls: 0.0001894  loss_rpn_loc: 0.002976  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:56] d2.utils.events INFO:  eta: 0:33:20  iter: 67459  total_loss: 0.06876  loss_cls: 0.01096  loss_box_reg: 0.02383  loss_mask: 0.03533  loss_rpn_cls: 0.0002621  loss_rpn_loc: 0.003447  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:16:58] d2.utils.events INFO:  eta: 0:33:18  iter: 67479  total_loss: 0.09299  loss_cls: 0.01249  loss_box_reg: 0.03523  loss_mask: 0.03778  loss_rpn_cls: 0.0006666  loss_rpn_loc: 0.003988  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:00] d2.utils.events INFO:  eta: 0:33:19  iter: 67499  total_loss: 0.1055  loss_cls: 0.01986  loss_box_reg: 0.03671  loss_mask: 0.04967  loss_rpn_cls: 0.0005352  loss_rpn_loc: 0.004509  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:02] d2.utils.events INFO:  eta: 0:33:16  iter: 67519  total_loss: 0.08292  loss_cls: 0.01087  loss_box_reg: 0.02698  loss_mask: 0.04127  loss_rpn_cls: 0.0004069  loss_rpn_loc: 0.004195  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:04] d2.utils.events INFO:  eta: 0:33:17  iter: 67539  total_loss: 0.1025  loss_cls: 0.01571  loss_box_reg: 0.03584  loss_mask: 0.04857  loss_rpn_cls: 0.000453  loss_rpn_loc: 0.008168  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:05] d2.utils.events INFO:  eta: 0:33:16  iter: 67559  total_loss: 0.08814  loss_cls: 0.01299  loss_box_reg: 0.02193  loss_mask: 0.05404  loss_rpn_cls: 0.000234  loss_rpn_loc: 0.003575  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:07] d2.utils.events INFO:  eta: 0:33:14  iter: 67579  total_loss: 0.09378  loss_cls: 0.01714  loss_box_reg: 0.02805  loss_mask: 0.05169  loss_rpn_cls: 0.0004928  loss_rpn_loc: 0.004535  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:09] d2.utils.events INFO:  eta: 0:33:11  iter: 67599  total_loss: 0.07159  loss_cls: 0.0079  loss_box_reg: 0.02626  loss_mask: 0.03639  loss_rpn_cls: 0.0001842  loss_rpn_loc: 0.002372  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:11] d2.utils.events INFO:  eta: 0:33:08  iter: 67619  total_loss: 0.1138  loss_cls: 0.01566  loss_box_reg: 0.04054  loss_mask: 0.04986  loss_rpn_cls: 0.0005615  loss_rpn_loc: 0.004805  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:13] d2.utils.events INFO:  eta: 0:33:08  iter: 67639  total_loss: 0.1122  loss_cls: 0.01491  loss_box_reg: 0.03683  loss_mask: 0.05555  loss_rpn_cls: 0.0002098  loss_rpn_loc: 0.002867  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:14] d2.utils.events INFO:  eta: 0:33:05  iter: 67659  total_loss: 0.08101  loss_cls: 0.00734  loss_box_reg: 0.02401  loss_mask: 0.03946  loss_rpn_cls: 6.572e-05  loss_rpn_loc: 0.001829  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:16] d2.utils.events INFO:  eta: 0:33:02  iter: 67679  total_loss: 0.08937  loss_cls: 0.01067  loss_box_reg: 0.02859  loss_mask: 0.04337  loss_rpn_cls: 0.0001418  loss_rpn_loc: 0.003173  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:18] d2.utils.events INFO:  eta: 0:33:00  iter: 67699  total_loss: 0.08599  loss_cls: 0.01285  loss_box_reg: 0.02556  loss_mask: 0.04318  loss_rpn_cls: 0.0003545  loss_rpn_loc: 0.00429  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:20] d2.utils.events INFO:  eta: 0:33:01  iter: 67719  total_loss: 0.08794  loss_cls: 0.01341  loss_box_reg: 0.02767  loss_mask: 0.04789  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.002659  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:21] d2.utils.events INFO:  eta: 0:32:56  iter: 67739  total_loss: 0.08539  loss_cls: 0.01045  loss_box_reg: 0.02473  loss_mask: 0.04653  loss_rpn_cls: 0.0001613  loss_rpn_loc: 0.00261  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:23] d2.utils.events INFO:  eta: 0:32:54  iter: 67759  total_loss: 0.0643  loss_cls: 0.007153  loss_box_reg: 0.01585  loss_mask: 0.03553  loss_rpn_cls: 0.0001833  loss_rpn_loc: 0.001772  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:25] d2.utils.events INFO:  eta: 0:32:53  iter: 67779  total_loss: 0.07536  loss_cls: 0.01242  loss_box_reg: 0.0215  loss_mask: 0.04726  loss_rpn_cls: 0.0003069  loss_rpn_loc: 0.001929  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:27] d2.utils.events INFO:  eta: 0:32:54  iter: 67799  total_loss: 0.08129  loss_cls: 0.01061  loss_box_reg: 0.02564  loss_mask: 0.04597  loss_rpn_cls: 0.0002049  loss_rpn_loc: 0.002802  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:28] d2.utils.events INFO:  eta: 0:32:48  iter: 67819  total_loss: 0.07904  loss_cls: 0.01384  loss_box_reg: 0.02303  loss_mask: 0.03564  loss_rpn_cls: 0.0002847  loss_rpn_loc: 0.004448  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:30] d2.utils.events INFO:  eta: 0:32:47  iter: 67839  total_loss: 0.08604  loss_cls: 0.01063  loss_box_reg: 0.02672  loss_mask: 0.04285  loss_rpn_cls: 0.0002619  loss_rpn_loc: 0.003525  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:32] d2.utils.events INFO:  eta: 0:32:44  iter: 67859  total_loss: 0.07064  loss_cls: 0.009542  loss_box_reg: 0.02051  loss_mask: 0.03989  loss_rpn_cls: 0.0002351  loss_rpn_loc: 0.00232  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:34] d2.utils.events INFO:  eta: 0:32:42  iter: 67879  total_loss: 0.09186  loss_cls: 0.01436  loss_box_reg: 0.03183  loss_mask: 0.04184  loss_rpn_cls: 0.0002047  loss_rpn_loc: 0.004308  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:35] d2.utils.events INFO:  eta: 0:32:39  iter: 67899  total_loss: 0.1045  loss_cls: 0.01587  loss_box_reg: 0.03164  loss_mask: 0.04964  loss_rpn_cls: 0.0003533  loss_rpn_loc: 0.004665  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:37] d2.utils.events INFO:  eta: 0:32:39  iter: 67919  total_loss: 0.09097  loss_cls: 0.01322  loss_box_reg: 0.03171  loss_mask: 0.04145  loss_rpn_cls: 0.0003638  loss_rpn_loc: 0.003447  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:39] d2.utils.events INFO:  eta: 0:32:39  iter: 67939  total_loss: 0.114  loss_cls: 0.01471  loss_box_reg: 0.04193  loss_mask: 0.05851  loss_rpn_cls: 0.000329  loss_rpn_loc: 0.005798  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:41] d2.utils.events INFO:  eta: 0:32:37  iter: 67959  total_loss: 0.0781  loss_cls: 0.008369  loss_box_reg: 0.02045  loss_mask: 0.04092  loss_rpn_cls: 0.0002373  loss_rpn_loc: 0.002127  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:43] d2.utils.events INFO:  eta: 0:32:36  iter: 67979  total_loss: 0.06838  loss_cls: 0.01195  loss_box_reg: 0.0177  loss_mask: 0.03888  loss_rpn_cls: 0.0002193  loss_rpn_loc: 0.002826  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:44] d2.utils.events INFO:  eta: 0:32:36  iter: 67999  total_loss: 0.1146  loss_cls: 0.01957  loss_box_reg: 0.03416  loss_mask: 0.05835  loss_rpn_cls: 0.0002564  loss_rpn_loc: 0.003665  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:46] d2.utils.events INFO:  eta: 0:32:32  iter: 68019  total_loss: 0.088  loss_cls: 0.01235  loss_box_reg: 0.02168  loss_mask: 0.04458  loss_rpn_cls: 0.0002847  loss_rpn_loc: 0.003675  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:48] d2.utils.events INFO:  eta: 0:32:32  iter: 68039  total_loss: 0.1108  loss_cls: 0.01299  loss_box_reg: 0.03751  loss_mask: 0.06012  loss_rpn_cls: 0.0002712  loss_rpn_loc: 0.005392  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:17:50] d2.utils.events INFO:  eta: 0:32:34  iter: 68059  total_loss: 0.1023  loss_cls: 0.01619  loss_box_reg: 0.03254  loss_mask: 0.0539  loss_rpn_cls: 0.0002674  loss_rpn_loc: 0.003903  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:51] d2.utils.events INFO:  eta: 0:32:30  iter: 68079  total_loss: 0.07847  loss_cls: 0.01106  loss_box_reg: 0.02231  loss_mask: 0.0437  loss_rpn_cls: 0.00024  loss_rpn_loc: 0.002917  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:17:53] d2.utils.events INFO:  eta: 0:32:28  iter: 68099  total_loss: 0.07463  loss_cls: 0.012  loss_box_reg: 0.02242  loss_mask: 0.04137  loss_rpn_cls: 0.0002037  loss_rpn_loc: 0.00379  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:17:55] d2.utils.events INFO:  eta: 0:32:26  iter: 68119  total_loss: 0.07559  loss_cls: 0.01257  loss_box_reg: 0.02207  loss_mask: 0.03871  loss_rpn_cls: 0.0002224  loss_rpn_loc: 0.003322  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:57] d2.utils.events INFO:  eta: 0:32:23  iter: 68139  total_loss: 0.08627  loss_cls: 0.01365  loss_box_reg: 0.02358  loss_mask: 0.04692  loss_rpn_cls: 0.0002935  loss_rpn_loc: 0.002516  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:17:58] d2.utils.events INFO:  eta: 0:32:23  iter: 68159  total_loss: 0.103  loss_cls: 0.01416  loss_box_reg: 0.03758  loss_mask: 0.05486  loss_rpn_cls: 0.0003378  loss_rpn_loc: 0.00687  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:00] d2.utils.events INFO:  eta: 0:32:27  iter: 68179  total_loss: 0.09286  loss_cls: 0.01129  loss_box_reg: 0.03124  loss_mask: 0.04882  loss_rpn_cls: 0.0002638  loss_rpn_loc: 0.004412  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:02] d2.utils.events INFO:  eta: 0:32:26  iter: 68199  total_loss: 0.07967  loss_cls: 0.009087  loss_box_reg: 0.02876  loss_mask: 0.04266  loss_rpn_cls: 0.0002491  loss_rpn_loc: 0.002457  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:04] d2.utils.events INFO:  eta: 0:32:24  iter: 68219  total_loss: 0.07828  loss_cls: 0.009057  loss_box_reg: 0.02328  loss_mask: 0.04187  loss_rpn_cls: 0.000455  loss_rpn_loc: 0.003573  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:06] d2.utils.events INFO:  eta: 0:32:22  iter: 68239  total_loss: 0.1015  loss_cls: 0.01548  loss_box_reg: 0.02811  loss_mask: 0.05444  loss_rpn_cls: 0.0002012  loss_rpn_loc: 0.002703  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:07] d2.utils.events INFO:  eta: 0:32:20  iter: 68259  total_loss: 0.08574  loss_cls: 0.009236  loss_box_reg: 0.02477  loss_mask: 0.04251  loss_rpn_cls: 0.0002217  loss_rpn_loc: 0.003484  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:09] d2.utils.events INFO:  eta: 0:32:19  iter: 68279  total_loss: 0.08276  loss_cls: 0.01283  loss_box_reg: 0.02393  loss_mask: 0.04767  loss_rpn_cls: 0.0003527  loss_rpn_loc: 0.00398  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:11] d2.utils.events INFO:  eta: 0:32:20  iter: 68299  total_loss: 0.1215  loss_cls: 0.01603  loss_box_reg: 0.03718  loss_mask: 0.05744  loss_rpn_cls: 0.0003696  loss_rpn_loc: 0.003424  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:13] d2.utils.events INFO:  eta: 0:32:13  iter: 68319  total_loss: 0.06587  loss_cls: 0.01165  loss_box_reg: 0.01626  loss_mask: 0.03513  loss_rpn_cls: 0.0002885  loss_rpn_loc: 0.001795  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:14] d2.utils.events INFO:  eta: 0:32:04  iter: 68339  total_loss: 0.09697  loss_cls: 0.009576  loss_box_reg: 0.02444  loss_mask: 0.04679  loss_rpn_cls: 0.0002856  loss_rpn_loc: 0.002856  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:16] d2.utils.events INFO:  eta: 0:32:02  iter: 68359  total_loss: 0.09941  loss_cls: 0.01733  loss_box_reg: 0.03416  loss_mask: 0.05639  loss_rpn_cls: 0.0004151  loss_rpn_loc: 0.006421  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:18] d2.utils.events INFO:  eta: 0:32:00  iter: 68379  total_loss: 0.08378  loss_cls: 0.009793  loss_box_reg: 0.02121  loss_mask: 0.04819  loss_rpn_cls: 0.0002818  loss_rpn_loc: 0.004567  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:20] d2.utils.events INFO:  eta: 0:31:57  iter: 68399  total_loss: 0.1032  loss_cls: 0.01522  loss_box_reg: 0.03478  loss_mask: 0.05679  loss_rpn_cls: 0.0002886  loss_rpn_loc: 0.004041  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:21] d2.utils.events INFO:  eta: 0:31:56  iter: 68419  total_loss: 0.09545  loss_cls: 0.01244  loss_box_reg: 0.026  loss_mask: 0.04872  loss_rpn_cls: 0.000201  loss_rpn_loc: 0.003372  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:23] d2.utils.events INFO:  eta: 0:31:54  iter: 68439  total_loss: 0.1029  loss_cls: 0.0135  loss_box_reg: 0.03455  loss_mask: 0.04882  loss_rpn_cls: 0.0007187  loss_rpn_loc: 0.003939  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:25] d2.utils.events INFO:  eta: 0:31:52  iter: 68459  total_loss: 0.09508  loss_cls: 0.01276  loss_box_reg: 0.02597  loss_mask: 0.05477  loss_rpn_cls: 0.0003664  loss_rpn_loc: 0.002913  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:27] d2.utils.events INFO:  eta: 0:31:50  iter: 68479  total_loss: 0.0898  loss_cls: 0.01338  loss_box_reg: 0.03134  loss_mask: 0.03305  loss_rpn_cls: 0.0001924  loss_rpn_loc: 0.003307  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:29] d2.utils.events INFO:  eta: 0:31:45  iter: 68499  total_loss: 0.07043  loss_cls: 0.00791  loss_box_reg: 0.02018  loss_mask: 0.04149  loss_rpn_cls: 0.0001992  loss_rpn_loc: 0.002845  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:30] d2.utils.events INFO:  eta: 0:31:43  iter: 68519  total_loss: 0.1088  loss_cls: 0.01899  loss_box_reg: 0.03826  loss_mask: 0.04594  loss_rpn_cls: 0.0003318  loss_rpn_loc: 0.003965  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:32] d2.utils.events INFO:  eta: 0:31:43  iter: 68539  total_loss: 0.08205  loss_cls: 0.01115  loss_box_reg: 0.02828  loss_mask: 0.04427  loss_rpn_cls: 0.000227  loss_rpn_loc: 0.003141  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:34] d2.utils.events INFO:  eta: 0:31:41  iter: 68559  total_loss: 0.08429  loss_cls: 0.009715  loss_box_reg: 0.02261  loss_mask: 0.04456  loss_rpn_cls: 0.0002601  loss_rpn_loc: 0.002689  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:36] d2.utils.events INFO:  eta: 0:31:40  iter: 68579  total_loss: 0.06457  loss_cls: 0.009135  loss_box_reg: 0.01933  loss_mask: 0.04042  loss_rpn_cls: 0.0001811  loss_rpn_loc: 0.003176  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:37] d2.utils.events INFO:  eta: 0:31:39  iter: 68599  total_loss: 0.06832  loss_cls: 0.007815  loss_box_reg: 0.01789  loss_mask: 0.03736  loss_rpn_cls: 0.0001774  loss_rpn_loc: 0.001671  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:39] d2.utils.events INFO:  eta: 0:31:36  iter: 68619  total_loss: 0.08712  loss_cls: 0.01203  loss_box_reg: 0.02562  loss_mask: 0.04392  loss_rpn_cls: 0.0002052  loss_rpn_loc: 0.00328  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:41] d2.utils.events INFO:  eta: 0:31:34  iter: 68639  total_loss: 0.086  loss_cls: 0.0152  loss_box_reg: 0.02606  loss_mask: 0.04462  loss_rpn_cls: 0.0002242  loss_rpn_loc: 0.00321  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:43] d2.utils.events INFO:  eta: 0:31:31  iter: 68659  total_loss: 0.0658  loss_cls: 0.007378  loss_box_reg: 0.01582  loss_mask: 0.04135  loss_rpn_cls: 0.0002543  loss_rpn_loc: 0.001998  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:18:44] d2.utils.events INFO:  eta: 0:31:29  iter: 68679  total_loss: 0.09648  loss_cls: 0.01665  loss_box_reg: 0.02555  loss_mask: 0.04736  loss_rpn_cls: 0.00041  loss_rpn_loc: 0.005574  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:18:46] d2.utils.events INFO:  eta: 0:31:25  iter: 68699  total_loss: 0.08188  loss_cls: 0.009989  loss_box_reg: 0.02551  loss_mask: 0.04201  loss_rpn_cls: 0.0003065  loss_rpn_loc: 0.00288  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:18:48] d2.utils.events INFO:  eta: 0:31:17  iter: 68719  total_loss: 0.06493  loss_cls: 0.008702  loss_box_reg: 0.018  loss_mask: 0.03404  loss_rpn_cls: 0.0001976  loss_rpn_loc: 0.001755  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:50] d2.utils.events INFO:  eta: 0:31:17  iter: 68739  total_loss: 0.103  loss_cls: 0.01113  loss_box_reg: 0.03019  loss_mask: 0.05023  loss_rpn_cls: 0.0002962  loss_rpn_loc: 0.003849  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:51] d2.utils.events INFO:  eta: 0:31:17  iter: 68759  total_loss: 0.08461  loss_cls: 0.01028  loss_box_reg: 0.02185  loss_mask: 0.04314  loss_rpn_cls: 0.0002283  loss_rpn_loc: 0.004475  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:53] d2.utils.events INFO:  eta: 0:31:16  iter: 68779  total_loss: 0.09537  loss_cls: 0.0133  loss_box_reg: 0.03281  loss_mask: 0.04631  loss_rpn_cls: 0.0004142  loss_rpn_loc: 0.004392  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:18:55] d2.utils.events INFO:  eta: 0:31:13  iter: 68799  total_loss: 0.07075  loss_cls: 0.008365  loss_box_reg: 0.02047  loss_mask: 0.03098  loss_rpn_cls: 0.0002065  loss_rpn_loc: 0.002231  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:18:57] d2.utils.events INFO:  eta: 0:31:12  iter: 68819  total_loss: 0.07927  loss_cls: 0.01051  loss_box_reg: 0.0282  loss_mask: 0.05046  loss_rpn_cls: 0.0002973  loss_rpn_loc: 0.003295  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:18:58] d2.utils.events INFO:  eta: 0:31:14  iter: 68839  total_loss: 0.08772  loss_cls: 0.01127  loss_box_reg: 0.02547  loss_mask: 0.05069  loss_rpn_cls: 0.0003065  loss_rpn_loc: 0.00332  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:00] d2.utils.events INFO:  eta: 0:31:14  iter: 68859  total_loss: 0.09369  loss_cls: 0.01295  loss_box_reg: 0.02771  loss_mask: 0.04949  loss_rpn_cls: 0.0001787  loss_rpn_loc: 0.003178  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:02] d2.utils.events INFO:  eta: 0:31:13  iter: 68879  total_loss: 0.1182  loss_cls: 0.01702  loss_box_reg: 0.03815  loss_mask: 0.04616  loss_rpn_cls: 0.0003918  loss_rpn_loc: 0.006591  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:04] d2.utils.events INFO:  eta: 0:31:12  iter: 68899  total_loss: 0.05905  loss_cls: 0.008652  loss_box_reg: 0.02104  loss_mask: 0.03587  loss_rpn_cls: 0.0001385  loss_rpn_loc: 0.001708  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:06] d2.utils.events INFO:  eta: 0:31:10  iter: 68919  total_loss: 0.1097  loss_cls: 0.01412  loss_box_reg: 0.03273  loss_mask: 0.0449  loss_rpn_cls: 0.0002948  loss_rpn_loc: 0.004903  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:08] d2.utils.events INFO:  eta: 0:31:07  iter: 68939  total_loss: 0.08275  loss_cls: 0.01598  loss_box_reg: 0.02729  loss_mask: 0.04619  loss_rpn_cls: 0.000382  loss_rpn_loc: 0.004253  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:09] d2.utils.events INFO:  eta: 0:31:06  iter: 68959  total_loss: 0.1292  loss_cls: 0.02037  loss_box_reg: 0.04212  loss_mask: 0.07156  loss_rpn_cls: 0.0002428  loss_rpn_loc: 0.004985  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:11] d2.utils.events INFO:  eta: 0:31:05  iter: 68979  total_loss: 0.08979  loss_cls: 0.01592  loss_box_reg: 0.0236  loss_mask: 0.0491  loss_rpn_cls: 0.000303  loss_rpn_loc: 0.004655  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:13] d2.utils.events INFO:  eta: 0:31:02  iter: 68999  total_loss: 0.06786  loss_cls: 0.007956  loss_box_reg: 0.01498  loss_mask: 0.0412  loss_rpn_cls: 0.0001002  loss_rpn_loc: 0.001922  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:15] d2.utils.events INFO:  eta: 0:31:00  iter: 69019  total_loss: 0.08713  loss_cls: 0.01092  loss_box_reg: 0.0244  loss_mask: 0.04592  loss_rpn_cls: 0.0002621  loss_rpn_loc: 0.003242  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:16] d2.utils.events INFO:  eta: 0:30:57  iter: 69039  total_loss: 0.07929  loss_cls: 0.009011  loss_box_reg: 0.02293  loss_mask: 0.0481  loss_rpn_cls: 0.0002586  loss_rpn_loc: 0.00365  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:18] d2.utils.events INFO:  eta: 0:30:51  iter: 69059  total_loss: 0.08374  loss_cls: 0.01353  loss_box_reg: 0.0264  loss_mask: 0.04445  loss_rpn_cls: 0.0004702  loss_rpn_loc: 0.003653  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:20] d2.utils.events INFO:  eta: 0:30:50  iter: 69079  total_loss: 0.1011  loss_cls: 0.0129  loss_box_reg: 0.02587  loss_mask: 0.04997  loss_rpn_cls: 0.0003247  loss_rpn_loc: 0.003398  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:22] d2.utils.events INFO:  eta: 0:30:47  iter: 69099  total_loss: 0.07715  loss_cls: 0.008654  loss_box_reg: 0.01808  loss_mask: 0.04057  loss_rpn_cls: 0.0002224  loss_rpn_loc: 0.003197  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:23] d2.utils.events INFO:  eta: 0:30:46  iter: 69119  total_loss: 0.07437  loss_cls: 0.00987  loss_box_reg: 0.02396  loss_mask: 0.0346  loss_rpn_cls: 0.0001874  loss_rpn_loc: 0.002132  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:25] d2.utils.events INFO:  eta: 0:30:45  iter: 69139  total_loss: 0.09105  loss_cls: 0.01181  loss_box_reg: 0.02925  loss_mask: 0.04291  loss_rpn_cls: 0.0002981  loss_rpn_loc: 0.004949  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:27] d2.utils.events INFO:  eta: 0:30:41  iter: 69159  total_loss: 0.07996  loss_cls: 0.01092  loss_box_reg: 0.02427  loss_mask: 0.04256  loss_rpn_cls: 0.0003097  loss_rpn_loc: 0.003352  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:29] d2.utils.events INFO:  eta: 0:30:43  iter: 69179  total_loss: 0.1357  loss_cls: 0.01686  loss_box_reg: 0.04319  loss_mask: 0.06357  loss_rpn_cls: 0.0004927  loss_rpn_loc: 0.006634  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:30] d2.utils.events INFO:  eta: 0:30:41  iter: 69199  total_loss: 0.1033  loss_cls: 0.01447  loss_box_reg: 0.03702  loss_mask: 0.05132  loss_rpn_cls: 0.0001847  loss_rpn_loc: 0.004501  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:32] d2.utils.events INFO:  eta: 0:30:38  iter: 69219  total_loss: 0.08074  loss_cls: 0.008995  loss_box_reg: 0.02119  loss_mask: 0.04123  loss_rpn_cls: 0.0001468  loss_rpn_loc: 0.001995  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:34] d2.utils.events INFO:  eta: 0:30:39  iter: 69239  total_loss: 0.1082  loss_cls: 0.01451  loss_box_reg: 0.03863  loss_mask: 0.05297  loss_rpn_cls: 0.0001761  loss_rpn_loc: 0.002691  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:36] d2.utils.events INFO:  eta: 0:30:37  iter: 69259  total_loss: 0.09906  loss_cls: 0.01597  loss_box_reg: 0.02944  loss_mask: 0.05187  loss_rpn_cls: 0.0003611  loss_rpn_loc: 0.003783  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:38] d2.utils.events INFO:  eta: 0:30:35  iter: 69279  total_loss: 0.06931  loss_cls: 0.01068  loss_box_reg: 0.0179  loss_mask: 0.04117  loss_rpn_cls: 0.0002211  loss_rpn_loc: 0.002098  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:39] d2.utils.events INFO:  eta: 0:30:33  iter: 69299  total_loss: 0.0842  loss_cls: 0.009359  loss_box_reg: 0.02586  loss_mask: 0.04736  loss_rpn_cls: 0.0002216  loss_rpn_loc: 0.002862  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:41] d2.utils.events INFO:  eta: 0:30:33  iter: 69319  total_loss: 0.08288  loss_cls: 0.008139  loss_box_reg: 0.01884  loss_mask: 0.04282  loss_rpn_cls: 0.000132  loss_rpn_loc: 0.001827  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:43] d2.utils.events INFO:  eta: 0:30:35  iter: 69339  total_loss: 0.09632  loss_cls: 0.0115  loss_box_reg: 0.03778  loss_mask: 0.04687  loss_rpn_cls: 0.0004059  loss_rpn_loc: 0.004166  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:45] d2.utils.events INFO:  eta: 0:30:34  iter: 69359  total_loss: 0.0949  loss_cls: 0.01005  loss_box_reg: 0.02184  loss_mask: 0.0504  loss_rpn_cls: 0.0002605  loss_rpn_loc: 0.003373  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:46] d2.utils.events INFO:  eta: 0:30:33  iter: 69379  total_loss: 0.07564  loss_cls: 0.009793  loss_box_reg: 0.02817  loss_mask: 0.04056  loss_rpn_cls: 0.0005166  loss_rpn_loc: 0.002894  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:48] d2.utils.events INFO:  eta: 0:30:29  iter: 69399  total_loss: 0.08729  loss_cls: 0.01321  loss_box_reg: 0.02671  loss_mask: 0.04133  loss_rpn_cls: 0.0002339  loss_rpn_loc: 0.005165  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:50] d2.utils.events INFO:  eta: 0:30:27  iter: 69419  total_loss: 0.09319  loss_cls: 0.01203  loss_box_reg: 0.0297  loss_mask: 0.04246  loss_rpn_cls: 0.0002222  loss_rpn_loc: 0.003594  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:52] d2.utils.events INFO:  eta: 0:30:28  iter: 69439  total_loss: 0.1069  loss_cls: 0.01648  loss_box_reg: 0.03872  loss_mask: 0.05134  loss_rpn_cls: 0.0006201  loss_rpn_loc: 0.006341  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:54] d2.utils.events INFO:  eta: 0:30:28  iter: 69459  total_loss: 0.117  loss_cls: 0.01678  loss_box_reg: 0.03035  loss_mask: 0.05596  loss_rpn_cls: 0.0003643  loss_rpn_loc: 0.006271  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:19:55] d2.utils.events INFO:  eta: 0:30:28  iter: 69479  total_loss: 0.08159  loss_cls: 0.01171  loss_box_reg: 0.02766  loss_mask: 0.04629  loss_rpn_cls: 0.0001672  loss_rpn_loc: 0.003022  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:19:57] d2.utils.events INFO:  eta: 0:30:26  iter: 69499  total_loss: 0.06823  loss_cls: 0.007821  loss_box_reg: 0.01989  loss_mask: 0.03685  loss_rpn_cls: 0.0001878  loss_rpn_loc: 0.002187  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:19:59] d2.utils.events INFO:  eta: 0:30:21  iter: 69519  total_loss: 0.07174  loss_cls: 0.01211  loss_box_reg: 0.02293  loss_mask: 0.03846  loss_rpn_cls: 0.0001763  loss_rpn_loc: 0.002158  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:20:01] d2.utils.events INFO:  eta: 0:30:14  iter: 69539  total_loss: 0.08673  loss_cls: 0.01153  loss_box_reg: 0.02075  loss_mask: 0.05074  loss_rpn_cls: 0.0001398  loss_rpn_loc: 0.002651  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:02] d2.utils.events INFO:  eta: 0:30:11  iter: 69559  total_loss: 0.07331  loss_cls: 0.01143  loss_box_reg: 0.02417  loss_mask: 0.03776  loss_rpn_cls: 0.0001912  loss_rpn_loc: 0.00419  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:04] d2.utils.events INFO:  eta: 0:30:11  iter: 69579  total_loss: 0.104  loss_cls: 0.01149  loss_box_reg: 0.02947  loss_mask: 0.05748  loss_rpn_cls: 0.0003629  loss_rpn_loc: 0.004113  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:06] d2.utils.events INFO:  eta: 0:30:07  iter: 69599  total_loss: 0.05269  loss_cls: 0.006724  loss_box_reg: 0.0158  loss_mask: 0.03478  loss_rpn_cls: 0.0001639  loss_rpn_loc: 0.001749  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:20:08] d2.utils.events INFO:  eta: 0:30:05  iter: 69619  total_loss: 0.08519  loss_cls: 0.01018  loss_box_reg: 0.02365  loss_mask: 0.04395  loss_rpn_cls: 0.0001651  loss_rpn_loc: 0.002966  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:09] d2.utils.events INFO:  eta: 0:30:02  iter: 69639  total_loss: 0.0812  loss_cls: 0.01289  loss_box_reg: 0.03205  loss_mask: 0.04519  loss_rpn_cls: 0.0002031  loss_rpn_loc: 0.003666  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:11] d2.utils.events INFO:  eta: 0:30:08  iter: 69659  total_loss: 0.142  loss_cls: 0.01919  loss_box_reg: 0.04276  loss_mask: 0.06561  loss_rpn_cls: 0.0004657  loss_rpn_loc: 0.008553  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:13] d2.utils.events INFO:  eta: 0:30:06  iter: 69679  total_loss: 0.09101  loss_cls: 0.01169  loss_box_reg: 0.02638  loss_mask: 0.04653  loss_rpn_cls: 0.0002783  loss_rpn_loc: 0.002503  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:20:15] d2.utils.events INFO:  eta: 0:30:04  iter: 69699  total_loss: 0.08123  loss_cls: 0.00757  loss_box_reg: 0.02538  loss_mask: 0.04292  loss_rpn_cls: 0.0001363  loss_rpn_loc: 0.002839  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:16] d2.utils.events INFO:  eta: 0:30:08  iter: 69719  total_loss: 0.08865  loss_cls: 0.01302  loss_box_reg: 0.02471  loss_mask: 0.03844  loss_rpn_cls: 0.0001963  loss_rpn_loc: 0.003636  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:18] d2.utils.events INFO:  eta: 0:30:08  iter: 69739  total_loss: 0.06571  loss_cls: 0.009218  loss_box_reg: 0.02053  loss_mask: 0.04084  loss_rpn_cls: 0.0001882  loss_rpn_loc: 0.00269  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:20] d2.utils.events INFO:  eta: 0:30:02  iter: 69759  total_loss: 0.082  loss_cls: 0.01175  loss_box_reg: 0.02427  loss_mask: 0.04035  loss_rpn_cls: 0.0005911  loss_rpn_loc: 0.005349  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:22] d2.utils.events INFO:  eta: 0:30:00  iter: 69779  total_loss: 0.1244  loss_cls: 0.01586  loss_box_reg: 0.03788  loss_mask: 0.07481  loss_rpn_cls: 0.0002979  loss_rpn_loc: 0.005636  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:24] d2.utils.events INFO:  eta: 0:30:01  iter: 69799  total_loss: 0.08054  loss_cls: 0.01071  loss_box_reg: 0.0237  loss_mask: 0.04452  loss_rpn_cls: 0.0001605  loss_rpn_loc: 0.002666  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:25] d2.utils.events INFO:  eta: 0:30:03  iter: 69819  total_loss: 0.0821  loss_cls: 0.0119  loss_box_reg: 0.02695  loss_mask: 0.03872  loss_rpn_cls: 0.0002965  loss_rpn_loc: 0.002764  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:27] d2.utils.events INFO:  eta: 0:30:00  iter: 69839  total_loss: 0.08416  loss_cls: 0.01405  loss_box_reg: 0.02418  loss_mask: 0.04246  loss_rpn_cls: 0.0002708  loss_rpn_loc: 0.003753  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:29] d2.utils.events INFO:  eta: 0:29:58  iter: 69859  total_loss: 0.07816  loss_cls: 0.008769  loss_box_reg: 0.02433  loss_mask: 0.04211  loss_rpn_cls: 0.000348  loss_rpn_loc: 0.004005  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:31] d2.utils.events INFO:  eta: 0:29:57  iter: 69879  total_loss: 0.1182  loss_cls: 0.01542  loss_box_reg: 0.04014  loss_mask: 0.05549  loss_rpn_cls: 0.0003146  loss_rpn_loc: 0.005239  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:33] d2.utils.events INFO:  eta: 0:29:55  iter: 69899  total_loss: 0.08947  loss_cls: 0.009787  loss_box_reg: 0.02198  loss_mask: 0.05382  loss_rpn_cls: 0.0002676  loss_rpn_loc: 0.003665  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:35] d2.utils.events INFO:  eta: 0:29:53  iter: 69919  total_loss: 0.1066  loss_cls: 0.01378  loss_box_reg: 0.037  loss_mask: 0.05575  loss_rpn_cls: 0.0002079  loss_rpn_loc: 0.005103  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:36] d2.utils.events INFO:  eta: 0:29:50  iter: 69939  total_loss: 0.08192  loss_cls: 0.01302  loss_box_reg: 0.02176  loss_mask: 0.03805  loss_rpn_cls: 0.0002787  loss_rpn_loc: 0.002881  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:38] d2.utils.events INFO:  eta: 0:29:42  iter: 69959  total_loss: 0.08346  loss_cls: 0.01112  loss_box_reg: 0.02586  loss_mask: 0.04511  loss_rpn_cls: 0.0001899  loss_rpn_loc: 0.002113  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:40] d2.utils.events INFO:  eta: 0:29:39  iter: 69979  total_loss: 0.07545  loss_cls: 0.008314  loss_box_reg: 0.02342  loss_mask: 0.04521  loss_rpn_cls: 0.0002398  loss_rpn_loc: 0.002576  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:42] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0069999.pth
[10/27 20:20:42] d2.utils.events INFO:  eta: 0:29:46  iter: 69999  total_loss: 0.09688  loss_cls: 0.01614  loss_box_reg: 0.03915  loss_mask: 0.03551  loss_rpn_cls: 0.0004243  loss_rpn_loc: 0.004804  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:44] d2.utils.events INFO:  eta: 0:29:45  iter: 70019  total_loss: 0.07151  loss_cls: 0.005645  loss_box_reg: 0.02038  loss_mask: 0.04165  loss_rpn_cls: 0.0001285  loss_rpn_loc: 0.001694  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:20:46] d2.utils.events INFO:  eta: 0:29:45  iter: 70039  total_loss: 0.101  loss_cls: 0.01102  loss_box_reg: 0.02971  loss_mask: 0.05105  loss_rpn_cls: 0.0003699  loss_rpn_loc: 0.004089  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:47] d2.utils.events INFO:  eta: 0:29:43  iter: 70059  total_loss: 0.07761  loss_cls: 0.006672  loss_box_reg: 0.02209  loss_mask: 0.04516  loss_rpn_cls: 0.0001912  loss_rpn_loc: 0.002061  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:49] d2.utils.events INFO:  eta: 0:29:40  iter: 70079  total_loss: 0.08342  loss_cls: 0.0103  loss_box_reg: 0.02651  loss_mask: 0.04242  loss_rpn_cls: 0.0002743  loss_rpn_loc: 0.002704  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:20:51] d2.utils.events INFO:  eta: 0:29:42  iter: 70099  total_loss: 0.09445  loss_cls: 0.01211  loss_box_reg: 0.0333  loss_mask: 0.04384  loss_rpn_cls: 0.0002759  loss_rpn_loc: 0.004259  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:20:53] d2.utils.events INFO:  eta: 0:29:39  iter: 70119  total_loss: 0.07294  loss_cls: 0.01066  loss_box_reg: 0.02067  loss_mask: 0.04174  loss_rpn_cls: 0.0001757  loss_rpn_loc: 0.002379  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:54] d2.utils.events INFO:  eta: 0:29:37  iter: 70139  total_loss: 0.07526  loss_cls: 0.01192  loss_box_reg: 0.02053  loss_mask: 0.04501  loss_rpn_cls: 0.0005384  loss_rpn_loc: 0.002964  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:56] d2.utils.events INFO:  eta: 0:29:35  iter: 70159  total_loss: 0.06966  loss_cls: 0.008038  loss_box_reg: 0.01953  loss_mask: 0.03524  loss_rpn_cls: 0.000198  loss_rpn_loc: 0.00424  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:20:58] d2.utils.events INFO:  eta: 0:29:30  iter: 70179  total_loss: 0.07725  loss_cls: 0.01111  loss_box_reg: 0.02372  loss_mask: 0.04363  loss_rpn_cls: 0.0003597  loss_rpn_loc: 0.003418  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:00] d2.utils.events INFO:  eta: 0:29:30  iter: 70199  total_loss: 0.09562  loss_cls: 0.01178  loss_box_reg: 0.02893  loss_mask: 0.04739  loss_rpn_cls: 0.0002848  loss_rpn_loc: 0.004202  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:01] d2.utils.events INFO:  eta: 0:29:28  iter: 70219  total_loss: 0.08564  loss_cls: 0.009611  loss_box_reg: 0.02778  loss_mask: 0.04373  loss_rpn_cls: 0.0002703  loss_rpn_loc: 0.002386  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:03] d2.utils.events INFO:  eta: 0:29:27  iter: 70239  total_loss: 0.09193  loss_cls: 0.01273  loss_box_reg: 0.0359  loss_mask: 0.04141  loss_rpn_cls: 0.0002991  loss_rpn_loc: 0.002761  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:05] d2.utils.events INFO:  eta: 0:29:24  iter: 70259  total_loss: 0.07817  loss_cls: 0.01234  loss_box_reg: 0.02194  loss_mask: 0.0506  loss_rpn_cls: 0.0004363  loss_rpn_loc: 0.002971  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:07] d2.utils.events INFO:  eta: 0:29:17  iter: 70279  total_loss: 0.07191  loss_cls: 0.007423  loss_box_reg: 0.01862  loss_mask: 0.04435  loss_rpn_cls: 0.0002221  loss_rpn_loc: 0.00241  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:09] d2.utils.events INFO:  eta: 0:29:20  iter: 70299  total_loss: 0.105  loss_cls: 0.01691  loss_box_reg: 0.03497  loss_mask: 0.04407  loss_rpn_cls: 0.0002509  loss_rpn_loc: 0.002915  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:10] d2.utils.events INFO:  eta: 0:29:19  iter: 70319  total_loss: 0.07158  loss_cls: 0.00926  loss_box_reg: 0.0231  loss_mask: 0.04164  loss_rpn_cls: 0.0001715  loss_rpn_loc: 0.002276  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:12] d2.utils.events INFO:  eta: 0:29:16  iter: 70339  total_loss: 0.09689  loss_cls: 0.01212  loss_box_reg: 0.02684  loss_mask: 0.06004  loss_rpn_cls: 0.0003351  loss_rpn_loc: 0.005052  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:14] d2.utils.events INFO:  eta: 0:29:14  iter: 70359  total_loss: 0.08802  loss_cls: 0.0146  loss_box_reg: 0.02778  loss_mask: 0.04772  loss_rpn_cls: 0.0002894  loss_rpn_loc: 0.004002  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:16] d2.utils.events INFO:  eta: 0:29:12  iter: 70379  total_loss: 0.07584  loss_cls: 0.0109  loss_box_reg: 0.02121  loss_mask: 0.03884  loss_rpn_cls: 0.0001033  loss_rpn_loc: 0.002526  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:18] d2.utils.events INFO:  eta: 0:29:04  iter: 70399  total_loss: 0.06282  loss_cls: 0.006274  loss_box_reg: 0.01405  loss_mask: 0.03556  loss_rpn_cls: 0.0001975  loss_rpn_loc: 0.002016  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:19] d2.utils.events INFO:  eta: 0:29:06  iter: 70419  total_loss: 0.09642  loss_cls: 0.01649  loss_box_reg: 0.03013  loss_mask: 0.05182  loss_rpn_cls: 0.0002561  loss_rpn_loc: 0.003862  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:21] d2.utils.events INFO:  eta: 0:29:00  iter: 70439  total_loss: 0.1008  loss_cls: 0.01302  loss_box_reg: 0.0255  loss_mask: 0.05552  loss_rpn_cls: 0.0006438  loss_rpn_loc: 0.003264  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:23] d2.utils.events INFO:  eta: 0:28:56  iter: 70459  total_loss: 0.08761  loss_cls: 0.01276  loss_box_reg: 0.02068  loss_mask: 0.0461  loss_rpn_cls: 0.0003657  loss_rpn_loc: 0.004279  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:25] d2.utils.events INFO:  eta: 0:28:54  iter: 70479  total_loss: 0.08344  loss_cls: 0.009903  loss_box_reg: 0.02333  loss_mask: 0.04104  loss_rpn_cls: 0.0003269  loss_rpn_loc: 0.003418  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:26] d2.utils.events INFO:  eta: 0:28:52  iter: 70499  total_loss: 0.08932  loss_cls: 0.01134  loss_box_reg: 0.02216  loss_mask: 0.04446  loss_rpn_cls: 0.0002476  loss_rpn_loc: 0.002784  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:28] d2.utils.events INFO:  eta: 0:28:51  iter: 70519  total_loss: 0.07951  loss_cls: 0.01045  loss_box_reg: 0.02739  loss_mask: 0.04204  loss_rpn_cls: 0.0002835  loss_rpn_loc: 0.003104  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:30] d2.utils.events INFO:  eta: 0:28:58  iter: 70539  total_loss: 0.09236  loss_cls: 0.01434  loss_box_reg: 0.02652  loss_mask: 0.04406  loss_rpn_cls: 0.0003803  loss_rpn_loc: 0.00501  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:21:32] d2.utils.events INFO:  eta: 0:28:57  iter: 70559  total_loss: 0.1073  loss_cls: 0.0141  loss_box_reg: 0.03462  loss_mask: 0.05717  loss_rpn_cls: 0.0002603  loss_rpn_loc: 0.00548  time: 0.0877  data_time: 0.0022  lr: 0.00025  max_mem: 1494M
[10/27 20:21:34] d2.utils.events INFO:  eta: 0:28:51  iter: 70579  total_loss: 0.06361  loss_cls: 0.006761  loss_box_reg: 0.01382  loss_mask: 0.03516  loss_rpn_cls: 0.0001588  loss_rpn_loc: 0.001916  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:35] d2.utils.events INFO:  eta: 0:28:53  iter: 70599  total_loss: 0.08426  loss_cls: 0.01425  loss_box_reg: 0.02494  loss_mask: 0.03889  loss_rpn_cls: 0.0002721  loss_rpn_loc: 0.003065  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:37] d2.utils.events INFO:  eta: 0:28:52  iter: 70619  total_loss: 0.07884  loss_cls: 0.01164  loss_box_reg: 0.02315  loss_mask: 0.04306  loss_rpn_cls: 0.000259  loss_rpn_loc: 0.002596  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:39] d2.utils.events INFO:  eta: 0:28:50  iter: 70639  total_loss: 0.09443  loss_cls: 0.01789  loss_box_reg: 0.03391  loss_mask: 0.05579  loss_rpn_cls: 0.0003634  loss_rpn_loc: 0.004726  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:41] d2.utils.events INFO:  eta: 0:28:48  iter: 70659  total_loss: 0.09688  loss_cls: 0.01642  loss_box_reg: 0.0307  loss_mask: 0.04691  loss_rpn_cls: 0.0002328  loss_rpn_loc: 0.004573  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:43] d2.utils.events INFO:  eta: 0:28:45  iter: 70679  total_loss: 0.09094  loss_cls: 0.01112  loss_box_reg: 0.02616  loss_mask: 0.0424  loss_rpn_cls: 0.0003068  loss_rpn_loc: 0.003369  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:44] d2.utils.events INFO:  eta: 0:28:41  iter: 70699  total_loss: 0.06422  loss_cls: 0.01119  loss_box_reg: 0.01858  loss_mask: 0.03581  loss_rpn_cls: 0.0001989  loss_rpn_loc: 0.002627  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:46] d2.utils.events INFO:  eta: 0:28:36  iter: 70719  total_loss: 0.07547  loss_cls: 0.009763  loss_box_reg: 0.01768  loss_mask: 0.04661  loss_rpn_cls: 0.0002598  loss_rpn_loc: 0.002028  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:48] d2.utils.events INFO:  eta: 0:28:41  iter: 70739  total_loss: 0.1219  loss_cls: 0.01575  loss_box_reg: 0.03619  loss_mask: 0.05691  loss_rpn_cls: 0.000202  loss_rpn_loc: 0.003918  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:50] d2.utils.events INFO:  eta: 0:28:39  iter: 70759  total_loss: 0.07229  loss_cls: 0.008657  loss_box_reg: 0.01732  loss_mask: 0.0384  loss_rpn_cls: 0.0001446  loss_rpn_loc: 0.001142  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:51] d2.utils.events INFO:  eta: 0:28:33  iter: 70779  total_loss: 0.07832  loss_cls: 0.01039  loss_box_reg: 0.02398  loss_mask: 0.04277  loss_rpn_cls: 0.0002541  loss_rpn_loc: 0.003536  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:53] d2.utils.events INFO:  eta: 0:28:35  iter: 70799  total_loss: 0.0819  loss_cls: 0.01237  loss_box_reg: 0.02497  loss_mask: 0.04256  loss_rpn_cls: 0.0001693  loss_rpn_loc: 0.003338  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:55] d2.utils.events INFO:  eta: 0:28:28  iter: 70819  total_loss: 0.08525  loss_cls: 0.01123  loss_box_reg: 0.02717  loss_mask: 0.04708  loss_rpn_cls: 0.0002506  loss_rpn_loc: 0.002358  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:21:57] d2.utils.events INFO:  eta: 0:28:28  iter: 70839  total_loss: 0.09215  loss_cls: 0.01081  loss_box_reg: 0.02651  loss_mask: 0.04349  loss_rpn_cls: 0.0003396  loss_rpn_loc: 0.003638  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:21:58] d2.utils.events INFO:  eta: 0:28:24  iter: 70859  total_loss: 0.08967  loss_cls: 0.01499  loss_box_reg: 0.0276  loss_mask: 0.05151  loss_rpn_cls: 0.0003306  loss_rpn_loc: 0.003909  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:00] d2.utils.events INFO:  eta: 0:28:19  iter: 70879  total_loss: 0.07155  loss_cls: 0.01098  loss_box_reg: 0.02404  loss_mask: 0.03527  loss_rpn_cls: 0.0003197  loss_rpn_loc: 0.004759  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:02] d2.utils.events INFO:  eta: 0:28:18  iter: 70899  total_loss: 0.07538  loss_cls: 0.01119  loss_box_reg: 0.0201  loss_mask: 0.04068  loss_rpn_cls: 0.0001136  loss_rpn_loc: 0.002128  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:04] d2.utils.events INFO:  eta: 0:28:16  iter: 70919  total_loss: 0.09181  loss_cls: 0.009444  loss_box_reg: 0.02401  loss_mask: 0.05079  loss_rpn_cls: 0.000296  loss_rpn_loc: 0.005018  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:05] d2.utils.events INFO:  eta: 0:28:17  iter: 70939  total_loss: 0.1163  loss_cls: 0.01513  loss_box_reg: 0.04345  loss_mask: 0.05723  loss_rpn_cls: 0.0002803  loss_rpn_loc: 0.002927  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:22:07] d2.utils.events INFO:  eta: 0:28:19  iter: 70959  total_loss: 0.1043  loss_cls: 0.01436  loss_box_reg: 0.03324  loss_mask: 0.05677  loss_rpn_cls: 0.0001859  loss_rpn_loc: 0.003538  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:09] d2.utils.events INFO:  eta: 0:28:17  iter: 70979  total_loss: 0.07008  loss_cls: 0.007671  loss_box_reg: 0.02072  loss_mask: 0.03944  loss_rpn_cls: 0.0001568  loss_rpn_loc: 0.002051  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:11] d2.utils.events INFO:  eta: 0:28:10  iter: 70999  total_loss: 0.09255  loss_cls: 0.01204  loss_box_reg: 0.02427  loss_mask: 0.04559  loss_rpn_cls: 0.0001513  loss_rpn_loc: 0.002933  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:13] d2.utils.events INFO:  eta: 0:28:09  iter: 71019  total_loss: 0.08187  loss_cls: 0.009472  loss_box_reg: 0.02093  loss_mask: 0.04284  loss_rpn_cls: 0.0002877  loss_rpn_loc: 0.002536  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:14] d2.utils.events INFO:  eta: 0:28:06  iter: 71039  total_loss: 0.09067  loss_cls: 0.01112  loss_box_reg: 0.0251  loss_mask: 0.04256  loss_rpn_cls: 0.0002886  loss_rpn_loc: 0.002976  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:16] d2.utils.events INFO:  eta: 0:28:04  iter: 71059  total_loss: 0.09302  loss_cls: 0.01367  loss_box_reg: 0.02172  loss_mask: 0.04707  loss_rpn_cls: 0.000422  loss_rpn_loc: 0.004277  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:18] d2.utils.events INFO:  eta: 0:28:02  iter: 71079  total_loss: 0.0766  loss_cls: 0.01145  loss_box_reg: 0.0229  loss_mask: 0.04398  loss_rpn_cls: 0.0002907  loss_rpn_loc: 0.002887  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:20] d2.utils.events INFO:  eta: 0:27:58  iter: 71099  total_loss: 0.09053  loss_cls: 0.01451  loss_box_reg: 0.03038  loss_mask: 0.04473  loss_rpn_cls: 0.0003546  loss_rpn_loc: 0.00307  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:21] d2.utils.events INFO:  eta: 0:27:55  iter: 71119  total_loss: 0.08431  loss_cls: 0.01109  loss_box_reg: 0.02093  loss_mask: 0.0511  loss_rpn_cls: 0.0003323  loss_rpn_loc: 0.003367  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:23] d2.utils.events INFO:  eta: 0:27:54  iter: 71139  total_loss: 0.06898  loss_cls: 0.008663  loss_box_reg: 0.02314  loss_mask: 0.039  loss_rpn_cls: 0.0001672  loss_rpn_loc: 0.002631  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:25] d2.utils.events INFO:  eta: 0:27:55  iter: 71159  total_loss: 0.1067  loss_cls: 0.01116  loss_box_reg: 0.03066  loss_mask: 0.06467  loss_rpn_cls: 0.0002794  loss_rpn_loc: 0.003983  time: 0.0877  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:27] d2.utils.events INFO:  eta: 0:27:52  iter: 71179  total_loss: 0.07218  loss_cls: 0.006791  loss_box_reg: 0.01594  loss_mask: 0.04362  loss_rpn_cls: 0.0001157  loss_rpn_loc: 0.002035  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:28] d2.utils.events INFO:  eta: 0:27:47  iter: 71199  total_loss: 0.07847  loss_cls: 0.0113  loss_box_reg: 0.02955  loss_mask: 0.04025  loss_rpn_cls: 0.0003556  loss_rpn_loc: 0.003058  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:30] d2.utils.events INFO:  eta: 0:27:45  iter: 71219  total_loss: 0.09081  loss_cls: 0.01293  loss_box_reg: 0.02618  loss_mask: 0.04975  loss_rpn_cls: 0.0002443  loss_rpn_loc: 0.003045  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:32] d2.utils.events INFO:  eta: 0:27:40  iter: 71239  total_loss: 0.08386  loss_cls: 0.01102  loss_box_reg: 0.02657  loss_mask: 0.0422  loss_rpn_cls: 0.0003819  loss_rpn_loc: 0.003408  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:22:34] d2.utils.events INFO:  eta: 0:27:36  iter: 71259  total_loss: 0.06358  loss_cls: 0.004987  loss_box_reg: 0.01162  loss_mask: 0.04053  loss_rpn_cls: 9.673e-05  loss_rpn_loc: 0.001955  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:35] d2.utils.events INFO:  eta: 0:27:36  iter: 71279  total_loss: 0.07594  loss_cls: 0.007621  loss_box_reg: 0.02162  loss_mask: 0.04755  loss_rpn_cls: 8.562e-05  loss_rpn_loc: 0.002109  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:37] d2.utils.events INFO:  eta: 0:27:34  iter: 71299  total_loss: 0.1037  loss_cls: 0.02006  loss_box_reg: 0.03607  loss_mask: 0.04594  loss_rpn_cls: 0.0003212  loss_rpn_loc: 0.004969  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:39] d2.utils.events INFO:  eta: 0:27:35  iter: 71319  total_loss: 0.1077  loss_cls: 0.01734  loss_box_reg: 0.03992  loss_mask: 0.05492  loss_rpn_cls: 0.0005256  loss_rpn_loc: 0.006338  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:41] d2.utils.events INFO:  eta: 0:27:34  iter: 71339  total_loss: 0.08931  loss_cls: 0.01139  loss_box_reg: 0.03074  loss_mask: 0.04426  loss_rpn_cls: 0.000402  loss_rpn_loc: 0.003486  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:43] d2.utils.events INFO:  eta: 0:27:31  iter: 71359  total_loss: 0.08087  loss_cls: 0.01044  loss_box_reg: 0.02415  loss_mask: 0.03881  loss_rpn_cls: 0.0002584  loss_rpn_loc: 0.002706  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:44] d2.utils.events INFO:  eta: 0:27:30  iter: 71379  total_loss: 0.09481  loss_cls: 0.01361  loss_box_reg: 0.02793  loss_mask: 0.04966  loss_rpn_cls: 0.0001974  loss_rpn_loc: 0.003932  time: 0.0877  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:22:46] d2.utils.events INFO:  eta: 0:27:32  iter: 71399  total_loss: 0.1003  loss_cls: 0.01441  loss_box_reg: 0.03638  loss_mask: 0.05627  loss_rpn_cls: 0.0005334  loss_rpn_loc: 0.006405  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:48] d2.utils.events INFO:  eta: 0:27:26  iter: 71419  total_loss: 0.05879  loss_cls: 0.005124  loss_box_reg: 0.01334  loss_mask: 0.0382  loss_rpn_cls: 0.0001229  loss_rpn_loc: 0.001595  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:50] d2.utils.events INFO:  eta: 0:27:24  iter: 71439  total_loss: 0.0922  loss_cls: 0.01166  loss_box_reg: 0.0323  loss_mask: 0.03858  loss_rpn_cls: 0.000329  loss_rpn_loc: 0.00398  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:51] d2.utils.events INFO:  eta: 0:27:22  iter: 71459  total_loss: 0.1014  loss_cls: 0.01277  loss_box_reg: 0.02904  loss_mask: 0.05044  loss_rpn_cls: 0.0003971  loss_rpn_loc: 0.006636  time: 0.0877  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:53] d2.utils.events INFO:  eta: 0:27:20  iter: 71479  total_loss: 0.09206  loss_cls: 0.01251  loss_box_reg: 0.02802  loss_mask: 0.04558  loss_rpn_cls: 0.0001916  loss_rpn_loc: 0.002807  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:55] d2.utils.events INFO:  eta: 0:27:17  iter: 71499  total_loss: 0.06896  loss_cls: 0.0079  loss_box_reg: 0.01925  loss_mask: 0.03454  loss_rpn_cls: 0.0002066  loss_rpn_loc: 0.002116  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:22:57] d2.utils.events INFO:  eta: 0:27:15  iter: 71519  total_loss: 0.08556  loss_cls: 0.01145  loss_box_reg: 0.02011  loss_mask: 0.041  loss_rpn_cls: 0.0003283  loss_rpn_loc: 0.002609  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:22:59] d2.utils.events INFO:  eta: 0:27:13  iter: 71539  total_loss: 0.1086  loss_cls: 0.01255  loss_box_reg: 0.02508  loss_mask: 0.0462  loss_rpn_cls: 0.000372  loss_rpn_loc: 0.003821  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:00] d2.utils.events INFO:  eta: 0:27:11  iter: 71559  total_loss: 0.1124  loss_cls: 0.01508  loss_box_reg: 0.0345  loss_mask: 0.0547  loss_rpn_cls: 0.000367  loss_rpn_loc: 0.004961  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:23:02] d2.utils.events INFO:  eta: 0:27:10  iter: 71579  total_loss: 0.06845  loss_cls: 0.008306  loss_box_reg: 0.01704  loss_mask: 0.03469  loss_rpn_cls: 0.000232  loss_rpn_loc: 0.002496  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:04] d2.utils.events INFO:  eta: 0:27:07  iter: 71599  total_loss: 0.08434  loss_cls: 0.009975  loss_box_reg: 0.02513  loss_mask: 0.04804  loss_rpn_cls: 0.0002523  loss_rpn_loc: 0.002806  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:06] d2.utils.events INFO:  eta: 0:27:06  iter: 71619  total_loss: 0.0913  loss_cls: 0.01328  loss_box_reg: 0.03371  loss_mask: 0.04644  loss_rpn_cls: 0.0001867  loss_rpn_loc: 0.002623  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:07] d2.utils.events INFO:  eta: 0:27:04  iter: 71639  total_loss: 0.07661  loss_cls: 0.007327  loss_box_reg: 0.02267  loss_mask: 0.0486  loss_rpn_cls: 0.0003909  loss_rpn_loc: 0.002558  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:09] d2.utils.events INFO:  eta: 0:27:01  iter: 71659  total_loss: 0.08892  loss_cls: 0.01105  loss_box_reg: 0.02575  loss_mask: 0.04339  loss_rpn_cls: 0.000249  loss_rpn_loc: 0.002992  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:11] d2.utils.events INFO:  eta: 0:27:00  iter: 71679  total_loss: 0.06748  loss_cls: 0.00867  loss_box_reg: 0.01843  loss_mask: 0.04354  loss_rpn_cls: 0.0001728  loss_rpn_loc: 0.00236  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:13] d2.utils.events INFO:  eta: 0:27:00  iter: 71699  total_loss: 0.07766  loss_cls: 0.009557  loss_box_reg: 0.02035  loss_mask: 0.04181  loss_rpn_cls: 0.0002495  loss_rpn_loc: 0.002501  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:15] d2.utils.events INFO:  eta: 0:27:01  iter: 71719  total_loss: 0.1011  loss_cls: 0.01385  loss_box_reg: 0.03735  loss_mask: 0.04359  loss_rpn_cls: 0.000301  loss_rpn_loc: 0.003984  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:16] d2.utils.events INFO:  eta: 0:26:56  iter: 71739  total_loss: 0.09519  loss_cls: 0.01272  loss_box_reg: 0.01889  loss_mask: 0.05682  loss_rpn_cls: 0.0003023  loss_rpn_loc: 0.004312  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:18] d2.utils.events INFO:  eta: 0:26:59  iter: 71759  total_loss: 0.08844  loss_cls: 0.0161  loss_box_reg: 0.02528  loss_mask: 0.04235  loss_rpn_cls: 0.0004076  loss_rpn_loc: 0.004722  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:20] d2.utils.events INFO:  eta: 0:26:54  iter: 71779  total_loss: 0.07302  loss_cls: 0.01122  loss_box_reg: 0.02091  loss_mask: 0.04294  loss_rpn_cls: 0.0001316  loss_rpn_loc: 0.001514  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:22] d2.utils.events INFO:  eta: 0:26:52  iter: 71799  total_loss: 0.061  loss_cls: 0.005409  loss_box_reg: 0.01904  loss_mask: 0.03748  loss_rpn_cls: 0.0002637  loss_rpn_loc: 0.002547  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:23] d2.utils.events INFO:  eta: 0:26:50  iter: 71819  total_loss: 0.08887  loss_cls: 0.00985  loss_box_reg: 0.02882  loss_mask: 0.05012  loss_rpn_cls: 0.0003969  loss_rpn_loc: 0.003021  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:25] d2.utils.events INFO:  eta: 0:26:47  iter: 71839  total_loss: 0.07179  loss_cls: 0.008545  loss_box_reg: 0.01956  loss_mask: 0.04371  loss_rpn_cls: 0.0002008  loss_rpn_loc: 0.002947  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:27] d2.utils.events INFO:  eta: 0:26:44  iter: 71859  total_loss: 0.07758  loss_cls: 0.0115  loss_box_reg: 0.02438  loss_mask: 0.0411  loss_rpn_cls: 0.0001797  loss_rpn_loc: 0.002681  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:29] d2.utils.events INFO:  eta: 0:26:43  iter: 71879  total_loss: 0.08586  loss_cls: 0.01202  loss_box_reg: 0.02718  loss_mask: 0.04563  loss_rpn_cls: 0.000269  loss_rpn_loc: 0.002765  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:30] d2.utils.events INFO:  eta: 0:26:41  iter: 71899  total_loss: 0.09028  loss_cls: 0.01261  loss_box_reg: 0.02344  loss_mask: 0.04577  loss_rpn_cls: 0.0004463  loss_rpn_loc: 0.003481  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:32] d2.utils.events INFO:  eta: 0:26:39  iter: 71919  total_loss: 0.0844  loss_cls: 0.0101  loss_box_reg: 0.0259  loss_mask: 0.04649  loss_rpn_cls: 0.0001302  loss_rpn_loc: 0.002895  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:34] d2.utils.events INFO:  eta: 0:26:38  iter: 71939  total_loss: 0.1262  loss_cls: 0.0194  loss_box_reg: 0.04158  loss_mask: 0.06349  loss_rpn_cls: 0.0004757  loss_rpn_loc: 0.006966  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:36] d2.utils.events INFO:  eta: 0:26:36  iter: 71959  total_loss: 0.07629  loss_cls: 0.01033  loss_box_reg: 0.02166  loss_mask: 0.0434  loss_rpn_cls: 0.000277  loss_rpn_loc: 0.00312  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:23:38] d2.utils.events INFO:  eta: 0:26:34  iter: 71979  total_loss: 0.08006  loss_cls: 0.008949  loss_box_reg: 0.02016  loss_mask: 0.0449  loss_rpn_cls: 0.0001666  loss_rpn_loc: 0.002496  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:39] d2.utils.events INFO:  eta: 0:26:32  iter: 71999  total_loss: 0.08174  loss_cls: 0.009684  loss_box_reg: 0.02264  loss_mask: 0.04094  loss_rpn_cls: 9.474e-05  loss_rpn_loc: 0.001815  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:23:41] d2.utils.events INFO:  eta: 0:26:28  iter: 72019  total_loss: 0.0628  loss_cls: 0.008183  loss_box_reg: 0.01857  loss_mask: 0.0363  loss_rpn_cls: 0.0001646  loss_rpn_loc: 0.002136  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:43] d2.utils.events INFO:  eta: 0:26:25  iter: 72039  total_loss: 0.07018  loss_cls: 0.0136  loss_box_reg: 0.0222  loss_mask: 0.04099  loss_rpn_cls: 0.0002666  loss_rpn_loc: 0.003176  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:45] d2.utils.events INFO:  eta: 0:26:25  iter: 72059  total_loss: 0.08847  loss_cls: 0.01425  loss_box_reg: 0.02961  loss_mask: 0.04099  loss_rpn_cls: 0.0001881  loss_rpn_loc: 0.003324  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:46] d2.utils.events INFO:  eta: 0:26:23  iter: 72079  total_loss: 0.0732  loss_cls: 0.00771  loss_box_reg: 0.02001  loss_mask: 0.04252  loss_rpn_cls: 0.0001581  loss_rpn_loc: 0.002019  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:48] d2.utils.events INFO:  eta: 0:26:21  iter: 72099  total_loss: 0.07543  loss_cls: 0.01048  loss_box_reg: 0.02281  loss_mask: 0.04099  loss_rpn_cls: 0.0001972  loss_rpn_loc: 0.001984  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:50] d2.utils.events INFO:  eta: 0:26:21  iter: 72119  total_loss: 0.1178  loss_cls: 0.01214  loss_box_reg: 0.0356  loss_mask: 0.05847  loss_rpn_cls: 0.0005887  loss_rpn_loc: 0.004062  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:52] d2.utils.events INFO:  eta: 0:26:18  iter: 72139  total_loss: 0.09871  loss_cls: 0.01322  loss_box_reg: 0.02468  loss_mask: 0.05128  loss_rpn_cls: 0.0003549  loss_rpn_loc: 0.004979  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:23:53] d2.utils.events INFO:  eta: 0:26:17  iter: 72159  total_loss: 0.102  loss_cls: 0.01446  loss_box_reg: 0.03791  loss_mask: 0.04671  loss_rpn_cls: 0.0001826  loss_rpn_loc: 0.003726  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:23:55] d2.utils.events INFO:  eta: 0:26:15  iter: 72179  total_loss: 0.07966  loss_cls: 0.01283  loss_box_reg: 0.02139  loss_mask: 0.04696  loss_rpn_cls: 0.0002957  loss_rpn_loc: 0.00285  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:57] d2.utils.events INFO:  eta: 0:26:13  iter: 72199  total_loss: 0.09003  loss_cls: 0.01453  loss_box_reg: 0.02834  loss_mask: 0.04303  loss_rpn_cls: 0.0002706  loss_rpn_loc: 0.002966  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:23:59] d2.utils.events INFO:  eta: 0:26:12  iter: 72219  total_loss: 0.09287  loss_cls: 0.0138  loss_box_reg: 0.03301  loss_mask: 0.04618  loss_rpn_cls: 0.0003648  loss_rpn_loc: 0.003387  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:01] d2.utils.events INFO:  eta: 0:26:15  iter: 72239  total_loss: 0.1119  loss_cls: 0.017  loss_box_reg: 0.03371  loss_mask: 0.05295  loss_rpn_cls: 0.0003071  loss_rpn_loc: 0.006475  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:02] d2.utils.events INFO:  eta: 0:26:14  iter: 72259  total_loss: 0.06347  loss_cls: 0.006802  loss_box_reg: 0.0156  loss_mask: 0.03273  loss_rpn_cls: 0.0001319  loss_rpn_loc: 0.002657  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:04] d2.utils.events INFO:  eta: 0:26:16  iter: 72279  total_loss: 0.09097  loss_cls: 0.01184  loss_box_reg: 0.03219  loss_mask: 0.04893  loss_rpn_cls: 0.0003918  loss_rpn_loc: 0.003566  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:06] d2.utils.events INFO:  eta: 0:26:11  iter: 72299  total_loss: 0.0832  loss_cls: 0.01359  loss_box_reg: 0.02559  loss_mask: 0.04067  loss_rpn_cls: 0.0002984  loss_rpn_loc: 0.004097  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:08] d2.utils.events INFO:  eta: 0:26:06  iter: 72319  total_loss: 0.09284  loss_cls: 0.009885  loss_box_reg: 0.02489  loss_mask: 0.05228  loss_rpn_cls: 0.0001877  loss_rpn_loc: 0.002385  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:09] d2.utils.events INFO:  eta: 0:26:02  iter: 72339  total_loss: 0.08493  loss_cls: 0.01337  loss_box_reg: 0.02954  loss_mask: 0.04882  loss_rpn_cls: 0.0002561  loss_rpn_loc: 0.003412  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:11] d2.utils.events INFO:  eta: 0:26:02  iter: 72359  total_loss: 0.07393  loss_cls: 0.008395  loss_box_reg: 0.01892  loss_mask: 0.03832  loss_rpn_cls: 0.0002021  loss_rpn_loc: 0.002412  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:13] d2.utils.events INFO:  eta: 0:26:00  iter: 72379  total_loss: 0.06807  loss_cls: 0.008565  loss_box_reg: 0.02001  loss_mask: 0.04012  loss_rpn_cls: 0.0001171  loss_rpn_loc: 0.002252  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:15] d2.utils.events INFO:  eta: 0:26:00  iter: 72399  total_loss: 0.1085  loss_cls: 0.008575  loss_box_reg: 0.03426  loss_mask: 0.04979  loss_rpn_cls: 0.0002674  loss_rpn_loc: 0.003677  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:17] d2.utils.events INFO:  eta: 0:26:00  iter: 72419  total_loss: 0.08517  loss_cls: 0.00984  loss_box_reg: 0.02108  loss_mask: 0.03739  loss_rpn_cls: 0.0005271  loss_rpn_loc: 0.003547  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:18] d2.utils.events INFO:  eta: 0:25:55  iter: 72439  total_loss: 0.07237  loss_cls: 0.009098  loss_box_reg: 0.01751  loss_mask: 0.04986  loss_rpn_cls: 0.0002198  loss_rpn_loc: 0.00236  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:20] d2.utils.events INFO:  eta: 0:25:54  iter: 72459  total_loss: 0.09134  loss_cls: 0.01266  loss_box_reg: 0.02557  loss_mask: 0.04422  loss_rpn_cls: 0.0002843  loss_rpn_loc: 0.002963  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:22] d2.utils.events INFO:  eta: 0:25:51  iter: 72479  total_loss: 0.0794  loss_cls: 0.008204  loss_box_reg: 0.02177  loss_mask: 0.04612  loss_rpn_cls: 0.0002551  loss_rpn_loc: 0.002703  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:24] d2.utils.events INFO:  eta: 0:25:52  iter: 72499  total_loss: 0.06846  loss_cls: 0.007376  loss_box_reg: 0.01791  loss_mask: 0.03869  loss_rpn_cls: 0.0001697  loss_rpn_loc: 0.001981  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:26] d2.utils.events INFO:  eta: 0:25:53  iter: 72519  total_loss: 0.1518  loss_cls: 0.02007  loss_box_reg: 0.04606  loss_mask: 0.07015  loss_rpn_cls: 0.0003078  loss_rpn_loc: 0.006026  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:27] d2.utils.events INFO:  eta: 0:25:47  iter: 72539  total_loss: 0.06623  loss_cls: 0.007258  loss_box_reg: 0.01989  loss_mask: 0.04642  loss_rpn_cls: 0.0001445  loss_rpn_loc: 0.002652  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:29] d2.utils.events INFO:  eta: 0:25:40  iter: 72559  total_loss: 0.05876  loss_cls: 0.005318  loss_box_reg: 0.01275  loss_mask: 0.03298  loss_rpn_cls: 0.0002067  loss_rpn_loc: 0.002184  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:24:31] d2.utils.events INFO:  eta: 0:25:44  iter: 72579  total_loss: 0.08571  loss_cls: 0.01431  loss_box_reg: 0.02701  loss_mask: 0.04634  loss_rpn_cls: 0.0002775  loss_rpn_loc: 0.003782  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:33] d2.utils.events INFO:  eta: 0:25:43  iter: 72599  total_loss: 0.07307  loss_cls: 0.01126  loss_box_reg: 0.0246  loss_mask: 0.0475  loss_rpn_cls: 0.0001625  loss_rpn_loc: 0.002354  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:34] d2.utils.events INFO:  eta: 0:25:39  iter: 72619  total_loss: 0.08875  loss_cls: 0.01036  loss_box_reg: 0.0269  loss_mask: 0.03944  loss_rpn_cls: 0.0002174  loss_rpn_loc: 0.003704  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:36] d2.utils.events INFO:  eta: 0:25:33  iter: 72639  total_loss: 0.06149  loss_cls: 0.007321  loss_box_reg: 0.01926  loss_mask: 0.03475  loss_rpn_cls: 0.0001893  loss_rpn_loc: 0.001774  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:38] d2.utils.events INFO:  eta: 0:25:31  iter: 72659  total_loss: 0.06755  loss_cls: 0.008608  loss_box_reg: 0.01688  loss_mask: 0.03964  loss_rpn_cls: 0.000134  loss_rpn_loc: 0.001896  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:40] d2.utils.events INFO:  eta: 0:25:30  iter: 72679  total_loss: 0.07085  loss_cls: 0.008312  loss_box_reg: 0.02103  loss_mask: 0.0389  loss_rpn_cls: 0.0002383  loss_rpn_loc: 0.002566  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:41] d2.utils.events INFO:  eta: 0:25:26  iter: 72699  total_loss: 0.08503  loss_cls: 0.0125  loss_box_reg: 0.02634  loss_mask: 0.04055  loss_rpn_cls: 0.0002085  loss_rpn_loc: 0.003905  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:43] d2.utils.events INFO:  eta: 0:25:24  iter: 72719  total_loss: 0.09479  loss_cls: 0.01114  loss_box_reg: 0.02651  loss_mask: 0.0523  loss_rpn_cls: 0.0004795  loss_rpn_loc: 0.005902  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:45] d2.utils.events INFO:  eta: 0:25:20  iter: 72739  total_loss: 0.07066  loss_cls: 0.009895  loss_box_reg: 0.01944  loss_mask: 0.04632  loss_rpn_cls: 0.000135  loss_rpn_loc: 0.001825  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:47] d2.utils.events INFO:  eta: 0:25:19  iter: 72759  total_loss: 0.0939  loss_cls: 0.01062  loss_box_reg: 0.02695  loss_mask: 0.05657  loss_rpn_cls: 0.0002792  loss_rpn_loc: 0.003637  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:48] d2.utils.events INFO:  eta: 0:25:21  iter: 72779  total_loss: 0.1133  loss_cls: 0.01984  loss_box_reg: 0.03896  loss_mask: 0.04901  loss_rpn_cls: 0.0002285  loss_rpn_loc: 0.00552  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:50] d2.utils.events INFO:  eta: 0:25:19  iter: 72799  total_loss: 0.1012  loss_cls: 0.01238  loss_box_reg: 0.0219  loss_mask: 0.06131  loss_rpn_cls: 0.0002017  loss_rpn_loc: 0.002746  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:52] d2.utils.events INFO:  eta: 0:25:17  iter: 72819  total_loss: 0.09016  loss_cls: 0.01312  loss_box_reg: 0.03231  loss_mask: 0.04109  loss_rpn_cls: 0.000249  loss_rpn_loc: 0.0032  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:54] d2.utils.events INFO:  eta: 0:25:17  iter: 72839  total_loss: 0.07558  loss_cls: 0.009476  loss_box_reg: 0.02475  loss_mask: 0.0404  loss_rpn_cls: 0.000152  loss_rpn_loc: 0.002942  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:56] d2.utils.events INFO:  eta: 0:25:18  iter: 72859  total_loss: 0.08883  loss_cls: 0.01366  loss_box_reg: 0.02499  loss_mask: 0.04293  loss_rpn_cls: 0.0005505  loss_rpn_loc: 0.003965  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:24:57] d2.utils.events INFO:  eta: 0:25:19  iter: 72879  total_loss: 0.1014  loss_cls: 0.01599  loss_box_reg: 0.03932  loss_mask: 0.04838  loss_rpn_cls: 0.0002963  loss_rpn_loc: 0.007141  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:24:59] d2.utils.events INFO:  eta: 0:25:17  iter: 72899  total_loss: 0.08821  loss_cls: 0.01117  loss_box_reg: 0.02525  loss_mask: 0.04394  loss_rpn_cls: 0.0002496  loss_rpn_loc: 0.004399  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:01] d2.utils.events INFO:  eta: 0:25:13  iter: 72919  total_loss: 0.06902  loss_cls: 0.01038  loss_box_reg: 0.01851  loss_mask: 0.03809  loss_rpn_cls: 0.0001391  loss_rpn_loc: 0.002326  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:03] d2.utils.events INFO:  eta: 0:25:06  iter: 72939  total_loss: 0.08424  loss_cls: 0.01032  loss_box_reg: 0.02731  loss_mask: 0.04409  loss_rpn_cls: 0.0003371  loss_rpn_loc: 0.003206  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:04] d2.utils.events INFO:  eta: 0:25:03  iter: 72959  total_loss: 0.06315  loss_cls: 0.006368  loss_box_reg: 0.01776  loss_mask: 0.04015  loss_rpn_cls: 0.000308  loss_rpn_loc: 0.002564  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:06] d2.utils.events INFO:  eta: 0:25:04  iter: 72979  total_loss: 0.08531  loss_cls: 0.01398  loss_box_reg: 0.0242  loss_mask: 0.04908  loss_rpn_cls: 8.527e-05  loss_rpn_loc: 0.002852  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:08] d2.utils.events INFO:  eta: 0:25:03  iter: 72999  total_loss: 0.08766  loss_cls: 0.01092  loss_box_reg: 0.02928  loss_mask: 0.05007  loss_rpn_cls: 0.0001851  loss_rpn_loc: 0.00294  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:10] d2.utils.events INFO:  eta: 0:25:07  iter: 73019  total_loss: 0.09112  loss_cls: 0.01061  loss_box_reg: 0.02015  loss_mask: 0.04079  loss_rpn_cls: 0.000404  loss_rpn_loc: 0.002038  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:11] d2.utils.events INFO:  eta: 0:25:05  iter: 73039  total_loss: 0.0646  loss_cls: 0.00936  loss_box_reg: 0.01909  loss_mask: 0.03828  loss_rpn_cls: 0.000151  loss_rpn_loc: 0.002159  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:13] d2.utils.events INFO:  eta: 0:25:01  iter: 73059  total_loss: 0.08267  loss_cls: 0.01048  loss_box_reg: 0.02516  loss_mask: 0.04654  loss_rpn_cls: 0.0003507  loss_rpn_loc: 0.002617  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:15] d2.utils.events INFO:  eta: 0:25:01  iter: 73079  total_loss: 0.09258  loss_cls: 0.01108  loss_box_reg: 0.03029  loss_mask: 0.04204  loss_rpn_cls: 0.0002738  loss_rpn_loc: 0.004794  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:17] d2.utils.events INFO:  eta: 0:25:01  iter: 73099  total_loss: 0.06768  loss_cls: 0.01015  loss_box_reg: 0.02035  loss_mask: 0.03792  loss_rpn_cls: 0.0001741  loss_rpn_loc: 0.00269  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:19] d2.utils.events INFO:  eta: 0:24:55  iter: 73119  total_loss: 0.07604  loss_cls: 0.009957  loss_box_reg: 0.01916  loss_mask: 0.04036  loss_rpn_cls: 0.000209  loss_rpn_loc: 0.002303  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:20] d2.utils.events INFO:  eta: 0:24:56  iter: 73139  total_loss: 0.0986  loss_cls: 0.01455  loss_box_reg: 0.03431  loss_mask: 0.0474  loss_rpn_cls: 0.0002688  loss_rpn_loc: 0.0038  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:25:22] d2.utils.events INFO:  eta: 0:24:53  iter: 73159  total_loss: 0.09151  loss_cls: 0.01831  loss_box_reg: 0.02791  loss_mask: 0.0409  loss_rpn_cls: 0.0002065  loss_rpn_loc: 0.003431  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:24] d2.utils.events INFO:  eta: 0:24:54  iter: 73179  total_loss: 0.09123  loss_cls: 0.0106  loss_box_reg: 0.02518  loss_mask: 0.04523  loss_rpn_cls: 0.0002206  loss_rpn_loc: 0.002683  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:26] d2.utils.events INFO:  eta: 0:24:53  iter: 73199  total_loss: 0.08457  loss_cls: 0.01286  loss_box_reg: 0.02829  loss_mask: 0.04828  loss_rpn_cls: 0.0003856  loss_rpn_loc: 0.004024  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:28] d2.utils.events INFO:  eta: 0:24:52  iter: 73219  total_loss: 0.1229  loss_cls: 0.01421  loss_box_reg: 0.0322  loss_mask: 0.05729  loss_rpn_cls: 0.0006301  loss_rpn_loc: 0.004877  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:29] d2.utils.events INFO:  eta: 0:24:48  iter: 73239  total_loss: 0.1004  loss_cls: 0.01378  loss_box_reg: 0.02958  loss_mask: 0.05605  loss_rpn_cls: 0.0004903  loss_rpn_loc: 0.003575  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:31] d2.utils.events INFO:  eta: 0:24:44  iter: 73259  total_loss: 0.05913  loss_cls: 0.00865  loss_box_reg: 0.0143  loss_mask: 0.03416  loss_rpn_cls: 0.0001433  loss_rpn_loc: 0.001407  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:33] d2.utils.events INFO:  eta: 0:24:45  iter: 73279  total_loss: 0.08957  loss_cls: 0.01408  loss_box_reg: 0.03015  loss_mask: 0.03587  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.003173  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:35] d2.utils.events INFO:  eta: 0:24:38  iter: 73299  total_loss: 0.06776  loss_cls: 0.01016  loss_box_reg: 0.02064  loss_mask: 0.0345  loss_rpn_cls: 0.0001374  loss_rpn_loc: 0.001971  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:36] d2.utils.events INFO:  eta: 0:24:35  iter: 73319  total_loss: 0.07789  loss_cls: 0.01357  loss_box_reg: 0.02565  loss_mask: 0.04192  loss_rpn_cls: 0.0002225  loss_rpn_loc: 0.00293  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:38] d2.utils.events INFO:  eta: 0:24:35  iter: 73339  total_loss: 0.08695  loss_cls: 0.01426  loss_box_reg: 0.0282  loss_mask: 0.04645  loss_rpn_cls: 0.0001515  loss_rpn_loc: 0.002059  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:40] d2.utils.events INFO:  eta: 0:24:37  iter: 73359  total_loss: 0.0947  loss_cls: 0.01379  loss_box_reg: 0.03049  loss_mask: 0.05418  loss_rpn_cls: 0.0002068  loss_rpn_loc: 0.003393  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:42] d2.utils.events INFO:  eta: 0:24:33  iter: 73379  total_loss: 0.08091  loss_cls: 0.00835  loss_box_reg: 0.02378  loss_mask: 0.04418  loss_rpn_cls: 0.0001549  loss_rpn_loc: 0.002079  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:44] d2.utils.events INFO:  eta: 0:24:26  iter: 73399  total_loss: 0.06821  loss_cls: 0.00688  loss_box_reg: 0.01213  loss_mask: 0.04144  loss_rpn_cls: 0.0001661  loss_rpn_loc: 0.002057  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:45] d2.utils.events INFO:  eta: 0:24:24  iter: 73419  total_loss: 0.06753  loss_cls: 0.00886  loss_box_reg: 0.01979  loss_mask: 0.03565  loss_rpn_cls: 0.0002149  loss_rpn_loc: 0.002463  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:47] d2.utils.events INFO:  eta: 0:24:23  iter: 73439  total_loss: 0.07385  loss_cls: 0.00753  loss_box_reg: 0.01693  loss_mask: 0.03952  loss_rpn_cls: 0.0001469  loss_rpn_loc: 0.002466  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:49] d2.utils.events INFO:  eta: 0:24:21  iter: 73459  total_loss: 0.08274  loss_cls: 0.01332  loss_box_reg: 0.02504  loss_mask: 0.04303  loss_rpn_cls: 0.0003019  loss_rpn_loc: 0.003917  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:51] d2.utils.events INFO:  eta: 0:24:20  iter: 73479  total_loss: 0.07521  loss_cls: 0.007123  loss_box_reg: 0.01917  loss_mask: 0.03936  loss_rpn_cls: 0.0001624  loss_rpn_loc: 0.002284  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:52] d2.utils.events INFO:  eta: 0:24:23  iter: 73499  total_loss: 0.09931  loss_cls: 0.01485  loss_box_reg: 0.03705  loss_mask: 0.04933  loss_rpn_cls: 0.0004638  loss_rpn_loc: 0.005939  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:54] d2.utils.events INFO:  eta: 0:24:16  iter: 73519  total_loss: 0.0657  loss_cls: 0.0076  loss_box_reg: 0.02018  loss_mask: 0.037  loss_rpn_cls: 0.0001453  loss_rpn_loc: 0.001941  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:25:56] d2.utils.events INFO:  eta: 0:24:17  iter: 73539  total_loss: 0.1117  loss_cls: 0.01453  loss_box_reg: 0.03277  loss_mask: 0.05181  loss_rpn_cls: 0.0002547  loss_rpn_loc: 0.004416  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:58] d2.utils.events INFO:  eta: 0:24:17  iter: 73559  total_loss: 0.06026  loss_cls: 0.00784  loss_box_reg: 0.01584  loss_mask: 0.03633  loss_rpn_cls: 0.0002146  loss_rpn_loc: 0.002225  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:25:59] d2.utils.events INFO:  eta: 0:24:13  iter: 73579  total_loss: 0.08874  loss_cls: 0.01257  loss_box_reg: 0.02732  loss_mask: 0.04441  loss_rpn_cls: 0.0002891  loss_rpn_loc: 0.002789  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:01] d2.utils.events INFO:  eta: 0:24:10  iter: 73599  total_loss: 0.05265  loss_cls: 0.007863  loss_box_reg: 0.01444  loss_mask: 0.03122  loss_rpn_cls: 0.0001337  loss_rpn_loc: 0.002095  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:03] d2.utils.events INFO:  eta: 0:24:08  iter: 73619  total_loss: 0.08204  loss_cls: 0.009448  loss_box_reg: 0.02324  loss_mask: 0.04166  loss_rpn_cls: 0.0002449  loss_rpn_loc: 0.002974  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:05] d2.utils.events INFO:  eta: 0:24:14  iter: 73639  total_loss: 0.08857  loss_cls: 0.01204  loss_box_reg: 0.034  loss_mask: 0.0442  loss_rpn_cls: 0.0003206  loss_rpn_loc: 0.003882  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:07] d2.utils.events INFO:  eta: 0:24:13  iter: 73659  total_loss: 0.09983  loss_cls: 0.01319  loss_box_reg: 0.02729  loss_mask: 0.0624  loss_rpn_cls: 0.0003798  loss_rpn_loc: 0.003823  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:08] d2.utils.events INFO:  eta: 0:24:12  iter: 73679  total_loss: 0.07724  loss_cls: 0.008714  loss_box_reg: 0.02623  loss_mask: 0.05136  loss_rpn_cls: 0.0003237  loss_rpn_loc: 0.0027  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:10] d2.utils.events INFO:  eta: 0:24:14  iter: 73699  total_loss: 0.09251  loss_cls: 0.0122  loss_box_reg: 0.02362  loss_mask: 0.04862  loss_rpn_cls: 0.0001589  loss_rpn_loc: 0.003348  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:12] d2.utils.events INFO:  eta: 0:24:09  iter: 73719  total_loss: 0.07812  loss_cls: 0.00908  loss_box_reg: 0.01987  loss_mask: 0.04724  loss_rpn_cls: 0.0001915  loss_rpn_loc: 0.002014  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:14] d2.utils.events INFO:  eta: 0:24:09  iter: 73739  total_loss: 0.09312  loss_cls: 0.008644  loss_box_reg: 0.02546  loss_mask: 0.05074  loss_rpn_cls: 0.000335  loss_rpn_loc: 0.002333  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:15] d2.utils.events INFO:  eta: 0:24:06  iter: 73759  total_loss: 0.07761  loss_cls: 0.009964  loss_box_reg: 0.0219  loss_mask: 0.04403  loss_rpn_cls: 0.0001565  loss_rpn_loc: 0.002504  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:17] d2.utils.events INFO:  eta: 0:24:03  iter: 73779  total_loss: 0.1024  loss_cls: 0.01211  loss_box_reg: 0.02454  loss_mask: 0.05721  loss_rpn_cls: 0.0003926  loss_rpn_loc: 0.004889  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:19] d2.utils.events INFO:  eta: 0:24:00  iter: 73799  total_loss: 0.07394  loss_cls: 0.0074  loss_box_reg: 0.01801  loss_mask: 0.04364  loss_rpn_cls: 0.0001102  loss_rpn_loc: 0.001965  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:21] d2.utils.events INFO:  eta: 0:23:56  iter: 73819  total_loss: 0.0791  loss_cls: 0.009678  loss_box_reg: 0.0195  loss_mask: 0.04967  loss_rpn_cls: 0.0002221  loss_rpn_loc: 0.00278  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:26:22] d2.utils.events INFO:  eta: 0:23:53  iter: 73839  total_loss: 0.0735  loss_cls: 0.007462  loss_box_reg: 0.01985  loss_mask: 0.05329  loss_rpn_cls: 0.0001723  loss_rpn_loc: 0.001613  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:24] d2.utils.events INFO:  eta: 0:23:52  iter: 73859  total_loss: 0.08988  loss_cls: 0.0147  loss_box_reg: 0.02581  loss_mask: 0.04995  loss_rpn_cls: 0.0003888  loss_rpn_loc: 0.00273  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:26] d2.utils.events INFO:  eta: 0:23:50  iter: 73879  total_loss: 0.09609  loss_cls: 0.01552  loss_box_reg: 0.02873  loss_mask: 0.05069  loss_rpn_cls: 0.0002961  loss_rpn_loc: 0.005263  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:28] d2.utils.events INFO:  eta: 0:23:49  iter: 73899  total_loss: 0.08584  loss_cls: 0.01109  loss_box_reg: 0.02634  loss_mask: 0.04204  loss_rpn_cls: 0.0001556  loss_rpn_loc: 0.003265  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:30] d2.utils.events INFO:  eta: 0:23:50  iter: 73919  total_loss: 0.08264  loss_cls: 0.01199  loss_box_reg: 0.03051  loss_mask: 0.03945  loss_rpn_cls: 0.0003196  loss_rpn_loc: 0.003766  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:31] d2.utils.events INFO:  eta: 0:23:50  iter: 73939  total_loss: 0.08719  loss_cls: 0.01413  loss_box_reg: 0.02734  loss_mask: 0.04088  loss_rpn_cls: 0.000382  loss_rpn_loc: 0.00321  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:33] d2.utils.events INFO:  eta: 0:23:50  iter: 73959  total_loss: 0.1186  loss_cls: 0.0144  loss_box_reg: 0.03345  loss_mask: 0.06153  loss_rpn_cls: 0.0003011  loss_rpn_loc: 0.003462  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:35] d2.utils.events INFO:  eta: 0:23:48  iter: 73979  total_loss: 0.08756  loss_cls: 0.01268  loss_box_reg: 0.02875  loss_mask: 0.04496  loss_rpn_cls: 0.0002435  loss_rpn_loc: 0.002922  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:37] d2.utils.events INFO:  eta: 0:23:42  iter: 73999  total_loss: 0.05586  loss_cls: 0.006177  loss_box_reg: 0.01328  loss_mask: 0.03727  loss_rpn_cls: 0.0001531  loss_rpn_loc: 0.001959  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:39] d2.utils.events INFO:  eta: 0:23:40  iter: 74019  total_loss: 0.09042  loss_cls: 0.009365  loss_box_reg: 0.02296  loss_mask: 0.0477  loss_rpn_cls: 0.0001843  loss_rpn_loc: 0.00276  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:40] d2.utils.events INFO:  eta: 0:23:38  iter: 74039  total_loss: 0.07705  loss_cls: 0.01104  loss_box_reg: 0.02343  loss_mask: 0.0387  loss_rpn_cls: 0.0001894  loss_rpn_loc: 0.003959  time: 0.0878  data_time: 0.0022  lr: 0.00025  max_mem: 1494M
[10/27 20:26:42] d2.utils.events INFO:  eta: 0:23:34  iter: 74059  total_loss: 0.05943  loss_cls: 0.007656  loss_box_reg: 0.01975  loss_mask: 0.03959  loss_rpn_cls: 0.0001698  loss_rpn_loc: 0.002362  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:44] d2.utils.events INFO:  eta: 0:23:33  iter: 74079  total_loss: 0.08294  loss_cls: 0.008345  loss_box_reg: 0.02659  loss_mask: 0.0451  loss_rpn_cls: 0.0003078  loss_rpn_loc: 0.004509  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:46] d2.utils.events INFO:  eta: 0:23:30  iter: 74099  total_loss: 0.06756  loss_cls: 0.01104  loss_box_reg: 0.02048  loss_mask: 0.03787  loss_rpn_cls: 0.0001834  loss_rpn_loc: 0.002252  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:47] d2.utils.events INFO:  eta: 0:23:30  iter: 74119  total_loss: 0.08874  loss_cls: 0.01189  loss_box_reg: 0.02482  loss_mask: 0.0477  loss_rpn_cls: 0.0001797  loss_rpn_loc: 0.002958  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:49] d2.utils.events INFO:  eta: 0:23:24  iter: 74139  total_loss: 0.06207  loss_cls: 0.006273  loss_box_reg: 0.01778  loss_mask: 0.03487  loss_rpn_cls: 0.0001189  loss_rpn_loc: 0.002015  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:51] d2.utils.events INFO:  eta: 0:23:25  iter: 74159  total_loss: 0.08402  loss_cls: 0.009985  loss_box_reg: 0.02543  loss_mask: 0.04633  loss_rpn_cls: 0.0003462  loss_rpn_loc: 0.004492  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:53] d2.utils.events INFO:  eta: 0:23:23  iter: 74179  total_loss: 0.1033  loss_cls: 0.01369  loss_box_reg: 0.03153  loss_mask: 0.04854  loss_rpn_cls: 0.0002755  loss_rpn_loc: 0.004272  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:55] d2.utils.events INFO:  eta: 0:23:22  iter: 74199  total_loss: 0.08255  loss_cls: 0.008476  loss_box_reg: 0.03181  loss_mask: 0.04301  loss_rpn_cls: 0.0001611  loss_rpn_loc: 0.002492  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:26:56] d2.utils.events INFO:  eta: 0:23:16  iter: 74219  total_loss: 0.06932  loss_cls: 0.01092  loss_box_reg: 0.01931  loss_mask: 0.03792  loss_rpn_cls: 0.0001236  loss_rpn_loc: 0.002283  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:26:58] d2.utils.events INFO:  eta: 0:23:11  iter: 74239  total_loss: 0.06843  loss_cls: 0.007072  loss_box_reg: 0.01617  loss_mask: 0.04305  loss_rpn_cls: 5.155e-05  loss_rpn_loc: 0.001543  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:00] d2.utils.events INFO:  eta: 0:23:12  iter: 74259  total_loss: 0.08728  loss_cls: 0.01134  loss_box_reg: 0.02754  loss_mask: 0.04485  loss_rpn_cls: 0.0002025  loss_rpn_loc: 0.003592  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:02] d2.utils.events INFO:  eta: 0:23:09  iter: 74279  total_loss: 0.08368  loss_cls: 0.01161  loss_box_reg: 0.02557  loss_mask: 0.04627  loss_rpn_cls: 0.0003625  loss_rpn_loc: 0.004036  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:03] d2.utils.events INFO:  eta: 0:23:09  iter: 74299  total_loss: 0.06637  loss_cls: 0.006658  loss_box_reg: 0.01841  loss_mask: 0.03769  loss_rpn_cls: 0.0002955  loss_rpn_loc: 0.002719  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:05] d2.utils.events INFO:  eta: 0:23:10  iter: 74319  total_loss: 0.1021  loss_cls: 0.01349  loss_box_reg: 0.03358  loss_mask: 0.05786  loss_rpn_cls: 0.0003136  loss_rpn_loc: 0.0034  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:07] d2.utils.events INFO:  eta: 0:23:05  iter: 74339  total_loss: 0.07462  loss_cls: 0.01117  loss_box_reg: 0.02009  loss_mask: 0.0438  loss_rpn_cls: 0.0001225  loss_rpn_loc: 0.002442  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:09] d2.utils.events INFO:  eta: 0:23:03  iter: 74359  total_loss: 0.08611  loss_cls: 0.01246  loss_box_reg: 0.02817  loss_mask: 0.0441  loss_rpn_cls: 0.0002425  loss_rpn_loc: 0.002822  time: 0.0878  data_time: 0.0022  lr: 0.00025  max_mem: 1494M
[10/27 20:27:11] d2.utils.events INFO:  eta: 0:23:03  iter: 74379  total_loss: 0.07978  loss_cls: 0.01068  loss_box_reg: 0.02506  loss_mask: 0.04477  loss_rpn_cls: 0.0002389  loss_rpn_loc: 0.003197  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:12] d2.utils.events INFO:  eta: 0:23:04  iter: 74399  total_loss: 0.0966  loss_cls: 0.01475  loss_box_reg: 0.02838  loss_mask: 0.04516  loss_rpn_cls: 0.000443  loss_rpn_loc: 0.003405  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:14] d2.utils.events INFO:  eta: 0:23:02  iter: 74419  total_loss: 0.0971  loss_cls: 0.006356  loss_box_reg: 0.02211  loss_mask: 0.05174  loss_rpn_cls: 0.0002603  loss_rpn_loc: 0.001679  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:16] d2.utils.events INFO:  eta: 0:23:01  iter: 74439  total_loss: 0.07299  loss_cls: 0.009329  loss_box_reg: 0.02346  loss_mask: 0.04221  loss_rpn_cls: 0.0001554  loss_rpn_loc: 0.002879  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:18] d2.utils.events INFO:  eta: 0:22:59  iter: 74459  total_loss: 0.0898  loss_cls: 0.008923  loss_box_reg: 0.02492  loss_mask: 0.04766  loss_rpn_cls: 0.0003012  loss_rpn_loc: 0.003814  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:19] d2.utils.events INFO:  eta: 0:22:56  iter: 74479  total_loss: 0.07414  loss_cls: 0.009087  loss_box_reg: 0.02067  loss_mask: 0.03844  loss_rpn_cls: 0.0002729  loss_rpn_loc: 0.00233  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:21] d2.utils.events INFO:  eta: 0:22:51  iter: 74499  total_loss: 0.07968  loss_cls: 0.01129  loss_box_reg: 0.02929  loss_mask: 0.04773  loss_rpn_cls: 0.0002195  loss_rpn_loc: 0.002429  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:23] d2.utils.events INFO:  eta: 0:22:52  iter: 74519  total_loss: 0.08283  loss_cls: 0.01014  loss_box_reg: 0.02971  loss_mask: 0.04504  loss_rpn_cls: 0.0002175  loss_rpn_loc: 0.002772  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:25] d2.utils.events INFO:  eta: 0:22:45  iter: 74539  total_loss: 0.06054  loss_cls: 0.006295  loss_box_reg: 0.01519  loss_mask: 0.04151  loss_rpn_cls: 8.628e-05  loss_rpn_loc: 0.002002  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:26] d2.utils.events INFO:  eta: 0:22:48  iter: 74559  total_loss: 0.0988  loss_cls: 0.01174  loss_box_reg: 0.01986  loss_mask: 0.04501  loss_rpn_cls: 0.0002536  loss_rpn_loc: 0.004376  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:28] d2.utils.events INFO:  eta: 0:22:46  iter: 74579  total_loss: 0.07275  loss_cls: 0.007474  loss_box_reg: 0.01968  loss_mask: 0.04335  loss_rpn_cls: 0.0001873  loss_rpn_loc: 0.002966  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:30] d2.utils.events INFO:  eta: 0:22:45  iter: 74599  total_loss: 0.06647  loss_cls: 0.01109  loss_box_reg: 0.0233  loss_mask: 0.04428  loss_rpn_cls: 0.0003077  loss_rpn_loc: 0.003892  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:32] d2.utils.events INFO:  eta: 0:22:42  iter: 74619  total_loss: 0.0808  loss_cls: 0.009231  loss_box_reg: 0.02396  loss_mask: 0.04066  loss_rpn_cls: 0.0002947  loss_rpn_loc: 0.003003  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:34] d2.utils.events INFO:  eta: 0:22:41  iter: 74639  total_loss: 0.1189  loss_cls: 0.01621  loss_box_reg: 0.03518  loss_mask: 0.06371  loss_rpn_cls: 0.0004103  loss_rpn_loc: 0.003237  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:35] d2.utils.events INFO:  eta: 0:22:38  iter: 74659  total_loss: 0.0817  loss_cls: 0.01066  loss_box_reg: 0.02043  loss_mask: 0.04777  loss_rpn_cls: 0.0002999  loss_rpn_loc: 0.003056  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:37] d2.utils.events INFO:  eta: 0:22:34  iter: 74679  total_loss: 0.06706  loss_cls: 0.008741  loss_box_reg: 0.01923  loss_mask: 0.03309  loss_rpn_cls: 0.0002043  loss_rpn_loc: 0.001466  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:39] d2.utils.events INFO:  eta: 0:22:30  iter: 74699  total_loss: 0.06945  loss_cls: 0.009389  loss_box_reg: 0.01596  loss_mask: 0.0376  loss_rpn_cls: 0.0001837  loss_rpn_loc: 0.003154  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:41] d2.utils.events INFO:  eta: 0:22:32  iter: 74719  total_loss: 0.0744  loss_cls: 0.007221  loss_box_reg: 0.01929  loss_mask: 0.04555  loss_rpn_cls: 0.0002761  loss_rpn_loc: 0.002816  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:42] d2.utils.events INFO:  eta: 0:22:29  iter: 74739  total_loss: 0.07148  loss_cls: 0.006416  loss_box_reg: 0.0191  loss_mask: 0.04256  loss_rpn_cls: 0.0001213  loss_rpn_loc: 0.002083  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:44] d2.utils.events INFO:  eta: 0:22:28  iter: 74759  total_loss: 0.07484  loss_cls: 0.007768  loss_box_reg: 0.01945  loss_mask: 0.04301  loss_rpn_cls: 0.0002008  loss_rpn_loc: 0.002452  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:46] d2.utils.events INFO:  eta: 0:22:24  iter: 74779  total_loss: 0.07919  loss_cls: 0.00949  loss_box_reg: 0.02104  loss_mask: 0.04112  loss_rpn_cls: 0.0002343  loss_rpn_loc: 0.00249  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:48] d2.utils.events INFO:  eta: 0:22:24  iter: 74799  total_loss: 0.1069  loss_cls: 0.01479  loss_box_reg: 0.02874  loss_mask: 0.05736  loss_rpn_cls: 0.0002862  loss_rpn_loc: 0.003788  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:27:49] d2.utils.events INFO:  eta: 0:22:24  iter: 74819  total_loss: 0.06561  loss_cls: 0.01025  loss_box_reg: 0.01857  loss_mask: 0.03706  loss_rpn_cls: 0.0001721  loss_rpn_loc: 0.002317  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:51] d2.utils.events INFO:  eta: 0:22:22  iter: 74839  total_loss: 0.07394  loss_cls: 0.006973  loss_box_reg: 0.01904  loss_mask: 0.04696  loss_rpn_cls: 0.0001431  loss_rpn_loc: 0.002581  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:53] d2.utils.events INFO:  eta: 0:22:19  iter: 74859  total_loss: 0.1005  loss_cls: 0.01548  loss_box_reg: 0.03106  loss_mask: 0.04955  loss_rpn_cls: 0.0003582  loss_rpn_loc: 0.006023  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:55] d2.utils.events INFO:  eta: 0:22:17  iter: 74879  total_loss: 0.1304  loss_cls: 0.01647  loss_box_reg: 0.03845  loss_mask: 0.06354  loss_rpn_cls: 0.0004969  loss_rpn_loc: 0.007617  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:56] d2.utils.events INFO:  eta: 0:22:13  iter: 74899  total_loss: 0.06422  loss_cls: 0.006737  loss_box_reg: 0.01624  loss_mask: 0.04076  loss_rpn_cls: 9.719e-05  loss_rpn_loc: 0.001759  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:27:58] d2.utils.events INFO:  eta: 0:22:11  iter: 74919  total_loss: 0.08904  loss_cls: 0.01078  loss_box_reg: 0.02356  loss_mask: 0.05107  loss_rpn_cls: 0.0002683  loss_rpn_loc: 0.002802  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:00] d2.utils.events INFO:  eta: 0:22:10  iter: 74939  total_loss: 0.0931  loss_cls: 0.01388  loss_box_reg: 0.03418  loss_mask: 0.04055  loss_rpn_cls: 0.0001673  loss_rpn_loc: 0.003486  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:28:02] d2.utils.events INFO:  eta: 0:22:08  iter: 74959  total_loss: 0.1363  loss_cls: 0.01717  loss_box_reg: 0.04443  loss_mask: 0.05868  loss_rpn_cls: 0.0003822  loss_rpn_loc: 0.005191  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:03] d2.utils.events INFO:  eta: 0:22:05  iter: 74979  total_loss: 0.07079  loss_cls: 0.007636  loss_box_reg: 0.02109  loss_mask: 0.03697  loss_rpn_cls: 0.0002932  loss_rpn_loc: 0.002619  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:05] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0074999.pth
[10/27 20:28:06] d2.utils.events INFO:  eta: 0:22:04  iter: 74999  total_loss: 0.07193  loss_cls: 0.007763  loss_box_reg: 0.01669  loss_mask: 0.03867  loss_rpn_cls: 0.0001658  loss_rpn_loc: 0.002089  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:07] d2.utils.events INFO:  eta: 0:22:03  iter: 75019  total_loss: 0.08825  loss_cls: 0.009723  loss_box_reg: 0.0232  loss_mask: 0.04845  loss_rpn_cls: 0.0003523  loss_rpn_loc: 0.005057  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:09] d2.utils.events INFO:  eta: 0:22:03  iter: 75039  total_loss: 0.08517  loss_cls: 0.01176  loss_box_reg: 0.02543  loss_mask: 0.04028  loss_rpn_cls: 0.000285  loss_rpn_loc: 0.003797  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:11] d2.utils.events INFO:  eta: 0:22:04  iter: 75059  total_loss: 0.1257  loss_cls: 0.0146  loss_box_reg: 0.03929  loss_mask: 0.06382  loss_rpn_cls: 0.0002685  loss_rpn_loc: 0.004827  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:13] d2.utils.events INFO:  eta: 0:22:03  iter: 75079  total_loss: 0.0763  loss_cls: 0.00989  loss_box_reg: 0.02289  loss_mask: 0.0469  loss_rpn_cls: 0.0001349  loss_rpn_loc: 0.002214  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:15] d2.utils.events INFO:  eta: 0:22:02  iter: 75099  total_loss: 0.07697  loss_cls: 0.006395  loss_box_reg: 0.01541  loss_mask: 0.04568  loss_rpn_cls: 0.0001809  loss_rpn_loc: 0.002031  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:16] d2.utils.events INFO:  eta: 0:22:01  iter: 75119  total_loss: 0.1008  loss_cls: 0.01648  loss_box_reg: 0.03388  loss_mask: 0.05084  loss_rpn_cls: 0.0002873  loss_rpn_loc: 0.004076  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:18] d2.utils.events INFO:  eta: 0:21:59  iter: 75139  total_loss: 0.07034  loss_cls: 0.008209  loss_box_reg: 0.01682  loss_mask: 0.03666  loss_rpn_cls: 9.447e-05  loss_rpn_loc: 0.00151  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:20] d2.utils.events INFO:  eta: 0:21:57  iter: 75159  total_loss: 0.1069  loss_cls: 0.0147  loss_box_reg: 0.03785  loss_mask: 0.04758  loss_rpn_cls: 0.0002467  loss_rpn_loc: 0.003493  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:22] d2.utils.events INFO:  eta: 0:21:53  iter: 75179  total_loss: 0.06793  loss_cls: 0.006684  loss_box_reg: 0.01928  loss_mask: 0.03875  loss_rpn_cls: 0.0001908  loss_rpn_loc: 0.00235  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:23] d2.utils.events INFO:  eta: 0:21:50  iter: 75199  total_loss: 0.09067  loss_cls: 0.01191  loss_box_reg: 0.02441  loss_mask: 0.04265  loss_rpn_cls: 0.0001394  loss_rpn_loc: 0.00301  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:25] d2.utils.events INFO:  eta: 0:21:49  iter: 75219  total_loss: 0.08681  loss_cls: 0.01099  loss_box_reg: 0.0254  loss_mask: 0.0454  loss_rpn_cls: 0.0002528  loss_rpn_loc: 0.00306  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:27] d2.utils.events INFO:  eta: 0:21:48  iter: 75239  total_loss: 0.09523  loss_cls: 0.01197  loss_box_reg: 0.0254  loss_mask: 0.04682  loss_rpn_cls: 0.00023  loss_rpn_loc: 0.003034  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:29] d2.utils.events INFO:  eta: 0:21:45  iter: 75259  total_loss: 0.07983  loss_cls: 0.01017  loss_box_reg: 0.02145  loss_mask: 0.04655  loss_rpn_cls: 0.000201  loss_rpn_loc: 0.002704  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:30] d2.utils.events INFO:  eta: 0:21:41  iter: 75279  total_loss: 0.08317  loss_cls: 0.01376  loss_box_reg: 0.02309  loss_mask: 0.04888  loss_rpn_cls: 0.0001773  loss_rpn_loc: 0.002864  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:32] d2.utils.events INFO:  eta: 0:21:40  iter: 75299  total_loss: 0.07672  loss_cls: 0.007463  loss_box_reg: 0.02201  loss_mask: 0.04201  loss_rpn_cls: 0.0001393  loss_rpn_loc: 0.002457  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:34] d2.utils.events INFO:  eta: 0:21:37  iter: 75319  total_loss: 0.07066  loss_cls: 0.008356  loss_box_reg: 0.02203  loss_mask: 0.04193  loss_rpn_cls: 0.0002245  loss_rpn_loc: 0.002975  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:36] d2.utils.events INFO:  eta: 0:21:36  iter: 75339  total_loss: 0.08055  loss_cls: 0.01082  loss_box_reg: 0.02221  loss_mask: 0.04003  loss_rpn_cls: 0.0002707  loss_rpn_loc: 0.002381  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:38] d2.utils.events INFO:  eta: 0:21:35  iter: 75359  total_loss: 0.1161  loss_cls: 0.01413  loss_box_reg: 0.0356  loss_mask: 0.05992  loss_rpn_cls: 0.000385  loss_rpn_loc: 0.004545  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:39] d2.utils.events INFO:  eta: 0:21:34  iter: 75379  total_loss: 0.1031  loss_cls: 0.01356  loss_box_reg: 0.03529  loss_mask: 0.05355  loss_rpn_cls: 0.0002715  loss_rpn_loc: 0.005996  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:41] d2.utils.events INFO:  eta: 0:21:30  iter: 75399  total_loss: 0.07081  loss_cls: 0.006946  loss_box_reg: 0.01657  loss_mask: 0.05072  loss_rpn_cls: 0.0001065  loss_rpn_loc: 0.002132  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:43] d2.utils.events INFO:  eta: 0:21:32  iter: 75419  total_loss: 0.09935  loss_cls: 0.01156  loss_box_reg: 0.03222  loss_mask: 0.04929  loss_rpn_cls: 0.0001457  loss_rpn_loc: 0.003025  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:45] d2.utils.events INFO:  eta: 0:21:29  iter: 75439  total_loss: 0.06667  loss_cls: 0.009371  loss_box_reg: 0.01896  loss_mask: 0.04392  loss_rpn_cls: 0.000163  loss_rpn_loc: 0.001998  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:46] d2.utils.events INFO:  eta: 0:21:27  iter: 75459  total_loss: 0.08085  loss_cls: 0.008686  loss_box_reg: 0.02087  loss_mask: 0.04106  loss_rpn_cls: 0.0003123  loss_rpn_loc: 0.002501  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:48] d2.utils.events INFO:  eta: 0:21:26  iter: 75479  total_loss: 0.09037  loss_cls: 0.008777  loss_box_reg: 0.02542  loss_mask: 0.05464  loss_rpn_cls: 0.0002974  loss_rpn_loc: 0.004347  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:50] d2.utils.events INFO:  eta: 0:21:23  iter: 75499  total_loss: 0.06011  loss_cls: 0.007416  loss_box_reg: 0.01402  loss_mask: 0.03391  loss_rpn_cls: 9.161e-05  loss_rpn_loc: 0.001902  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:52] d2.utils.events INFO:  eta: 0:21:21  iter: 75519  total_loss: 0.07534  loss_cls: 0.01151  loss_box_reg: 0.02559  loss_mask: 0.04263  loss_rpn_cls: 0.0002106  loss_rpn_loc: 0.002966  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:53] d2.utils.events INFO:  eta: 0:21:21  iter: 75539  total_loss: 0.07003  loss_cls: 0.007812  loss_box_reg: 0.02045  loss_mask: 0.03883  loss_rpn_cls: 0.0002399  loss_rpn_loc: 0.003576  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:55] d2.utils.events INFO:  eta: 0:21:16  iter: 75559  total_loss: 0.06868  loss_cls: 0.0116  loss_box_reg: 0.01724  loss_mask: 0.03821  loss_rpn_cls: 0.0001899  loss_rpn_loc: 0.002181  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:28:57] d2.utils.events INFO:  eta: 0:21:15  iter: 75579  total_loss: 0.09558  loss_cls: 0.008345  loss_box_reg: 0.02424  loss_mask: 0.0426  loss_rpn_cls: 0.0003421  loss_rpn_loc: 0.002321  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:28:59] d2.utils.events INFO:  eta: 0:21:13  iter: 75599  total_loss: 0.07755  loss_cls: 0.009412  loss_box_reg: 0.02079  loss_mask: 0.04249  loss_rpn_cls: 0.0002095  loss_rpn_loc: 0.002321  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:00] d2.utils.events INFO:  eta: 0:21:11  iter: 75619  total_loss: 0.07763  loss_cls: 0.01096  loss_box_reg: 0.02314  loss_mask: 0.04569  loss_rpn_cls: 0.0001985  loss_rpn_loc: 0.002919  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:02] d2.utils.events INFO:  eta: 0:21:07  iter: 75639  total_loss: 0.09307  loss_cls: 0.01294  loss_box_reg: 0.02641  loss_mask: 0.05581  loss_rpn_cls: 0.0001737  loss_rpn_loc: 0.002883  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:04] d2.utils.events INFO:  eta: 0:21:05  iter: 75659  total_loss: 0.06197  loss_cls: 0.00722  loss_box_reg: 0.01704  loss_mask: 0.04413  loss_rpn_cls: 0.0001576  loss_rpn_loc: 0.002236  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:06] d2.utils.events INFO:  eta: 0:21:03  iter: 75679  total_loss: 0.08797  loss_cls: 0.009863  loss_box_reg: 0.02424  loss_mask: 0.04044  loss_rpn_cls: 0.0002676  loss_rpn_loc: 0.002648  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:07] d2.utils.events INFO:  eta: 0:21:03  iter: 75699  total_loss: 0.1263  loss_cls: 0.01616  loss_box_reg: 0.03999  loss_mask: 0.05891  loss_rpn_cls: 0.0002711  loss_rpn_loc: 0.005464  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:09] d2.utils.events INFO:  eta: 0:21:02  iter: 75719  total_loss: 0.1281  loss_cls: 0.01668  loss_box_reg: 0.03963  loss_mask: 0.05931  loss_rpn_cls: 0.0003186  loss_rpn_loc: 0.00576  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:11] d2.utils.events INFO:  eta: 0:21:00  iter: 75739  total_loss: 0.07397  loss_cls: 0.009115  loss_box_reg: 0.02202  loss_mask: 0.03813  loss_rpn_cls: 0.0001958  loss_rpn_loc: 0.002139  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:29:13] d2.utils.events INFO:  eta: 0:20:58  iter: 75759  total_loss: 0.08397  loss_cls: 0.008888  loss_box_reg: 0.0206  loss_mask: 0.05115  loss_rpn_cls: 0.0002977  loss_rpn_loc: 0.003296  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:15] d2.utils.events INFO:  eta: 0:20:57  iter: 75779  total_loss: 0.0684  loss_cls: 0.006846  loss_box_reg: 0.01392  loss_mask: 0.04205  loss_rpn_cls: 0.0001435  loss_rpn_loc: 0.001967  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:16] d2.utils.events INFO:  eta: 0:20:54  iter: 75799  total_loss: 0.07676  loss_cls: 0.009783  loss_box_reg: 0.02032  loss_mask: 0.04242  loss_rpn_cls: 0.0003851  loss_rpn_loc: 0.003098  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:18] d2.utils.events INFO:  eta: 0:20:52  iter: 75819  total_loss: 0.05375  loss_cls: 0.00801  loss_box_reg: 0.01551  loss_mask: 0.03932  loss_rpn_cls: 0.000122  loss_rpn_loc: 0.001627  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:20] d2.utils.events INFO:  eta: 0:20:51  iter: 75839  total_loss: 0.1123  loss_cls: 0.01582  loss_box_reg: 0.03737  loss_mask: 0.05904  loss_rpn_cls: 0.0003224  loss_rpn_loc: 0.003613  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:22] d2.utils.events INFO:  eta: 0:20:48  iter: 75859  total_loss: 0.07957  loss_cls: 0.01416  loss_box_reg: 0.02292  loss_mask: 0.03975  loss_rpn_cls: 0.0002019  loss_rpn_loc: 0.002228  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:23] d2.utils.events INFO:  eta: 0:20:45  iter: 75879  total_loss: 0.07659  loss_cls: 0.007005  loss_box_reg: 0.02077  loss_mask: 0.03952  loss_rpn_cls: 0.000163  loss_rpn_loc: 0.002783  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:25] d2.utils.events INFO:  eta: 0:20:44  iter: 75899  total_loss: 0.0626  loss_cls: 0.008692  loss_box_reg: 0.01534  loss_mask: 0.03865  loss_rpn_cls: 0.0001724  loss_rpn_loc: 0.001332  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:27] d2.utils.events INFO:  eta: 0:20:39  iter: 75919  total_loss: 0.0589  loss_cls: 0.006409  loss_box_reg: 0.01556  loss_mask: 0.03579  loss_rpn_cls: 0.0001582  loss_rpn_loc: 0.001568  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:29] d2.utils.events INFO:  eta: 0:20:36  iter: 75939  total_loss: 0.08092  loss_cls: 0.008726  loss_box_reg: 0.02254  loss_mask: 0.03919  loss_rpn_cls: 0.0003825  loss_rpn_loc: 0.004343  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:30] d2.utils.events INFO:  eta: 0:20:33  iter: 75959  total_loss: 0.09077  loss_cls: 0.009558  loss_box_reg: 0.0296  loss_mask: 0.05345  loss_rpn_cls: 0.0002448  loss_rpn_loc: 0.00333  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:32] d2.utils.events INFO:  eta: 0:20:32  iter: 75979  total_loss: 0.08049  loss_cls: 0.009098  loss_box_reg: 0.02382  loss_mask: 0.04949  loss_rpn_cls: 0.000307  loss_rpn_loc: 0.002692  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:34] d2.utils.events INFO:  eta: 0:20:34  iter: 75999  total_loss: 0.09262  loss_cls: 0.01352  loss_box_reg: 0.02892  loss_mask: 0.04695  loss_rpn_cls: 0.0002789  loss_rpn_loc: 0.002383  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:36] d2.utils.events INFO:  eta: 0:20:30  iter: 76019  total_loss: 0.06773  loss_cls: 0.01021  loss_box_reg: 0.02074  loss_mask: 0.03754  loss_rpn_cls: 0.0002215  loss_rpn_loc: 0.002013  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:38] d2.utils.events INFO:  eta: 0:20:31  iter: 76039  total_loss: 0.09599  loss_cls: 0.01191  loss_box_reg: 0.02824  loss_mask: 0.0452  loss_rpn_cls: 0.0003432  loss_rpn_loc: 0.003284  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:39] d2.utils.events INFO:  eta: 0:20:27  iter: 76059  total_loss: 0.09094  loss_cls: 0.01333  loss_box_reg: 0.02121  loss_mask: 0.04181  loss_rpn_cls: 0.0003704  loss_rpn_loc: 0.005047  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:41] d2.utils.events INFO:  eta: 0:20:25  iter: 76079  total_loss: 0.07334  loss_cls: 0.008543  loss_box_reg: 0.01921  loss_mask: 0.04153  loss_rpn_cls: 0.0001591  loss_rpn_loc: 0.002189  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:29:43] d2.utils.events INFO:  eta: 0:20:23  iter: 76099  total_loss: 0.08544  loss_cls: 0.01357  loss_box_reg: 0.01978  loss_mask: 0.04772  loss_rpn_cls: 0.0002305  loss_rpn_loc: 0.003028  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:45] d2.utils.events INFO:  eta: 0:20:19  iter: 76119  total_loss: 0.07749  loss_cls: 0.00808  loss_box_reg: 0.0259  loss_mask: 0.03851  loss_rpn_cls: 0.0001554  loss_rpn_loc: 0.001944  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:46] d2.utils.events INFO:  eta: 0:20:20  iter: 76139  total_loss: 0.1105  loss_cls: 0.01468  loss_box_reg: 0.03433  loss_mask: 0.05497  loss_rpn_cls: 0.000279  loss_rpn_loc: 0.00416  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:48] d2.utils.events INFO:  eta: 0:20:18  iter: 76159  total_loss: 0.07209  loss_cls: 0.007434  loss_box_reg: 0.0184  loss_mask: 0.04298  loss_rpn_cls: 0.0001984  loss_rpn_loc: 0.004011  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:50] d2.utils.events INFO:  eta: 0:20:16  iter: 76179  total_loss: 0.08369  loss_cls: 0.007365  loss_box_reg: 0.02049  loss_mask: 0.04416  loss_rpn_cls: 0.0001801  loss_rpn_loc: 0.002326  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:52] d2.utils.events INFO:  eta: 0:20:14  iter: 76199  total_loss: 0.06446  loss_cls: 0.006636  loss_box_reg: 0.01748  loss_mask: 0.04185  loss_rpn_cls: 0.0001474  loss_rpn_loc: 0.001443  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:29:53] d2.utils.events INFO:  eta: 0:20:11  iter: 76219  total_loss: 0.07189  loss_cls: 0.008124  loss_box_reg: 0.0194  loss_mask: 0.03846  loss_rpn_cls: 0.0001824  loss_rpn_loc: 0.003148  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:29:55] d2.utils.events INFO:  eta: 0:20:10  iter: 76239  total_loss: 0.0828  loss_cls: 0.01013  loss_box_reg: 0.01995  loss_mask: 0.04864  loss_rpn_cls: 0.0002564  loss_rpn_loc: 0.003436  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:29:57] d2.utils.events INFO:  eta: 0:20:08  iter: 76259  total_loss: 0.07125  loss_cls: 0.01056  loss_box_reg: 0.02332  loss_mask: 0.04219  loss_rpn_cls: 0.0001839  loss_rpn_loc: 0.002725  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:29:59] d2.utils.events INFO:  eta: 0:20:10  iter: 76279  total_loss: 0.118  loss_cls: 0.0123  loss_box_reg: 0.03719  loss_mask: 0.06087  loss_rpn_cls: 0.0003893  loss_rpn_loc: 0.003984  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:00] d2.utils.events INFO:  eta: 0:20:08  iter: 76299  total_loss: 0.08226  loss_cls: 0.01141  loss_box_reg: 0.03028  loss_mask: 0.04192  loss_rpn_cls: 0.0004235  loss_rpn_loc: 0.003692  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:02] d2.utils.events INFO:  eta: 0:20:05  iter: 76319  total_loss: 0.07727  loss_cls: 0.00603  loss_box_reg: 0.01615  loss_mask: 0.04656  loss_rpn_cls: 0.0002077  loss_rpn_loc: 0.002549  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:04] d2.utils.events INFO:  eta: 0:20:04  iter: 76339  total_loss: 0.06591  loss_cls: 0.009523  loss_box_reg: 0.021  loss_mask: 0.04038  loss_rpn_cls: 0.0001324  loss_rpn_loc: 0.002782  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:06] d2.utils.events INFO:  eta: 0:20:03  iter: 76359  total_loss: 0.1039  loss_cls: 0.01129  loss_box_reg: 0.03786  loss_mask: 0.0601  loss_rpn_cls: 0.0003411  loss_rpn_loc: 0.004181  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:07] d2.utils.events INFO:  eta: 0:19:58  iter: 76379  total_loss: 0.07075  loss_cls: 0.008974  loss_box_reg: 0.02106  loss_mask: 0.0375  loss_rpn_cls: 0.0001312  loss_rpn_loc: 0.002146  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:09] d2.utils.events INFO:  eta: 0:19:56  iter: 76399  total_loss: 0.07284  loss_cls: 0.01357  loss_box_reg: 0.01931  loss_mask: 0.03758  loss_rpn_cls: 0.0002201  loss_rpn_loc: 0.002006  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:11] d2.utils.events INFO:  eta: 0:19:54  iter: 76419  total_loss: 0.07712  loss_cls: 0.009797  loss_box_reg: 0.02284  loss_mask: 0.03679  loss_rpn_cls: 0.0002794  loss_rpn_loc: 0.002459  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:13] d2.utils.events INFO:  eta: 0:19:53  iter: 76439  total_loss: 0.07959  loss_cls: 0.01034  loss_box_reg: 0.02249  loss_mask: 0.0477  loss_rpn_cls: 0.0002525  loss_rpn_loc: 0.003179  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:15] d2.utils.events INFO:  eta: 0:19:52  iter: 76459  total_loss: 0.09919  loss_cls: 0.01505  loss_box_reg: 0.02981  loss_mask: 0.04942  loss_rpn_cls: 0.000339  loss_rpn_loc: 0.002491  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:16] d2.utils.events INFO:  eta: 0:19:49  iter: 76479  total_loss: 0.06155  loss_cls: 0.007676  loss_box_reg: 0.009816  loss_mask: 0.04032  loss_rpn_cls: 9.506e-05  loss_rpn_loc: 0.001442  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:18] d2.utils.events INFO:  eta: 0:19:47  iter: 76499  total_loss: 0.08805  loss_cls: 0.01154  loss_box_reg: 0.02304  loss_mask: 0.04611  loss_rpn_cls: 0.0002684  loss_rpn_loc: 0.002611  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:30:20] d2.utils.events INFO:  eta: 0:19:45  iter: 76519  total_loss: 0.05973  loss_cls: 0.006346  loss_box_reg: 0.01405  loss_mask: 0.03572  loss_rpn_cls: 8.662e-05  loss_rpn_loc: 0.001898  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:30:21] d2.utils.events INFO:  eta: 0:19:43  iter: 76539  total_loss: 0.08275  loss_cls: 0.01191  loss_box_reg: 0.02434  loss_mask: 0.05114  loss_rpn_cls: 0.000249  loss_rpn_loc: 0.002566  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:23] d2.utils.events INFO:  eta: 0:19:43  iter: 76559  total_loss: 0.07734  loss_cls: 0.01335  loss_box_reg: 0.02103  loss_mask: 0.04285  loss_rpn_cls: 0.0001442  loss_rpn_loc: 0.003063  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:25] d2.utils.events INFO:  eta: 0:19:41  iter: 76579  total_loss: 0.1089  loss_cls: 0.01476  loss_box_reg: 0.03814  loss_mask: 0.05685  loss_rpn_cls: 0.0006351  loss_rpn_loc: 0.005176  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:27] d2.utils.events INFO:  eta: 0:19:41  iter: 76599  total_loss: 0.09863  loss_cls: 0.01874  loss_box_reg: 0.03126  loss_mask: 0.05425  loss_rpn_cls: 0.0002877  loss_rpn_loc: 0.004618  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:30:29] d2.utils.events INFO:  eta: 0:19:39  iter: 76619  total_loss: 0.08332  loss_cls: 0.007837  loss_box_reg: 0.02007  loss_mask: 0.03768  loss_rpn_cls: 0.000283  loss_rpn_loc: 0.004146  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:30] d2.utils.events INFO:  eta: 0:19:38  iter: 76639  total_loss: 0.09087  loss_cls: 0.01125  loss_box_reg: 0.02948  loss_mask: 0.04759  loss_rpn_cls: 0.0001797  loss_rpn_loc: 0.003476  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:32] d2.utils.events INFO:  eta: 0:19:37  iter: 76659  total_loss: 0.08302  loss_cls: 0.006929  loss_box_reg: 0.0202  loss_mask: 0.04202  loss_rpn_cls: 0.0003199  loss_rpn_loc: 0.003329  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:34] d2.utils.events INFO:  eta: 0:19:35  iter: 76679  total_loss: 0.07648  loss_cls: 0.01125  loss_box_reg: 0.03059  loss_mask: 0.04082  loss_rpn_cls: 0.0002161  loss_rpn_loc: 0.003291  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:36] d2.utils.events INFO:  eta: 0:19:31  iter: 76699  total_loss: 0.07208  loss_cls: 0.008564  loss_box_reg: 0.01528  loss_mask: 0.04655  loss_rpn_cls: 0.0001547  loss_rpn_loc: 0.001751  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:37] d2.utils.events INFO:  eta: 0:19:28  iter: 76719  total_loss: 0.0878  loss_cls: 0.01026  loss_box_reg: 0.02557  loss_mask: 0.04295  loss_rpn_cls: 0.0003022  loss_rpn_loc: 0.004444  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:39] d2.utils.events INFO:  eta: 0:19:27  iter: 76739  total_loss: 0.07699  loss_cls: 0.009238  loss_box_reg: 0.0209  loss_mask: 0.04029  loss_rpn_cls: 0.0001237  loss_rpn_loc: 0.002755  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:41] d2.utils.events INFO:  eta: 0:19:28  iter: 76759  total_loss: 0.07759  loss_cls: 0.01106  loss_box_reg: 0.02107  loss_mask: 0.04354  loss_rpn_cls: 0.0001695  loss_rpn_loc: 0.002345  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:43] d2.utils.events INFO:  eta: 0:19:25  iter: 76779  total_loss: 0.0728  loss_cls: 0.005908  loss_box_reg: 0.01702  loss_mask: 0.04176  loss_rpn_cls: 0.0001366  loss_rpn_loc: 0.001957  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:44] d2.utils.events INFO:  eta: 0:19:21  iter: 76799  total_loss: 0.09294  loss_cls: 0.01047  loss_box_reg: 0.02117  loss_mask: 0.05681  loss_rpn_cls: 0.0001787  loss_rpn_loc: 0.003512  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:46] d2.utils.events INFO:  eta: 0:19:21  iter: 76819  total_loss: 0.07545  loss_cls: 0.01142  loss_box_reg: 0.01817  loss_mask: 0.0469  loss_rpn_cls: 0.0001308  loss_rpn_loc: 0.002339  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:48] d2.utils.events INFO:  eta: 0:19:21  iter: 76839  total_loss: 0.08444  loss_cls: 0.01415  loss_box_reg: 0.03083  loss_mask: 0.05312  loss_rpn_cls: 0.0003446  loss_rpn_loc: 0.003398  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:30:50] d2.utils.events INFO:  eta: 0:19:19  iter: 76859  total_loss: 0.0752  loss_cls: 0.008911  loss_box_reg: 0.0188  loss_mask: 0.04555  loss_rpn_cls: 0.0001706  loss_rpn_loc: 0.00307  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:30:52] d2.utils.events INFO:  eta: 0:19:16  iter: 76879  total_loss: 0.07306  loss_cls: 0.008093  loss_box_reg: 0.01917  loss_mask: 0.04249  loss_rpn_cls: 0.0001994  loss_rpn_loc: 0.002805  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:53] d2.utils.events INFO:  eta: 0:19:12  iter: 76899  total_loss: 0.06102  loss_cls: 0.005612  loss_box_reg: 0.01197  loss_mask: 0.03429  loss_rpn_cls: 0.0001235  loss_rpn_loc: 0.002371  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:55] d2.utils.events INFO:  eta: 0:19:13  iter: 76919  total_loss: 0.08089  loss_cls: 0.01167  loss_box_reg: 0.02383  loss_mask: 0.04351  loss_rpn_cls: 0.0001646  loss_rpn_loc: 0.002758  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:30:57] d2.utils.events INFO:  eta: 0:19:12  iter: 76939  total_loss: 0.08531  loss_cls: 0.01034  loss_box_reg: 0.03013  loss_mask: 0.04202  loss_rpn_cls: 0.0001727  loss_rpn_loc: 0.002394  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:30:59] d2.utils.events INFO:  eta: 0:19:10  iter: 76959  total_loss: 0.09434  loss_cls: 0.01735  loss_box_reg: 0.0289  loss_mask: 0.04905  loss_rpn_cls: 0.000322  loss_rpn_loc: 0.004585  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:00] d2.utils.events INFO:  eta: 0:19:08  iter: 76979  total_loss: 0.06488  loss_cls: 0.009026  loss_box_reg: 0.01442  loss_mask: 0.0361  loss_rpn_cls: 7.801e-05  loss_rpn_loc: 0.001946  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:02] d2.utils.events INFO:  eta: 0:19:04  iter: 76999  total_loss: 0.1336  loss_cls: 0.01709  loss_box_reg: 0.04195  loss_mask: 0.06491  loss_rpn_cls: 0.0004582  loss_rpn_loc: 0.00596  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:04] d2.utils.events INFO:  eta: 0:19:03  iter: 77019  total_loss: 0.07761  loss_cls: 0.01279  loss_box_reg: 0.02286  loss_mask: 0.0439  loss_rpn_cls: 0.0003478  loss_rpn_loc: 0.00249  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:06] d2.utils.events INFO:  eta: 0:19:00  iter: 77039  total_loss: 0.08857  loss_cls: 0.01218  loss_box_reg: 0.02808  loss_mask: 0.04406  loss_rpn_cls: 0.000348  loss_rpn_loc: 0.002724  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:07] d2.utils.events INFO:  eta: 0:18:58  iter: 77059  total_loss: 0.07356  loss_cls: 0.009001  loss_box_reg: 0.02063  loss_mask: 0.03655  loss_rpn_cls: 0.0002484  loss_rpn_loc: 0.002157  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:09] d2.utils.events INFO:  eta: 0:18:55  iter: 77079  total_loss: 0.06613  loss_cls: 0.01054  loss_box_reg: 0.01808  loss_mask: 0.03976  loss_rpn_cls: 0.0002327  loss_rpn_loc: 0.002463  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:11] d2.utils.events INFO:  eta: 0:18:54  iter: 77099  total_loss: 0.06161  loss_cls: 0.01093  loss_box_reg: 0.01903  loss_mask: 0.03515  loss_rpn_cls: 0.0003568  loss_rpn_loc: 0.002215  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:13] d2.utils.events INFO:  eta: 0:18:53  iter: 77119  total_loss: 0.07972  loss_cls: 0.009898  loss_box_reg: 0.02604  loss_mask: 0.05001  loss_rpn_cls: 0.0003299  loss_rpn_loc: 0.00383  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:14] d2.utils.events INFO:  eta: 0:18:51  iter: 77139  total_loss: 0.1259  loss_cls: 0.01674  loss_box_reg: 0.03599  loss_mask: 0.06194  loss_rpn_cls: 0.0003459  loss_rpn_loc: 0.005661  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:16] d2.utils.events INFO:  eta: 0:18:49  iter: 77159  total_loss: 0.07094  loss_cls: 0.009075  loss_box_reg: 0.01712  loss_mask: 0.0393  loss_rpn_cls: 5.789e-05  loss_rpn_loc: 0.001416  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:18] d2.utils.events INFO:  eta: 0:18:47  iter: 77179  total_loss: 0.06204  loss_cls: 0.009036  loss_box_reg: 0.01815  loss_mask: 0.03634  loss_rpn_cls: 0.0001392  loss_rpn_loc: 0.002523  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:20] d2.utils.events INFO:  eta: 0:18:49  iter: 77199  total_loss: 0.1061  loss_cls: 0.01629  loss_box_reg: 0.03074  loss_mask: 0.05416  loss_rpn_cls: 0.0003235  loss_rpn_loc: 0.004521  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:22] d2.utils.events INFO:  eta: 0:18:48  iter: 77219  total_loss: 0.08671  loss_cls: 0.01172  loss_box_reg: 0.02537  loss_mask: 0.0433  loss_rpn_cls: 0.0001851  loss_rpn_loc: 0.003225  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:23] d2.utils.events INFO:  eta: 0:18:45  iter: 77239  total_loss: 0.07176  loss_cls: 0.00936  loss_box_reg: 0.02114  loss_mask: 0.03917  loss_rpn_cls: 0.0001495  loss_rpn_loc: 0.002964  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:25] d2.utils.events INFO:  eta: 0:18:43  iter: 77259  total_loss: 0.07845  loss_cls: 0.008688  loss_box_reg: 0.02202  loss_mask: 0.04628  loss_rpn_cls: 0.0002181  loss_rpn_loc: 0.003353  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:31:27] d2.utils.events INFO:  eta: 0:18:41  iter: 77279  total_loss: 0.08208  loss_cls: 0.006474  loss_box_reg: 0.02049  loss_mask: 0.04246  loss_rpn_cls: 0.0002556  loss_rpn_loc: 0.002819  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:29] d2.utils.events INFO:  eta: 0:18:39  iter: 77299  total_loss: 0.09756  loss_cls: 0.01306  loss_box_reg: 0.02578  loss_mask: 0.05361  loss_rpn_cls: 0.0002271  loss_rpn_loc: 0.002389  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:30] d2.utils.events INFO:  eta: 0:18:38  iter: 77319  total_loss: 0.07582  loss_cls: 0.008752  loss_box_reg: 0.01848  loss_mask: 0.04666  loss_rpn_cls: 0.000316  loss_rpn_loc: 0.002739  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:32] d2.utils.events INFO:  eta: 0:18:35  iter: 77339  total_loss: 0.08363  loss_cls: 0.008855  loss_box_reg: 0.02495  loss_mask: 0.04673  loss_rpn_cls: 0.0004372  loss_rpn_loc: 0.002639  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:34] d2.utils.events INFO:  eta: 0:18:32  iter: 77359  total_loss: 0.0875  loss_cls: 0.01503  loss_box_reg: 0.03157  loss_mask: 0.04797  loss_rpn_cls: 0.0004195  loss_rpn_loc: 0.00332  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:36] d2.utils.events INFO:  eta: 0:18:32  iter: 77379  total_loss: 0.06912  loss_cls: 0.007762  loss_box_reg: 0.01908  loss_mask: 0.03791  loss_rpn_cls: 0.0001558  loss_rpn_loc: 0.002269  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:37] d2.utils.events INFO:  eta: 0:18:29  iter: 77399  total_loss: 0.08063  loss_cls: 0.007153  loss_box_reg: 0.0213  loss_mask: 0.0414  loss_rpn_cls: 0.0002127  loss_rpn_loc: 0.002741  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:39] d2.utils.events INFO:  eta: 0:18:25  iter: 77419  total_loss: 0.07363  loss_cls: 0.009802  loss_box_reg: 0.01772  loss_mask: 0.04154  loss_rpn_cls: 0.000158  loss_rpn_loc: 0.00205  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:31:41] d2.utils.events INFO:  eta: 0:18:26  iter: 77439  total_loss: 0.1305  loss_cls: 0.01733  loss_box_reg: 0.04068  loss_mask: 0.06405  loss_rpn_cls: 0.0005474  loss_rpn_loc: 0.006744  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:43] d2.utils.events INFO:  eta: 0:18:26  iter: 77459  total_loss: 0.1355  loss_cls: 0.01372  loss_box_reg: 0.04113  loss_mask: 0.06819  loss_rpn_cls: 0.0008329  loss_rpn_loc: 0.009037  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:45] d2.utils.events INFO:  eta: 0:18:29  iter: 77479  total_loss: 0.1328  loss_cls: 0.01492  loss_box_reg: 0.04217  loss_mask: 0.0673  loss_rpn_cls: 0.0003904  loss_rpn_loc: 0.006411  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:31:46] d2.utils.events INFO:  eta: 0:18:27  iter: 77499  total_loss: 0.1121  loss_cls: 0.01428  loss_box_reg: 0.03644  loss_mask: 0.05273  loss_rpn_cls: 0.0004612  loss_rpn_loc: 0.002861  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:48] d2.utils.events INFO:  eta: 0:18:25  iter: 77519  total_loss: 0.05605  loss_cls: 0.006126  loss_box_reg: 0.009336  loss_mask: 0.04374  loss_rpn_cls: 0.0001309  loss_rpn_loc: 0.002062  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:50] d2.utils.events INFO:  eta: 0:18:24  iter: 77539  total_loss: 0.07692  loss_cls: 0.007975  loss_box_reg: 0.01808  loss_mask: 0.03969  loss_rpn_cls: 0.0001543  loss_rpn_loc: 0.002426  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:51] d2.utils.events INFO:  eta: 0:18:21  iter: 77559  total_loss: 0.07515  loss_cls: 0.007377  loss_box_reg: 0.02114  loss_mask: 0.04243  loss_rpn_cls: 0.0004132  loss_rpn_loc: 0.002389  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:53] d2.utils.events INFO:  eta: 0:18:16  iter: 77579  total_loss: 0.06345  loss_cls: 0.007961  loss_box_reg: 0.01546  loss_mask: 0.04291  loss_rpn_cls: 0.0001882  loss_rpn_loc: 0.001756  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:31:55] d2.utils.events INFO:  eta: 0:18:13  iter: 77599  total_loss: 0.07896  loss_cls: 0.01229  loss_box_reg: 0.02232  loss_mask: 0.03857  loss_rpn_cls: 0.0001574  loss_rpn_loc: 0.002675  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:57] d2.utils.events INFO:  eta: 0:18:09  iter: 77619  total_loss: 0.06621  loss_cls: 0.005448  loss_box_reg: 0.01532  loss_mask: 0.03748  loss_rpn_cls: 9.843e-05  loss_rpn_loc: 0.001797  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:31:58] d2.utils.events INFO:  eta: 0:18:09  iter: 77639  total_loss: 0.08421  loss_cls: 0.008988  loss_box_reg: 0.02484  loss_mask: 0.04751  loss_rpn_cls: 9.288e-05  loss_rpn_loc: 0.002168  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:00] d2.utils.events INFO:  eta: 0:18:06  iter: 77659  total_loss: 0.07914  loss_cls: 0.005362  loss_box_reg: 0.02379  loss_mask: 0.03964  loss_rpn_cls: 0.00017  loss_rpn_loc: 0.001893  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:02] d2.utils.events INFO:  eta: 0:18:05  iter: 77679  total_loss: 0.07284  loss_cls: 0.009973  loss_box_reg: 0.02361  loss_mask: 0.03856  loss_rpn_cls: 0.0002605  loss_rpn_loc: 0.003146  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:04] d2.utils.events INFO:  eta: 0:18:04  iter: 77699  total_loss: 0.08876  loss_cls: 0.01221  loss_box_reg: 0.02533  loss_mask: 0.0505  loss_rpn_cls: 0.0001613  loss_rpn_loc: 0.003235  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:06] d2.utils.events INFO:  eta: 0:18:03  iter: 77719  total_loss: 0.07038  loss_cls: 0.009074  loss_box_reg: 0.0181  loss_mask: 0.04267  loss_rpn_cls: 0.0002043  loss_rpn_loc: 0.002343  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:07] d2.utils.events INFO:  eta: 0:18:01  iter: 77739  total_loss: 0.07677  loss_cls: 0.009749  loss_box_reg: 0.02472  loss_mask: 0.04123  loss_rpn_cls: 0.0001199  loss_rpn_loc: 0.002232  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:09] d2.utils.events INFO:  eta: 0:17:58  iter: 77759  total_loss: 0.05902  loss_cls: 0.008194  loss_box_reg: 0.01805  loss_mask: 0.03613  loss_rpn_cls: 0.0001857  loss_rpn_loc: 0.002531  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:11] d2.utils.events INFO:  eta: 0:17:57  iter: 77779  total_loss: 0.08686  loss_cls: 0.008575  loss_box_reg: 0.02081  loss_mask: 0.04329  loss_rpn_cls: 0.000258  loss_rpn_loc: 0.002579  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:13] d2.utils.events INFO:  eta: 0:17:55  iter: 77799  total_loss: 0.07449  loss_cls: 0.006022  loss_box_reg: 0.01443  loss_mask: 0.03644  loss_rpn_cls: 0.0001283  loss_rpn_loc: 0.001925  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:14] d2.utils.events INFO:  eta: 0:17:53  iter: 77819  total_loss: 0.08303  loss_cls: 0.008429  loss_box_reg: 0.02085  loss_mask: 0.04909  loss_rpn_cls: 0.0002266  loss_rpn_loc: 0.001822  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:16] d2.utils.events INFO:  eta: 0:17:49  iter: 77839  total_loss: 0.08405  loss_cls: 0.01065  loss_box_reg: 0.02884  loss_mask: 0.04948  loss_rpn_cls: 0.0003606  loss_rpn_loc: 0.003371  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:18] d2.utils.events INFO:  eta: 0:17:49  iter: 77859  total_loss: 0.07847  loss_cls: 0.01124  loss_box_reg: 0.02227  loss_mask: 0.04064  loss_rpn_cls: 0.0002844  loss_rpn_loc: 0.00308  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:20] d2.utils.events INFO:  eta: 0:17:48  iter: 77879  total_loss: 0.07316  loss_cls: 0.008213  loss_box_reg: 0.02507  loss_mask: 0.04603  loss_rpn_cls: 0.0002148  loss_rpn_loc: 0.002954  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:21] d2.utils.events INFO:  eta: 0:17:48  iter: 77899  total_loss: 0.08125  loss_cls: 0.009312  loss_box_reg: 0.02261  loss_mask: 0.05843  loss_rpn_cls: 8.679e-05  loss_rpn_loc: 0.002448  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:23] d2.utils.events INFO:  eta: 0:17:46  iter: 77919  total_loss: 0.07562  loss_cls: 0.009093  loss_box_reg: 0.02165  loss_mask: 0.03743  loss_rpn_cls: 0.0002678  loss_rpn_loc: 0.00427  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:25] d2.utils.events INFO:  eta: 0:17:43  iter: 77939  total_loss: 0.08259  loss_cls: 0.00938  loss_box_reg: 0.02393  loss_mask: 0.04137  loss_rpn_cls: 0.000298  loss_rpn_loc: 0.005978  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:27] d2.utils.events INFO:  eta: 0:17:41  iter: 77959  total_loss: 0.06113  loss_cls: 0.007768  loss_box_reg: 0.01758  loss_mask: 0.03771  loss_rpn_cls: 0.0001504  loss_rpn_loc: 0.001752  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:28] d2.utils.events INFO:  eta: 0:17:41  iter: 77979  total_loss: 0.08751  loss_cls: 0.01152  loss_box_reg: 0.02406  loss_mask: 0.04374  loss_rpn_cls: 0.0002146  loss_rpn_loc: 0.002512  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:30] d2.utils.events INFO:  eta: 0:17:39  iter: 77999  total_loss: 0.09161  loss_cls: 0.009977  loss_box_reg: 0.02362  loss_mask: 0.05118  loss_rpn_cls: 0.000296  loss_rpn_loc: 0.004585  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:32] d2.utils.events INFO:  eta: 0:17:37  iter: 78019  total_loss: 0.07508  loss_cls: 0.009631  loss_box_reg: 0.01731  loss_mask: 0.03987  loss_rpn_cls: 0.0002285  loss_rpn_loc: 0.003148  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:34] d2.utils.events INFO:  eta: 0:17:33  iter: 78039  total_loss: 0.0642  loss_cls: 0.006813  loss_box_reg: 0.01718  loss_mask: 0.04082  loss_rpn_cls: 0.000131  loss_rpn_loc: 0.002047  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:35] d2.utils.events INFO:  eta: 0:17:32  iter: 78059  total_loss: 0.1103  loss_cls: 0.01344  loss_box_reg: 0.03174  loss_mask: 0.06124  loss_rpn_cls: 0.0002386  loss_rpn_loc: 0.003889  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:37] d2.utils.events INFO:  eta: 0:17:32  iter: 78079  total_loss: 0.1296  loss_cls: 0.01848  loss_box_reg: 0.0412  loss_mask: 0.05781  loss_rpn_cls: 0.0003736  loss_rpn_loc: 0.005235  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:39] d2.utils.events INFO:  eta: 0:17:28  iter: 78099  total_loss: 0.06369  loss_cls: 0.0102  loss_box_reg: 0.01226  loss_mask: 0.04095  loss_rpn_cls: 8.903e-05  loss_rpn_loc: 0.00128  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:41] d2.utils.events INFO:  eta: 0:17:26  iter: 78119  total_loss: 0.08671  loss_cls: 0.01186  loss_box_reg: 0.02907  loss_mask: 0.04516  loss_rpn_cls: 0.0001252  loss_rpn_loc: 0.002592  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:42] d2.utils.events INFO:  eta: 0:17:24  iter: 78139  total_loss: 0.07499  loss_cls: 0.009145  loss_box_reg: 0.02245  loss_mask: 0.0365  loss_rpn_cls: 0.0001139  loss_rpn_loc: 0.002167  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:44] d2.utils.events INFO:  eta: 0:17:22  iter: 78159  total_loss: 0.06913  loss_cls: 0.008532  loss_box_reg: 0.01886  loss_mask: 0.03734  loss_rpn_cls: 0.0001672  loss_rpn_loc: 0.002726  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:46] d2.utils.events INFO:  eta: 0:17:20  iter: 78179  total_loss: 0.06054  loss_cls: 0.005454  loss_box_reg: 0.02014  loss_mask: 0.03387  loss_rpn_cls: 0.0002242  loss_rpn_loc: 0.002298  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:48] d2.utils.events INFO:  eta: 0:17:18  iter: 78199  total_loss: 0.09003  loss_cls: 0.009771  loss_box_reg: 0.02863  loss_mask: 0.04539  loss_rpn_cls: 0.0003878  loss_rpn_loc: 0.00296  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:49] d2.utils.events INFO:  eta: 0:17:16  iter: 78219  total_loss: 0.06181  loss_cls: 0.006194  loss_box_reg: 0.01485  loss_mask: 0.03869  loss_rpn_cls: 0.0001695  loss_rpn_loc: 0.001768  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:51] d2.utils.events INFO:  eta: 0:17:16  iter: 78239  total_loss: 0.1054  loss_cls: 0.01456  loss_box_reg: 0.03276  loss_mask: 0.06274  loss_rpn_cls: 0.0003816  loss_rpn_loc: 0.00483  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:32:53] d2.utils.events INFO:  eta: 0:17:14  iter: 78259  total_loss: 0.08929  loss_cls: 0.0077  loss_box_reg: 0.02129  loss_mask: 0.04992  loss_rpn_cls: 0.0004244  loss_rpn_loc: 0.004394  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:55] d2.utils.events INFO:  eta: 0:17:11  iter: 78279  total_loss: 0.06741  loss_cls: 0.009155  loss_box_reg: 0.01716  loss_mask: 0.04143  loss_rpn_cls: 0.0001701  loss_rpn_loc: 0.002084  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:32:57] d2.utils.events INFO:  eta: 0:17:09  iter: 78299  total_loss: 0.06897  loss_cls: 0.006809  loss_box_reg: 0.02052  loss_mask: 0.03478  loss_rpn_cls: 0.0002818  loss_rpn_loc: 0.003788  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:32:58] d2.utils.events INFO:  eta: 0:17:07  iter: 78319  total_loss: 0.08021  loss_cls: 0.007835  loss_box_reg: 0.01533  loss_mask: 0.05149  loss_rpn_cls: 0.0001644  loss_rpn_loc: 0.001181  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:00] d2.utils.events INFO:  eta: 0:17:06  iter: 78339  total_loss: 0.08095  loss_cls: 0.01167  loss_box_reg: 0.02165  loss_mask: 0.04475  loss_rpn_cls: 0.0003321  loss_rpn_loc: 0.004098  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:02] d2.utils.events INFO:  eta: 0:17:01  iter: 78359  total_loss: 0.06973  loss_cls: 0.006535  loss_box_reg: 0.01734  loss_mask: 0.0409  loss_rpn_cls: 0.0001472  loss_rpn_loc: 0.001983  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:04] d2.utils.events INFO:  eta: 0:17:02  iter: 78379  total_loss: 0.0919  loss_cls: 0.01082  loss_box_reg: 0.02369  loss_mask: 0.04364  loss_rpn_cls: 0.0001534  loss_rpn_loc: 0.002421  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:05] d2.utils.events INFO:  eta: 0:17:00  iter: 78399  total_loss: 0.06289  loss_cls: 0.008222  loss_box_reg: 0.01526  loss_mask: 0.0376  loss_rpn_cls: 0.0001004  loss_rpn_loc: 0.001476  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:07] d2.utils.events INFO:  eta: 0:16:59  iter: 78419  total_loss: 0.07425  loss_cls: 0.009705  loss_box_reg: 0.02047  loss_mask: 0.04297  loss_rpn_cls: 0.0002052  loss_rpn_loc: 0.003607  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:09] d2.utils.events INFO:  eta: 0:16:54  iter: 78439  total_loss: 0.07298  loss_cls: 0.00839  loss_box_reg: 0.02014  loss_mask: 0.03982  loss_rpn_cls: 0.0002286  loss_rpn_loc: 0.002564  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:10] d2.utils.events INFO:  eta: 0:16:49  iter: 78459  total_loss: 0.0775  loss_cls: 0.01109  loss_box_reg: 0.02161  loss_mask: 0.04529  loss_rpn_cls: 0.0002702  loss_rpn_loc: 0.002417  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:12] d2.utils.events INFO:  eta: 0:16:47  iter: 78479  total_loss: 0.09598  loss_cls: 0.01391  loss_box_reg: 0.02975  loss_mask: 0.05673  loss_rpn_cls: 0.0002821  loss_rpn_loc: 0.003668  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:14] d2.utils.events INFO:  eta: 0:16:45  iter: 78499  total_loss: 0.07699  loss_cls: 0.01138  loss_box_reg: 0.02286  loss_mask: 0.04574  loss_rpn_cls: 0.0001716  loss_rpn_loc: 0.001608  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:16] d2.utils.events INFO:  eta: 0:16:45  iter: 78519  total_loss: 0.1439  loss_cls: 0.01601  loss_box_reg: 0.03513  loss_mask: 0.0614  loss_rpn_cls: 0.0006472  loss_rpn_loc: 0.0063  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:18] d2.utils.events INFO:  eta: 0:16:45  iter: 78539  total_loss: 0.09615  loss_cls: 0.01209  loss_box_reg: 0.02837  loss_mask: 0.04897  loss_rpn_cls: 0.0003784  loss_rpn_loc: 0.003532  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:33:19] d2.utils.events INFO:  eta: 0:16:44  iter: 78559  total_loss: 0.08432  loss_cls: 0.009184  loss_box_reg: 0.022  loss_mask: 0.04564  loss_rpn_cls: 0.0001645  loss_rpn_loc: 0.002642  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:21] d2.utils.events INFO:  eta: 0:16:45  iter: 78579  total_loss: 0.1298  loss_cls: 0.0167  loss_box_reg: 0.04164  loss_mask: 0.06069  loss_rpn_cls: 0.0004624  loss_rpn_loc: 0.005216  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:23] d2.utils.events INFO:  eta: 0:16:43  iter: 78599  total_loss: 0.08667  loss_cls: 0.01033  loss_box_reg: 0.02417  loss_mask: 0.03848  loss_rpn_cls: 0.000185  loss_rpn_loc: 0.003133  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:25] d2.utils.events INFO:  eta: 0:16:42  iter: 78619  total_loss: 0.07745  loss_cls: 0.008636  loss_box_reg: 0.0189  loss_mask: 0.03897  loss_rpn_cls: 0.0002373  loss_rpn_loc: 0.00294  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:27] d2.utils.events INFO:  eta: 0:16:40  iter: 78639  total_loss: 0.07196  loss_cls: 0.008773  loss_box_reg: 0.01614  loss_mask: 0.04514  loss_rpn_cls: 0.0001243  loss_rpn_loc: 0.002309  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:28] d2.utils.events INFO:  eta: 0:16:38  iter: 78659  total_loss: 0.0693  loss_cls: 0.006815  loss_box_reg: 0.01979  loss_mask: 0.04266  loss_rpn_cls: 9.831e-05  loss_rpn_loc: 0.001872  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:30] d2.utils.events INFO:  eta: 0:16:33  iter: 78679  total_loss: 0.05893  loss_cls: 0.00658  loss_box_reg: 0.0146  loss_mask: 0.03883  loss_rpn_cls: 0.0003005  loss_rpn_loc: 0.002329  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:32] d2.utils.events INFO:  eta: 0:16:31  iter: 78699  total_loss: 0.07851  loss_cls: 0.008475  loss_box_reg: 0.02165  loss_mask: 0.04848  loss_rpn_cls: 0.0001395  loss_rpn_loc: 0.002306  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:34] d2.utils.events INFO:  eta: 0:16:32  iter: 78719  total_loss: 0.1064  loss_cls: 0.01198  loss_box_reg: 0.03449  loss_mask: 0.05847  loss_rpn_cls: 0.0002754  loss_rpn_loc: 0.004612  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:35] d2.utils.events INFO:  eta: 0:16:28  iter: 78739  total_loss: 0.06766  loss_cls: 0.006856  loss_box_reg: 0.01932  loss_mask: 0.04303  loss_rpn_cls: 0.0001123  loss_rpn_loc: 0.001367  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:37] d2.utils.events INFO:  eta: 0:16:24  iter: 78759  total_loss: 0.05535  loss_cls: 0.004758  loss_box_reg: 0.0108  loss_mask: 0.033  loss_rpn_cls: 0.0002344  loss_rpn_loc: 0.001925  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:39] d2.utils.events INFO:  eta: 0:16:22  iter: 78779  total_loss: 0.08962  loss_cls: 0.01292  loss_box_reg: 0.02699  loss_mask: 0.04761  loss_rpn_cls: 0.0003446  loss_rpn_loc: 0.004359  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:41] d2.utils.events INFO:  eta: 0:16:25  iter: 78799  total_loss: 0.1347  loss_cls: 0.01455  loss_box_reg: 0.03808  loss_mask: 0.06522  loss_rpn_cls: 0.0004015  loss_rpn_loc: 0.006635  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:33:42] d2.utils.events INFO:  eta: 0:16:24  iter: 78819  total_loss: 0.09767  loss_cls: 0.01335  loss_box_reg: 0.03254  loss_mask: 0.04858  loss_rpn_cls: 0.0002117  loss_rpn_loc: 0.004855  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:44] d2.utils.events INFO:  eta: 0:16:22  iter: 78839  total_loss: 0.07203  loss_cls: 0.005968  loss_box_reg: 0.0192  loss_mask: 0.03786  loss_rpn_cls: 0.0001601  loss_rpn_loc: 0.001727  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:46] d2.utils.events INFO:  eta: 0:16:20  iter: 78859  total_loss: 0.1065  loss_cls: 0.01276  loss_box_reg: 0.02267  loss_mask: 0.05506  loss_rpn_cls: 0.0002992  loss_rpn_loc: 0.005198  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:33:48] d2.utils.events INFO:  eta: 0:16:19  iter: 78879  total_loss: 0.08698  loss_cls: 0.01188  loss_box_reg: 0.02487  loss_mask: 0.04297  loss_rpn_cls: 0.0002304  loss_rpn_loc: 0.002967  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:49] d2.utils.events INFO:  eta: 0:16:20  iter: 78899  total_loss: 0.08197  loss_cls: 0.01137  loss_box_reg: 0.02434  loss_mask: 0.03966  loss_rpn_cls: 0.0002926  loss_rpn_loc: 0.002734  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:51] d2.utils.events INFO:  eta: 0:16:17  iter: 78919  total_loss: 0.05885  loss_cls: 0.007879  loss_box_reg: 0.01635  loss_mask: 0.03749  loss_rpn_cls: 0.0001805  loss_rpn_loc: 0.001637  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:53] d2.utils.events INFO:  eta: 0:16:13  iter: 78939  total_loss: 0.06932  loss_cls: 0.008104  loss_box_reg: 0.01623  loss_mask: 0.04069  loss_rpn_cls: 0.0001643  loss_rpn_loc: 0.001754  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:55] d2.utils.events INFO:  eta: 0:16:11  iter: 78959  total_loss: 0.08031  loss_cls: 0.009548  loss_box_reg: 0.01997  loss_mask: 0.04905  loss_rpn_cls: 0.0003629  loss_rpn_loc: 0.002756  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:56] d2.utils.events INFO:  eta: 0:16:05  iter: 78979  total_loss: 0.06441  loss_cls: 0.008252  loss_box_reg: 0.01784  loss_mask: 0.03804  loss_rpn_cls: 9.624e-05  loss_rpn_loc: 0.001414  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:33:58] d2.utils.events INFO:  eta: 0:16:04  iter: 78999  total_loss: 0.1043  loss_cls: 0.01356  loss_box_reg: 0.03489  loss_mask: 0.04466  loss_rpn_cls: 0.0002106  loss_rpn_loc: 0.004224  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:00] d2.utils.events INFO:  eta: 0:16:02  iter: 79019  total_loss: 0.06759  loss_cls: 0.009074  loss_box_reg: 0.01848  loss_mask: 0.03672  loss_rpn_cls: 0.0001879  loss_rpn_loc: 0.00282  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:34:02] d2.utils.events INFO:  eta: 0:16:05  iter: 79039  total_loss: 0.08612  loss_cls: 0.01079  loss_box_reg: 0.02632  loss_mask: 0.0498  loss_rpn_cls: 0.0002114  loss_rpn_loc: 0.003255  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:03] d2.utils.events INFO:  eta: 0:16:02  iter: 79059  total_loss: 0.06952  loss_cls: 0.007851  loss_box_reg: 0.01885  loss_mask: 0.04555  loss_rpn_cls: 0.0002663  loss_rpn_loc: 0.003308  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:05] d2.utils.events INFO:  eta: 0:15:56  iter: 79079  total_loss: 0.0762  loss_cls: 0.01042  loss_box_reg: 0.02103  loss_mask: 0.04088  loss_rpn_cls: 0.000148  loss_rpn_loc: 0.002225  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:07] d2.utils.events INFO:  eta: 0:16:00  iter: 79099  total_loss: 0.07408  loss_cls: 0.009395  loss_box_reg: 0.02248  loss_mask: 0.04316  loss_rpn_cls: 0.0003135  loss_rpn_loc: 0.002598  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:34:09] d2.utils.events INFO:  eta: 0:15:57  iter: 79119  total_loss: 0.07095  loss_cls: 0.008584  loss_box_reg: 0.01954  loss_mask: 0.04309  loss_rpn_cls: 0.000244  loss_rpn_loc: 0.002897  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:34:10] d2.utils.events INFO:  eta: 0:15:55  iter: 79139  total_loss: 0.1126  loss_cls: 0.01211  loss_box_reg: 0.02825  loss_mask: 0.06209  loss_rpn_cls: 0.0002315  loss_rpn_loc: 0.002989  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:34:12] d2.utils.events INFO:  eta: 0:15:57  iter: 79159  total_loss: 0.09729  loss_cls: 0.01173  loss_box_reg: 0.02956  loss_mask: 0.05139  loss_rpn_cls: 0.0001979  loss_rpn_loc: 0.00293  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:14] d2.utils.events INFO:  eta: 0:15:56  iter: 79179  total_loss: 0.07835  loss_cls: 0.009274  loss_box_reg: 0.02225  loss_mask: 0.04601  loss_rpn_cls: 0.0001457  loss_rpn_loc: 0.002645  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:16] d2.utils.events INFO:  eta: 0:15:54  iter: 79199  total_loss: 0.09075  loss_cls: 0.01152  loss_box_reg: 0.03056  loss_mask: 0.04653  loss_rpn_cls: 0.0002728  loss_rpn_loc: 0.005809  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:18] d2.utils.events INFO:  eta: 0:15:53  iter: 79219  total_loss: 0.08484  loss_cls: 0.009336  loss_box_reg: 0.0189  loss_mask: 0.04435  loss_rpn_cls: 0.0003074  loss_rpn_loc: 0.002823  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:19] d2.utils.events INFO:  eta: 0:15:48  iter: 79239  total_loss: 0.06781  loss_cls: 0.007097  loss_box_reg: 0.01565  loss_mask: 0.04422  loss_rpn_cls: 0.0002495  loss_rpn_loc: 0.001726  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:34:21] d2.utils.events INFO:  eta: 0:15:47  iter: 79259  total_loss: 0.07763  loss_cls: 0.008019  loss_box_reg: 0.02318  loss_mask: 0.04123  loss_rpn_cls: 0.0002668  loss_rpn_loc: 0.003116  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:23] d2.utils.events INFO:  eta: 0:15:48  iter: 79279  total_loss: 0.0931  loss_cls: 0.01436  loss_box_reg: 0.03401  loss_mask: 0.05376  loss_rpn_cls: 0.0003372  loss_rpn_loc: 0.003892  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:25] d2.utils.events INFO:  eta: 0:15:45  iter: 79299  total_loss: 0.06946  loss_cls: 0.008127  loss_box_reg: 0.01788  loss_mask: 0.0352  loss_rpn_cls: 0.00014  loss_rpn_loc: 0.002345  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:26] d2.utils.events INFO:  eta: 0:15:44  iter: 79319  total_loss: 0.07769  loss_cls: 0.009404  loss_box_reg: 0.021  loss_mask: 0.03793  loss_rpn_cls: 0.00014  loss_rpn_loc: 0.001837  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:28] d2.utils.events INFO:  eta: 0:15:43  iter: 79339  total_loss: 0.08942  loss_cls: 0.0112  loss_box_reg: 0.02801  loss_mask: 0.05687  loss_rpn_cls: 0.0002366  loss_rpn_loc: 0.004334  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:30] d2.utils.events INFO:  eta: 0:15:42  iter: 79359  total_loss: 0.1032  loss_cls: 0.01383  loss_box_reg: 0.03442  loss_mask: 0.05801  loss_rpn_cls: 0.0002956  loss_rpn_loc: 0.004835  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:32] d2.utils.events INFO:  eta: 0:15:40  iter: 79379  total_loss: 0.06834  loss_cls: 0.008242  loss_box_reg: 0.01972  loss_mask: 0.04476  loss_rpn_cls: 9.61e-05  loss_rpn_loc: 0.002047  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:34] d2.utils.events INFO:  eta: 0:15:39  iter: 79399  total_loss: 0.08309  loss_cls: 0.01274  loss_box_reg: 0.02337  loss_mask: 0.0375  loss_rpn_cls: 0.0002055  loss_rpn_loc: 0.003365  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:35] d2.utils.events INFO:  eta: 0:15:37  iter: 79419  total_loss: 0.0739  loss_cls: 0.007892  loss_box_reg: 0.01862  loss_mask: 0.03655  loss_rpn_cls: 0.0001805  loss_rpn_loc: 0.002336  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:37] d2.utils.events INFO:  eta: 0:15:36  iter: 79439  total_loss: 0.0819  loss_cls: 0.008076  loss_box_reg: 0.02093  loss_mask: 0.04454  loss_rpn_cls: 0.0001919  loss_rpn_loc: 0.002254  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:39] d2.utils.events INFO:  eta: 0:15:33  iter: 79459  total_loss: 0.06135  loss_cls: 0.006591  loss_box_reg: 0.009201  loss_mask: 0.03715  loss_rpn_cls: 7.738e-05  loss_rpn_loc: 0.001494  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:41] d2.utils.events INFO:  eta: 0:15:33  iter: 79479  total_loss: 0.08069  loss_cls: 0.009137  loss_box_reg: 0.02077  loss_mask: 0.04353  loss_rpn_cls: 0.0002287  loss_rpn_loc: 0.002787  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:42] d2.utils.events INFO:  eta: 0:15:31  iter: 79499  total_loss: 0.0795  loss_cls: 0.009957  loss_box_reg: 0.02031  loss_mask: 0.04146  loss_rpn_cls: 0.0004215  loss_rpn_loc: 0.002959  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:44] d2.utils.events INFO:  eta: 0:15:28  iter: 79519  total_loss: 0.0612  loss_cls: 0.009813  loss_box_reg: 0.01812  loss_mask: 0.03564  loss_rpn_cls: 0.0001859  loss_rpn_loc: 0.002231  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:46] d2.utils.events INFO:  eta: 0:15:26  iter: 79539  total_loss: 0.1078  loss_cls: 0.01295  loss_box_reg: 0.03409  loss_mask: 0.06229  loss_rpn_cls: 0.0001388  loss_rpn_loc: 0.003942  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:48] d2.utils.events INFO:  eta: 0:15:24  iter: 79559  total_loss: 0.06943  loss_cls: 0.009316  loss_box_reg: 0.01743  loss_mask: 0.03797  loss_rpn_cls: 0.0003303  loss_rpn_loc: 0.002004  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:50] d2.utils.events INFO:  eta: 0:15:22  iter: 79579  total_loss: 0.07966  loss_cls: 0.01236  loss_box_reg: 0.02128  loss_mask: 0.04551  loss_rpn_cls: 0.0005302  loss_rpn_loc: 0.003357  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:51] d2.utils.events INFO:  eta: 0:15:20  iter: 79599  total_loss: 0.07612  loss_cls: 0.00656  loss_box_reg: 0.02018  loss_mask: 0.04565  loss_rpn_cls: 0.0002811  loss_rpn_loc: 0.004279  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:53] d2.utils.events INFO:  eta: 0:15:18  iter: 79619  total_loss: 0.0781  loss_cls: 0.007853  loss_box_reg: 0.02113  loss_mask: 0.038  loss_rpn_cls: 0.0001841  loss_rpn_loc: 0.002317  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:55] d2.utils.events INFO:  eta: 0:15:16  iter: 79639  total_loss: 0.05994  loss_cls: 0.005928  loss_box_reg: 0.0144  loss_mask: 0.03758  loss_rpn_cls: 0.0001415  loss_rpn_loc: 0.002397  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:34:57] d2.utils.events INFO:  eta: 0:15:15  iter: 79659  total_loss: 0.1008  loss_cls: 0.01248  loss_box_reg: 0.02902  loss_mask: 0.04929  loss_rpn_cls: 0.0002874  loss_rpn_loc: 0.004051  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:34:58] d2.utils.events INFO:  eta: 0:15:15  iter: 79679  total_loss: 0.1166  loss_cls: 0.01465  loss_box_reg: 0.03747  loss_mask: 0.05999  loss_rpn_cls: 0.0004732  loss_rpn_loc: 0.003715  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:00] d2.utils.events INFO:  eta: 0:15:13  iter: 79699  total_loss: 0.08415  loss_cls: 0.008999  loss_box_reg: 0.02313  loss_mask: 0.04134  loss_rpn_cls: 0.0004157  loss_rpn_loc: 0.002478  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:35:02] d2.utils.events INFO:  eta: 0:15:11  iter: 79719  total_loss: 0.09204  loss_cls: 0.01177  loss_box_reg: 0.02777  loss_mask: 0.05478  loss_rpn_cls: 0.0002361  loss_rpn_loc: 0.004886  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:35:04] d2.utils.events INFO:  eta: 0:15:10  iter: 79739  total_loss: 0.08038  loss_cls: 0.009185  loss_box_reg: 0.02068  loss_mask: 0.03751  loss_rpn_cls: 0.0001582  loss_rpn_loc: 0.001911  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:05] d2.utils.events INFO:  eta: 0:15:09  iter: 79759  total_loss: 0.06111  loss_cls: 0.009144  loss_box_reg: 0.01726  loss_mask: 0.03121  loss_rpn_cls: 0.0001293  loss_rpn_loc: 0.001944  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:35:07] d2.utils.events INFO:  eta: 0:15:08  iter: 79779  total_loss: 0.08242  loss_cls: 0.006626  loss_box_reg: 0.02137  loss_mask: 0.05175  loss_rpn_cls: 0.000262  loss_rpn_loc: 0.00259  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:09] d2.utils.events INFO:  eta: 0:15:03  iter: 79799  total_loss: 0.07296  loss_cls: 0.007744  loss_box_reg: 0.02122  loss_mask: 0.0421  loss_rpn_cls: 0.0002981  loss_rpn_loc: 0.003074  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:35:11] d2.utils.events INFO:  eta: 0:15:01  iter: 79819  total_loss: 0.07253  loss_cls: 0.008588  loss_box_reg: 0.01833  loss_mask: 0.03909  loss_rpn_cls: 0.0001774  loss_rpn_loc: 0.00229  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:12] d2.utils.events INFO:  eta: 0:14:59  iter: 79839  total_loss: 0.06096  loss_cls: 0.008429  loss_box_reg: 0.01681  loss_mask: 0.03932  loss_rpn_cls: 0.000145  loss_rpn_loc: 0.002284  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:14] d2.utils.events INFO:  eta: 0:14:55  iter: 79859  total_loss: 0.04596  loss_cls: 0.003037  loss_box_reg: 0.01091  loss_mask: 0.03323  loss_rpn_cls: 0.0001309  loss_rpn_loc: 0.0009895  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:35:16] d2.utils.events INFO:  eta: 0:14:52  iter: 79879  total_loss: 0.08041  loss_cls: 0.008333  loss_box_reg: 0.0189  loss_mask: 0.05573  loss_rpn_cls: 0.0003119  loss_rpn_loc: 0.003277  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:35:18] d2.utils.events INFO:  eta: 0:14:50  iter: 79899  total_loss: 0.06875  loss_cls: 0.007294  loss_box_reg: 0.02116  loss_mask: 0.04101  loss_rpn_cls: 0.0002715  loss_rpn_loc: 0.00265  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:19] d2.utils.events INFO:  eta: 0:14:48  iter: 79919  total_loss: 0.06594  loss_cls: 0.007887  loss_box_reg: 0.01665  loss_mask: 0.03999  loss_rpn_cls: 8.802e-05  loss_rpn_loc: 0.001916  time: 0.0878  data_time: 0.0020  lr: 0.00025  max_mem: 1494M
[10/27 20:35:21] d2.utils.events INFO:  eta: 0:14:47  iter: 79939  total_loss: 0.08755  loss_cls: 0.01077  loss_box_reg: 0.029  loss_mask: 0.04567  loss_rpn_cls: 0.0002237  loss_rpn_loc: 0.002862  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:35:23] d2.utils.events INFO:  eta: 0:14:46  iter: 79959  total_loss: 0.07359  loss_cls: 0.008505  loss_box_reg: 0.02215  loss_mask: 0.04062  loss_rpn_cls: 0.0002019  loss_rpn_loc: 0.002324  time: 0.0878  data_time: 0.0019  lr: 0.00025  max_mem: 1494M
[10/27 20:35:25] d2.utils.events INFO:  eta: 0:14:46  iter: 79979  total_loss: 0.08356  loss_cls: 0.01363  loss_box_reg: 0.03338  loss_mask: 0.0428  loss_rpn_cls: 0.0002766  loss_rpn_loc: 0.005225  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:35:26] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0079999.pth
[10/27 20:35:27] d2.utils.events INFO:  eta: 0:14:45  iter: 79999  total_loss: 0.08296  loss_cls: 0.01285  loss_box_reg: 0.02478  loss_mask: 0.05003  loss_rpn_cls: 0.0004451  loss_rpn_loc: 0.004525  time: 0.0878  data_time: 0.0021  lr: 0.00025  max_mem: 1494M
[10/27 20:35:29] d2.utils.events INFO:  eta: 0:14:43  iter: 80019  total_loss: 0.07339  loss_cls: 0.008624  loss_box_reg: 0.02144  loss_mask: 0.03934  loss_rpn_cls: 0.0002096  loss_rpn_loc: 0.002216  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:30] d2.utils.events INFO:  eta: 0:14:38  iter: 80039  total_loss: 0.06568  loss_cls: 0.00564  loss_box_reg: 0.01905  loss_mask: 0.04489  loss_rpn_cls: 0.000133  loss_rpn_loc: 0.001158  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:32] d2.utils.events INFO:  eta: 0:14:39  iter: 80059  total_loss: 0.1196  loss_cls: 0.01184  loss_box_reg: 0.02931  loss_mask: 0.06097  loss_rpn_cls: 0.000651  loss_rpn_loc: 0.004834  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:34] d2.utils.events INFO:  eta: 0:14:40  iter: 80079  total_loss: 0.1218  loss_cls: 0.01294  loss_box_reg: 0.0383  loss_mask: 0.06045  loss_rpn_cls: 0.0002759  loss_rpn_loc: 0.004975  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:36] d2.utils.events INFO:  eta: 0:14:38  iter: 80099  total_loss: 0.1141  loss_cls: 0.01256  loss_box_reg: 0.03515  loss_mask: 0.05627  loss_rpn_cls: 0.0003186  loss_rpn_loc: 0.004353  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:37] d2.utils.events INFO:  eta: 0:14:36  iter: 80119  total_loss: 0.08222  loss_cls: 0.01185  loss_box_reg: 0.03389  loss_mask: 0.04441  loss_rpn_cls: 0.0002418  loss_rpn_loc: 0.003078  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:39] d2.utils.events INFO:  eta: 0:14:35  iter: 80139  total_loss: 0.07652  loss_cls: 0.01104  loss_box_reg: 0.01889  loss_mask: 0.03584  loss_rpn_cls: 0.0002133  loss_rpn_loc: 0.003361  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:41] d2.utils.events INFO:  eta: 0:14:31  iter: 80159  total_loss: 0.06644  loss_cls: 0.005318  loss_box_reg: 0.01924  loss_mask: 0.04038  loss_rpn_cls: 0.0001628  loss_rpn_loc: 0.002826  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:43] d2.utils.events INFO:  eta: 0:14:29  iter: 80179  total_loss: 0.08119  loss_cls: 0.01177  loss_box_reg: 0.02518  loss_mask: 0.04508  loss_rpn_cls: 0.0001473  loss_rpn_loc: 0.002887  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:45] d2.utils.events INFO:  eta: 0:14:28  iter: 80199  total_loss: 0.08722  loss_cls: 0.01035  loss_box_reg: 0.03349  loss_mask: 0.04912  loss_rpn_cls: 0.000363  loss_rpn_loc: 0.005365  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:46] d2.utils.events INFO:  eta: 0:14:26  iter: 80219  total_loss: 0.08211  loss_cls: 0.01012  loss_box_reg: 0.0248  loss_mask: 0.04356  loss_rpn_cls: 0.0002604  loss_rpn_loc: 0.003184  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:48] d2.utils.events INFO:  eta: 0:14:25  iter: 80239  total_loss: 0.1129  loss_cls: 0.01245  loss_box_reg: 0.03079  loss_mask: 0.05681  loss_rpn_cls: 0.0003551  loss_rpn_loc: 0.005124  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:50] d2.utils.events INFO:  eta: 0:14:24  iter: 80259  total_loss: 0.09278  loss_cls: 0.01256  loss_box_reg: 0.0242  loss_mask: 0.05158  loss_rpn_cls: 0.0002062  loss_rpn_loc: 0.002663  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:52] d2.utils.events INFO:  eta: 0:14:20  iter: 80279  total_loss: 0.05984  loss_cls: 0.006239  loss_box_reg: 0.01743  loss_mask: 0.03743  loss_rpn_cls: 0.0001401  loss_rpn_loc: 0.001429  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:53] d2.utils.events INFO:  eta: 0:14:18  iter: 80299  total_loss: 0.07697  loss_cls: 0.008345  loss_box_reg: 0.0198  loss_mask: 0.04186  loss_rpn_cls: 0.0001539  loss_rpn_loc: 0.002611  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:55] d2.utils.events INFO:  eta: 0:14:17  iter: 80319  total_loss: 0.08337  loss_cls: 0.007814  loss_box_reg: 0.01697  loss_mask: 0.04524  loss_rpn_cls: 0.0001897  loss_rpn_loc: 0.00224  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:57] d2.utils.events INFO:  eta: 0:14:14  iter: 80339  total_loss: 0.05989  loss_cls: 0.006068  loss_box_reg: 0.01307  loss_mask: 0.03459  loss_rpn_cls: 0.0001361  loss_rpn_loc: 0.001816  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:35:59] d2.utils.events INFO:  eta: 0:14:11  iter: 80359  total_loss: 0.06973  loss_cls: 0.004561  loss_box_reg: 0.01484  loss_mask: 0.0454  loss_rpn_cls: 9.063e-05  loss_rpn_loc: 0.001629  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:00] d2.utils.events INFO:  eta: 0:14:09  iter: 80379  total_loss: 0.06601  loss_cls: 0.008011  loss_box_reg: 0.01592  loss_mask: 0.04021  loss_rpn_cls: 0.0001751  loss_rpn_loc: 0.00191  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:02] d2.utils.events INFO:  eta: 0:14:06  iter: 80399  total_loss: 0.0698  loss_cls: 0.005605  loss_box_reg: 0.01753  loss_mask: 0.03902  loss_rpn_cls: 0.0001786  loss_rpn_loc: 0.002757  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:04] d2.utils.events INFO:  eta: 0:14:07  iter: 80419  total_loss: 0.1155  loss_cls: 0.01553  loss_box_reg: 0.03649  loss_mask: 0.05299  loss_rpn_cls: 0.0002308  loss_rpn_loc: 0.005113  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:06] d2.utils.events INFO:  eta: 0:14:05  iter: 80439  total_loss: 0.06936  loss_cls: 0.008019  loss_box_reg: 0.01224  loss_mask: 0.04555  loss_rpn_cls: 0.0001816  loss_rpn_loc: 0.002153  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:08] d2.utils.events INFO:  eta: 0:14:04  iter: 80459  total_loss: 0.07118  loss_cls: 0.007446  loss_box_reg: 0.01738  loss_mask: 0.04452  loss_rpn_cls: 0.0002308  loss_rpn_loc: 0.002819  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:09] d2.utils.events INFO:  eta: 0:14:00  iter: 80479  total_loss: 0.07339  loss_cls: 0.007268  loss_box_reg: 0.01591  loss_mask: 0.04253  loss_rpn_cls: 0.0001456  loss_rpn_loc: 0.001574  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:11] d2.utils.events INFO:  eta: 0:13:58  iter: 80499  total_loss: 0.07624  loss_cls: 0.008103  loss_box_reg: 0.01863  loss_mask: 0.04412  loss_rpn_cls: 0.0002857  loss_rpn_loc: 0.002517  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:13] d2.utils.events INFO:  eta: 0:13:58  iter: 80519  total_loss: 0.1066  loss_cls: 0.01212  loss_box_reg: 0.0346  loss_mask: 0.05318  loss_rpn_cls: 0.0002497  loss_rpn_loc: 0.003893  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:15] d2.utils.events INFO:  eta: 0:13:54  iter: 80539  total_loss: 0.08569  loss_cls: 0.01266  loss_box_reg: 0.02275  loss_mask: 0.04261  loss_rpn_cls: 0.0002237  loss_rpn_loc: 0.00299  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:16] d2.utils.events INFO:  eta: 0:13:52  iter: 80559  total_loss: 0.06605  loss_cls: 0.007901  loss_box_reg: 0.01786  loss_mask: 0.03861  loss_rpn_cls: 0.0001859  loss_rpn_loc: 0.002496  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:18] d2.utils.events INFO:  eta: 0:13:50  iter: 80579  total_loss: 0.06579  loss_cls: 0.00789  loss_box_reg: 0.01687  loss_mask: 0.0375  loss_rpn_cls: 0.000146  loss_rpn_loc: 0.001737  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:20] d2.utils.events INFO:  eta: 0:13:48  iter: 80599  total_loss: 0.1021  loss_cls: 0.011  loss_box_reg: 0.03125  loss_mask: 0.05255  loss_rpn_cls: 0.0001562  loss_rpn_loc: 0.004329  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:22] d2.utils.events INFO:  eta: 0:13:48  iter: 80619  total_loss: 0.08159  loss_cls: 0.0105  loss_box_reg: 0.02174  loss_mask: 0.0417  loss_rpn_cls: 0.0002542  loss_rpn_loc: 0.002654  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:23] d2.utils.events INFO:  eta: 0:13:46  iter: 80639  total_loss: 0.07101  loss_cls: 0.008419  loss_box_reg: 0.01992  loss_mask: 0.03967  loss_rpn_cls: 0.0002684  loss_rpn_loc: 0.00195  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:25] d2.utils.events INFO:  eta: 0:13:43  iter: 80659  total_loss: 0.06959  loss_cls: 0.007458  loss_box_reg: 0.01418  loss_mask: 0.04784  loss_rpn_cls: 0.0001358  loss_rpn_loc: 0.00172  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:27] d2.utils.events INFO:  eta: 0:13:41  iter: 80679  total_loss: 0.08522  loss_cls: 0.0129  loss_box_reg: 0.02706  loss_mask: 0.05083  loss_rpn_cls: 0.000315  loss_rpn_loc: 0.003455  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:29] d2.utils.events INFO:  eta: 0:13:40  iter: 80699  total_loss: 0.06668  loss_cls: 0.007695  loss_box_reg: 0.02205  loss_mask: 0.03733  loss_rpn_cls: 0.0001377  loss_rpn_loc: 0.002084  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:30] d2.utils.events INFO:  eta: 0:13:37  iter: 80719  total_loss: 0.07311  loss_cls: 0.008726  loss_box_reg: 0.02049  loss_mask: 0.03798  loss_rpn_cls: 0.0002995  loss_rpn_loc: 0.00398  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:32] d2.utils.events INFO:  eta: 0:13:33  iter: 80739  total_loss: 0.05346  loss_cls: 0.006663  loss_box_reg: 0.01317  loss_mask: 0.03363  loss_rpn_cls: 0.000143  loss_rpn_loc: 0.001478  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:34] d2.utils.events INFO:  eta: 0:13:33  iter: 80759  total_loss: 0.1075  loss_cls: 0.01101  loss_box_reg: 0.03594  loss_mask: 0.05395  loss_rpn_cls: 0.0004196  loss_rpn_loc: 0.005383  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:36] d2.utils.events INFO:  eta: 0:13:31  iter: 80779  total_loss: 0.05709  loss_cls: 0.005773  loss_box_reg: 0.01149  loss_mask: 0.03888  loss_rpn_cls: 0.0001385  loss_rpn_loc: 0.001205  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:37] d2.utils.events INFO:  eta: 0:13:29  iter: 80799  total_loss: 0.08179  loss_cls: 0.008065  loss_box_reg: 0.01928  loss_mask: 0.05013  loss_rpn_cls: 0.00024  loss_rpn_loc: 0.002719  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:39] d2.utils.events INFO:  eta: 0:13:28  iter: 80819  total_loss: 0.07897  loss_cls: 0.01324  loss_box_reg: 0.02311  loss_mask: 0.03817  loss_rpn_cls: 0.0001277  loss_rpn_loc: 0.002636  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:41] d2.utils.events INFO:  eta: 0:13:28  iter: 80839  total_loss: 0.09895  loss_cls: 0.0149  loss_box_reg: 0.03169  loss_mask: 0.05137  loss_rpn_cls: 0.0002335  loss_rpn_loc: 0.002372  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:43] d2.utils.events INFO:  eta: 0:13:28  iter: 80859  total_loss: 0.0728  loss_cls: 0.009406  loss_box_reg: 0.01756  loss_mask: 0.04412  loss_rpn_cls: 0.0001862  loss_rpn_loc: 0.002183  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:44] d2.utils.events INFO:  eta: 0:13:27  iter: 80879  total_loss: 0.06881  loss_cls: 0.01164  loss_box_reg: 0.02176  loss_mask: 0.03441  loss_rpn_cls: 0.00029  loss_rpn_loc: 0.002546  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:46] d2.utils.events INFO:  eta: 0:13:23  iter: 80899  total_loss: 0.0714  loss_cls: 0.008041  loss_box_reg: 0.01778  loss_mask: 0.04171  loss_rpn_cls: 0.0002699  loss_rpn_loc: 0.002262  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:48] d2.utils.events INFO:  eta: 0:13:23  iter: 80919  total_loss: 0.1004  loss_cls: 0.01357  loss_box_reg: 0.02803  loss_mask: 0.05416  loss_rpn_cls: 0.0002813  loss_rpn_loc: 0.003794  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:50] d2.utils.events INFO:  eta: 0:13:22  iter: 80939  total_loss: 0.08464  loss_cls: 0.01274  loss_box_reg: 0.02804  loss_mask: 0.04513  loss_rpn_cls: 0.0001455  loss_rpn_loc: 0.002758  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:52] d2.utils.events INFO:  eta: 0:13:20  iter: 80959  total_loss: 0.07849  loss_cls: 0.01014  loss_box_reg: 0.02223  loss_mask: 0.04281  loss_rpn_cls: 0.0002288  loss_rpn_loc: 0.002795  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:53] d2.utils.events INFO:  eta: 0:13:18  iter: 80979  total_loss: 0.08965  loss_cls: 0.01536  loss_box_reg: 0.02754  loss_mask: 0.04484  loss_rpn_cls: 0.0003078  loss_rpn_loc: 0.003358  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:55] d2.utils.events INFO:  eta: 0:13:16  iter: 80999  total_loss: 0.05812  loss_cls: 0.005256  loss_box_reg: 0.01737  loss_mask: 0.03888  loss_rpn_cls: 0.000222  loss_rpn_loc: 0.001757  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:57] d2.utils.events INFO:  eta: 0:13:15  iter: 81019  total_loss: 0.06972  loss_cls: 0.009832  loss_box_reg: 0.01858  loss_mask: 0.04087  loss_rpn_cls: 0.0002626  loss_rpn_loc: 0.002525  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:36:59] d2.utils.events INFO:  eta: 0:13:14  iter: 81039  total_loss: 0.08551  loss_cls: 0.009162  loss_box_reg: 0.02335  loss_mask: 0.05972  loss_rpn_cls: 0.0001605  loss_rpn_loc: 0.001839  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:00] d2.utils.events INFO:  eta: 0:13:12  iter: 81059  total_loss: 0.08259  loss_cls: 0.01112  loss_box_reg: 0.02961  loss_mask: 0.04526  loss_rpn_cls: 0.0002857  loss_rpn_loc: 0.004442  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:02] d2.utils.events INFO:  eta: 0:13:09  iter: 81079  total_loss: 0.08093  loss_cls: 0.01058  loss_box_reg: 0.02056  loss_mask: 0.03867  loss_rpn_cls: 0.0001676  loss_rpn_loc: 0.002148  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:04] d2.utils.events INFO:  eta: 0:13:07  iter: 81099  total_loss: 0.0762  loss_cls: 0.009864  loss_box_reg: 0.02382  loss_mask: 0.04264  loss_rpn_cls: 0.0003245  loss_rpn_loc: 0.002799  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:06] d2.utils.events INFO:  eta: 0:13:03  iter: 81119  total_loss: 0.05653  loss_cls: 0.005197  loss_box_reg: 0.01772  loss_mask: 0.03455  loss_rpn_cls: 0.000126  loss_rpn_loc: 0.001695  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:07] d2.utils.events INFO:  eta: 0:13:00  iter: 81139  total_loss: 0.05761  loss_cls: 0.006161  loss_box_reg: 0.0105  loss_mask: 0.04095  loss_rpn_cls: 0.0002095  loss_rpn_loc: 0.001765  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:09] d2.utils.events INFO:  eta: 0:13:00  iter: 81159  total_loss: 0.08437  loss_cls: 0.01  loss_box_reg: 0.02073  loss_mask: 0.04546  loss_rpn_cls: 0.0003484  loss_rpn_loc: 0.003516  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:11] d2.utils.events INFO:  eta: 0:12:58  iter: 81179  total_loss: 0.07557  loss_cls: 0.01157  loss_box_reg: 0.02317  loss_mask: 0.03761  loss_rpn_cls: 0.0001321  loss_rpn_loc: 0.00189  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:13] d2.utils.events INFO:  eta: 0:12:54  iter: 81199  total_loss: 0.08593  loss_cls: 0.01106  loss_box_reg: 0.0234  loss_mask: 0.04797  loss_rpn_cls: 0.0002612  loss_rpn_loc: 0.002958  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:14] d2.utils.events INFO:  eta: 0:12:51  iter: 81219  total_loss: 0.06095  loss_cls: 0.00719  loss_box_reg: 0.01706  loss_mask: 0.03243  loss_rpn_cls: 0.0001036  loss_rpn_loc: 0.002417  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:16] d2.utils.events INFO:  eta: 0:12:48  iter: 81239  total_loss: 0.07418  loss_cls: 0.0102  loss_box_reg: 0.02047  loss_mask: 0.04878  loss_rpn_cls: 0.000256  loss_rpn_loc: 0.002531  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:18] d2.utils.events INFO:  eta: 0:12:45  iter: 81259  total_loss: 0.08531  loss_cls: 0.007812  loss_box_reg: 0.02637  loss_mask: 0.05036  loss_rpn_cls: 0.0003427  loss_rpn_loc: 0.003605  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:20] d2.utils.events INFO:  eta: 0:12:46  iter: 81279  total_loss: 0.08451  loss_cls: 0.01462  loss_box_reg: 0.02363  loss_mask: 0.04927  loss_rpn_cls: 0.0001835  loss_rpn_loc: 0.002617  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:22] d2.utils.events INFO:  eta: 0:12:46  iter: 81299  total_loss: 0.07205  loss_cls: 0.01026  loss_box_reg: 0.02165  loss_mask: 0.03463  loss_rpn_cls: 0.0002715  loss_rpn_loc: 0.003284  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:23] d2.utils.events INFO:  eta: 0:12:44  iter: 81319  total_loss: 0.07202  loss_cls: 0.008518  loss_box_reg: 0.01694  loss_mask: 0.04284  loss_rpn_cls: 0.0001066  loss_rpn_loc: 0.001602  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:25] d2.utils.events INFO:  eta: 0:12:43  iter: 81339  total_loss: 0.06653  loss_cls: 0.00739  loss_box_reg: 0.01505  loss_mask: 0.04073  loss_rpn_cls: 9.07e-05  loss_rpn_loc: 0.001786  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:27] d2.utils.events INFO:  eta: 0:12:42  iter: 81359  total_loss: 0.09009  loss_cls: 0.008142  loss_box_reg: 0.02771  loss_mask: 0.05364  loss_rpn_cls: 0.0001222  loss_rpn_loc: 0.001832  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:29] d2.utils.events INFO:  eta: 0:12:43  iter: 81379  total_loss: 0.08639  loss_cls: 0.01229  loss_box_reg: 0.02226  loss_mask: 0.04783  loss_rpn_cls: 0.0004051  loss_rpn_loc: 0.002816  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:31] d2.utils.events INFO:  eta: 0:12:42  iter: 81399  total_loss: 0.1146  loss_cls: 0.01219  loss_box_reg: 0.03258  loss_mask: 0.05321  loss_rpn_cls: 0.000466  loss_rpn_loc: 0.005277  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:32] d2.utils.events INFO:  eta: 0:12:39  iter: 81419  total_loss: 0.08113  loss_cls: 0.01231  loss_box_reg: 0.02031  loss_mask: 0.0422  loss_rpn_cls: 0.0001833  loss_rpn_loc: 0.002844  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:34] d2.utils.events INFO:  eta: 0:12:38  iter: 81439  total_loss: 0.12  loss_cls: 0.01306  loss_box_reg: 0.02887  loss_mask: 0.05998  loss_rpn_cls: 0.0007711  loss_rpn_loc: 0.006267  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:36] d2.utils.events INFO:  eta: 0:12:37  iter: 81459  total_loss: 0.07189  loss_cls: 0.008909  loss_box_reg: 0.01954  loss_mask: 0.03908  loss_rpn_cls: 0.0002035  loss_rpn_loc: 0.00214  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:38] d2.utils.events INFO:  eta: 0:12:35  iter: 81479  total_loss: 0.07223  loss_cls: 0.00901  loss_box_reg: 0.0182  loss_mask: 0.0461  loss_rpn_cls: 0.0001475  loss_rpn_loc: 0.002847  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:39] d2.utils.events INFO:  eta: 0:12:33  iter: 81499  total_loss: 0.07675  loss_cls: 0.009451  loss_box_reg: 0.02117  loss_mask: 0.05235  loss_rpn_cls: 0.0004838  loss_rpn_loc: 0.00318  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:41] d2.utils.events INFO:  eta: 0:12:31  iter: 81519  total_loss: 0.07983  loss_cls: 0.01276  loss_box_reg: 0.01937  loss_mask: 0.03834  loss_rpn_cls: 0.0002739  loss_rpn_loc: 0.003258  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:43] d2.utils.events INFO:  eta: 0:12:29  iter: 81539  total_loss: 0.06279  loss_cls: 0.007209  loss_box_reg: 0.01537  loss_mask: 0.03857  loss_rpn_cls: 7.118e-05  loss_rpn_loc: 0.001722  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:45] d2.utils.events INFO:  eta: 0:12:28  iter: 81559  total_loss: 0.09562  loss_cls: 0.0101  loss_box_reg: 0.02947  loss_mask: 0.06097  loss_rpn_cls: 0.0003154  loss_rpn_loc: 0.004106  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:46] d2.utils.events INFO:  eta: 0:12:25  iter: 81579  total_loss: 0.05517  loss_cls: 0.004504  loss_box_reg: 0.01054  loss_mask: 0.03417  loss_rpn_cls: 0.0001608  loss_rpn_loc: 0.001813  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:48] d2.utils.events INFO:  eta: 0:12:21  iter: 81599  total_loss: 0.07031  loss_cls: 0.00863  loss_box_reg: 0.0218  loss_mask: 0.04162  loss_rpn_cls: 0.0001928  loss_rpn_loc: 0.002082  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:50] d2.utils.events INFO:  eta: 0:12:18  iter: 81619  total_loss: 0.06774  loss_cls: 0.006853  loss_box_reg: 0.01745  loss_mask: 0.04215  loss_rpn_cls: 0.0001282  loss_rpn_loc: 0.001788  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:52] d2.utils.events INFO:  eta: 0:12:19  iter: 81639  total_loss: 0.1091  loss_cls: 0.014  loss_box_reg: 0.02962  loss_mask: 0.05757  loss_rpn_cls: 0.000239  loss_rpn_loc: 0.002716  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:53] d2.utils.events INFO:  eta: 0:12:18  iter: 81659  total_loss: 0.09133  loss_cls: 0.00973  loss_box_reg: 0.02393  loss_mask: 0.05814  loss_rpn_cls: 0.0005019  loss_rpn_loc: 0.003774  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:55] d2.utils.events INFO:  eta: 0:12:16  iter: 81679  total_loss: 0.07595  loss_cls: 0.009095  loss_box_reg: 0.02061  loss_mask: 0.04347  loss_rpn_cls: 0.0002926  loss_rpn_loc: 0.002232  time: 0.0878  data_time: 0.0022  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:57] d2.utils.events INFO:  eta: 0:12:14  iter: 81699  total_loss: 0.07855  loss_cls: 0.007297  loss_box_reg: 0.02323  loss_mask: 0.04419  loss_rpn_cls: 0.000189  loss_rpn_loc: 0.002247  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:37:59] d2.utils.events INFO:  eta: 0:12:11  iter: 81719  total_loss: 0.06742  loss_cls: 0.007659  loss_box_reg: 0.01751  loss_mask: 0.03606  loss_rpn_cls: 0.0002788  loss_rpn_loc: 0.001487  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:00] d2.utils.events INFO:  eta: 0:12:12  iter: 81739  total_loss: 0.08908  loss_cls: 0.01336  loss_box_reg: 0.029  loss_mask: 0.04871  loss_rpn_cls: 0.0001458  loss_rpn_loc: 0.002243  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:02] d2.utils.events INFO:  eta: 0:12:09  iter: 81759  total_loss: 0.06551  loss_cls: 0.007106  loss_box_reg: 0.01622  loss_mask: 0.04207  loss_rpn_cls: 0.0001711  loss_rpn_loc: 0.001827  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:04] d2.utils.events INFO:  eta: 0:12:08  iter: 81779  total_loss: 0.07542  loss_cls: 0.006698  loss_box_reg: 0.01812  loss_mask: 0.04352  loss_rpn_cls: 0.000274  loss_rpn_loc: 0.003858  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:06] d2.utils.events INFO:  eta: 0:12:07  iter: 81799  total_loss: 0.0826  loss_cls: 0.01042  loss_box_reg: 0.02128  loss_mask: 0.0526  loss_rpn_cls: 0.0001033  loss_rpn_loc: 0.002261  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:07] d2.utils.events INFO:  eta: 0:12:03  iter: 81819  total_loss: 0.04981  loss_cls: 0.003843  loss_box_reg: 0.01189  loss_mask: 0.03493  loss_rpn_cls: 0.0001353  loss_rpn_loc: 0.001592  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:09] d2.utils.events INFO:  eta: 0:12:00  iter: 81839  total_loss: 0.0611  loss_cls: 0.005823  loss_box_reg: 0.01355  loss_mask: 0.03719  loss_rpn_cls: 0.0002791  loss_rpn_loc: 0.001839  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:11] d2.utils.events INFO:  eta: 0:11:59  iter: 81859  total_loss: 0.08054  loss_cls: 0.007518  loss_box_reg: 0.02023  loss_mask: 0.04691  loss_rpn_cls: 0.0001933  loss_rpn_loc: 0.002941  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:13] d2.utils.events INFO:  eta: 0:11:58  iter: 81879  total_loss: 0.08486  loss_cls: 0.00947  loss_box_reg: 0.02825  loss_mask: 0.04766  loss_rpn_cls: 0.0004287  loss_rpn_loc: 0.00342  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:15] d2.utils.events INFO:  eta: 0:11:58  iter: 81899  total_loss: 0.09689  loss_cls: 0.009296  loss_box_reg: 0.02932  loss_mask: 0.05724  loss_rpn_cls: 0.0001954  loss_rpn_loc: 0.004201  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:16] d2.utils.events INFO:  eta: 0:11:54  iter: 81919  total_loss: 0.07249  loss_cls: 0.008686  loss_box_reg: 0.01564  loss_mask: 0.04669  loss_rpn_cls: 0.0002782  loss_rpn_loc: 0.002588  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:18] d2.utils.events INFO:  eta: 0:11:53  iter: 81939  total_loss: 0.07748  loss_cls: 0.008242  loss_box_reg: 0.02262  loss_mask: 0.05  loss_rpn_cls: 0.0002552  loss_rpn_loc: 0.00273  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:20] d2.utils.events INFO:  eta: 0:11:51  iter: 81959  total_loss: 0.08922  loss_cls: 0.01082  loss_box_reg: 0.02851  loss_mask: 0.05317  loss_rpn_cls: 0.0001544  loss_rpn_loc: 0.003244  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:22] d2.utils.events INFO:  eta: 0:11:49  iter: 81979  total_loss: 0.1099  loss_cls: 0.01554  loss_box_reg: 0.03574  loss_mask: 0.05341  loss_rpn_cls: 0.0001444  loss_rpn_loc: 0.003471  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:24] d2.utils.events INFO:  eta: 0:11:49  iter: 81999  total_loss: 0.09245  loss_cls: 0.008462  loss_box_reg: 0.02995  loss_mask: 0.05119  loss_rpn_cls: 0.0001678  loss_rpn_loc: 0.002591  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:25] d2.utils.events INFO:  eta: 0:11:46  iter: 82019  total_loss: 0.05559  loss_cls: 0.006595  loss_box_reg: 0.01265  loss_mask: 0.03674  loss_rpn_cls: 0.0001166  loss_rpn_loc: 0.001362  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:27] d2.utils.events INFO:  eta: 0:11:44  iter: 82039  total_loss: 0.05221  loss_cls: 0.005352  loss_box_reg: 0.009208  loss_mask: 0.03135  loss_rpn_cls: 0.0001661  loss_rpn_loc: 0.001712  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:29] d2.utils.events INFO:  eta: 0:11:42  iter: 82059  total_loss: 0.07317  loss_cls: 0.008738  loss_box_reg: 0.01939  loss_mask: 0.03868  loss_rpn_cls: 0.0001344  loss_rpn_loc: 0.00155  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:30] d2.utils.events INFO:  eta: 0:11:40  iter: 82079  total_loss: 0.08817  loss_cls: 0.008819  loss_box_reg: 0.0262  loss_mask: 0.05314  loss_rpn_cls: 0.0002436  loss_rpn_loc: 0.003057  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:32] d2.utils.events INFO:  eta: 0:11:37  iter: 82099  total_loss: 0.0697  loss_cls: 0.008355  loss_box_reg: 0.01574  loss_mask: 0.04206  loss_rpn_cls: 0.000204  loss_rpn_loc: 0.002204  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:34] d2.utils.events INFO:  eta: 0:11:35  iter: 82119  total_loss: 0.06633  loss_cls: 0.006529  loss_box_reg: 0.01523  loss_mask: 0.03837  loss_rpn_cls: 0.000187  loss_rpn_loc: 0.001638  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:36] d2.utils.events INFO:  eta: 0:11:35  iter: 82139  total_loss: 0.08835  loss_cls: 0.01179  loss_box_reg: 0.03153  loss_mask: 0.04006  loss_rpn_cls: 0.0002922  loss_rpn_loc: 0.003893  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:37] d2.utils.events INFO:  eta: 0:11:33  iter: 82159  total_loss: 0.08424  loss_cls: 0.01177  loss_box_reg: 0.02039  loss_mask: 0.05156  loss_rpn_cls: 0.0002174  loss_rpn_loc: 0.002816  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:39] d2.utils.events INFO:  eta: 0:11:31  iter: 82179  total_loss: 0.07111  loss_cls: 0.007483  loss_box_reg: 0.01897  loss_mask: 0.03772  loss_rpn_cls: 0.0001642  loss_rpn_loc: 0.002364  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:41] d2.utils.events INFO:  eta: 0:11:30  iter: 82199  total_loss: 0.09939  loss_cls: 0.009402  loss_box_reg: 0.02563  loss_mask: 0.05625  loss_rpn_cls: 0.000233  loss_rpn_loc: 0.004  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:43] d2.utils.events INFO:  eta: 0:11:28  iter: 82219  total_loss: 0.07886  loss_cls: 0.01002  loss_box_reg: 0.02118  loss_mask: 0.04584  loss_rpn_cls: 0.0002177  loss_rpn_loc: 0.002475  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:45] d2.utils.events INFO:  eta: 0:11:28  iter: 82239  total_loss: 0.09848  loss_cls: 0.01528  loss_box_reg: 0.02989  loss_mask: 0.05738  loss_rpn_cls: 0.0002492  loss_rpn_loc: 0.003652  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:47] d2.utils.events INFO:  eta: 0:11:26  iter: 82259  total_loss: 0.135  loss_cls: 0.01366  loss_box_reg: 0.03691  loss_mask: 0.0718  loss_rpn_cls: 0.0004282  loss_rpn_loc: 0.006693  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:48] d2.utils.events INFO:  eta: 0:11:23  iter: 82279  total_loss: 0.06331  loss_cls: 0.004401  loss_box_reg: 0.01618  loss_mask: 0.04005  loss_rpn_cls: 0.0001027  loss_rpn_loc: 0.001485  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:50] d2.utils.events INFO:  eta: 0:11:21  iter: 82299  total_loss: 0.1128  loss_cls: 0.0159  loss_box_reg: 0.03569  loss_mask: 0.06284  loss_rpn_cls: 0.0002353  loss_rpn_loc: 0.004586  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:52] d2.utils.events INFO:  eta: 0:11:20  iter: 82319  total_loss: 0.06473  loss_cls: 0.006002  loss_box_reg: 0.01647  loss_mask: 0.03655  loss_rpn_cls: 0.0002534  loss_rpn_loc: 0.001808  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:54] d2.utils.events INFO:  eta: 0:11:18  iter: 82339  total_loss: 0.06261  loss_cls: 0.008677  loss_box_reg: 0.01606  loss_mask: 0.03732  loss_rpn_cls: 0.0001184  loss_rpn_loc: 0.00173  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:55] d2.utils.events INFO:  eta: 0:11:16  iter: 82359  total_loss: 0.08077  loss_cls: 0.009043  loss_box_reg: 0.01807  loss_mask: 0.04077  loss_rpn_cls: 0.0002849  loss_rpn_loc: 0.002817  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:57] d2.utils.events INFO:  eta: 0:11:14  iter: 82379  total_loss: 0.08078  loss_cls: 0.01275  loss_box_reg: 0.02334  loss_mask: 0.0486  loss_rpn_cls: 0.0002242  loss_rpn_loc: 0.003179  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:38:59] d2.utils.events INFO:  eta: 0:11:11  iter: 82399  total_loss: 0.06504  loss_cls: 0.007873  loss_box_reg: 0.01886  loss_mask: 0.04013  loss_rpn_cls: 0.0002219  loss_rpn_loc: 0.001491  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:01] d2.utils.events INFO:  eta: 0:11:09  iter: 82419  total_loss: 0.06979  loss_cls: 0.009001  loss_box_reg: 0.01757  loss_mask: 0.04136  loss_rpn_cls: 0.0001567  loss_rpn_loc: 0.001488  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:02] d2.utils.events INFO:  eta: 0:11:06  iter: 82439  total_loss: 0.06859  loss_cls: 0.006239  loss_box_reg: 0.01808  loss_mask: 0.04493  loss_rpn_cls: 0.0001371  loss_rpn_loc: 0.001725  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:04] d2.utils.events INFO:  eta: 0:11:04  iter: 82459  total_loss: 0.07457  loss_cls: 0.008908  loss_box_reg: 0.01716  loss_mask: 0.04358  loss_rpn_cls: 0.0001438  loss_rpn_loc: 0.001662  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:06] d2.utils.events INFO:  eta: 0:11:03  iter: 82479  total_loss: 0.09933  loss_cls: 0.01307  loss_box_reg: 0.03153  loss_mask: 0.05068  loss_rpn_cls: 0.0003819  loss_rpn_loc: 0.006148  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:08] d2.utils.events INFO:  eta: 0:11:02  iter: 82499  total_loss: 0.07197  loss_cls: 0.008185  loss_box_reg: 0.02166  loss_mask: 0.04614  loss_rpn_cls: 0.0002802  loss_rpn_loc: 0.00219  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:09] d2.utils.events INFO:  eta: 0:11:00  iter: 82519  total_loss: 0.07599  loss_cls: 0.01343  loss_box_reg: 0.02439  loss_mask: 0.05082  loss_rpn_cls: 0.0002408  loss_rpn_loc: 0.002849  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:11] d2.utils.events INFO:  eta: 0:10:59  iter: 82539  total_loss: 0.08809  loss_cls: 0.01198  loss_box_reg: 0.02917  loss_mask: 0.04989  loss_rpn_cls: 0.0002921  loss_rpn_loc: 0.003213  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:13] d2.utils.events INFO:  eta: 0:10:58  iter: 82559  total_loss: 0.08585  loss_cls: 0.01183  loss_box_reg: 0.03173  loss_mask: 0.04252  loss_rpn_cls: 0.0003628  loss_rpn_loc: 0.002193  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:15] d2.utils.events INFO:  eta: 0:10:57  iter: 82579  total_loss: 0.06524  loss_cls: 0.005593  loss_box_reg: 0.01471  loss_mask: 0.04873  loss_rpn_cls: 0.0001428  loss_rpn_loc: 0.001743  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:17] d2.utils.events INFO:  eta: 0:10:55  iter: 82599  total_loss: 0.06582  loss_cls: 0.00714  loss_box_reg: 0.01542  loss_mask: 0.0384  loss_rpn_cls: 0.0001504  loss_rpn_loc: 0.002055  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:18] d2.utils.events INFO:  eta: 0:10:53  iter: 82619  total_loss: 0.06217  loss_cls: 0.005519  loss_box_reg: 0.01616  loss_mask: 0.03673  loss_rpn_cls: 0.0001104  loss_rpn_loc: 0.001201  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:20] d2.utils.events INFO:  eta: 0:10:51  iter: 82639  total_loss: 0.08472  loss_cls: 0.01029  loss_box_reg: 0.027  loss_mask: 0.04181  loss_rpn_cls: 0.000247  loss_rpn_loc: 0.003143  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:22] d2.utils.events INFO:  eta: 0:10:49  iter: 82659  total_loss: 0.07788  loss_cls: 0.009068  loss_box_reg: 0.02175  loss_mask: 0.04383  loss_rpn_cls: 0.00019  loss_rpn_loc: 0.002086  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:24] d2.utils.events INFO:  eta: 0:10:47  iter: 82679  total_loss: 0.07183  loss_cls: 0.007776  loss_box_reg: 0.01729  loss_mask: 0.0408  loss_rpn_cls: 0.0002006  loss_rpn_loc: 0.002059  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:25] d2.utils.events INFO:  eta: 0:10:46  iter: 82699  total_loss: 0.0702  loss_cls: 0.00794  loss_box_reg: 0.01916  loss_mask: 0.04252  loss_rpn_cls: 0.0004837  loss_rpn_loc: 0.005447  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:27] d2.utils.events INFO:  eta: 0:10:45  iter: 82719  total_loss: 0.0849  loss_cls: 0.01289  loss_box_reg: 0.02761  loss_mask: 0.03989  loss_rpn_cls: 0.0001438  loss_rpn_loc: 0.003488  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:29] d2.utils.events INFO:  eta: 0:10:43  iter: 82739  total_loss: 0.08455  loss_cls: 0.008599  loss_box_reg: 0.02114  loss_mask: 0.04802  loss_rpn_cls: 0.0001436  loss_rpn_loc: 0.002791  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:31] d2.utils.events INFO:  eta: 0:10:41  iter: 82759  total_loss: 0.06584  loss_cls: 0.006568  loss_box_reg: 0.01703  loss_mask: 0.03749  loss_rpn_cls: 0.0002606  loss_rpn_loc: 0.00193  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:32] d2.utils.events INFO:  eta: 0:10:38  iter: 82779  total_loss: 0.06851  loss_cls: 0.00933  loss_box_reg: 0.01809  loss_mask: 0.04101  loss_rpn_cls: 0.0001852  loss_rpn_loc: 0.002247  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:34] d2.utils.events INFO:  eta: 0:10:36  iter: 82799  total_loss: 0.09023  loss_cls: 0.01189  loss_box_reg: 0.02276  loss_mask: 0.05824  loss_rpn_cls: 0.0002823  loss_rpn_loc: 0.002803  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:36] d2.utils.events INFO:  eta: 0:10:36  iter: 82819  total_loss: 0.08184  loss_cls: 0.007364  loss_box_reg: 0.0199  loss_mask: 0.0418  loss_rpn_cls: 0.0001958  loss_rpn_loc: 0.002407  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:38] d2.utils.events INFO:  eta: 0:10:35  iter: 82839  total_loss: 0.09743  loss_cls: 0.01318  loss_box_reg: 0.0346  loss_mask: 0.04367  loss_rpn_cls: 0.0004978  loss_rpn_loc: 0.004342  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:39] d2.utils.events INFO:  eta: 0:10:33  iter: 82859  total_loss: 0.06861  loss_cls: 0.005842  loss_box_reg: 0.01601  loss_mask: 0.04235  loss_rpn_cls: 0.0001581  loss_rpn_loc: 0.001601  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:41] d2.utils.events INFO:  eta: 0:10:31  iter: 82879  total_loss: 0.07748  loss_cls: 0.01145  loss_box_reg: 0.02658  loss_mask: 0.04719  loss_rpn_cls: 0.0002627  loss_rpn_loc: 0.002565  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:43] d2.utils.events INFO:  eta: 0:10:29  iter: 82899  total_loss: 0.08243  loss_cls: 0.01231  loss_box_reg: 0.02245  loss_mask: 0.04779  loss_rpn_cls: 0.0002145  loss_rpn_loc: 0.002404  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:45] d2.utils.events INFO:  eta: 0:10:28  iter: 82919  total_loss: 0.06593  loss_cls: 0.005669  loss_box_reg: 0.01739  loss_mask: 0.03818  loss_rpn_cls: 0.0002688  loss_rpn_loc: 0.002001  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:47] d2.utils.events INFO:  eta: 0:10:26  iter: 82939  total_loss: 0.09454  loss_cls: 0.00757  loss_box_reg: 0.02106  loss_mask: 0.05689  loss_rpn_cls: 0.0003105  loss_rpn_loc: 0.003229  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:48] d2.utils.events INFO:  eta: 0:10:23  iter: 82959  total_loss: 0.06594  loss_cls: 0.007908  loss_box_reg: 0.01492  loss_mask: 0.03969  loss_rpn_cls: 0.0001404  loss_rpn_loc: 0.001524  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:50] d2.utils.events INFO:  eta: 0:10:21  iter: 82979  total_loss: 0.07985  loss_cls: 0.01005  loss_box_reg: 0.02377  loss_mask: 0.04458  loss_rpn_cls: 0.0002872  loss_rpn_loc: 0.00338  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:52] d2.utils.events INFO:  eta: 0:10:19  iter: 82999  total_loss: 0.07726  loss_cls: 0.008229  loss_box_reg: 0.02891  loss_mask: 0.04157  loss_rpn_cls: 0.0001051  loss_rpn_loc: 0.001888  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:54] d2.utils.events INFO:  eta: 0:10:17  iter: 83019  total_loss: 0.06529  loss_cls: 0.006959  loss_box_reg: 0.01804  loss_mask: 0.0392  loss_rpn_cls: 0.0002238  loss_rpn_loc: 0.002121  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:55] d2.utils.events INFO:  eta: 0:10:16  iter: 83039  total_loss: 0.09029  loss_cls: 0.01179  loss_box_reg: 0.02436  loss_mask: 0.04735  loss_rpn_cls: 0.0004753  loss_rpn_loc: 0.004315  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:57] d2.utils.events INFO:  eta: 0:10:14  iter: 83059  total_loss: 0.05012  loss_cls: 0.004937  loss_box_reg: 0.01022  loss_mask: 0.03168  loss_rpn_cls: 0.0001193  loss_rpn_loc: 0.0008065  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:39:59] d2.utils.events INFO:  eta: 0:10:12  iter: 83079  total_loss: 0.07807  loss_cls: 0.01006  loss_box_reg: 0.01906  loss_mask: 0.04781  loss_rpn_cls: 0.0002198  loss_rpn_loc: 0.003038  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:01] d2.utils.events INFO:  eta: 0:10:10  iter: 83099  total_loss: 0.06844  loss_cls: 0.006589  loss_box_reg: 0.0158  loss_mask: 0.04393  loss_rpn_cls: 0.0002899  loss_rpn_loc: 0.001925  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:02] d2.utils.events INFO:  eta: 0:10:09  iter: 83119  total_loss: 0.07448  loss_cls: 0.009049  loss_box_reg: 0.01958  loss_mask: 0.04012  loss_rpn_cls: 0.0001688  loss_rpn_loc: 0.002188  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:04] d2.utils.events INFO:  eta: 0:10:07  iter: 83139  total_loss: 0.07531  loss_cls: 0.00938  loss_box_reg: 0.01819  loss_mask: 0.04609  loss_rpn_cls: 0.0002459  loss_rpn_loc: 0.002279  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:06] d2.utils.events INFO:  eta: 0:10:06  iter: 83159  total_loss: 0.09948  loss_cls: 0.01303  loss_box_reg: 0.0301  loss_mask: 0.04549  loss_rpn_cls: 0.0002961  loss_rpn_loc: 0.005093  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:08] d2.utils.events INFO:  eta: 0:10:04  iter: 83179  total_loss: 0.077  loss_cls: 0.008718  loss_box_reg: 0.02224  loss_mask: 0.04714  loss_rpn_cls: 0.0002667  loss_rpn_loc: 0.002826  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:09] d2.utils.events INFO:  eta: 0:10:02  iter: 83199  total_loss: 0.09648  loss_cls: 0.0123  loss_box_reg: 0.02558  loss_mask: 0.05725  loss_rpn_cls: 0.0002219  loss_rpn_loc: 0.004589  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:11] d2.utils.events INFO:  eta: 0:10:00  iter: 83219  total_loss: 0.05863  loss_cls: 0.00771  loss_box_reg: 0.01345  loss_mask: 0.03407  loss_rpn_cls: 0.0001258  loss_rpn_loc: 0.001972  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:13] d2.utils.events INFO:  eta: 0:09:58  iter: 83239  total_loss: 0.08587  loss_cls: 0.008449  loss_box_reg: 0.02739  loss_mask: 0.04889  loss_rpn_cls: 0.0001591  loss_rpn_loc: 0.002049  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:15] d2.utils.events INFO:  eta: 0:09:55  iter: 83259  total_loss: 0.08646  loss_cls: 0.007957  loss_box_reg: 0.02155  loss_mask: 0.05399  loss_rpn_cls: 0.0002964  loss_rpn_loc: 0.002712  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:17] d2.utils.events INFO:  eta: 0:09:54  iter: 83279  total_loss: 0.07102  loss_cls: 0.007884  loss_box_reg: 0.01925  loss_mask: 0.03692  loss_rpn_cls: 0.0002209  loss_rpn_loc: 0.003023  time: 0.0878  data_time: 0.0018  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:18] d2.utils.events INFO:  eta: 0:09:52  iter: 83299  total_loss: 0.07035  loss_cls: 0.01222  loss_box_reg: 0.02055  loss_mask: 0.04322  loss_rpn_cls: 0.0001647  loss_rpn_loc: 0.002841  time: 0.0878  data_time: 0.0018  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:20] d2.utils.events INFO:  eta: 0:09:50  iter: 83319  total_loss: 0.0768  loss_cls: 0.01119  loss_box_reg: 0.02679  loss_mask: 0.03909  loss_rpn_cls: 0.000264  loss_rpn_loc: 0.002813  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:22] d2.utils.events INFO:  eta: 0:09:48  iter: 83339  total_loss: 0.07066  loss_cls: 0.007485  loss_box_reg: 0.01746  loss_mask: 0.04341  loss_rpn_cls: 8.519e-05  loss_rpn_loc: 0.002106  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:23] d2.utils.events INFO:  eta: 0:09:45  iter: 83359  total_loss: 0.0662  loss_cls: 0.005772  loss_box_reg: 0.0149  loss_mask: 0.04221  loss_rpn_cls: 0.0002208  loss_rpn_loc: 0.001593  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:25] d2.utils.events INFO:  eta: 0:09:43  iter: 83379  total_loss: 0.06133  loss_cls: 0.006614  loss_box_reg: 0.01772  loss_mask: 0.03752  loss_rpn_cls: 0.0001152  loss_rpn_loc: 0.002139  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:27] d2.utils.events INFO:  eta: 0:09:42  iter: 83399  total_loss: 0.08886  loss_cls: 0.01387  loss_box_reg: 0.03017  loss_mask: 0.04238  loss_rpn_cls: 0.0002547  loss_rpn_loc: 0.003887  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:29] d2.utils.events INFO:  eta: 0:09:41  iter: 83419  total_loss: 0.0801  loss_cls: 0.01033  loss_box_reg: 0.02524  loss_mask: 0.04088  loss_rpn_cls: 0.0002064  loss_rpn_loc: 0.00423  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:31] d2.utils.events INFO:  eta: 0:09:39  iter: 83439  total_loss: 0.07704  loss_cls: 0.007959  loss_box_reg: 0.0198  loss_mask: 0.04781  loss_rpn_cls: 0.0001738  loss_rpn_loc: 0.002188  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:32] d2.utils.events INFO:  eta: 0:09:38  iter: 83459  total_loss: 0.1029  loss_cls: 0.01365  loss_box_reg: 0.03288  loss_mask: 0.04903  loss_rpn_cls: 0.0001926  loss_rpn_loc: 0.003073  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:34] d2.utils.events INFO:  eta: 0:09:35  iter: 83479  total_loss: 0.04676  loss_cls: 0.005182  loss_box_reg: 0.01012  loss_mask: 0.03109  loss_rpn_cls: 0.0001532  loss_rpn_loc: 0.001912  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:36] d2.utils.events INFO:  eta: 0:09:34  iter: 83499  total_loss: 0.07491  loss_cls: 0.008749  loss_box_reg: 0.02145  loss_mask: 0.04741  loss_rpn_cls: 0.0003226  loss_rpn_loc: 0.003476  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:38] d2.utils.events INFO:  eta: 0:09:31  iter: 83519  total_loss: 0.06487  loss_cls: 0.006717  loss_box_reg: 0.0159  loss_mask: 0.03532  loss_rpn_cls: 0.0001897  loss_rpn_loc: 0.002461  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:39] d2.utils.events INFO:  eta: 0:09:28  iter: 83539  total_loss: 0.06635  loss_cls: 0.01111  loss_box_reg: 0.01615  loss_mask: 0.03989  loss_rpn_cls: 0.0002391  loss_rpn_loc: 0.001437  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:41] d2.utils.events INFO:  eta: 0:09:26  iter: 83559  total_loss: 0.1212  loss_cls: 0.01438  loss_box_reg: 0.03442  loss_mask: 0.05924  loss_rpn_cls: 0.0003321  loss_rpn_loc: 0.00553  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:43] d2.utils.events INFO:  eta: 0:09:24  iter: 83579  total_loss: 0.06445  loss_cls: 0.006931  loss_box_reg: 0.01708  loss_mask: 0.03827  loss_rpn_cls: 0.00013  loss_rpn_loc: 0.001933  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:45] d2.utils.events INFO:  eta: 0:09:25  iter: 83599  total_loss: 0.08492  loss_cls: 0.009623  loss_box_reg: 0.02141  loss_mask: 0.0512  loss_rpn_cls: 0.000227  loss_rpn_loc: 0.002457  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:46] d2.utils.events INFO:  eta: 0:09:23  iter: 83619  total_loss: 0.06848  loss_cls: 0.004332  loss_box_reg: 0.009727  loss_mask: 0.04469  loss_rpn_cls: 0.0001332  loss_rpn_loc: 0.001099  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:48] d2.utils.events INFO:  eta: 0:09:21  iter: 83639  total_loss: 0.0678  loss_cls: 0.007904  loss_box_reg: 0.01853  loss_mask: 0.03935  loss_rpn_cls: 0.0001964  loss_rpn_loc: 0.001965  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:50] d2.utils.events INFO:  eta: 0:09:18  iter: 83659  total_loss: 0.06867  loss_cls: 0.007891  loss_box_reg: 0.01754  loss_mask: 0.0415  loss_rpn_cls: 0.0001807  loss_rpn_loc: 0.002514  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:52] d2.utils.events INFO:  eta: 0:09:16  iter: 83679  total_loss: 0.07182  loss_cls: 0.006934  loss_box_reg: 0.01721  loss_mask: 0.04074  loss_rpn_cls: 0.0002355  loss_rpn_loc: 0.001957  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:53] d2.utils.events INFO:  eta: 0:09:14  iter: 83699  total_loss: 0.07595  loss_cls: 0.00867  loss_box_reg: 0.02305  loss_mask: 0.04389  loss_rpn_cls: 0.0001809  loss_rpn_loc: 0.001748  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:55] d2.utils.events INFO:  eta: 0:09:12  iter: 83719  total_loss: 0.08043  loss_cls: 0.007135  loss_box_reg: 0.016  loss_mask: 0.04918  loss_rpn_cls: 0.0001979  loss_rpn_loc: 0.002128  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:57] d2.utils.events INFO:  eta: 0:09:10  iter: 83739  total_loss: 0.06716  loss_cls: 0.008046  loss_box_reg: 0.01886  loss_mask: 0.03173  loss_rpn_cls: 0.0001433  loss_rpn_loc: 0.002191  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:40:59] d2.utils.events INFO:  eta: 0:09:09  iter: 83759  total_loss: 0.07515  loss_cls: 0.01115  loss_box_reg: 0.02477  loss_mask: 0.03761  loss_rpn_cls: 0.00021  loss_rpn_loc: 0.002535  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:00] d2.utils.events INFO:  eta: 0:09:08  iter: 83779  total_loss: 0.07481  loss_cls: 0.008496  loss_box_reg: 0.02425  loss_mask: 0.04744  loss_rpn_cls: 0.0002406  loss_rpn_loc: 0.002819  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:02] d2.utils.events INFO:  eta: 0:09:06  iter: 83799  total_loss: 0.07673  loss_cls: 0.007053  loss_box_reg: 0.01696  loss_mask: 0.05072  loss_rpn_cls: 0.0001759  loss_rpn_loc: 0.001827  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:04] d2.utils.events INFO:  eta: 0:09:04  iter: 83819  total_loss: 0.08597  loss_cls: 0.01163  loss_box_reg: 0.02226  loss_mask: 0.04771  loss_rpn_cls: 0.0002415  loss_rpn_loc: 0.002109  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:06] d2.utils.events INFO:  eta: 0:09:01  iter: 83839  total_loss: 0.06499  loss_cls: 0.005399  loss_box_reg: 0.01808  loss_mask: 0.04253  loss_rpn_cls: 0.0001819  loss_rpn_loc: 0.002433  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:07] d2.utils.events INFO:  eta: 0:09:00  iter: 83859  total_loss: 0.08561  loss_cls: 0.0111  loss_box_reg: 0.01965  loss_mask: 0.05063  loss_rpn_cls: 0.0001912  loss_rpn_loc: 0.002559  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:09] d2.utils.events INFO:  eta: 0:08:58  iter: 83879  total_loss: 0.06548  loss_cls: 0.006394  loss_box_reg: 0.01858  loss_mask: 0.0406  loss_rpn_cls: 0.0001099  loss_rpn_loc: 0.002294  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:11] d2.utils.events INFO:  eta: 0:08:56  iter: 83899  total_loss: 0.0911  loss_cls: 0.00963  loss_box_reg: 0.02946  loss_mask: 0.05133  loss_rpn_cls: 0.0002648  loss_rpn_loc: 0.004268  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:13] d2.utils.events INFO:  eta: 0:08:54  iter: 83919  total_loss: 0.08699  loss_cls: 0.01056  loss_box_reg: 0.02236  loss_mask: 0.04832  loss_rpn_cls: 0.0002995  loss_rpn_loc: 0.003591  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:15] d2.utils.events INFO:  eta: 0:08:52  iter: 83939  total_loss: 0.06149  loss_cls: 0.006786  loss_box_reg: 0.01612  loss_mask: 0.04198  loss_rpn_cls: 0.0001941  loss_rpn_loc: 0.001893  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:16] d2.utils.events INFO:  eta: 0:08:51  iter: 83959  total_loss: 0.06261  loss_cls: 0.006896  loss_box_reg: 0.01815  loss_mask: 0.03549  loss_rpn_cls: 0.0002997  loss_rpn_loc: 0.002354  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:18] d2.utils.events INFO:  eta: 0:08:49  iter: 83979  total_loss: 0.07083  loss_cls: 0.006353  loss_box_reg: 0.01921  loss_mask: 0.03903  loss_rpn_cls: 0.0001939  loss_rpn_loc: 0.002806  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:20] d2.utils.events INFO:  eta: 0:08:48  iter: 83999  total_loss: 0.07216  loss_cls: 0.007346  loss_box_reg: 0.02062  loss_mask: 0.04128  loss_rpn_cls: 0.0002272  loss_rpn_loc: 0.003499  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:22] d2.utils.events INFO:  eta: 0:08:47  iter: 84019  total_loss: 0.08529  loss_cls: 0.008216  loss_box_reg: 0.01897  loss_mask: 0.05228  loss_rpn_cls: 0.0002434  loss_rpn_loc: 0.00295  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:24] d2.utils.events INFO:  eta: 0:08:44  iter: 84039  total_loss: 0.06511  loss_cls: 0.005011  loss_box_reg: 0.02351  loss_mask: 0.0448  loss_rpn_cls: 0.0002362  loss_rpn_loc: 0.003157  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:25] d2.utils.events INFO:  eta: 0:08:44  iter: 84059  total_loss: 0.1  loss_cls: 0.01052  loss_box_reg: 0.03361  loss_mask: 0.05456  loss_rpn_cls: 0.0002826  loss_rpn_loc: 0.005789  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:27] d2.utils.events INFO:  eta: 0:08:42  iter: 84079  total_loss: 0.07678  loss_cls: 0.006291  loss_box_reg: 0.01752  loss_mask: 0.04531  loss_rpn_cls: 0.000264  loss_rpn_loc: 0.001766  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:29] d2.utils.events INFO:  eta: 0:08:42  iter: 84099  total_loss: 0.08139  loss_cls: 0.01081  loss_box_reg: 0.02642  loss_mask: 0.04243  loss_rpn_cls: 0.0001548  loss_rpn_loc: 0.002434  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:31] d2.utils.events INFO:  eta: 0:08:40  iter: 84119  total_loss: 0.08127  loss_cls: 0.007908  loss_box_reg: 0.01806  loss_mask: 0.04753  loss_rpn_cls: 0.0002249  loss_rpn_loc: 0.002109  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:32] d2.utils.events INFO:  eta: 0:08:37  iter: 84139  total_loss: 0.05278  loss_cls: 0.006445  loss_box_reg: 0.01336  loss_mask: 0.03509  loss_rpn_cls: 0.000127  loss_rpn_loc: 0.002034  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:34] d2.utils.events INFO:  eta: 0:08:35  iter: 84159  total_loss: 0.06512  loss_cls: 0.004564  loss_box_reg: 0.01198  loss_mask: 0.04847  loss_rpn_cls: 0.0002359  loss_rpn_loc: 0.001887  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:36] d2.utils.events INFO:  eta: 0:08:32  iter: 84179  total_loss: 0.06988  loss_cls: 0.008964  loss_box_reg: 0.0176  loss_mask: 0.03777  loss_rpn_cls: 0.0002282  loss_rpn_loc: 0.002254  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:38] d2.utils.events INFO:  eta: 0:08:30  iter: 84199  total_loss: 0.0526  loss_cls: 0.005411  loss_box_reg: 0.01461  loss_mask: 0.02917  loss_rpn_cls: 0.0001223  loss_rpn_loc: 0.001748  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:39] d2.utils.events INFO:  eta: 0:08:29  iter: 84219  total_loss: 0.07676  loss_cls: 0.009139  loss_box_reg: 0.02439  loss_mask: 0.04405  loss_rpn_cls: 0.0002118  loss_rpn_loc: 0.001864  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:41] d2.utils.events INFO:  eta: 0:08:27  iter: 84239  total_loss: 0.07243  loss_cls: 0.009094  loss_box_reg: 0.01925  loss_mask: 0.04629  loss_rpn_cls: 0.0002705  loss_rpn_loc: 0.001854  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:43] d2.utils.events INFO:  eta: 0:08:25  iter: 84259  total_loss: 0.07248  loss_cls: 0.008443  loss_box_reg: 0.01832  loss_mask: 0.03966  loss_rpn_cls: 0.0001398  loss_rpn_loc: 0.002635  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:45] d2.utils.events INFO:  eta: 0:08:25  iter: 84279  total_loss: 0.1057  loss_cls: 0.01255  loss_box_reg: 0.03596  loss_mask: 0.05203  loss_rpn_cls: 0.0004938  loss_rpn_loc: 0.005105  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:46] d2.utils.events INFO:  eta: 0:08:23  iter: 84299  total_loss: 0.08136  loss_cls: 0.009552  loss_box_reg: 0.02401  loss_mask: 0.04401  loss_rpn_cls: 0.0003697  loss_rpn_loc: 0.003249  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:48] d2.utils.events INFO:  eta: 0:08:21  iter: 84319  total_loss: 0.0713  loss_cls: 0.006935  loss_box_reg: 0.02055  loss_mask: 0.03787  loss_rpn_cls: 0.0003477  loss_rpn_loc: 0.003415  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:50] d2.utils.events INFO:  eta: 0:08:19  iter: 84339  total_loss: 0.05932  loss_cls: 0.007615  loss_box_reg: 0.01089  loss_mask: 0.03568  loss_rpn_cls: 0.0001163  loss_rpn_loc: 0.001813  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:52] d2.utils.events INFO:  eta: 0:08:18  iter: 84359  total_loss: 0.0689  loss_cls: 0.008548  loss_box_reg: 0.01637  loss_mask: 0.04333  loss_rpn_cls: 0.000297  loss_rpn_loc: 0.003536  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:54] d2.utils.events INFO:  eta: 0:08:17  iter: 84379  total_loss: 0.114  loss_cls: 0.01496  loss_box_reg: 0.03335  loss_mask: 0.05657  loss_rpn_cls: 0.0002138  loss_rpn_loc: 0.003875  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:55] d2.utils.events INFO:  eta: 0:08:15  iter: 84399  total_loss: 0.1059  loss_cls: 0.01389  loss_box_reg: 0.03184  loss_mask: 0.0595  loss_rpn_cls: 0.000194  loss_rpn_loc: 0.002749  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:57] d2.utils.events INFO:  eta: 0:08:14  iter: 84419  total_loss: 0.07979  loss_cls: 0.01394  loss_box_reg: 0.02365  loss_mask: 0.05159  loss_rpn_cls: 0.0001292  loss_rpn_loc: 0.002743  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:41:59] d2.utils.events INFO:  eta: 0:08:13  iter: 84439  total_loss: 0.09279  loss_cls: 0.01507  loss_box_reg: 0.031  loss_mask: 0.04786  loss_rpn_cls: 0.0001963  loss_rpn_loc: 0.002054  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:01] d2.utils.events INFO:  eta: 0:08:10  iter: 84459  total_loss: 0.07836  loss_cls: 0.007693  loss_box_reg: 0.01787  loss_mask: 0.0394  loss_rpn_cls: 0.0001999  loss_rpn_loc: 0.002577  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:02] d2.utils.events INFO:  eta: 0:08:08  iter: 84479  total_loss: 0.06779  loss_cls: 0.00544  loss_box_reg: 0.01684  loss_mask: 0.03478  loss_rpn_cls: 0.0001341  loss_rpn_loc: 0.002186  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:04] d2.utils.events INFO:  eta: 0:08:06  iter: 84499  total_loss: 0.05684  loss_cls: 0.005762  loss_box_reg: 0.01134  loss_mask: 0.04778  loss_rpn_cls: 0.0001645  loss_rpn_loc: 0.00154  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:06] d2.utils.events INFO:  eta: 0:08:05  iter: 84519  total_loss: 0.06761  loss_cls: 0.007225  loss_box_reg: 0.01762  loss_mask: 0.04144  loss_rpn_cls: 0.0003126  loss_rpn_loc: 0.001927  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:08] d2.utils.events INFO:  eta: 0:08:03  iter: 84539  total_loss: 0.0845  loss_cls: 0.009675  loss_box_reg: 0.01825  loss_mask: 0.05106  loss_rpn_cls: 0.0002224  loss_rpn_loc: 0.001645  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:09] d2.utils.events INFO:  eta: 0:08:00  iter: 84559  total_loss: 0.05671  loss_cls: 0.004207  loss_box_reg: 0.01634  loss_mask: 0.0393  loss_rpn_cls: 0.0001469  loss_rpn_loc: 0.001639  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:11] d2.utils.events INFO:  eta: 0:07:59  iter: 84579  total_loss: 0.07773  loss_cls: 0.008568  loss_box_reg: 0.02153  loss_mask: 0.04124  loss_rpn_cls: 0.0004147  loss_rpn_loc: 0.003161  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:13] d2.utils.events INFO:  eta: 0:07:56  iter: 84599  total_loss: 0.07677  loss_cls: 0.01155  loss_box_reg: 0.02061  loss_mask: 0.04454  loss_rpn_cls: 0.0002121  loss_rpn_loc: 0.002442  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:15] d2.utils.events INFO:  eta: 0:07:56  iter: 84619  total_loss: 0.07709  loss_cls: 0.01083  loss_box_reg: 0.02176  loss_mask: 0.04327  loss_rpn_cls: 0.0002964  loss_rpn_loc: 0.002814  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:16] d2.utils.events INFO:  eta: 0:07:54  iter: 84639  total_loss: 0.07638  loss_cls: 0.007752  loss_box_reg: 0.01621  loss_mask: 0.04379  loss_rpn_cls: 0.0002006  loss_rpn_loc: 0.002494  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:18] d2.utils.events INFO:  eta: 0:07:51  iter: 84659  total_loss: 0.05588  loss_cls: 0.004657  loss_box_reg: 0.01457  loss_mask: 0.03427  loss_rpn_cls: 8.971e-05  loss_rpn_loc: 0.001268  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:20] d2.utils.events INFO:  eta: 0:07:50  iter: 84679  total_loss: 0.07782  loss_cls: 0.006715  loss_box_reg: 0.02214  loss_mask: 0.04246  loss_rpn_cls: 0.0002488  loss_rpn_loc: 0.001742  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:22] d2.utils.events INFO:  eta: 0:07:48  iter: 84699  total_loss: 0.06363  loss_cls: 0.005312  loss_box_reg: 0.01447  loss_mask: 0.04296  loss_rpn_cls: 0.0002215  loss_rpn_loc: 0.001476  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:23] d2.utils.events INFO:  eta: 0:07:46  iter: 84719  total_loss: 0.05817  loss_cls: 0.006565  loss_box_reg: 0.01335  loss_mask: 0.03994  loss_rpn_cls: 0.0001978  loss_rpn_loc: 0.001855  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:25] d2.utils.events INFO:  eta: 0:07:44  iter: 84739  total_loss: 0.06836  loss_cls: 0.008212  loss_box_reg: 0.01633  loss_mask: 0.04564  loss_rpn_cls: 0.000158  loss_rpn_loc: 0.002232  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:27] d2.utils.events INFO:  eta: 0:07:42  iter: 84759  total_loss: 0.09665  loss_cls: 0.01092  loss_box_reg: 0.03096  loss_mask: 0.05339  loss_rpn_cls: 0.0002702  loss_rpn_loc: 0.004391  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:29] d2.utils.events INFO:  eta: 0:07:41  iter: 84779  total_loss: 0.08279  loss_cls: 0.01221  loss_box_reg: 0.02441  loss_mask: 0.04817  loss_rpn_cls: 0.000309  loss_rpn_loc: 0.00263  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:31] d2.utils.events INFO:  eta: 0:07:40  iter: 84799  total_loss: 0.08679  loss_cls: 0.01054  loss_box_reg: 0.02598  loss_mask: 0.04458  loss_rpn_cls: 0.000338  loss_rpn_loc: 0.004499  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:32] d2.utils.events INFO:  eta: 0:07:38  iter: 84819  total_loss: 0.07568  loss_cls: 0.005934  loss_box_reg: 0.01891  loss_mask: 0.04621  loss_rpn_cls: 6.843e-05  loss_rpn_loc: 0.001695  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:34] d2.utils.events INFO:  eta: 0:07:37  iter: 84839  total_loss: 0.08766  loss_cls: 0.01139  loss_box_reg: 0.02854  loss_mask: 0.04325  loss_rpn_cls: 0.0002019  loss_rpn_loc: 0.002398  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:36] d2.utils.events INFO:  eta: 0:07:34  iter: 84859  total_loss: 0.06607  loss_cls: 0.004738  loss_box_reg: 0.01724  loss_mask: 0.04046  loss_rpn_cls: 0.000104  loss_rpn_loc: 0.001651  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:38] d2.utils.events INFO:  eta: 0:07:33  iter: 84879  total_loss: 0.07164  loss_cls: 0.009936  loss_box_reg: 0.02044  loss_mask: 0.04168  loss_rpn_cls: 0.0002859  loss_rpn_loc: 0.003246  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:40] d2.utils.events INFO:  eta: 0:07:30  iter: 84899  total_loss: 0.07805  loss_cls: 0.007836  loss_box_reg: 0.01937  loss_mask: 0.03965  loss_rpn_cls: 0.0002573  loss_rpn_loc: 0.003015  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:41] d2.utils.events INFO:  eta: 0:07:30  iter: 84919  total_loss: 0.1025  loss_cls: 0.01018  loss_box_reg: 0.03144  loss_mask: 0.04545  loss_rpn_cls: 0.0002414  loss_rpn_loc: 0.003826  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:43] d2.utils.events INFO:  eta: 0:07:29  iter: 84939  total_loss: 0.08174  loss_cls: 0.01122  loss_box_reg: 0.02115  loss_mask: 0.04811  loss_rpn_cls: 0.0004226  loss_rpn_loc: 0.003698  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:45] d2.utils.events INFO:  eta: 0:07:27  iter: 84959  total_loss: 0.07319  loss_cls: 0.01108  loss_box_reg: 0.02086  loss_mask: 0.03891  loss_rpn_cls: 0.000341  loss_rpn_loc: 0.003228  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:47] d2.utils.events INFO:  eta: 0:07:25  iter: 84979  total_loss: 0.07865  loss_cls: 0.009475  loss_box_reg: 0.02482  loss_mask: 0.05026  loss_rpn_cls: 0.0003491  loss_rpn_loc: 0.002518  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:49] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0084999.pth
[10/27 20:42:49] d2.utils.events INFO:  eta: 0:07:23  iter: 84999  total_loss: 0.07082  loss_cls: 0.01034  loss_box_reg: 0.01892  loss_mask: 0.03477  loss_rpn_cls: 0.0002262  loss_rpn_loc: 0.002332  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:51] d2.utils.events INFO:  eta: 0:07:22  iter: 85019  total_loss: 0.09073  loss_cls: 0.01203  loss_box_reg: 0.02836  loss_mask: 0.05145  loss_rpn_cls: 0.0002942  loss_rpn_loc: 0.003486  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:53] d2.utils.events INFO:  eta: 0:07:20  iter: 85039  total_loss: 0.08093  loss_cls: 0.009011  loss_box_reg: 0.02298  loss_mask: 0.04311  loss_rpn_cls: 0.0002183  loss_rpn_loc: 0.002165  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:54] d2.utils.events INFO:  eta: 0:07:18  iter: 85059  total_loss: 0.06862  loss_cls: 0.008539  loss_box_reg: 0.01572  loss_mask: 0.04017  loss_rpn_cls: 0.0001737  loss_rpn_loc: 0.002013  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:56] d2.utils.events INFO:  eta: 0:07:16  iter: 85079  total_loss: 0.06788  loss_cls: 0.008143  loss_box_reg: 0.01871  loss_mask: 0.0479  loss_rpn_cls: 0.000209  loss_rpn_loc: 0.00219  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:42:58] d2.utils.events INFO:  eta: 0:07:13  iter: 85099  total_loss: 0.07052  loss_cls: 0.008877  loss_box_reg: 0.01981  loss_mask: 0.0378  loss_rpn_cls: 0.0001748  loss_rpn_loc: 0.002456  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:00] d2.utils.events INFO:  eta: 0:07:12  iter: 85119  total_loss: 0.08311  loss_cls: 0.006613  loss_box_reg: 0.02178  loss_mask: 0.04854  loss_rpn_cls: 0.0002805  loss_rpn_loc: 0.002591  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:01] d2.utils.events INFO:  eta: 0:07:10  iter: 85139  total_loss: 0.08451  loss_cls: 0.01026  loss_box_reg: 0.01836  loss_mask: 0.05551  loss_rpn_cls: 0.0001988  loss_rpn_loc: 0.002784  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:03] d2.utils.events INFO:  eta: 0:07:09  iter: 85159  total_loss: 0.05977  loss_cls: 0.006431  loss_box_reg: 0.016  loss_mask: 0.03456  loss_rpn_cls: 0.0001096  loss_rpn_loc: 0.001595  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:05] d2.utils.events INFO:  eta: 0:07:07  iter: 85179  total_loss: 0.06468  loss_cls: 0.007969  loss_box_reg: 0.0178  loss_mask: 0.04134  loss_rpn_cls: 0.0003132  loss_rpn_loc: 0.002226  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:06] d2.utils.events INFO:  eta: 0:07:05  iter: 85199  total_loss: 0.05558  loss_cls: 0.005481  loss_box_reg: 0.01266  loss_mask: 0.03988  loss_rpn_cls: 0.000133  loss_rpn_loc: 0.0007906  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:08] d2.utils.events INFO:  eta: 0:07:03  iter: 85219  total_loss: 0.07307  loss_cls: 0.008341  loss_box_reg: 0.01879  loss_mask: 0.04496  loss_rpn_cls: 0.0001675  loss_rpn_loc: 0.001881  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:10] d2.utils.events INFO:  eta: 0:07:01  iter: 85239  total_loss: 0.1176  loss_cls: 0.007593  loss_box_reg: 0.02701  loss_mask: 0.06694  loss_rpn_cls: 0.0002904  loss_rpn_loc: 0.002687  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:12] d2.utils.events INFO:  eta: 0:07:00  iter: 85259  total_loss: 0.08914  loss_cls: 0.01036  loss_box_reg: 0.02903  loss_mask: 0.04084  loss_rpn_cls: 0.0002849  loss_rpn_loc: 0.002723  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:14] d2.utils.events INFO:  eta: 0:06:57  iter: 85279  total_loss: 0.05  loss_cls: 0.006625  loss_box_reg: 0.0133  loss_mask: 0.02916  loss_rpn_cls: 0.0001103  loss_rpn_loc: 0.001811  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:15] d2.utils.events INFO:  eta: 0:06:54  iter: 85299  total_loss: 0.06735  loss_cls: 0.006079  loss_box_reg: 0.01688  loss_mask: 0.04224  loss_rpn_cls: 0.0001242  loss_rpn_loc: 0.001655  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:17] d2.utils.events INFO:  eta: 0:06:53  iter: 85319  total_loss: 0.1133  loss_cls: 0.01243  loss_box_reg: 0.03414  loss_mask: 0.06079  loss_rpn_cls: 0.0003308  loss_rpn_loc: 0.005342  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:19] d2.utils.events INFO:  eta: 0:06:52  iter: 85339  total_loss: 0.07222  loss_cls: 0.007141  loss_box_reg: 0.01755  loss_mask: 0.03814  loss_rpn_cls: 0.0001963  loss_rpn_loc: 0.001919  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:21] d2.utils.events INFO:  eta: 0:06:50  iter: 85359  total_loss: 0.06613  loss_cls: 0.007534  loss_box_reg: 0.01593  loss_mask: 0.03898  loss_rpn_cls: 9.179e-05  loss_rpn_loc: 0.00179  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:22] d2.utils.events INFO:  eta: 0:06:47  iter: 85379  total_loss: 0.1047  loss_cls: 0.009547  loss_box_reg: 0.02969  loss_mask: 0.06018  loss_rpn_cls: 0.0002158  loss_rpn_loc: 0.004499  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:24] d2.utils.events INFO:  eta: 0:06:45  iter: 85399  total_loss: 0.07774  loss_cls: 0.01211  loss_box_reg: 0.02159  loss_mask: 0.03862  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.003648  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:26] d2.utils.events INFO:  eta: 0:06:42  iter: 85419  total_loss: 0.07304  loss_cls: 0.008401  loss_box_reg: 0.01976  loss_mask: 0.0424  loss_rpn_cls: 0.0003874  loss_rpn_loc: 0.002881  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:28] d2.utils.events INFO:  eta: 0:06:41  iter: 85439  total_loss: 0.08246  loss_cls: 0.009987  loss_box_reg: 0.02401  loss_mask: 0.04397  loss_rpn_cls: 0.0006967  loss_rpn_loc: 0.003612  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:29] d2.utils.events INFO:  eta: 0:06:39  iter: 85459  total_loss: 0.06451  loss_cls: 0.006743  loss_box_reg: 0.01675  loss_mask: 0.04173  loss_rpn_cls: 0.0001917  loss_rpn_loc: 0.002003  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:31] d2.utils.events INFO:  eta: 0:06:38  iter: 85479  total_loss: 0.0629  loss_cls: 0.005562  loss_box_reg: 0.01297  loss_mask: 0.03505  loss_rpn_cls: 6.656e-05  loss_rpn_loc: 0.00151  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:33] d2.utils.events INFO:  eta: 0:06:37  iter: 85499  total_loss: 0.07037  loss_cls: 0.009504  loss_box_reg: 0.01733  loss_mask: 0.0432  loss_rpn_cls: 0.0001914  loss_rpn_loc: 0.003147  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:35] d2.utils.events INFO:  eta: 0:06:35  iter: 85519  total_loss: 0.06697  loss_cls: 0.007834  loss_box_reg: 0.0181  loss_mask: 0.04185  loss_rpn_cls: 0.0001586  loss_rpn_loc: 0.001647  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:37] d2.utils.events INFO:  eta: 0:06:34  iter: 85539  total_loss: 0.09205  loss_cls: 0.01433  loss_box_reg: 0.02667  loss_mask: 0.0457  loss_rpn_cls: 0.0001861  loss_rpn_loc: 0.002859  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:38] d2.utils.events INFO:  eta: 0:06:32  iter: 85559  total_loss: 0.05757  loss_cls: 0.006598  loss_box_reg: 0.01373  loss_mask: 0.0383  loss_rpn_cls: 0.0001664  loss_rpn_loc: 0.001912  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:40] d2.utils.events INFO:  eta: 0:06:30  iter: 85579  total_loss: 0.08346  loss_cls: 0.01067  loss_box_reg: 0.02677  loss_mask: 0.05104  loss_rpn_cls: 0.0001994  loss_rpn_loc: 0.004352  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:42] d2.utils.events INFO:  eta: 0:06:29  iter: 85599  total_loss: 0.06621  loss_cls: 0.006244  loss_box_reg: 0.01978  loss_mask: 0.03919  loss_rpn_cls: 0.000233  loss_rpn_loc: 0.00141  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:44] d2.utils.events INFO:  eta: 0:06:26  iter: 85619  total_loss: 0.06934  loss_cls: 0.006094  loss_box_reg: 0.01555  loss_mask: 0.04131  loss_rpn_cls: 0.0001609  loss_rpn_loc: 0.002028  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:45] d2.utils.events INFO:  eta: 0:06:25  iter: 85639  total_loss: 0.08264  loss_cls: 0.01424  loss_box_reg: 0.02468  loss_mask: 0.041  loss_rpn_cls: 0.0002221  loss_rpn_loc: 0.003339  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:47] d2.utils.events INFO:  eta: 0:06:24  iter: 85659  total_loss: 0.0823  loss_cls: 0.009406  loss_box_reg: 0.02296  loss_mask: 0.04886  loss_rpn_cls: 0.0003115  loss_rpn_loc: 0.002699  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:49] d2.utils.events INFO:  eta: 0:06:23  iter: 85679  total_loss: 0.09212  loss_cls: 0.01045  loss_box_reg: 0.031  loss_mask: 0.04281  loss_rpn_cls: 0.0003593  loss_rpn_loc: 0.004798  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:51] d2.utils.events INFO:  eta: 0:06:21  iter: 85699  total_loss: 0.06213  loss_cls: 0.007789  loss_box_reg: 0.01497  loss_mask: 0.04577  loss_rpn_cls: 0.0002391  loss_rpn_loc: 0.003751  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:53] d2.utils.events INFO:  eta: 0:06:20  iter: 85719  total_loss: 0.06758  loss_cls: 0.007147  loss_box_reg: 0.01709  loss_mask: 0.04676  loss_rpn_cls: 0.0004445  loss_rpn_loc: 0.002966  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:54] d2.utils.events INFO:  eta: 0:06:18  iter: 85739  total_loss: 0.06652  loss_cls: 0.006104  loss_box_reg: 0.01778  loss_mask: 0.04206  loss_rpn_cls: 0.0001784  loss_rpn_loc: 0.001729  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:56] d2.utils.events INFO:  eta: 0:06:16  iter: 85759  total_loss: 0.08191  loss_cls: 0.01023  loss_box_reg: 0.02892  loss_mask: 0.0451  loss_rpn_cls: 0.0002247  loss_rpn_loc: 0.002514  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:43:58] d2.utils.events INFO:  eta: 0:06:14  iter: 85779  total_loss: 0.05912  loss_cls: 0.006128  loss_box_reg: 0.01817  loss_mask: 0.03666  loss_rpn_cls: 0.0001717  loss_rpn_loc: 0.002339  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:00] d2.utils.events INFO:  eta: 0:06:11  iter: 85799  total_loss: 0.06604  loss_cls: 0.006462  loss_box_reg: 0.01793  loss_mask: 0.03983  loss_rpn_cls: 9.106e-05  loss_rpn_loc: 0.001562  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:01] d2.utils.events INFO:  eta: 0:06:10  iter: 85819  total_loss: 0.0745  loss_cls: 0.009528  loss_box_reg: 0.01868  loss_mask: 0.03684  loss_rpn_cls: 0.0001584  loss_rpn_loc: 0.00193  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:03] d2.utils.events INFO:  eta: 0:06:08  iter: 85839  total_loss: 0.08566  loss_cls: 0.0101  loss_box_reg: 0.02874  loss_mask: 0.04525  loss_rpn_cls: 0.00021  loss_rpn_loc: 0.002907  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:05] d2.utils.events INFO:  eta: 0:06:07  iter: 85859  total_loss: 0.07269  loss_cls: 0.008333  loss_box_reg: 0.01902  loss_mask: 0.03895  loss_rpn_cls: 0.0001514  loss_rpn_loc: 0.001698  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:07] d2.utils.events INFO:  eta: 0:06:05  iter: 85879  total_loss: 0.07463  loss_cls: 0.006071  loss_box_reg: 0.01929  loss_mask: 0.04699  loss_rpn_cls: 0.0001382  loss_rpn_loc: 0.002075  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:09] d2.utils.events INFO:  eta: 0:06:03  iter: 85899  total_loss: 0.0742  loss_cls: 0.007332  loss_box_reg: 0.01661  loss_mask: 0.04631  loss_rpn_cls: 0.0002025  loss_rpn_loc: 0.002357  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:10] d2.utils.events INFO:  eta: 0:06:01  iter: 85919  total_loss: 0.09265  loss_cls: 0.009482  loss_box_reg: 0.02063  loss_mask: 0.05232  loss_rpn_cls: 0.0002237  loss_rpn_loc: 0.002489  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:12] d2.utils.events INFO:  eta: 0:05:59  iter: 85939  total_loss: 0.1004  loss_cls: 0.01466  loss_box_reg: 0.03224  loss_mask: 0.04743  loss_rpn_cls: 0.0006767  loss_rpn_loc: 0.003836  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:14] d2.utils.events INFO:  eta: 0:05:57  iter: 85959  total_loss: 0.06299  loss_cls: 0.006981  loss_box_reg: 0.02016  loss_mask: 0.04205  loss_rpn_cls: 0.0002655  loss_rpn_loc: 0.002524  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:16] d2.utils.events INFO:  eta: 0:05:55  iter: 85979  total_loss: 0.07256  loss_cls: 0.008488  loss_box_reg: 0.02072  loss_mask: 0.04096  loss_rpn_cls: 0.0002491  loss_rpn_loc: 0.002521  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:17] d2.utils.events INFO:  eta: 0:05:53  iter: 85999  total_loss: 0.07564  loss_cls: 0.01032  loss_box_reg: 0.02167  loss_mask: 0.0386  loss_rpn_cls: 0.0003015  loss_rpn_loc: 0.002815  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:19] d2.utils.events INFO:  eta: 0:05:51  iter: 86019  total_loss: 0.06197  loss_cls: 0.006473  loss_box_reg: 0.01485  loss_mask: 0.04268  loss_rpn_cls: 0.000103  loss_rpn_loc: 0.002569  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:21] d2.utils.events INFO:  eta: 0:05:48  iter: 86039  total_loss: 0.08031  loss_cls: 0.008819  loss_box_reg: 0.0199  loss_mask: 0.04789  loss_rpn_cls: 0.0001512  loss_rpn_loc: 0.002008  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:23] d2.utils.events INFO:  eta: 0:05:46  iter: 86059  total_loss: 0.07008  loss_cls: 0.005989  loss_box_reg: 0.01736  loss_mask: 0.04806  loss_rpn_cls: 0.0001328  loss_rpn_loc: 0.002052  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:24] d2.utils.events INFO:  eta: 0:05:44  iter: 86079  total_loss: 0.07174  loss_cls: 0.006459  loss_box_reg: 0.01859  loss_mask: 0.03447  loss_rpn_cls: 0.0001835  loss_rpn_loc: 0.002062  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:26] d2.utils.events INFO:  eta: 0:05:43  iter: 86099  total_loss: 0.09534  loss_cls: 0.006649  loss_box_reg: 0.02393  loss_mask: 0.05408  loss_rpn_cls: 0.0002194  loss_rpn_loc: 0.004053  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:28] d2.utils.events INFO:  eta: 0:05:40  iter: 86119  total_loss: 0.06052  loss_cls: 0.00523  loss_box_reg: 0.01167  loss_mask: 0.0401  loss_rpn_cls: 0.0001738  loss_rpn_loc: 0.001298  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:30] d2.utils.events INFO:  eta: 0:05:39  iter: 86139  total_loss: 0.07666  loss_cls: 0.008849  loss_box_reg: 0.01833  loss_mask: 0.04056  loss_rpn_cls: 0.0001941  loss_rpn_loc: 0.002068  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:31] d2.utils.events INFO:  eta: 0:05:38  iter: 86159  total_loss: 0.08073  loss_cls: 0.009297  loss_box_reg: 0.02041  loss_mask: 0.04126  loss_rpn_cls: 0.0001957  loss_rpn_loc: 0.002371  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:33] d2.utils.events INFO:  eta: 0:05:36  iter: 86179  total_loss: 0.07008  loss_cls: 0.006762  loss_box_reg: 0.01561  loss_mask: 0.04337  loss_rpn_cls: 0.0002917  loss_rpn_loc: 0.001819  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:35] d2.utils.events INFO:  eta: 0:05:35  iter: 86199  total_loss: 0.08874  loss_cls: 0.01218  loss_box_reg: 0.02736  loss_mask: 0.04178  loss_rpn_cls: 0.000106  loss_rpn_loc: 0.002294  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:37] d2.utils.events INFO:  eta: 0:05:33  iter: 86219  total_loss: 0.06813  loss_cls: 0.008218  loss_box_reg: 0.01618  loss_mask: 0.04394  loss_rpn_cls: 0.0001501  loss_rpn_loc: 0.002053  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:38] d2.utils.events INFO:  eta: 0:05:31  iter: 86239  total_loss: 0.07472  loss_cls: 0.008491  loss_box_reg: 0.01729  loss_mask: 0.04728  loss_rpn_cls: 0.0002134  loss_rpn_loc: 0.002617  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:40] d2.utils.events INFO:  eta: 0:05:29  iter: 86259  total_loss: 0.06398  loss_cls: 0.01004  loss_box_reg: 0.01717  loss_mask: 0.04139  loss_rpn_cls: 0.0001452  loss_rpn_loc: 0.001639  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:42] d2.utils.events INFO:  eta: 0:05:28  iter: 86279  total_loss: 0.1213  loss_cls: 0.01502  loss_box_reg: 0.03647  loss_mask: 0.06145  loss_rpn_cls: 0.0004812  loss_rpn_loc: 0.003395  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:44] d2.utils.events INFO:  eta: 0:05:27  iter: 86299  total_loss: 0.0708  loss_cls: 0.009589  loss_box_reg: 0.02251  loss_mask: 0.03346  loss_rpn_cls: 0.000239  loss_rpn_loc: 0.002016  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:46] d2.utils.events INFO:  eta: 0:05:24  iter: 86319  total_loss: 0.08204  loss_cls: 0.009323  loss_box_reg: 0.01882  loss_mask: 0.04391  loss_rpn_cls: 0.0003641  loss_rpn_loc: 0.002437  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:47] d2.utils.events INFO:  eta: 0:05:23  iter: 86339  total_loss: 0.08752  loss_cls: 0.009578  loss_box_reg: 0.02475  loss_mask: 0.0457  loss_rpn_cls: 0.0001859  loss_rpn_loc: 0.002961  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:49] d2.utils.events INFO:  eta: 0:05:22  iter: 86359  total_loss: 0.0844  loss_cls: 0.006529  loss_box_reg: 0.02356  loss_mask: 0.04236  loss_rpn_cls: 0.0003351  loss_rpn_loc: 0.003715  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:51] d2.utils.events INFO:  eta: 0:05:20  iter: 86379  total_loss: 0.08517  loss_cls: 0.009955  loss_box_reg: 0.02474  loss_mask: 0.05214  loss_rpn_cls: 0.0003791  loss_rpn_loc: 0.003501  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:53] d2.utils.events INFO:  eta: 0:05:18  iter: 86399  total_loss: 0.08151  loss_cls: 0.01141  loss_box_reg: 0.02124  loss_mask: 0.05108  loss_rpn_cls: 0.0001856  loss_rpn_loc: 0.002032  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:55] d2.utils.events INFO:  eta: 0:05:17  iter: 86419  total_loss: 0.1154  loss_cls: 0.01428  loss_box_reg: 0.0324  loss_mask: 0.05873  loss_rpn_cls: 0.0004785  loss_rpn_loc: 0.004977  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:56] d2.utils.events INFO:  eta: 0:05:15  iter: 86439  total_loss: 0.06801  loss_cls: 0.004853  loss_box_reg: 0.01465  loss_mask: 0.04439  loss_rpn_cls: 0.0001298  loss_rpn_loc: 0.001256  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:44:58] d2.utils.events INFO:  eta: 0:05:13  iter: 86459  total_loss: 0.07814  loss_cls: 0.008154  loss_box_reg: 0.01929  loss_mask: 0.04042  loss_rpn_cls: 0.0002103  loss_rpn_loc: 0.002145  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:00] d2.utils.events INFO:  eta: 0:05:11  iter: 86479  total_loss: 0.07921  loss_cls: 0.007032  loss_box_reg: 0.02077  loss_mask: 0.04957  loss_rpn_cls: 0.0001991  loss_rpn_loc: 0.00206  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:02] d2.utils.events INFO:  eta: 0:05:10  iter: 86499  total_loss: 0.08564  loss_cls: 0.01106  loss_box_reg: 0.02437  loss_mask: 0.04448  loss_rpn_cls: 0.0001857  loss_rpn_loc: 0.002792  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:03] d2.utils.events INFO:  eta: 0:05:08  iter: 86519  total_loss: 0.0681  loss_cls: 0.006631  loss_box_reg: 0.01579  loss_mask: 0.04244  loss_rpn_cls: 0.0001257  loss_rpn_loc: 0.002136  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:05] d2.utils.events INFO:  eta: 0:05:05  iter: 86539  total_loss: 0.05622  loss_cls: 0.004284  loss_box_reg: 0.01112  loss_mask: 0.03748  loss_rpn_cls: 0.0002024  loss_rpn_loc: 0.001955  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:07] d2.utils.events INFO:  eta: 0:05:04  iter: 86559  total_loss: 0.06755  loss_cls: 0.00824  loss_box_reg: 0.01768  loss_mask: 0.04263  loss_rpn_cls: 0.0001513  loss_rpn_loc: 0.002405  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:09] d2.utils.events INFO:  eta: 0:05:02  iter: 86579  total_loss: 0.08386  loss_cls: 0.01127  loss_box_reg: 0.02162  loss_mask: 0.04286  loss_rpn_cls: 0.0002992  loss_rpn_loc: 0.003343  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:10] d2.utils.events INFO:  eta: 0:05:00  iter: 86599  total_loss: 0.0589  loss_cls: 0.008599  loss_box_reg: 0.01363  loss_mask: 0.0355  loss_rpn_cls: 6.6e-05  loss_rpn_loc: 0.00158  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:12] d2.utils.events INFO:  eta: 0:04:59  iter: 86619  total_loss: 0.08104  loss_cls: 0.01035  loss_box_reg: 0.02813  loss_mask: 0.04299  loss_rpn_cls: 0.0002567  loss_rpn_loc: 0.002681  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:14] d2.utils.events INFO:  eta: 0:04:57  iter: 86639  total_loss: 0.07641  loss_cls: 0.009399  loss_box_reg: 0.01918  loss_mask: 0.04713  loss_rpn_cls: 0.0002843  loss_rpn_loc: 0.003177  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:16] d2.utils.events INFO:  eta: 0:04:55  iter: 86659  total_loss: 0.06699  loss_cls: 0.008412  loss_box_reg: 0.02397  loss_mask: 0.03803  loss_rpn_cls: 0.0001265  loss_rpn_loc: 0.002415  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:18] d2.utils.events INFO:  eta: 0:04:53  iter: 86679  total_loss: 0.06472  loss_cls: 0.00863  loss_box_reg: 0.01643  loss_mask: 0.05006  loss_rpn_cls: 0.0003939  loss_rpn_loc: 0.002491  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:19] d2.utils.events INFO:  eta: 0:04:51  iter: 86699  total_loss: 0.07529  loss_cls: 0.01123  loss_box_reg: 0.02529  loss_mask: 0.03776  loss_rpn_cls: 0.0001486  loss_rpn_loc: 0.003064  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:21] d2.utils.events INFO:  eta: 0:04:49  iter: 86719  total_loss: 0.1012  loss_cls: 0.01412  loss_box_reg: 0.02854  loss_mask: 0.06744  loss_rpn_cls: 0.0002233  loss_rpn_loc: 0.007268  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:23] d2.utils.events INFO:  eta: 0:04:48  iter: 86739  total_loss: 0.08417  loss_cls: 0.007048  loss_box_reg: 0.02165  loss_mask: 0.04502  loss_rpn_cls: 0.0001686  loss_rpn_loc: 0.002456  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:25] d2.utils.events INFO:  eta: 0:04:47  iter: 86759  total_loss: 0.07605  loss_cls: 0.00917  loss_box_reg: 0.02565  loss_mask: 0.04118  loss_rpn_cls: 0.0001259  loss_rpn_loc: 0.001889  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:26] d2.utils.events INFO:  eta: 0:04:45  iter: 86779  total_loss: 0.06945  loss_cls: 0.007776  loss_box_reg: 0.01622  loss_mask: 0.03945  loss_rpn_cls: 0.0004516  loss_rpn_loc: 0.002989  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:28] d2.utils.events INFO:  eta: 0:04:44  iter: 86799  total_loss: 0.0779  loss_cls: 0.01144  loss_box_reg: 0.02057  loss_mask: 0.05213  loss_rpn_cls: 0.0005261  loss_rpn_loc: 0.00395  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:30] d2.utils.events INFO:  eta: 0:04:42  iter: 86819  total_loss: 0.06634  loss_cls: 0.005131  loss_box_reg: 0.01581  loss_mask: 0.04263  loss_rpn_cls: 0.0001661  loss_rpn_loc: 0.001608  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:32] d2.utils.events INFO:  eta: 0:04:39  iter: 86839  total_loss: 0.07223  loss_cls: 0.008708  loss_box_reg: 0.01481  loss_mask: 0.04547  loss_rpn_cls: 0.000171  loss_rpn_loc: 0.002532  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:33] d2.utils.events INFO:  eta: 0:04:37  iter: 86859  total_loss: 0.06964  loss_cls: 0.00894  loss_box_reg: 0.0201  loss_mask: 0.0419  loss_rpn_cls: 0.0001529  loss_rpn_loc: 0.002045  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:35] d2.utils.events INFO:  eta: 0:04:35  iter: 86879  total_loss: 0.06751  loss_cls: 0.007299  loss_box_reg: 0.01757  loss_mask: 0.04153  loss_rpn_cls: 0.0002515  loss_rpn_loc: 0.002249  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:37] d2.utils.events INFO:  eta: 0:04:34  iter: 86899  total_loss: 0.1327  loss_cls: 0.01077  loss_box_reg: 0.0309  loss_mask: 0.06699  loss_rpn_cls: 0.0003887  loss_rpn_loc: 0.004989  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:39] d2.utils.events INFO:  eta: 0:04:32  iter: 86919  total_loss: 0.0647  loss_cls: 0.006527  loss_box_reg: 0.01112  loss_mask: 0.03817  loss_rpn_cls: 9.451e-05  loss_rpn_loc: 0.001294  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:40] d2.utils.events INFO:  eta: 0:04:29  iter: 86939  total_loss: 0.05812  loss_cls: 0.007329  loss_box_reg: 0.01691  loss_mask: 0.03851  loss_rpn_cls: 0.0001709  loss_rpn_loc: 0.001533  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:42] d2.utils.events INFO:  eta: 0:04:28  iter: 86959  total_loss: 0.07613  loss_cls: 0.006822  loss_box_reg: 0.01947  loss_mask: 0.04662  loss_rpn_cls: 0.0001931  loss_rpn_loc: 0.002215  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:44] d2.utils.events INFO:  eta: 0:04:27  iter: 86979  total_loss: 0.07798  loss_cls: 0.009955  loss_box_reg: 0.01752  loss_mask: 0.04424  loss_rpn_cls: 0.000261  loss_rpn_loc: 0.002118  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:46] d2.utils.events INFO:  eta: 0:04:25  iter: 86999  total_loss: 0.08076  loss_cls: 0.009348  loss_box_reg: 0.01953  loss_mask: 0.03847  loss_rpn_cls: 0.0001921  loss_rpn_loc: 0.002508  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:48] d2.utils.events INFO:  eta: 0:04:23  iter: 87019  total_loss: 0.06674  loss_cls: 0.008363  loss_box_reg: 0.01545  loss_mask: 0.03698  loss_rpn_cls: 0.0002847  loss_rpn_loc: 0.002286  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:49] d2.utils.events INFO:  eta: 0:04:21  iter: 87039  total_loss: 0.06487  loss_cls: 0.005871  loss_box_reg: 0.01739  loss_mask: 0.03703  loss_rpn_cls: 0.000131  loss_rpn_loc: 0.001635  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:51] d2.utils.events INFO:  eta: 0:04:19  iter: 87059  total_loss: 0.0838  loss_cls: 0.00999  loss_box_reg: 0.02559  loss_mask: 0.05333  loss_rpn_cls: 0.0003557  loss_rpn_loc: 0.003443  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:53] d2.utils.events INFO:  eta: 0:04:17  iter: 87079  total_loss: 0.07269  loss_cls: 0.005751  loss_box_reg: 0.01777  loss_mask: 0.04171  loss_rpn_cls: 0.0002458  loss_rpn_loc: 0.001712  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:55] d2.utils.events INFO:  eta: 0:04:16  iter: 87099  total_loss: 0.08296  loss_cls: 0.009662  loss_box_reg: 0.02849  loss_mask: 0.04554  loss_rpn_cls: 0.0001642  loss_rpn_loc: 0.002594  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:56] d2.utils.events INFO:  eta: 0:04:15  iter: 87119  total_loss: 0.09291  loss_cls: 0.01177  loss_box_reg: 0.02595  loss_mask: 0.05314  loss_rpn_cls: 0.0002309  loss_rpn_loc: 0.003703  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:45:58] d2.utils.events INFO:  eta: 0:04:13  iter: 87139  total_loss: 0.07695  loss_cls: 0.006918  loss_box_reg: 0.01338  loss_mask: 0.04886  loss_rpn_cls: 0.0001589  loss_rpn_loc: 0.002072  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:00] d2.utils.events INFO:  eta: 0:04:11  iter: 87159  total_loss: 0.07041  loss_cls: 0.008047  loss_box_reg: 0.01412  loss_mask: 0.04205  loss_rpn_cls: 0.0001661  loss_rpn_loc: 0.002497  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:02] d2.utils.events INFO:  eta: 0:04:09  iter: 87179  total_loss: 0.06486  loss_cls: 0.008199  loss_box_reg: 0.01708  loss_mask: 0.03832  loss_rpn_cls: 0.0003268  loss_rpn_loc: 0.003719  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:03] d2.utils.events INFO:  eta: 0:04:08  iter: 87199  total_loss: 0.07111  loss_cls: 0.007681  loss_box_reg: 0.01561  loss_mask: 0.04587  loss_rpn_cls: 0.0001537  loss_rpn_loc: 0.00203  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:05] d2.utils.events INFO:  eta: 0:04:06  iter: 87219  total_loss: 0.05341  loss_cls: 0.005249  loss_box_reg: 0.01474  loss_mask: 0.03587  loss_rpn_cls: 0.0001367  loss_rpn_loc: 0.001435  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:07] d2.utils.events INFO:  eta: 0:04:04  iter: 87239  total_loss: 0.07172  loss_cls: 0.008975  loss_box_reg: 0.0161  loss_mask: 0.0372  loss_rpn_cls: 0.0001779  loss_rpn_loc: 0.002763  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:09] d2.utils.events INFO:  eta: 0:04:02  iter: 87259  total_loss: 0.07216  loss_cls: 0.01019  loss_box_reg: 0.01998  loss_mask: 0.03948  loss_rpn_cls: 0.0001715  loss_rpn_loc: 0.00215  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:11] d2.utils.events INFO:  eta: 0:04:01  iter: 87279  total_loss: 0.07331  loss_cls: 0.008437  loss_box_reg: 0.02533  loss_mask: 0.04043  loss_rpn_cls: 0.0004295  loss_rpn_loc: 0.004784  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:12] d2.utils.events INFO:  eta: 0:03:59  iter: 87299  total_loss: 0.1083  loss_cls: 0.01077  loss_box_reg: 0.03131  loss_mask: 0.05807  loss_rpn_cls: 0.0005975  loss_rpn_loc: 0.00635  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:14] d2.utils.events INFO:  eta: 0:03:57  iter: 87319  total_loss: 0.06444  loss_cls: 0.007008  loss_box_reg: 0.01593  loss_mask: 0.04109  loss_rpn_cls: 0.0003213  loss_rpn_loc: 0.003005  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:16] d2.utils.events INFO:  eta: 0:03:56  iter: 87339  total_loss: 0.08574  loss_cls: 0.008053  loss_box_reg: 0.0231  loss_mask: 0.04664  loss_rpn_cls: 0.0002195  loss_rpn_loc: 0.002521  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:18] d2.utils.events INFO:  eta: 0:03:54  iter: 87359  total_loss: 0.1149  loss_cls: 0.01248  loss_box_reg: 0.02734  loss_mask: 0.06775  loss_rpn_cls: 0.0003099  loss_rpn_loc: 0.003653  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:19] d2.utils.events INFO:  eta: 0:03:52  iter: 87379  total_loss: 0.07156  loss_cls: 0.008335  loss_box_reg: 0.01883  loss_mask: 0.05023  loss_rpn_cls: 0.0002146  loss_rpn_loc: 0.002305  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:21] d2.utils.events INFO:  eta: 0:03:51  iter: 87399  total_loss: 0.07542  loss_cls: 0.01094  loss_box_reg: 0.02186  loss_mask: 0.04485  loss_rpn_cls: 0.0004535  loss_rpn_loc: 0.003201  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:23] d2.utils.events INFO:  eta: 0:03:49  iter: 87419  total_loss: 0.077  loss_cls: 0.0091  loss_box_reg: 0.02347  loss_mask: 0.04234  loss_rpn_cls: 0.0002647  loss_rpn_loc: 0.002381  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:25] d2.utils.events INFO:  eta: 0:03:47  iter: 87439  total_loss: 0.06404  loss_cls: 0.005717  loss_box_reg: 0.01352  loss_mask: 0.04655  loss_rpn_cls: 0.0002058  loss_rpn_loc: 0.001565  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:26] d2.utils.events INFO:  eta: 0:03:46  iter: 87459  total_loss: 0.07965  loss_cls: 0.008183  loss_box_reg: 0.01916  loss_mask: 0.05113  loss_rpn_cls: 0.0001352  loss_rpn_loc: 0.001989  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:28] d2.utils.events INFO:  eta: 0:03:44  iter: 87479  total_loss: 0.0571  loss_cls: 0.004797  loss_box_reg: 0.01707  loss_mask: 0.03527  loss_rpn_cls: 0.0001476  loss_rpn_loc: 0.002866  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:30] d2.utils.events INFO:  eta: 0:03:41  iter: 87499  total_loss: 0.06901  loss_cls: 0.008326  loss_box_reg: 0.01605  loss_mask: 0.04466  loss_rpn_cls: 0.0001642  loss_rpn_loc: 0.001644  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:32] d2.utils.events INFO:  eta: 0:03:39  iter: 87519  total_loss: 0.06857  loss_cls: 0.007786  loss_box_reg: 0.01593  loss_mask: 0.03908  loss_rpn_cls: 0.0001772  loss_rpn_loc: 0.002297  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:34] d2.utils.events INFO:  eta: 0:03:38  iter: 87539  total_loss: 0.05544  loss_cls: 0.006089  loss_box_reg: 0.014  loss_mask: 0.03389  loss_rpn_cls: 0.0001265  loss_rpn_loc: 0.001944  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:35] d2.utils.events INFO:  eta: 0:03:36  iter: 87559  total_loss: 0.06109  loss_cls: 0.007687  loss_box_reg: 0.01484  loss_mask: 0.03803  loss_rpn_cls: 0.0001189  loss_rpn_loc: 0.001812  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:37] d2.utils.events INFO:  eta: 0:03:35  iter: 87579  total_loss: 0.1091  loss_cls: 0.01058  loss_box_reg: 0.0335  loss_mask: 0.0639  loss_rpn_cls: 0.0005475  loss_rpn_loc: 0.003745  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:39] d2.utils.events INFO:  eta: 0:03:33  iter: 87599  total_loss: 0.1122  loss_cls: 0.01239  loss_box_reg: 0.03602  loss_mask: 0.04786  loss_rpn_cls: 0.000302  loss_rpn_loc: 0.004638  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:41] d2.utils.events INFO:  eta: 0:03:31  iter: 87619  total_loss: 0.07996  loss_cls: 0.006467  loss_box_reg: 0.02341  loss_mask: 0.04962  loss_rpn_cls: 6.003e-05  loss_rpn_loc: 0.001514  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:43] d2.utils.events INFO:  eta: 0:03:29  iter: 87639  total_loss: 0.07237  loss_cls: 0.0065  loss_box_reg: 0.01815  loss_mask: 0.04493  loss_rpn_cls: 0.0001448  loss_rpn_loc: 0.001523  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:44] d2.utils.events INFO:  eta: 0:03:27  iter: 87659  total_loss: 0.08551  loss_cls: 0.009787  loss_box_reg: 0.0286  loss_mask: 0.03711  loss_rpn_cls: 0.000275  loss_rpn_loc: 0.004048  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:46] d2.utils.events INFO:  eta: 0:03:26  iter: 87679  total_loss: 0.09416  loss_cls: 0.01121  loss_box_reg: 0.0268  loss_mask: 0.05599  loss_rpn_cls: 0.0005724  loss_rpn_loc: 0.005005  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:48] d2.utils.events INFO:  eta: 0:03:23  iter: 87699  total_loss: 0.05057  loss_cls: 0.00477  loss_box_reg: 0.01156  loss_mask: 0.03359  loss_rpn_cls: 0.0001355  loss_rpn_loc: 0.001383  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:50] d2.utils.events INFO:  eta: 0:03:22  iter: 87719  total_loss: 0.08334  loss_cls: 0.009541  loss_box_reg: 0.02454  loss_mask: 0.04596  loss_rpn_cls: 0.0002127  loss_rpn_loc: 0.002745  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:51] d2.utils.events INFO:  eta: 0:03:20  iter: 87739  total_loss: 0.1151  loss_cls: 0.01368  loss_box_reg: 0.03772  loss_mask: 0.06201  loss_rpn_cls: 0.0002727  loss_rpn_loc: 0.004473  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:53] d2.utils.events INFO:  eta: 0:03:18  iter: 87759  total_loss: 0.0783  loss_cls: 0.008115  loss_box_reg: 0.01748  loss_mask: 0.0502  loss_rpn_cls: 0.0001147  loss_rpn_loc: 0.001811  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:55] d2.utils.events INFO:  eta: 0:03:16  iter: 87779  total_loss: 0.06863  loss_cls: 0.005592  loss_box_reg: 0.01543  loss_mask: 0.04395  loss_rpn_cls: 0.0001305  loss_rpn_loc: 0.002259  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:57] d2.utils.events INFO:  eta: 0:03:14  iter: 87799  total_loss: 0.06775  loss_cls: 0.009582  loss_box_reg: 0.01486  loss_mask: 0.04382  loss_rpn_cls: 0.0002491  loss_rpn_loc: 0.002905  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:46:59] d2.utils.events INFO:  eta: 0:03:13  iter: 87819  total_loss: 0.08349  loss_cls: 0.009202  loss_box_reg: 0.02529  loss_mask: 0.04949  loss_rpn_cls: 0.0003457  loss_rpn_loc: 0.003125  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:00] d2.utils.events INFO:  eta: 0:03:11  iter: 87839  total_loss: 0.08268  loss_cls: 0.00942  loss_box_reg: 0.01845  loss_mask: 0.041  loss_rpn_cls: 0.0001906  loss_rpn_loc: 0.002482  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:02] d2.utils.events INFO:  eta: 0:03:10  iter: 87859  total_loss: 0.06999  loss_cls: 0.01012  loss_box_reg: 0.01906  loss_mask: 0.04068  loss_rpn_cls: 0.0002045  loss_rpn_loc: 0.002113  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:04] d2.utils.events INFO:  eta: 0:03:08  iter: 87879  total_loss: 0.05346  loss_cls: 0.003822  loss_box_reg: 0.01124  loss_mask: 0.03353  loss_rpn_cls: 0.0001436  loss_rpn_loc: 0.00179  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:06] d2.utils.events INFO:  eta: 0:03:05  iter: 87899  total_loss: 0.06658  loss_cls: 0.007264  loss_box_reg: 0.01768  loss_mask: 0.04069  loss_rpn_cls: 0.0001252  loss_rpn_loc: 0.002396  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:07] d2.utils.events INFO:  eta: 0:03:04  iter: 87919  total_loss: 0.07109  loss_cls: 0.009306  loss_box_reg: 0.02086  loss_mask: 0.04054  loss_rpn_cls: 0.000189  loss_rpn_loc: 0.002385  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:09] d2.utils.events INFO:  eta: 0:03:02  iter: 87939  total_loss: 0.07201  loss_cls: 0.008333  loss_box_reg: 0.02143  loss_mask: 0.04529  loss_rpn_cls: 0.0002677  loss_rpn_loc: 0.002252  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:11] d2.utils.events INFO:  eta: 0:03:00  iter: 87959  total_loss: 0.07848  loss_cls: 0.01105  loss_box_reg: 0.02237  loss_mask: 0.04841  loss_rpn_cls: 0.0002772  loss_rpn_loc: 0.002631  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:13] d2.utils.events INFO:  eta: 0:02:59  iter: 87979  total_loss: 0.08442  loss_cls: 0.006079  loss_box_reg: 0.02021  loss_mask: 0.04511  loss_rpn_cls: 0.000201  loss_rpn_loc: 0.003092  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:14] d2.utils.events INFO:  eta: 0:02:57  iter: 87999  total_loss: 0.08473  loss_cls: 0.007529  loss_box_reg: 0.02438  loss_mask: 0.05287  loss_rpn_cls: 0.0001758  loss_rpn_loc: 0.003756  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:16] d2.utils.events INFO:  eta: 0:02:55  iter: 88019  total_loss: 0.06458  loss_cls: 0.007305  loss_box_reg: 0.01823  loss_mask: 0.04219  loss_rpn_cls: 0.0001863  loss_rpn_loc: 0.002003  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:18] d2.utils.events INFO:  eta: 0:02:54  iter: 88039  total_loss: 0.08096  loss_cls: 0.008031  loss_box_reg: 0.02088  loss_mask: 0.04554  loss_rpn_cls: 6.639e-05  loss_rpn_loc: 0.001941  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:20] d2.utils.events INFO:  eta: 0:02:52  iter: 88059  total_loss: 0.06723  loss_cls: 0.007874  loss_box_reg: 0.01496  loss_mask: 0.04414  loss_rpn_cls: 0.0001147  loss_rpn_loc: 0.001775  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:21] d2.utils.events INFO:  eta: 0:02:50  iter: 88079  total_loss: 0.06881  loss_cls: 0.009209  loss_box_reg: 0.02159  loss_mask: 0.0319  loss_rpn_cls: 0.0002945  loss_rpn_loc: 0.002507  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:23] d2.utils.events INFO:  eta: 0:02:48  iter: 88099  total_loss: 0.06776  loss_cls: 0.008454  loss_box_reg: 0.0176  loss_mask: 0.04057  loss_rpn_cls: 0.0001845  loss_rpn_loc: 0.002823  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:25] d2.utils.events INFO:  eta: 0:02:46  iter: 88119  total_loss: 0.07142  loss_cls: 0.008925  loss_box_reg: 0.01812  loss_mask: 0.03932  loss_rpn_cls: 0.0002762  loss_rpn_loc: 0.002536  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:27] d2.utils.events INFO:  eta: 0:02:44  iter: 88139  total_loss: 0.07369  loss_cls: 0.01017  loss_box_reg: 0.02067  loss_mask: 0.03922  loss_rpn_cls: 0.0003018  loss_rpn_loc: 0.001766  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:28] d2.utils.events INFO:  eta: 0:02:42  iter: 88159  total_loss: 0.0654  loss_cls: 0.00699  loss_box_reg: 0.01564  loss_mask: 0.03561  loss_rpn_cls: 0.000196  loss_rpn_loc: 0.002359  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:30] d2.utils.events INFO:  eta: 0:02:41  iter: 88179  total_loss: 0.1083  loss_cls: 0.01176  loss_box_reg: 0.03316  loss_mask: 0.06254  loss_rpn_cls: 0.0004018  loss_rpn_loc: 0.003764  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:32] d2.utils.events INFO:  eta: 0:02:39  iter: 88199  total_loss: 0.06674  loss_cls: 0.007337  loss_box_reg: 0.02119  loss_mask: 0.04203  loss_rpn_cls: 0.000346  loss_rpn_loc: 0.002405  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:34] d2.utils.events INFO:  eta: 0:02:37  iter: 88219  total_loss: 0.08304  loss_cls: 0.009382  loss_box_reg: 0.01941  loss_mask: 0.04137  loss_rpn_cls: 0.000208  loss_rpn_loc: 0.003051  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:36] d2.utils.events INFO:  eta: 0:02:36  iter: 88239  total_loss: 0.09359  loss_cls: 0.01289  loss_box_reg: 0.02975  loss_mask: 0.04962  loss_rpn_cls: 0.0004188  loss_rpn_loc: 0.003848  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:37] d2.utils.events INFO:  eta: 0:02:34  iter: 88259  total_loss: 0.06681  loss_cls: 0.00831  loss_box_reg: 0.0166  loss_mask: 0.04051  loss_rpn_cls: 0.0001476  loss_rpn_loc: 0.002137  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:39] d2.utils.events INFO:  eta: 0:02:32  iter: 88279  total_loss: 0.07452  loss_cls: 0.007827  loss_box_reg: 0.01779  loss_mask: 0.04556  loss_rpn_cls: 0.0001805  loss_rpn_loc: 0.002111  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:41] d2.utils.events INFO:  eta: 0:02:30  iter: 88299  total_loss: 0.08109  loss_cls: 0.005868  loss_box_reg: 0.01774  loss_mask: 0.03857  loss_rpn_cls: 0.0001085  loss_rpn_loc: 0.001572  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:43] d2.utils.events INFO:  eta: 0:02:28  iter: 88319  total_loss: 0.05528  loss_cls: 0.0033  loss_box_reg: 0.009502  loss_mask: 0.0393  loss_rpn_cls: 0.0002106  loss_rpn_loc: 0.001708  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:44] d2.utils.events INFO:  eta: 0:02:26  iter: 88339  total_loss: 0.08091  loss_cls: 0.009056  loss_box_reg: 0.02181  loss_mask: 0.05049  loss_rpn_cls: 0.0002811  loss_rpn_loc: 0.00362  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:46] d2.utils.events INFO:  eta: 0:02:25  iter: 88359  total_loss: 0.07856  loss_cls: 0.01075  loss_box_reg: 0.02098  loss_mask: 0.04222  loss_rpn_cls: 0.0001957  loss_rpn_loc: 0.002313  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:48] d2.utils.events INFO:  eta: 0:02:23  iter: 88379  total_loss: 0.08083  loss_cls: 0.007738  loss_box_reg: 0.02628  loss_mask: 0.05097  loss_rpn_cls: 0.0002703  loss_rpn_loc: 0.002362  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:50] d2.utils.events INFO:  eta: 0:02:21  iter: 88399  total_loss: 0.07488  loss_cls: 0.008053  loss_box_reg: 0.0193  loss_mask: 0.04542  loss_rpn_cls: 0.0001421  loss_rpn_loc: 0.002661  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:52] d2.utils.events INFO:  eta: 0:02:19  iter: 88419  total_loss: 0.0604  loss_cls: 0.008367  loss_box_reg: 0.01581  loss_mask: 0.0385  loss_rpn_cls: 0.0001745  loss_rpn_loc: 0.001385  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:53] d2.utils.events INFO:  eta: 0:02:17  iter: 88439  total_loss: 0.06415  loss_cls: 0.00652  loss_box_reg: 0.01656  loss_mask: 0.03515  loss_rpn_cls: 0.0002208  loss_rpn_loc: 0.002327  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:55] d2.utils.events INFO:  eta: 0:02:15  iter: 88459  total_loss: 0.105  loss_cls: 0.01022  loss_box_reg: 0.03086  loss_mask: 0.05747  loss_rpn_cls: 0.0003875  loss_rpn_loc: 0.004806  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:57] d2.utils.events INFO:  eta: 0:02:14  iter: 88479  total_loss: 0.08508  loss_cls: 0.00824  loss_box_reg: 0.02173  loss_mask: 0.04362  loss_rpn_cls: 0.0002003  loss_rpn_loc: 0.003335  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:47:59] d2.utils.events INFO:  eta: 0:02:12  iter: 88499  total_loss: 0.06883  loss_cls: 0.009985  loss_box_reg: 0.01818  loss_mask: 0.03605  loss_rpn_cls: 0.0003397  loss_rpn_loc: 0.001714  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:00] d2.utils.events INFO:  eta: 0:02:11  iter: 88519  total_loss: 0.06865  loss_cls: 0.009286  loss_box_reg: 0.01729  loss_mask: 0.03519  loss_rpn_cls: 0.0002001  loss_rpn_loc: 0.002734  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:02] d2.utils.events INFO:  eta: 0:02:09  iter: 88539  total_loss: 0.08751  loss_cls: 0.01216  loss_box_reg: 0.02151  loss_mask: 0.0552  loss_rpn_cls: 0.0001622  loss_rpn_loc: 0.003024  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:04] d2.utils.events INFO:  eta: 0:02:07  iter: 88559  total_loss: 0.05328  loss_cls: 0.00472  loss_box_reg: 0.01423  loss_mask: 0.0334  loss_rpn_cls: 0.0001376  loss_rpn_loc: 0.001657  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:06] d2.utils.events INFO:  eta: 0:02:05  iter: 88579  total_loss: 0.07958  loss_cls: 0.007516  loss_box_reg: 0.0201  loss_mask: 0.04735  loss_rpn_cls: 0.0001603  loss_rpn_loc: 0.0027  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:07] d2.utils.events INFO:  eta: 0:02:03  iter: 88599  total_loss: 0.08915  loss_cls: 0.01045  loss_box_reg: 0.02795  loss_mask: 0.04855  loss_rpn_cls: 0.000137  loss_rpn_loc: 0.001911  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:09] d2.utils.events INFO:  eta: 0:02:01  iter: 88619  total_loss: 0.05937  loss_cls: 0.006179  loss_box_reg: 0.01728  loss_mask: 0.03539  loss_rpn_cls: 0.0002171  loss_rpn_loc: 0.001629  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:11] d2.utils.events INFO:  eta: 0:02:00  iter: 88639  total_loss: 0.06879  loss_cls: 0.007776  loss_box_reg: 0.02076  loss_mask: 0.04048  loss_rpn_cls: 0.0002601  loss_rpn_loc: 0.002687  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:13] d2.utils.events INFO:  eta: 0:01:58  iter: 88659  total_loss: 0.08501  loss_cls: 0.01103  loss_box_reg: 0.02272  loss_mask: 0.0477  loss_rpn_cls: 0.0002659  loss_rpn_loc: 0.003935  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:15] d2.utils.events INFO:  eta: 0:01:56  iter: 88679  total_loss: 0.07657  loss_cls: 0.006836  loss_box_reg: 0.02361  loss_mask: 0.04324  loss_rpn_cls: 0.000222  loss_rpn_loc: 0.002357  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:16] d2.utils.events INFO:  eta: 0:01:54  iter: 88699  total_loss: 0.06111  loss_cls: 0.008237  loss_box_reg: 0.01997  loss_mask: 0.03211  loss_rpn_cls: 0.0001351  loss_rpn_loc: 0.002024  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:18] d2.utils.events INFO:  eta: 0:01:52  iter: 88719  total_loss: 0.07186  loss_cls: 0.004711  loss_box_reg: 0.01456  loss_mask: 0.04984  loss_rpn_cls: 0.0003574  loss_rpn_loc: 0.003446  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:20] d2.utils.events INFO:  eta: 0:01:50  iter: 88739  total_loss: 0.06868  loss_cls: 0.00686  loss_box_reg: 0.01475  loss_mask: 0.04461  loss_rpn_cls: 0.0001965  loss_rpn_loc: 0.002043  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:22] d2.utils.events INFO:  eta: 0:01:49  iter: 88759  total_loss: 0.109  loss_cls: 0.01093  loss_box_reg: 0.02769  loss_mask: 0.05597  loss_rpn_cls: 0.0002865  loss_rpn_loc: 0.002641  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:23] d2.utils.events INFO:  eta: 0:01:47  iter: 88779  total_loss: 0.07768  loss_cls: 0.01093  loss_box_reg: 0.02682  loss_mask: 0.04803  loss_rpn_cls: 0.0003694  loss_rpn_loc: 0.002688  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:25] d2.utils.events INFO:  eta: 0:01:45  iter: 88799  total_loss: 0.06861  loss_cls: 0.006498  loss_box_reg: 0.01751  loss_mask: 0.04086  loss_rpn_cls: 0.0002102  loss_rpn_loc: 0.002426  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:27] d2.utils.events INFO:  eta: 0:01:44  iter: 88819  total_loss: 0.05736  loss_cls: 0.007192  loss_box_reg: 0.01539  loss_mask: 0.03686  loss_rpn_cls: 9.044e-05  loss_rpn_loc: 0.001556  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:29] d2.utils.events INFO:  eta: 0:01:42  iter: 88839  total_loss: 0.06847  loss_cls: 0.008937  loss_box_reg: 0.01998  loss_mask: 0.04133  loss_rpn_cls: 0.0002185  loss_rpn_loc: 0.002666  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:31] d2.utils.events INFO:  eta: 0:01:40  iter: 88859  total_loss: 0.06967  loss_cls: 0.009127  loss_box_reg: 0.01972  loss_mask: 0.04066  loss_rpn_cls: 0.0003478  loss_rpn_loc: 0.002126  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:32] d2.utils.events INFO:  eta: 0:01:38  iter: 88879  total_loss: 0.08406  loss_cls: 0.006703  loss_box_reg: 0.01988  loss_mask: 0.05443  loss_rpn_cls: 0.0002185  loss_rpn_loc: 0.002758  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:34] d2.utils.events INFO:  eta: 0:01:37  iter: 88899  total_loss: 0.09927  loss_cls: 0.01036  loss_box_reg: 0.02744  loss_mask: 0.06094  loss_rpn_cls: 0.0003772  loss_rpn_loc: 0.003418  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:36] d2.utils.events INFO:  eta: 0:01:35  iter: 88919  total_loss: 0.05337  loss_cls: 0.011  loss_box_reg: 0.01691  loss_mask: 0.03163  loss_rpn_cls: 0.0002955  loss_rpn_loc: 0.001504  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:37] d2.utils.events INFO:  eta: 0:01:33  iter: 88939  total_loss: 0.06634  loss_cls: 0.007687  loss_box_reg: 0.01823  loss_mask: 0.03663  loss_rpn_cls: 0.0001156  loss_rpn_loc: 0.001533  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:39] d2.utils.events INFO:  eta: 0:01:31  iter: 88959  total_loss: 0.07243  loss_cls: 0.007754  loss_box_reg: 0.01904  loss_mask: 0.03936  loss_rpn_cls: 0.000216  loss_rpn_loc: 0.002208  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:41] d2.utils.events INFO:  eta: 0:01:30  iter: 88979  total_loss: 0.06907  loss_cls: 0.007809  loss_box_reg: 0.01582  loss_mask: 0.03979  loss_rpn_cls: 0.0001464  loss_rpn_loc: 0.001545  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:43] d2.utils.events INFO:  eta: 0:01:28  iter: 88999  total_loss: 0.06659  loss_cls: 0.007317  loss_box_reg: 0.01465  loss_mask: 0.04557  loss_rpn_cls: 0.000161  loss_rpn_loc: 0.002143  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:44] d2.utils.events INFO:  eta: 0:01:26  iter: 89019  total_loss: 0.08037  loss_cls: 0.01309  loss_box_reg: 0.02575  loss_mask: 0.04602  loss_rpn_cls: 0.0004263  loss_rpn_loc: 0.004494  time: 0.0878  data_time: 0.0021  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:46] d2.utils.events INFO:  eta: 0:01:24  iter: 89039  total_loss: 0.07968  loss_cls: 0.009291  loss_box_reg: 0.02254  loss_mask: 0.04751  loss_rpn_cls: 0.0001425  loss_rpn_loc: 0.003133  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:48] d2.utils.events INFO:  eta: 0:01:23  iter: 89059  total_loss: 0.08137  loss_cls: 0.01111  loss_box_reg: 0.02594  loss_mask: 0.04411  loss_rpn_cls: 0.0003579  loss_rpn_loc: 0.003713  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:50] d2.utils.events INFO:  eta: 0:01:21  iter: 89079  total_loss: 0.07151  loss_cls: 0.008407  loss_box_reg: 0.01808  loss_mask: 0.04549  loss_rpn_cls: 0.0001368  loss_rpn_loc: 0.001741  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:52] d2.utils.events INFO:  eta: 0:01:19  iter: 89099  total_loss: 0.08461  loss_cls: 0.006928  loss_box_reg: 0.0249  loss_mask: 0.04817  loss_rpn_cls: 0.0001505  loss_rpn_loc: 0.002231  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:53] d2.utils.events INFO:  eta: 0:01:17  iter: 89119  total_loss: 0.06809  loss_cls: 0.00633  loss_box_reg: 0.01322  loss_mask: 0.04051  loss_rpn_cls: 0.0002498  loss_rpn_loc: 0.001859  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:55] d2.utils.events INFO:  eta: 0:01:16  iter: 89139  total_loss: 0.08316  loss_cls: 0.01001  loss_box_reg: 0.02374  loss_mask: 0.04195  loss_rpn_cls: 0.0001438  loss_rpn_loc: 0.002545  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:57] d2.utils.events INFO:  eta: 0:01:14  iter: 89159  total_loss: 0.08136  loss_cls: 0.007883  loss_box_reg: 0.0194  loss_mask: 0.04914  loss_rpn_cls: 0.0002305  loss_rpn_loc: 0.002545  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:48:59] d2.utils.events INFO:  eta: 0:01:12  iter: 89179  total_loss: 0.06841  loss_cls: 0.007938  loss_box_reg: 0.01764  loss_mask: 0.04992  loss_rpn_cls: 0.0001041  loss_rpn_loc: 0.001405  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:00] d2.utils.events INFO:  eta: 0:01:10  iter: 89199  total_loss: 0.06388  loss_cls: 0.007956  loss_box_reg: 0.01875  loss_mask: 0.04052  loss_rpn_cls: 0.0001678  loss_rpn_loc: 0.002105  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:02] d2.utils.events INFO:  eta: 0:01:08  iter: 89219  total_loss: 0.07261  loss_cls: 0.008564  loss_box_reg: 0.01825  loss_mask: 0.04019  loss_rpn_cls: 0.0001693  loss_rpn_loc: 0.002014  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:04] d2.utils.events INFO:  eta: 0:01:07  iter: 89239  total_loss: 0.09962  loss_cls: 0.01867  loss_box_reg: 0.03211  loss_mask: 0.05043  loss_rpn_cls: 0.00026  loss_rpn_loc: 0.004694  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:06] d2.utils.events INFO:  eta: 0:01:05  iter: 89259  total_loss: 0.08408  loss_cls: 0.01044  loss_box_reg: 0.02071  loss_mask: 0.04529  loss_rpn_cls: 0.0004477  loss_rpn_loc: 0.004701  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:08] d2.utils.events INFO:  eta: 0:01:03  iter: 89279  total_loss: 0.06034  loss_cls: 0.005837  loss_box_reg: 0.01715  loss_mask: 0.03743  loss_rpn_cls: 0.0002106  loss_rpn_loc: 0.00263  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:10] d2.utils.events INFO:  eta: 0:01:01  iter: 89299  total_loss: 0.08316  loss_cls: 0.01165  loss_box_reg: 0.02182  loss_mask: 0.04169  loss_rpn_cls: 0.0001664  loss_rpn_loc: 0.002142  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:11] d2.utils.events INFO:  eta: 0:01:00  iter: 89319  total_loss: 0.06421  loss_cls: 0.009173  loss_box_reg: 0.01891  loss_mask: 0.0415  loss_rpn_cls: 0.0003292  loss_rpn_loc: 0.004273  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:13] d2.utils.events INFO:  eta: 0:00:58  iter: 89339  total_loss: 0.07663  loss_cls: 0.006358  loss_box_reg: 0.02316  loss_mask: 0.04101  loss_rpn_cls: 0.0002515  loss_rpn_loc: 0.002034  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:15] d2.utils.events INFO:  eta: 0:00:56  iter: 89359  total_loss: 0.06174  loss_cls: 0.00521  loss_box_reg: 0.01528  loss_mask: 0.03659  loss_rpn_cls: 0.0001686  loss_rpn_loc: 0.001745  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:17] d2.utils.events INFO:  eta: 0:00:54  iter: 89379  total_loss: 0.08093  loss_cls: 0.01169  loss_box_reg: 0.02417  loss_mask: 0.043  loss_rpn_cls: 0.0003335  loss_rpn_loc: 0.003394  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:18] d2.utils.events INFO:  eta: 0:00:53  iter: 89399  total_loss: 0.07379  loss_cls: 0.01023  loss_box_reg: 0.02298  loss_mask: 0.04434  loss_rpn_cls: 0.000138  loss_rpn_loc: 0.002488  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:20] d2.utils.events INFO:  eta: 0:00:51  iter: 89419  total_loss: 0.07526  loss_cls: 0.006221  loss_box_reg: 0.0143  loss_mask: 0.04385  loss_rpn_cls: 0.0003516  loss_rpn_loc: 0.002867  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:22] d2.utils.events INFO:  eta: 0:00:49  iter: 89439  total_loss: 0.0596  loss_cls: 0.004047  loss_box_reg: 0.01299  loss_mask: 0.03821  loss_rpn_cls: 5.951e-05  loss_rpn_loc: 0.0009322  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:24] d2.utils.events INFO:  eta: 0:00:47  iter: 89459  total_loss: 0.07989  loss_cls: 0.00858  loss_box_reg: 0.02057  loss_mask: 0.04907  loss_rpn_cls: 0.0002023  loss_rpn_loc: 0.002307  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:25] d2.utils.events INFO:  eta: 0:00:45  iter: 89479  total_loss: 0.06991  loss_cls: 0.006937  loss_box_reg: 0.01767  loss_mask: 0.03882  loss_rpn_cls: 0.0003758  loss_rpn_loc: 0.001911  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:27] d2.utils.events INFO:  eta: 0:00:44  iter: 89499  total_loss: 0.06608  loss_cls: 0.006649  loss_box_reg: 0.01885  loss_mask: 0.0381  loss_rpn_cls: 0.0001694  loss_rpn_loc: 0.002406  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:29] d2.utils.events INFO:  eta: 0:00:42  iter: 89519  total_loss: 0.06714  loss_cls: 0.007516  loss_box_reg: 0.01921  loss_mask: 0.0384  loss_rpn_cls: 0.0002077  loss_rpn_loc: 0.001702  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:31] d2.utils.events INFO:  eta: 0:00:40  iter: 89539  total_loss: 0.09589  loss_cls: 0.01011  loss_box_reg: 0.02348  loss_mask: 0.05402  loss_rpn_cls: 0.0002499  loss_rpn_loc: 0.002508  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:32] d2.utils.events INFO:  eta: 0:00:38  iter: 89559  total_loss: 0.0599  loss_cls: 0.009951  loss_box_reg: 0.02118  loss_mask: 0.03646  loss_rpn_cls: 0.0001426  loss_rpn_loc: 0.002038  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:34] d2.utils.events INFO:  eta: 0:00:37  iter: 89579  total_loss: 0.06706  loss_cls: 0.00746  loss_box_reg: 0.01785  loss_mask: 0.05107  loss_rpn_cls: 0.0001604  loss_rpn_loc: 0.002252  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:36] d2.utils.events INFO:  eta: 0:00:35  iter: 89599  total_loss: 0.08869  loss_cls: 0.009562  loss_box_reg: 0.02394  loss_mask: 0.05561  loss_rpn_cls: 0.0002665  loss_rpn_loc: 0.003976  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:38] d2.utils.events INFO:  eta: 0:00:33  iter: 89619  total_loss: 0.0821  loss_cls: 0.01028  loss_box_reg: 0.02029  loss_mask: 0.04825  loss_rpn_cls: 0.0004598  loss_rpn_loc: 0.004782  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:40] d2.utils.events INFO:  eta: 0:00:31  iter: 89639  total_loss: 0.06462  loss_cls: 0.006301  loss_box_reg: 0.01627  loss_mask: 0.03812  loss_rpn_cls: 0.0001489  loss_rpn_loc: 0.001754  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:41] d2.utils.events INFO:  eta: 0:00:30  iter: 89659  total_loss: 0.08698  loss_cls: 0.01077  loss_box_reg: 0.03346  loss_mask: 0.03802  loss_rpn_cls: 0.0002499  loss_rpn_loc: 0.003395  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:43] d2.utils.events INFO:  eta: 0:00:28  iter: 89679  total_loss: 0.09028  loss_cls: 0.01053  loss_box_reg: 0.02958  loss_mask: 0.04499  loss_rpn_cls: 0.0003607  loss_rpn_loc: 0.004681  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:45] d2.utils.events INFO:  eta: 0:00:26  iter: 89699  total_loss: 0.07455  loss_cls: 0.01092  loss_box_reg: 0.01895  loss_mask: 0.03833  loss_rpn_cls: 0.00019  loss_rpn_loc: 0.002576  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:47] d2.utils.events INFO:  eta: 0:00:24  iter: 89719  total_loss: 0.06664  loss_cls: 0.005508  loss_box_reg: 0.01543  loss_mask: 0.04314  loss_rpn_cls: 0.0001452  loss_rpn_loc: 0.002135  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:48] d2.utils.events INFO:  eta: 0:00:23  iter: 89739  total_loss: 0.08189  loss_cls: 0.01026  loss_box_reg: 0.02793  loss_mask: 0.04471  loss_rpn_cls: 0.0004842  loss_rpn_loc: 0.003556  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:50] d2.utils.events INFO:  eta: 0:00:21  iter: 89759  total_loss: 0.05957  loss_cls: 0.005799  loss_box_reg: 0.01389  loss_mask: 0.03979  loss_rpn_cls: 0.0001355  loss_rpn_loc: 0.001792  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:52] d2.utils.events INFO:  eta: 0:00:19  iter: 89779  total_loss: 0.06492  loss_cls: 0.008142  loss_box_reg: 0.0171  loss_mask: 0.036  loss_rpn_cls: 0.0002263  loss_rpn_loc: 0.002535  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:54] d2.utils.events INFO:  eta: 0:00:17  iter: 89799  total_loss: 0.08343  loss_cls: 0.006288  loss_box_reg: 0.0218  loss_mask: 0.04982  loss_rpn_cls: 0.000152  loss_rpn_loc: 0.002131  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:55] d2.utils.events INFO:  eta: 0:00:15  iter: 89819  total_loss: 0.06545  loss_cls: 0.005827  loss_box_reg: 0.01746  loss_mask: 0.04421  loss_rpn_cls: 0.0001431  loss_rpn_loc: 0.002191  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:57] d2.utils.events INFO:  eta: 0:00:14  iter: 89839  total_loss: 0.07672  loss_cls: 0.00988  loss_box_reg: 0.02114  loss_mask: 0.04026  loss_rpn_cls: 0.0003625  loss_rpn_loc: 0.001796  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:49:59] d2.utils.events INFO:  eta: 0:00:12  iter: 89859  total_loss: 0.09277  loss_cls: 0.01321  loss_box_reg: 0.02845  loss_mask: 0.04628  loss_rpn_cls: 0.0002192  loss_rpn_loc: 0.003556  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:01] d2.utils.events INFO:  eta: 0:00:10  iter: 89879  total_loss: 0.0744  loss_cls: 0.01156  loss_box_reg: 0.02432  loss_mask: 0.03829  loss_rpn_cls: 0.0001911  loss_rpn_loc: 0.00183  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:03] d2.utils.events INFO:  eta: 0:00:08  iter: 89899  total_loss: 0.09158  loss_cls: 0.009782  loss_box_reg: 0.02447  loss_mask: 0.05248  loss_rpn_cls: 0.00013  loss_rpn_loc: 0.002467  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:04] d2.utils.events INFO:  eta: 0:00:07  iter: 89919  total_loss: 0.0662  loss_cls: 0.004981  loss_box_reg: 0.01148  loss_mask: 0.04634  loss_rpn_cls: 0.0001581  loss_rpn_loc: 0.0007801  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:06] d2.utils.events INFO:  eta: 0:00:05  iter: 89939  total_loss: 0.06915  loss_cls: 0.009044  loss_box_reg: 0.0197  loss_mask: 0.04382  loss_rpn_cls: 0.0002182  loss_rpn_loc: 0.002988  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:08] d2.utils.events INFO:  eta: 0:00:03  iter: 89959  total_loss: 0.09358  loss_cls: 0.01005  loss_box_reg: 0.02289  loss_mask: 0.04807  loss_rpn_cls: 0.0004529  loss_rpn_loc: 0.003432  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:10] d2.utils.events INFO:  eta: 0:00:01  iter: 89979  total_loss: 0.07159  loss_cls: 0.007434  loss_box_reg: 0.01667  loss_mask: 0.03902  loss_rpn_cls: 0.0001301  loss_rpn_loc: 0.001997  time: 0.0878  data_time: 0.0019  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:11] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_0089999.pth
[10/27 20:50:12] fvcore.common.checkpoint INFO: Saving checkpoint to ./output_300/model_final.pth
[10/27 20:50:12] d2.utils.events INFO:  eta: 0:00:00  iter: 89999  total_loss: 0.06038  loss_cls: 0.006185  loss_box_reg: 0.01406  loss_mask: 0.03303  loss_rpn_cls: 0.0001436  loss_rpn_loc: 0.001993  time: 0.0878  data_time: 0.0020  lr: 2.5e-05  max_mem: 1494M
[10/27 20:50:12] d2.engine.hooks INFO: Overall training speed: 64998 iterations in 1:35:07 (0.0878 s / it)
[10/27 20:50:12] d2.engine.hooks INFO: Total training time: 1:35:42 (0:00:35 on hooks)
[10/27 20:50:27] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.90 seconds.
[10/27 20:50:28] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[10/27 20:50:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[10/27 20:50:38] d2.data.common INFO: Serializing 301 elements to byte tensors and concatenating them all ...
[10/27 20:50:38] d2.data.common INFO: Serialized dataset takes 1.19 MiB
[10/27 20:50:50] d2.evaluation.evaluator INFO: Start inference on 301 batches
[10/27 20:50:51] d2.evaluation.evaluator INFO: Inference done 11/301. Dataloading: 0.0007 s/iter. Inference: 0.0310 s/iter. Eval: 0.0033 s/iter. Total: 0.0351 s/iter. ETA=0:00:10
[10/27 20:50:56] d2.evaluation.evaluator INFO: Inference done 169/301. Dataloading: 0.0010 s/iter. Inference: 0.0278 s/iter. Eval: 0.0031 s/iter. Total: 0.0319 s/iter. ETA=0:00:04
[10/27 20:51:00] d2.evaluation.evaluator INFO: Total inference time: 0:00:09.448004 (0.031919 s / iter per device, on 1 devices)
[10/27 20:51:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:08 (0.027571 s / iter per device, on 1 devices)
[10/27 20:51:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[10/27 20:51:00] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[10/27 20:51:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[10/27 20:51:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[10/27 20:53:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 133.37 seconds.
[10/27 20:53:15] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[10/27 20:53:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 6.57 seconds.
[10/27 20:53:21] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.989 | 0.990  | 0.990  | 0.779 | 0.926 | 0.826 |
[10/27 20:53:21] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.990 | bicycle      | 0.990 | car            | 0.990 |
| motorcycle    | 0.990 | airplane     | 0.990 | bus            | 0.990 |
| train         | 0.990 | truck        | 0.987 | boat           | 0.990 |
| traffic light | 0.990 | fire hydrant | 0.990 | stop sign      | 0.990 |
| parking meter | 0.990 | bench        | 0.990 | bird           | 0.990 |
| cat           | 0.990 | dog          | 0.990 | horse          | 0.990 |
| sheep         | 0.990 | cow          | 0.980 | elephant       | 0.990 |
| bear          | 0.990 | zebra        | 0.990 | giraffe        | 0.990 |
| backpack      | 0.990 | umbrella     | 0.990 | handbag        | 0.990 |
| tie           | 0.990 | suitcase     | 0.990 | frisbee        | 0.990 |
| skis          | 0.990 | snowboard    | 0.990 | sports ball    | 0.990 |
| kite          | 0.990 | baseball bat | 0.990 | baseball glove | 0.990 |
| skateboard    | 0.990 | surfboard    | 0.990 | tennis racket  | 0.990 |
| bottle        | 0.990 | wine glass   | 0.990 | cup            | 0.990 |
| fork          | 0.965 | knife        | 0.990 | spoon          | 0.990 |
| bowl          | 0.990 | banana       | 0.990 | apple          | 0.990 |
| sandwich      | 0.990 | orange       | 0.990 | broccoli       | 0.990 |
| carrot        | 0.963 | hot dog      | 0.990 | pizza          | 0.990 |
| donut         | 0.990 | cake         | 0.990 | chair          | 0.990 |
| couch         | 0.990 | potted plant | 0.990 | bed            | 0.990 |
| dining table  | 0.990 | toilet       | 0.990 | tv             | 0.990 |
| laptop        | 0.990 | mouse        | 0.990 | remote         | 0.979 |
| keyboard      | 0.990 | cell phone   | 0.990 | microwave      | 0.990 |
| oven          | 0.990 | toaster      | 0.990 | sink           | 0.990 |
| refrigerator  | 0.990 | book         | 0.990 | clock          | 0.990 |
| vase          | 0.990 | scissors     | 0.990 | teddy bear     | 0.990 |
| hair drier    | 0.990 | toothbrush   | 0.990 |                |       |
[10/27 20:53:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[10/27 20:56:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 163.72 seconds.
[10/27 20:56:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[10/27 20:56:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 6.58 seconds.
[10/27 20:56:31] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.944 | 0.987  | 0.977  | 0.709 | 0.885 | 0.816 |
[10/27 20:56:31] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.990 | bicycle      | 0.820 | car            | 0.937 |
| motorcycle    | 0.846 | airplane     | 0.891 | bus            | 0.875 |
| train         | 0.990 | truck        | 0.952 | boat           | 0.934 |
| traffic light | 0.960 | fire hydrant | 0.990 | stop sign      | 0.990 |
| parking meter | 0.990 | bench        | 0.990 | bird           | 0.853 |
| cat           | 0.990 | dog          | 0.990 | horse          | 0.990 |
| sheep         | 0.924 | cow          | 0.831 | elephant       | 0.990 |
| bear          | 0.990 | zebra        | 0.863 | giraffe        | 0.908 |
| backpack      | 0.933 | umbrella     | 0.990 | handbag        | 0.883 |
| tie           | 0.990 | suitcase     | 0.990 | frisbee        | 0.990 |
| skis          | 0.685 | snowboard    | 0.941 | sports ball    | 0.950 |
| kite          | 0.878 | baseball bat | 0.891 | baseball glove | 0.963 |
| skateboard    | 0.857 | surfboard    | 0.990 | tennis racket  | 0.950 |
| bottle        | 0.963 | wine glass   | 0.931 | cup            | 0.990 |
| fork          | 0.792 | knife        | 0.990 | spoon          | 0.865 |
| bowl          | 0.947 | banana       | 0.990 | apple          | 0.981 |
| sandwich      | 0.990 | orange       | 0.990 | broccoli       | 0.990 |
| carrot        | 0.792 | hot dog      | 0.537 | pizza          | 0.990 |
| donut         | 0.974 | cake         | 0.990 | chair          | 0.990 |
| couch         | 0.973 | potted plant | 0.950 | bed            | 0.990 |
| dining table  | 0.965 | toilet       | 0.990 | tv             | 0.990 |
| laptop        | 0.990 | mouse        | 0.990 | remote         | 0.990 |
| keyboard      | 0.978 | cell phone   | 0.990 | microwave      | 0.990 |
| oven          | 0.990 | toaster      | 0.990 | sink           | 0.962 |
| refrigerator  | 0.990 | book         | 0.990 | clock          | 0.978 |
| vase          | 0.990 | scissors     | 0.891 | teddy bear     | 0.990 |
| hair drier    | 0.990 | toothbrush   | 0.891 |                |       |
[10/27 20:56:44] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: 0.9891,0.9901,0.9901,0.7789,0.9261,0.8263
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: Task: segm
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[10/27 20:56:44] d2.evaluation.testing INFO: copypaste: 0.9438,0.9872,0.9774,0.7089,0.8846,0.8156
[11/11 01:13:58] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 01:13:59] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 01:13:59] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 01:13:59] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 01:13:59] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 01:13:59] d2.utils.env INFO: Using a generated random seed 59711951
[11/11 01:14:00] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 01:14:15] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.75 seconds.
[11/11 01:14:16] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 01:14:24] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 01:14:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 01:14:26] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 01:14:26] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 01:14:39] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/11 01:14:40] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3762 s/iter. Eval: 0.0049 s/iter. Total: 0.3811 s/iter. ETA=0:00:00
[11/11 01:14:40] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.457464 (0.457464 s / iter per device, on 1 devices)
[11/11 01:14:40] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.376165 s / iter per device, on 1 devices)
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:14:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 01:14:40] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/11 01:14:40] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:14:40] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/11 01:18:46] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 01:18:46] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 01:18:46] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 01:18:46] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 01:18:46] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 01:18:46] d2.utils.env INFO: Using a generated random seed 47013325
[11/11 01:18:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 01:19:02] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.53 seconds.
[11/11 01:19:03] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 01:19:11] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 656          |   bicycle    | 18           |      car      | 133          |
|  motorcycle   | 38           |   airplane   | 5            |      bus      | 26           |
|     train     | 13           |    truck     | 33           |     boat      | 29           |
| traffic light | 28           | fire hydrant | 7            |   stop sign   | 2            |
| parking meter | 5            |    bench     | 15           |     bird      | 19           |
|      cat      | 12           |     dog      | 13           |     horse     | 13           |
|     sheep     | 3            |     cow      | 39           |   elephant    | 13           |
|     bear      | 5            |    zebra     | 25           |    giraffe    | 9            |
|   backpack    | 26           |   umbrella   | 32           |    handbag    | 44           |
|      tie      | 25           |   suitcase   | 9            |    frisbee    | 5            |
|     skis      | 15           |  snowboard   | 5            |  sports ball  | 26           |
|     kite      | 19           | baseball bat | 9            | baseball gl.. | 17           |
|  skateboard   | 18           |  surfboard   | 8            | tennis racket | 12           |
|    bottle     | 65           |  wine glass  | 5            |      cup      | 27           |
|     fork      | 8            |    knife     | 13           |     spoon     | 26           |
|     bowl      | 43           |    banana    | 28           |     apple     | 24           |
|   sandwich    | 8            |    orange    | 26           |   broccoli    | 13           |
|    carrot     | 12           |   hot dog    | 8            |     pizza     | 5            |
|     donut     | 31           |     cake     | 15           |     chair     | 84           |
|     couch     | 25           | potted plant | 25           |      bed      | 11           |
| dining table  | 31           |    toilet    | 5            |      tv       | 22           |
|    laptop     | 12           |    mouse     | 5            |    remote     | 27           |
|   keyboard    | 8            |  cell phone  | 12           |   microwave   | 7            |
|     oven      | 11           |   toaster    | 1            |     sink      | 17           |
| refrigerator  | 5            |     book     | 49           |     clock     | 22           |
|     vase      | 15           |   scissors   | 2            |  teddy bear   | 8            |
|  hair drier   | 1            |  toothbrush  | 5            |               |              |
|     total     | 2196         |              |              |               |              |[0m
[11/11 01:19:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 01:19:13] d2.data.common INFO: Serializing 301 elements to byte tensors and concatenating them all ...
[11/11 01:19:13] d2.data.common INFO: Serialized dataset takes 1.19 MiB
[11/11 01:19:26] d2.evaluation.evaluator INFO: Start inference on 301 batches
[11/11 01:19:27] d2.evaluation.evaluator INFO: Inference done 11/301. Dataloading: 0.0007 s/iter. Inference: 0.0416 s/iter. Eval: 0.0038 s/iter. Total: 0.0462 s/iter. ETA=0:00:13
[11/11 01:19:32] d2.evaluation.evaluator INFO: Inference done 153/301. Dataloading: 0.0010 s/iter. Inference: 0.0316 s/iter. Eval: 0.0031 s/iter. Total: 0.0357 s/iter. ETA=0:00:05
[11/11 01:19:37] d2.evaluation.evaluator INFO: Total inference time: 0:00:10.292491 (0.034772 s / iter per device, on 1 devices)
[11/11 01:19:37] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:08 (0.030327 s / iter per device, on 1 devices)
[11/11 01:19:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 01:19:37] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 01:19:37] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 01:19:37] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 01:19:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.17 seconds.
[11/11 01:19:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:19:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.19 seconds.
[11/11 01:19:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 97.768 | 98.687 | 98.356 | 96.904 | 98.660 | 99.427 |
[11/11 01:19:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP      |
|:--------------|:--------|:-------------|:--------|:---------------|:--------|
| person        | 97.222  | bicycle      | 100.000 | car            | 98.348  |
| motorcycle    | 90.936  | airplane     | 100.000 | bus            | 93.757  |
| train         | 100.000 | truck        | 98.998  | boat           | 99.307  |
| traffic light | 99.491  | fire hydrant | 100.000 | stop sign      | 100.000 |
| parking meter | 100.000 | bench        | 100.000 | bird           | 100.000 |
| cat           | 100.000 | dog          | 100.000 | horse          | 100.000 |
| sheep         | 100.000 | cow          | 97.997  | elephant       | 100.000 |
| bear          | 100.000 | zebra        | 95.281  | giraffe        | 100.000 |
| backpack      | 84.158  | umbrella     | 100.000 | handbag        | 98.006  |
| tie           | 94.803  | suitcase     | 100.000 | frisbee        | 100.000 |
| skis          | 98.733  | snowboard    | 100.000 | sports ball    | 67.327  |
| kite          | 99.078  | baseball bat | 100.000 | baseball glove | 98.218  |
| skateboard    | 99.345  | surfboard    | 100.000 | tennis racket  | 100.000 |
| bottle        | 98.020  | wine glass   | 100.000 | cup            | 100.000 |
| fork          | 95.644  | knife        | 100.000 | spoon          | 91.834  |
| bowl          | 99.295  | banana       | 96.086  | apple          | 99.472  |
| sandwich      | 100.000 | orange       | 99.383  | broccoli       | 100.000 |
| carrot        | 86.445  | hot dog      | 87.129  | pizza          | 100.000 |
| donut         | 98.790  | cake         | 98.614  | chair          | 100.000 |
| couch         | 100.000 | potted plant | 100.000 | bed            | 100.000 |
| dining table  | 100.000 | toilet       | 100.000 | tv             | 100.000 |
| laptop        | 100.000 | mouse        | 100.000 | remote         | 97.833  |
| keyboard      | 100.000 | cell phone   | 100.000 | microwave      | 100.000 |
| oven          | 100.000 | toaster      | 100.000 | sink           | 100.000 |
| refrigerator  | 100.000 | book         | 88.684  | clock          | 100.000 |
| vase          | 96.535  | scissors     | 100.000 | teddy bear     | 96.510  |
| hair drier    | 100.000 | toothbrush   | 80.198  |                |         |
[11/11 01:19:38] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 01:19:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.27 seconds.
[11/11 01:19:38] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:19:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.19 seconds.
[11/11 01:19:38] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 87.462 | 97.751 | 94.194 | 82.509 | 90.450 | 95.144 |
[11/11 01:19:38] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP      | category     | AP      | category       | AP      |
|:--------------|:--------|:-------------|:--------|:---------------|:--------|
| person        | 82.733  | bicycle      | 73.850  | car            | 86.114  |
| motorcycle    | 67.329  | airplane     | 90.000  | bus            | 76.170  |
| train         | 98.036  | truck        | 92.250  | boat           | 83.917  |
| traffic light | 92.456  | fire hydrant | 95.248  | stop sign      | 100.000 |
| parking meter | 100.000 | bench        | 83.532  | bird           | 78.327  |
| cat           | 97.291  | dog          | 91.802  | horse          | 89.726  |
| sheep         | 91.122  | cow          | 77.242  | elephant       | 91.514  |
| bear          | 96.832  | zebra        | 69.268  | giraffe        | 81.529  |
| backpack      | 75.939  | umbrella     | 93.241  | handbag        | 79.497  |
| tie           | 77.818  | suitcase     | 98.570  | frisbee        | 100.000 |
| skis          | 55.193  | snowboard    | 92.030  | sports ball    | 62.859  |
| kite          | 77.154  | baseball bat | 81.501  | baseball glove | 91.381  |
| skateboard    | 77.747  | surfboard    | 90.619  | tennis racket  | 91.825  |
| bottle        | 92.099  | wine glass   | 91.624  | cup            | 97.509  |
| fork          | 61.057  | knife        | 76.099  | spoon          | 70.716  |
| bowl          | 91.225  | banana       | 86.436  | apple          | 95.776  |
| sandwich      | 100.000 | orange       | 98.355  | broccoli       | 96.496  |
| carrot        | 61.215  | hot dog      | 27.723  | pizza          | 100.000 |
| donut         | 96.975  | cake         | 96.190  | chair          | 86.326  |
| couch         | 92.831  | potted plant | 88.936  | bed            | 97.040  |
| dining table  | 85.762  | toilet       | 98.020  | tv             | 98.755  |
| laptop        | 97.486  | mouse        | 100.000 | remote         | 91.675  |
| keyboard      | 97.624  | cell phone   | 98.317  | microwave      | 100.000 |
| oven          | 96.099  | toaster      | 100.000 | sink           | 94.581  |
| refrigerator  | 98.020  | book         | 76.669  | clock          | 97.475  |
| vase          | 91.120  | scissors     | 80.099  | teddy bear     | 94.381  |
| hair drier    | 100.000 | toothbrush   | 64.587  |                |         |
[11/11 01:19:38] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: 97.7684,98.6871,98.3561,96.9042,98.6602,99.4272
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:19:38] d2.evaluation.testing INFO: copypaste: 87.4620,97.7508,94.1941,82.5089,90.4503,95.1443
[11/11 01:27:53] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 01:27:54] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 01:27:54] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 01:27:54] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 01:27:54] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 01:27:54] d2.utils.env INFO: Using a generated random seed 54419896
[11/11 01:27:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 01:28:10] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.81 seconds.
[11/11 01:28:11] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 01:28:18] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 01:28:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 01:28:20] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 01:28:20] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 01:28:33] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/11 01:28:33] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3849 s/iter. Eval: 0.0049 s/iter. Total: 0.3898 s/iter. ETA=0:00:00
[11/11 01:28:33] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.450853 (0.450853 s / iter per device, on 1 devices)
[11/11 01:28:33] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.384903 s / iter per device, on 1 devices)
[11/11 01:28:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 01:28:33] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 01:28:33] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 01:28:33] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 01:28:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 01:28:34] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/11 01:28:34] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 01:28:34] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/11 16:12:46] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 16:12:47] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 16:12:47] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 16:12:47] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 16:12:47] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 16:12:47] d2.utils.env INFO: Using a generated random seed 47707425
[11/11 16:13:02] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.68 seconds.
[11/11 16:13:03] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 16:13:11] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 16:13:11] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 16:13:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 16:13:13] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 16:13:13] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 16:13:13] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 16:13:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 16:13:13] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 16:13:13] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 16:13:14] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 16:13:14] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/11 16:13:14] d2.utils.events INFO:  iter: 2  total_loss: 0.1383  loss_cls: 0.01951  loss_box_reg: 0.03758  loss_mask: 0.07291  loss_rpn_cls: 0.0006816  loss_rpn_loc: 0.00766  data_time: 0.1305  lr: N/A  max_mem: 1269M
[11/11 16:22:33] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 16:22:34] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 16:22:34] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 16:22:34] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 16:22:34] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 16:22:34] d2.utils.env INFO: Using a generated random seed 34286446
[11/11 16:22:49] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.42 seconds.
[11/11 16:22:50] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 16:22:58] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 16:22:58] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 16:22:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 16:22:59] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 16:22:59] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 16:22:59] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 16:22:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 16:23:00] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 16:23:00] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 16:23:00] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 16:23:00] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/11 16:23:00] d2.utils.events INFO:  iter: 2  total_loss: 0.1386  loss_cls: 0.01526  loss_box_reg: 0.04005  loss_mask: 0.07263  loss_rpn_cls: 0.005019  loss_rpn_loc: 0.005638  data_time: 0.1562  lr: N/A  max_mem: 1269M
[11/11 17:16:16] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 17:16:16] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 17:16:16] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 17:16:17] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 17:16:17] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 17:16:17] d2.utils.env INFO: Using a generated random seed 17217027
[11/11 17:16:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 17:16:32] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.44 seconds.
[11/11 17:16:33] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 17:16:41] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 17:16:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 17:16:43] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 17:16:43] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 17:16:55] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/11 17:16:56] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3922 s/iter. Eval: 0.0048 s/iter. Total: 0.3970 s/iter. ETA=0:00:00
[11/11 17:16:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.456574 (0.456574 s / iter per device, on 1 devices)
[11/11 17:16:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.392225 s / iter per device, on 1 devices)
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:16:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:16:56] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/11 17:16:56] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:16:56] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/11 17:21:49] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 17:21:50] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 17:21:50] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 17:21:50] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 17:21:50] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 17:21:50] d2.utils.env INFO: Using a generated random seed 50608928
[11/11 17:21:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 17:22:05] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.31 seconds.
[11/11 17:22:06] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 17:22:14] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 17:22:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 17:22:16] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 17:22:16] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 17:22:28] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/11 17:22:29] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3868 s/iter. Eval: 0.0048 s/iter. Total: 0.3917 s/iter. ETA=0:00:00
[11/11 17:22:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.451576 (0.451576 s / iter per device, on 1 devices)
[11/11 17:22:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.386817 s / iter per device, on 1 devices)
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:22:29] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:22:29] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/11 17:22:29] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:22:29] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/11 17:26:31] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 17:26:32] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 17:26:32] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/11 17:26:32] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 17:26:32] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 17:26:32] d2.utils.env INFO: Using a generated random seed 32620500
[11/11 17:26:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 17:26:47] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.37 seconds.
[11/11 17:26:48] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 17:26:56] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 17:26:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/11 17:26:58] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 17:26:58] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 17:27:10] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/11 17:27:11] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3852 s/iter. Eval: 0.0049 s/iter. Total: 0.3901 s/iter. ETA=0:00:00
[11/11 17:27:11] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.452904 (0.452904 s / iter per device, on 1 devices)
[11/11 17:27:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.385244 s / iter per device, on 1 devices)
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:27:11] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/11 17:27:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/11 17:27:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/11 17:27:12] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/11 17:27:12] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/11 17:27:12] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/11 17:27:12] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: Task: segm
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/11 17:27:12] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/11 17:28:04] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 17:28:05] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 17:28:05] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 17:28:05] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 17:28:05] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 17:28:05] d2.utils.env INFO: Using a generated random seed 5853954
[11/11 17:28:20] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.26 seconds.
[11/11 17:28:21] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 17:28:29] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 17:28:29] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 17:28:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 17:28:31] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 17:28:31] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 17:28:31] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 17:28:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 17:28:31] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 17:28:31] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 17:28:31] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 17:28:32] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/11 17:28:32] d2.utils.events INFO:  iter: 2  total_loss: 0.141  loss_cls: 0.02035  loss_box_reg: 0.04127  loss_mask: 0.07321  loss_rpn_cls: 0.000506  loss_rpn_loc: 0.005638  data_time: 0.1386  lr: N/A  max_mem: 1269M
[11/11 21:26:33] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:26:34] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:26:34] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:26:34] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:26:34] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:26:34] d2.utils.env INFO: Using a generated random seed 34935832
[11/11 21:26:49] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.46 seconds.
[11/11 21:26:50] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:26:58] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:26:58] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:27:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:27:00] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:27:00] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:27:00] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:27:00] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:27:00] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:27:00] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:27:00] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 21:27:01] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/11 21:27:01] d2.utils.events INFO:  iter: 2  total_loss: 0.1391  loss_cls: 0.01933  loss_box_reg: 0.03754  loss_mask: 0.07401  loss_rpn_cls: 0.0006109  loss_rpn_loc: 0.00766  data_time: 0.1522  lr: N/A  max_mem: 1271M
[11/11 21:28:02] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:28:03] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:28:03] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:28:03] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:28:03] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:28:03] d2.utils.env INFO: Using a generated random seed 4004431
[11/11 21:28:19] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.59 seconds.
[11/11 21:28:20] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:28:27] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:28:27] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:28:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:28:29] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:28:29] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:28:29] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:28:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:28:30] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:28:30] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:28:30] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 21:28:31] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/11 21:28:31] d2.utils.events INFO:  iter: 2  total_loss: 0.1344  loss_cls: 0.01205  loss_box_reg: 0.04169  loss_mask: 0.07458  loss_rpn_cls: 0.0004629  loss_rpn_loc: 0.005638  data_time: 0.1478  lr: N/A  max_mem: 1271M
[11/11 21:28:54] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:28:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:28:55] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:28:55] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:28:55] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:28:55] d2.utils.env INFO: Using a generated random seed 56024002
[11/11 21:29:11] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.70 seconds.
[11/11 21:29:12] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:29:19] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:29:19] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:29:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:29:21] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:29:21] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:29:21] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:29:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:29:22] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:29:22] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:29:22] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 21:29:23] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/11 21:29:23] d2.utils.events INFO:  iter: 2  total_loss: 0.1399  loss_cls: 0.01737  loss_box_reg: 0.04193  loss_mask: 0.07449  loss_rpn_cls: 0.0004638  loss_rpn_loc: 0.005638  data_time: 0.1481  lr: N/A  max_mem: 1271M
[11/11 21:39:28] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:39:29] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:39:29] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:39:29] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:39:29] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:39:29] d2.utils.env INFO: Using a generated random seed 29943168
[11/11 21:39:44] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.55 seconds.
[11/11 21:39:45] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:39:53] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:39:53] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:39:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:39:55] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:39:55] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:39:55] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:39:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:39:55] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:39:55] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:39:55] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 21:40:45] d2.engine.hooks INFO: Total training time: 0:00:49 (0:00:00 on hooks)
[11/11 21:40:45] d2.utils.events INFO:  iter: 1    lr: N/A  max_mem: 1139M
[11/11 21:44:43] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:44:44] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:44:44] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:44:44] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:44:44] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:44:44] d2.utils.env INFO: Using a generated random seed 44493205
[11/11 21:44:59] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.63 seconds.
[11/11 21:45:00] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:45:08] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:45:08] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:45:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:45:10] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:45:10] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:45:10] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:45:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:45:10] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:45:10] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:45:10] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 21:55:57] d2.engine.hooks INFO: Total training time: 0:10:46 (0:00:00 on hooks)
[11/11 21:55:57] d2.utils.events INFO:  iter: 2  total_loss: 0.138  loss_cls: 0.01604  loss_box_reg: 0.04228  loss_mask: 0.07361  loss_rpn_cls: 0.0004629  loss_rpn_loc: 0.005638  data_time: 0.1485  lr: N/A  max_mem: 1271M
[11/11 21:56:20] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 21:56:21] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 21:56:21] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 21:56:21] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 21:56:21] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 21:56:21] d2.utils.env INFO: Using a generated random seed 21783519
[11/11 21:56:36] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.57 seconds.
[11/11 21:56:37] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 21:56:45] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 21:56:45] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 21:56:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 21:56:47] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 21:56:47] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 21:56:47] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 21:56:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 21:56:47] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 21:56:47] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 21:56:47] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 22:03:00] d2.engine.hooks INFO: Total training time: 0:06:13 (0:00:00 on hooks)
[11/11 22:03:00] d2.utils.events INFO:  iter: 2  total_loss: 0.1389  loss_cls: 0.01743  loss_box_reg: 0.0429  loss_mask: 0.07195  loss_rpn_cls: 0.000954  loss_rpn_loc: 0.005638  data_time: 0.1569  lr: N/A  max_mem: 1271M
[11/11 23:04:45] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:04:46] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:04:46] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:04:46] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:04:46] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:04:46] d2.utils.env INFO: Using a generated random seed 46928165
[11/11 23:05:02] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.33 seconds.
[11/11 23:05:03] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:05:11] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:05:11] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:05:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:05:13] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:05:13] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:05:13] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:05:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:05:13] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:05:13] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:05:14] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:05:15] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/11 23:05:15] d2.utils.events INFO:  iter: 2  total_loss: 0.1422  loss_cls: 0.01386  loss_box_reg: 0.04272  loss_mask: 0.07335  loss_rpn_cls: 0.006653  loss_rpn_loc: 0.005638  data_time: 0.1571  lr: N/A  max_mem: 1271M
[11/11 23:06:36] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:06:37] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:06:37] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:06:37] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:06:37] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:06:37] d2.utils.env INFO: Using a generated random seed 37447431
[11/11 23:06:53] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.13 seconds.
[11/11 23:06:53] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:07:01] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:07:01] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:07:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:07:03] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:07:03] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:07:03] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:07:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:07:04] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:07:04] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:07:04] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:07:04] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/11 23:07:04] d2.utils.events INFO:  iter: 2  total_loss: 0.1378  loss_cls: 0.01795  loss_box_reg: 0.03574  loss_mask: 0.07165  loss_rpn_cls: 0.004807  loss_rpn_loc: 0.00766  data_time: 0.1632  lr: N/A  max_mem: 1269M
[11/11 23:09:24] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:09:25] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:09:25] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:09:25] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:09:25] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:09:25] d2.utils.env INFO: Using a generated random seed 25712889
[11/11 23:09:40] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.62 seconds.
[11/11 23:09:41] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:09:49] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:09:49] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:09:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:09:51] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:09:51] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:09:51] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:09:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:09:51] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:09:51] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:09:51] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:09:52] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/11 23:09:52] d2.utils.events INFO:  iter: 2  total_loss: 0.1321  loss_cls: 0.01642  loss_box_reg: 0.03468  loss_mask: 0.0727  loss_rpn_cls: 0.0006252  loss_rpn_loc: 0.00766  data_time: 0.1537  lr: N/A  max_mem: 1269M
[11/11 23:11:41] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:11:41] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:11:41] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:11:42] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:11:42] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:11:42] d2.utils.env INFO: Using a generated random seed 42361579
[11/11 23:11:57] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.83 seconds.
[11/11 23:11:58] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:12:06] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:12:06] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:12:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:12:08] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:12:08] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:12:08] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:12:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:12:08] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:12:08] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:12:08] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:12:09] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/11 23:12:09] d2.utils.events INFO:  iter: 2  total_loss: 0.142  loss_cls: 0.02153  loss_box_reg: 0.03617  loss_mask: 0.07355  loss_rpn_cls: 0.003095  loss_rpn_loc: 0.00766  data_time: 0.1528  lr: N/A  max_mem: 1271M
[11/11 23:24:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:24:44] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:24:44] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:24:44] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:24:44] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:24:44] d2.utils.env INFO: Using a generated random seed 45296879
[11/11 23:25:00] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.78 seconds.
[11/11 23:25:01] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:25:09] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:25:09] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:25:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:25:11] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:25:11] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:25:11] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:25:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:25:11] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:25:11] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:25:11] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:25:33] d2.engine.hooks INFO: Total training time: 0:00:21 (0:00:00 on hooks)
[11/11 23:25:33] d2.utils.events INFO:  iter: 2  total_loss: 0.1366  loss_cls: 0.01506  loss_box_reg: 0.043  loss_mask: 0.07245  loss_rpn_cls: 0.0004648  loss_rpn_loc: 0.005638  data_time: 0.1477  lr: N/A  max_mem: 1271M
[11/11 23:26:36] detectron2 INFO: Rank of current process: 0. World size: 1
[11/11 23:26:36] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 23:26:36] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/11 23:26:36] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/11 23:26:36] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/11 23:26:36] d2.utils.env INFO: Using a generated random seed 37207810
[11/11 23:26:52] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.87 seconds.
[11/11 23:26:53] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/11 23:27:01] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/11 23:27:01] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/11 23:27:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice'), RandomFlip()]
[11/11 23:27:03] d2.data.build INFO: Using training sampler TrainingSampler
[11/11 23:27:03] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/11 23:27:03] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/11 23:27:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/11 23:27:03] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/11 23:27:03] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/11 23:27:03] d2.engine.train_loop INFO: Starting training from iteration 1
[11/11 23:27:36] d2.engine.hooks INFO: Total training time: 0:00:32 (0:00:00 on hooks)
[11/11 23:27:36] d2.utils.events INFO:  iter: 2  total_loss: 0.1379  loss_cls: 0.01828  loss_box_reg: 0.03745  loss_mask: 0.07373  loss_rpn_cls: 0.0007869  loss_rpn_loc: 0.00766  data_time: 0.1523  lr: N/A  max_mem: 1271M
[11/12 00:18:02] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 00:18:03] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 00:18:03] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 00:18:03] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 00:18:03] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 00:18:03] d2.utils.env INFO: Using a generated random seed 3939810
[11/12 00:18:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 00:18:19] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.74 seconds.
[11/12 00:18:20] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 00:18:28] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 00:18:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 00:18:30] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 00:18:30] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 00:18:43] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 00:18:43] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3913 s/iter. Eval: 0.0049 s/iter. Total: 0.3962 s/iter. ETA=0:00:00
[11/12 00:18:43] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.471138 (0.471138 s / iter per device, on 1 devices)
[11/12 00:18:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.391344 s / iter per device, on 1 devices)
[11/12 00:18:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 00:18:43] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 00:18:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 00:18:43] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 00:18:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 00:18:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 00:18:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 00:18:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 00:18:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 00:18:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 00:18:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 00:18:44] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 00:18:44] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 00:18:44] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 00:37:41] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 00:37:42] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 00:37:42] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 00:37:42] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 00:37:42] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 00:37:42] d2.utils.env INFO: Using a generated random seed 43022906
[11/12 00:37:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 00:37:58] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.53 seconds.
[11/12 00:37:59] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 00:38:07] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 00:38:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 00:38:09] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 00:38:09] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 00:38:21] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 00:38:22] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3894 s/iter. Eval: 0.0048 s/iter. Total: 0.3942 s/iter. ETA=0:00:00
[11/12 00:38:22] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.455787 (0.455787 s / iter per device, on 1 devices)
[11/12 00:38:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.389391 s / iter per device, on 1 devices)
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 00:38:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 00:38:22] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 00:38:22] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 00:38:22] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 01:17:42] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 01:17:43] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 01:17:43] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 01:17:43] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 01:17:43] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 01:17:43] d2.utils.env INFO: Using a generated random seed 44018956
[11/12 01:17:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 01:17:59] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.88 seconds.
[11/12 01:18:00] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 01:18:08] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 01:18:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 01:18:10] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 01:18:10] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 01:18:23] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 01:18:24] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3871 s/iter. Eval: 0.0049 s/iter. Total: 0.3920 s/iter. ETA=0:00:00
[11/12 01:18:24] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.454738 (0.454738 s / iter per device, on 1 devices)
[11/12 01:18:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.387096 s / iter per device, on 1 devices)
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:18:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:18:24] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 01:18:24] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:18:24] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 01:20:37] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 01:20:38] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 01:20:38] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 01:20:38] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 01:20:38] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 01:20:38] d2.utils.env INFO: Using a generated random seed 38970922
[11/12 01:20:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 01:20:54] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.32 seconds.
[11/12 01:20:55] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 01:21:04] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 01:21:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 01:21:05] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 01:21:05] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 01:21:18] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 01:21:19] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3856 s/iter. Eval: 0.0048 s/iter. Total: 0.3904 s/iter. ETA=0:00:00
[11/12 01:21:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.465007 (0.465007 s / iter per device, on 1 devices)
[11/12 01:21:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.385590 s / iter per device, on 1 devices)
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:21:19] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:21:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:21:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:21:20] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 01:21:20] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:21:20] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 01:21:20] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:21:20] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 01:25:28] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 01:25:29] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 01:25:29] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 01:25:29] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 01:25:29] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 01:25:29] d2.utils.env INFO: Using a generated random seed 29592317
[11/12 01:25:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 01:25:45] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.96 seconds.
[11/12 01:25:46] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 01:25:54] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 01:25:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 01:25:56] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 01:25:56] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 01:26:09] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 01:26:10] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3990 s/iter. Eval: 0.0049 s/iter. Total: 0.4040 s/iter. ETA=0:00:00
[11/12 01:26:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.481104 (0.481104 s / iter per device, on 1 devices)
[11/12 01:26:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.399011 s / iter per device, on 1 devices)
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:26:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:26:10] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 01:26:10] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:26:10] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 01:42:15] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 01:42:16] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 01:42:16] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 01:42:16] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 01:42:16] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 01:42:16] d2.utils.env INFO: Using a generated random seed 16973146
[11/12 01:42:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 01:42:32] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.76 seconds.
[11/12 01:42:33] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 01:42:41] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 01:42:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 01:42:43] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 01:42:43] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 01:42:56] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 01:42:56] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3917 s/iter. Eval: 0.0049 s/iter. Total: 0.3966 s/iter. ETA=0:00:00
[11/12 01:42:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461910 (0.461910 s / iter per device, on 1 devices)
[11/12 01:42:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.391748 s / iter per device, on 1 devices)
[11/12 01:42:56] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 01:42:56] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 01:42:56] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 01:42:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 01:42:57] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 01:42:57] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 01:42:57] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:16:25] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:16:26] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:16:26] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:16:26] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:16:26] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:16:26] d2.utils.env INFO: Using a generated random seed 26479997
[11/12 02:16:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:16:41] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.77 seconds.
[11/12 02:16:42] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:16:50] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:16:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:16:52] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:16:52] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:17:05] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:18:38] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:18:39] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:18:39] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:18:39] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:18:39] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:18:39] d2.utils.env INFO: Using a generated random seed 40070562
[11/12 02:18:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:18:56] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.94 seconds.
[11/12 02:18:57] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:19:05] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:19:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:19:07] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:19:07] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:19:21] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:19:22] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3809 s/iter. Eval: 0.0049 s/iter. Total: 0.3857 s/iter. ETA=0:00:00
[11/12 02:19:22] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461336 (0.461336 s / iter per device, on 1 devices)
[11/12 02:19:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.380853 s / iter per device, on 1 devices)
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:19:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:19:22] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:19:22] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:19:22] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:26:47] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:26:47] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:26:47] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:26:47] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:26:47] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:26:47] d2.utils.env INFO: Using a generated random seed 48186720
[11/12 02:26:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:27:03] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.82 seconds.
[11/12 02:27:04] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:27:12] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:27:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:27:14] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:27:14] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:27:27] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:27:58] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 30.9987 s/iter. Eval: 0.0055 s/iter. Total: 31.0042 s/iter. ETA=0:00:00
[11/12 02:27:58] d2.evaluation.evaluator INFO: Total inference time: 0:00:31.108319 (31.108319 s / iter per device, on 1 devices)
[11/12 02:27:58] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (30.998744 s / iter per device, on 1 devices)
[11/12 02:27:58] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:27:58] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:27:58] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:27:58] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:27:58] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:27:58] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:27:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:27:59] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:27:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:27:59] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:27:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:27:59] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:27:59] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:27:59] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:39:32] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:39:32] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:39:32] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:39:32] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:39:32] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:39:33] d2.utils.env INFO: Using a generated random seed 33388870
[11/12 02:39:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:39:48] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.81 seconds.
[11/12 02:39:49] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:39:57] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:39:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:39:59] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:39:59] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:40:12] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:41:05] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 52.2024 s/iter. Eval: 0.0088 s/iter. Total: 52.2111 s/iter. ETA=0:00:00
[11/12 02:41:05] d2.evaluation.evaluator INFO: Total inference time: 0:00:52.303531 (52.303531 s / iter per device, on 1 devices)
[11/12 02:41:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:52 (52.202359 s / iter per device, on 1 devices)
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:41:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:41:05] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:41:05] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:41:05] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:43:07] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:43:08] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:43:08] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:43:08] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:43:08] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:43:08] d2.utils.env INFO: Using a generated random seed 8864250
[11/12 02:43:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:43:23] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.60 seconds.
[11/12 02:43:24] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:43:32] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:43:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:43:34] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:43:34] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:43:47] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:44:10] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 22.8537 s/iter. Eval: 0.0096 s/iter. Total: 22.8633 s/iter. ETA=0:00:00
[11/12 02:44:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:22.944929 (22.944929 s / iter per device, on 1 devices)
[11/12 02:44:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (22.853674 s / iter per device, on 1 devices)
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:44:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:44:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:44:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:44:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:44:10] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:44:11] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:44:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:44:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:44:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:44:11] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:44:11] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:44:11] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:44:11] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:44:11] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:46:22] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:46:22] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:46:22] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:46:22] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:46:22] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:46:22] d2.utils.env INFO: Using a generated random seed 23238571
[11/12 02:46:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:46:38] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.68 seconds.
[11/12 02:46:39] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:46:47] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:46:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:46:49] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:46:49] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:47:02] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:47:02] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3951 s/iter. Eval: 0.0049 s/iter. Total: 0.4000 s/iter. ETA=0:00:00
[11/12 02:47:02] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.460486 (0.460486 s / iter per device, on 1 devices)
[11/12 02:47:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.395088 s / iter per device, on 1 devices)
[11/12 02:47:02] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:47:02] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:47:02] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:47:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:47:03] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:47:03] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:47:03] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:50:39] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:50:40] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:50:40] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:50:40] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:50:40] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:50:40] d2.utils.env INFO: Using a generated random seed 40595327
[11/12 02:50:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:50:55] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.83 seconds.
[11/12 02:50:56] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:51:05] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:51:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:51:06] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:51:06] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:51:19] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:51:20] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3967 s/iter. Eval: 0.0049 s/iter. Total: 0.4016 s/iter. ETA=0:00:00
[11/12 02:51:20] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.475729 (0.475729 s / iter per device, on 1 devices)
[11/12 02:51:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.396687 s / iter per device, on 1 devices)
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:51:20] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:51:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:51:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:51:21] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:51:21] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:51:21] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:51:21] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:51:21] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 02:53:03] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 02:53:04] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 02:53:04] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 02:53:04] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 02:53:04] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 02:53:04] d2.utils.env INFO: Using a generated random seed 5054583
[11/12 02:53:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 02:53:20] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.53 seconds.
[11/12 02:53:21] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 02:53:28] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 02:53:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 02:53:30] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 02:53:30] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 02:53:43] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 02:53:44] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.4016 s/iter. Eval: 0.0048 s/iter. Total: 0.4064 s/iter. ETA=0:00:00
[11/12 02:53:44] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.471838 (0.471838 s / iter per device, on 1 devices)
[11/12 02:53:44] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.401559 s / iter per device, on 1 devices)
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 02:53:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 02:53:44] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 02:53:44] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 02:53:44] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 03:01:22] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 03:01:23] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 03:01:23] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 03:01:23] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 03:01:23] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 03:01:23] d2.utils.env INFO: Using a generated random seed 24194776
[11/12 03:01:24] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 03:01:39] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.81 seconds.
[11/12 03:01:40] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 03:01:48] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 03:01:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 03:01:50] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 03:01:50] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 03:02:03] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 03:02:04] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3901 s/iter. Eval: 0.0049 s/iter. Total: 0.3950 s/iter. ETA=0:00:00
[11/12 03:02:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.468977 (0.468977 s / iter per device, on 1 devices)
[11/12 03:02:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.390083 s / iter per device, on 1 devices)
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 03:02:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 03:02:04] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 03:02:04] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 03:02:04] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 03:02:47] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 03:02:48] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 03:02:48] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/12 03:02:48] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 03:02:48] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 03:02:48] d2.utils.env INFO: Using a generated random seed 49053228
[11/12 03:03:04] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.76 seconds.
[11/12 03:03:05] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 03:03:13] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/12 03:03:13] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 03:03:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/12 03:03:15] d2.data.build INFO: Using training sampler TrainingSampler
[11/12 03:03:15] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 03:03:15] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 03:03:15] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 03:03:15] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/12 03:03:15] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/12 03:03:15] d2.engine.train_loop INFO: Starting training from iteration 1
[11/12 03:03:25] d2.engine.hooks INFO: Total training time: 0:00:10 (0:00:00 on hooks)
[11/12 03:03:25] d2.utils.events INFO:  iter: 2  total_loss: 0.1401  loss_cls: 0.01698  loss_box_reg: 0.04011  loss_mask: 0.07693  loss_rpn_cls: 0.0004708  loss_rpn_loc: 0.005638  data_time: 0.1417  lr: N/A  max_mem: 1271M
[11/12 03:03:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 03:03:45] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 03:03:45] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/12 03:03:45] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 03:03:45] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 03:03:45] d2.utils.env INFO: Using a generated random seed 45766008
[11/12 03:04:00] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.75 seconds.
[11/12 03:04:01] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 03:04:09] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/12 03:04:09] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 03:04:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/12 03:04:11] d2.data.build INFO: Using training sampler TrainingSampler
[11/12 03:04:11] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 03:04:11] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 03:04:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 03:04:12] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/12 03:04:12] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/12 03:04:12] d2.engine.train_loop INFO: Starting training from iteration 1
[11/12 03:04:12] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/12 03:04:12] d2.utils.events INFO:  iter: 2  total_loss: 0.1425  loss_cls: 0.01669  loss_box_reg: 0.04369  loss_mask: 0.07584  loss_rpn_cls: 0.0005963  loss_rpn_loc: 0.005638  data_time: 0.1439  lr: N/A  max_mem: 1269M
[11/12 12:05:46] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:05:47] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:05:47] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/12 12:05:47] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:05:47] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:05:47] d2.utils.env INFO: Using a generated random seed 47667326
[11/12 12:06:34] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:06:35] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:06:35] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:06:35] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:06:35] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:06:35] d2.utils.env INFO: Using a generated random seed 36377994
[11/12 12:06:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:06:51] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.83 seconds.
[11/12 12:06:52] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:07:00] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:07:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:07:02] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:07:02] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:07:15] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:07:16] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3857 s/iter. Eval: 0.0049 s/iter. Total: 0.3907 s/iter. ETA=0:00:00
[11/12 12:07:16] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.463772 (0.463772 s / iter per device, on 1 devices)
[11/12 12:07:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.385748 s / iter per device, on 1 devices)
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:07:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:07:16] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:07:16] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:07:16] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 12:08:31] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:08:32] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:08:32] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:08:32] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:08:32] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:08:32] d2.utils.env INFO: Using a generated random seed 33009506
[11/12 12:08:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:08:48] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.90 seconds.
[11/12 12:08:49] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:08:57] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:08:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:08:59] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:08:59] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:09:12] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:09:12] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3855 s/iter. Eval: 0.0049 s/iter. Total: 0.3904 s/iter. ETA=0:00:00
[11/12 12:09:12] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.457036 (0.457036 s / iter per device, on 1 devices)
[11/12 12:09:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.385508 s / iter per device, on 1 devices)
[11/12 12:09:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:09:12] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:09:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:09:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:09:13] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:09:13] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:09:13] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 12:31:55] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:31:56] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:31:56] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:31:56] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:31:56] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:31:56] d2.utils.env INFO: Using a generated random seed 57182104
[11/12 12:31:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:32:12] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.82 seconds.
[11/12 12:32:13] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:32:21] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:32:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:32:23] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:32:23] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:32:36] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:32:37] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3885 s/iter. Eval: 0.0049 s/iter. Total: 0.3934 s/iter. ETA=0:00:00
[11/12 12:32:37] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461416 (0.461416 s / iter per device, on 1 devices)
[11/12 12:32:37] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.388483 s / iter per device, on 1 devices)
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:32:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:32:37] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:32:37] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:32:37] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 12:33:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:33:20] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:33:20] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:33:20] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:33:20] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:33:20] d2.utils.env INFO: Using a generated random seed 21054917
[11/12 12:33:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:33:36] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.96 seconds.
[11/12 12:33:37] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:33:45] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:33:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:33:47] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:33:47] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:34:00] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:34:01] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3886 s/iter. Eval: 0.0049 s/iter. Total: 0.3935 s/iter. ETA=0:00:00
[11/12 12:34:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461555 (0.461555 s / iter per device, on 1 devices)
[11/12 12:34:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.388551 s / iter per device, on 1 devices)
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:34:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:34:01] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:34:01] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:34:01] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 12:36:55] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:36:56] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:36:56] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:36:56] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:36:56] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:36:56] d2.utils.env INFO: Using a generated random seed 57200105
[11/12 12:36:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:37:12] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.73 seconds.
[11/12 12:37:13] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:37:21] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:37:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:37:23] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:37:23] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:37:36] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:37:36] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3871 s/iter. Eval: 0.0048 s/iter. Total: 0.3918 s/iter. ETA=0:00:00
[11/12 12:37:36] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461071 (0.461071 s / iter per device, on 1 devices)
[11/12 12:37:36] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.387053 s / iter per device, on 1 devices)
[11/12 12:37:36] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:37:36] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:37:36] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:37:36] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:37:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:37:36] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:37:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:37:37] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:37:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:37:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:37:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:37:37] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:37:37] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:37:37] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 12:42:57] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 12:42:58] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 12:42:58] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 12:42:58] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 12:42:58] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 12:42:58] d2.utils.env INFO: Using a generated random seed 58782672
[11/12 12:42:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 12:43:13] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.71 seconds.
[11/12 12:43:14] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 12:43:22] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 12:43:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 12:43:24] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 12:43:24] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 12:43:37] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 12:43:38] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3979 s/iter. Eval: 0.0049 s/iter. Total: 0.4028 s/iter. ETA=0:00:00
[11/12 12:43:38] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.477573 (0.477573 s / iter per device, on 1 devices)
[11/12 12:43:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.397895 s / iter per device, on 1 devices)
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:43:38] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 12:43:38] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 12:43:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 12:43:39] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 12:43:39] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 12:43:39] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 12:43:39] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 12:43:39] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 13:01:34] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 13:01:35] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 13:01:35] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 13:01:35] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 13:01:35] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 13:01:35] d2.utils.env INFO: Using a generated random seed 35863803
[11/12 13:01:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 13:01:51] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.43 seconds.
[11/12 13:01:52] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 13:02:02] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 13:02:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 13:02:04] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 13:02:04] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 13:02:17] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 13:02:18] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3981 s/iter. Eval: 0.0049 s/iter. Total: 0.4031 s/iter. ETA=0:00:00
[11/12 13:02:18] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.469769 (0.469769 s / iter per device, on 1 devices)
[11/12 13:02:18] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.398121 s / iter per device, on 1 devices)
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:02:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:02:18] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 13:02:18] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:02:18] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 13:03:20] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 13:03:21] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 13:03:21] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 13:03:21] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 13:03:21] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 13:03:21] d2.utils.env INFO: Using a generated random seed 21898083
[11/12 13:03:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 13:03:36] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.73 seconds.
[11/12 13:03:37] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 13:03:46] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 13:03:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 13:03:48] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 13:03:48] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 13:04:01] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 13:04:02] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3930 s/iter. Eval: 0.0050 s/iter. Total: 0.3980 s/iter. ETA=0:00:00
[11/12 13:04:02] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.478878 (0.478878 s / iter per device, on 1 devices)
[11/12 13:04:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.392991 s / iter per device, on 1 devices)
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50   |  AP75   |  APs   |   APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:-------:|:-----:|
| 95.260 | 100.000 | 100.000 | 95.000 | 100.000 |  nan  |
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:04:02] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 94.975 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 95.545 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:04:02] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:04:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 13:04:03] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 13:04:03] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:04:03] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 13:04:03] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: 95.2599,100.0000,100.0000,95.0000,100.0000,nan
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:04:03] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 13:06:49] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 13:06:50] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 13:06:50] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 13:06:50] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 13:06:50] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 13:06:50] d2.utils.env INFO: Using a generated random seed 50775386
[11/12 13:06:50] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 13:07:05] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.56 seconds.
[11/12 13:07:06] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 13:07:14] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 13:07:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 13:07:16] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 13:07:16] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 13:07:29] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 13:07:29] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3927 s/iter. Eval: 0.0048 s/iter. Total: 0.3975 s/iter. ETA=0:00:00
[11/12 13:07:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.460463 (0.460463 s / iter per device, on 1 devices)
[11/12 13:07:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.392692 s / iter per device, on 1 devices)
[11/12 13:07:29] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 13:07:29] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 13:07:29] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 13:07:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 13:07:30] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 13:07:30] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 13:07:30] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/12 17:58:22] detectron2 INFO: Rank of current process: 0. World size: 1
[11/12 17:58:23] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 17:58:23] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/12 17:58:23] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/12 17:58:23] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/12 17:58:23] d2.utils.env INFO: Using a generated random seed 24307139
[11/12 17:58:24] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/12 17:58:39] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.99 seconds.
[11/12 17:58:40] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/12 17:58:48] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/12 17:58:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/12 17:58:50] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/12 17:58:50] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/12 17:59:03] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/12 17:59:04] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3787 s/iter. Eval: 0.0049 s/iter. Total: 0.3837 s/iter. ETA=0:00:00
[11/12 17:59:04] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.447754 (0.447754 s / iter per device, on 1 devices)
[11/12 17:59:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.378748 s / iter per device, on 1 devices)
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/12 17:59:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/12 17:59:04] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/12 17:59:04] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: Task: segm
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/12 17:59:04] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/13 00:01:33] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:01:34] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:01:34] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:01:34] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:01:34] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:01:34] d2.utils.env INFO: Using a generated random seed 35511546
[11/13 00:01:50] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.96 seconds.
[11/13 00:01:51] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:01:59] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:01:59] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:02:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:02:01] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:02:01] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:02:01] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:02:01] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:02:01] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:02:01] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:02:01] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:02:02] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:02:02] d2.utils.events INFO:  iter: 2  total_loss: 0.1382  loss_cls: 0.01433  loss_box_reg: 0.04415  loss_mask: 0.07356  loss_rpn_cls: 0.0004986  loss_rpn_loc: 0.005638  data_time: 0.1590  lr: N/A  max_mem: 1269M
[11/13 00:04:42] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:04:43] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:04:43] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:04:43] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:04:43] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:04:43] d2.utils.env INFO: Using a generated random seed 43840491
[11/13 00:04:58] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.60 seconds.
[11/13 00:04:59] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:05:07] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:05:07] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:05:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:05:09] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:05:09] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:05:09] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:05:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:05:09] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:05:09] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:05:09] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:05:10] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:05:10] d2.utils.events INFO:  iter: 2  total_loss: 0.1308  loss_cls: 0.01271  loss_box_reg: 0.04116  loss_mask: 0.07081  loss_rpn_cls: 0.0004655  loss_rpn_loc: 0.005638  data_time: 0.1603  lr: N/A  max_mem: 1269M
[11/13 00:16:05] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:16:06] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:16:06] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:16:06] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:16:06] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:16:06] d2.utils.env INFO: Using a generated random seed 7250155
[11/13 00:16:22] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.80 seconds.
[11/13 00:16:23] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:16:31] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:16:31] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:16:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:16:33] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:16:33] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:16:33] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:16:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:16:33] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:16:33] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:16:33] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:16:34] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:16:34] d2.utils.events INFO:  iter: 2  total_loss: 0.1375  loss_cls: 0.01493  loss_box_reg: 0.04339  loss_mask: 0.07304  loss_rpn_cls: 0.0005162  loss_rpn_loc: 0.005638  data_time: 0.1581  lr: N/A  max_mem: 1269M
[11/13 00:17:30] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:17:30] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:17:30] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:17:30] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:17:30] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:17:30] d2.utils.env INFO: Using a generated random seed 31596534
[11/13 00:17:47] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 16.02 seconds.
[11/13 00:17:48] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:17:56] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:17:56] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:17:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:17:58] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:17:58] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:17:58] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:17:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:17:59] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:17:59] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:17:59] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:18:00] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:18:00] d2.utils.events INFO:  iter: 2  total_loss: 0.1372  loss_cls: 0.01575  loss_box_reg: 0.04142  loss_mask: 0.07389  loss_rpn_cls: 0.0005362  loss_rpn_loc: 0.005638  data_time: 0.1414  lr: N/A  max_mem: 1269M
[11/13 00:21:41] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:21:41] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:21:41] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:21:41] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:21:41] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:21:41] d2.utils.env INFO: Using a generated random seed 42642072
[11/13 00:21:57] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.73 seconds.
[11/13 00:21:58] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:22:06] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:22:06] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:22:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:22:08] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:22:08] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:22:08] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:22:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:22:08] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:22:08] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:22:08] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:22:09] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:22:09] d2.utils.events INFO:  iter: 2  total_loss: 0.137  loss_cls: 0.01623  loss_box_reg: 0.04277  loss_mask: 0.07188  loss_rpn_cls: 0.0005028  loss_rpn_loc: 0.005638  data_time: 0.1359  lr: N/A  max_mem: 1269M
[11/13 00:23:54] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:23:55] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:23:55] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:23:55] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:23:55] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:23:55] d2.utils.env INFO: Using a generated random seed 56138344
[11/13 00:24:11] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.89 seconds.
[11/13 00:24:12] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:24:20] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:24:20] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:24:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:24:22] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:24:22] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:24:22] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:24:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:24:22] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:24:22] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:24:22] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:24:23] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:24:23] d2.utils.events INFO:  iter: 2  total_loss: 0.1374  loss_cls: 0.01575  loss_box_reg: 0.04239  loss_mask: 0.07316  loss_rpn_cls: 0.0004888  loss_rpn_loc: 0.005638  data_time: 0.1458  lr: N/A  max_mem: 1269M
[11/13 00:42:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:42:20] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:42:20] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:42:20] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:42:20] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:42:20] d2.utils.env INFO: Using a generated random seed 21241355
[11/13 00:42:36] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.64 seconds.
[11/13 00:42:37] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:42:45] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:42:45] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:42:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:42:47] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:42:47] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:42:47] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:42:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:42:48] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:42:48] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:42:48] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:42:48] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:42:48] d2.utils.events INFO:  iter: 2  total_loss: 0.1352  loss_cls: 0.01203  loss_box_reg: 0.04134  loss_mask: 0.07564  loss_rpn_cls: 0.0005486  loss_rpn_loc: 0.005638  data_time: 0.1568  lr: N/A  max_mem: 1269M
[11/13 00:44:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:44:45] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:44:45] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:44:45] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:44:45] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:44:45] d2.utils.env INFO: Using a generated random seed 46306310
[11/13 00:45:01] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.91 seconds.
[11/13 00:45:02] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:45:10] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:45:10] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:45:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:45:12] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:45:12] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:45:12] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:45:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:45:12] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:45:12] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:45:12] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:45:14] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:45:14] d2.utils.events INFO:  iter: 3  total_loss: 0.1412  loss_cls: 0.01808  loss_box_reg: 0.04285  loss_mask: 0.07405  loss_rpn_cls: 0.0005699  loss_rpn_loc: 0.005634  data_time: 0.0659  lr: 2e-05  max_mem: 1320M
[11/13 00:50:58] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 00:50:59] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:50:59] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 00:50:59] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 00:50:59] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 00:50:59] d2.utils.env INFO: Using a generated random seed 60207645
[11/13 00:51:15] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.23 seconds.
[11/13 00:51:16] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 00:51:24] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 00:51:24] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 00:51:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 00:51:26] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 00:51:26] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 00:51:26] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 00:51:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 00:51:26] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 00:51:26] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 00:51:26] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 00:51:27] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 00:51:27] d2.utils.events INFO:  iter: 3  total_loss: 0.138  loss_cls: 0.01687  loss_box_reg: 0.04095  loss_mask: 0.07404  loss_rpn_cls: 0.0004658  loss_rpn_loc: 0.005634  data_time: 0.0721  lr: 2e-05  max_mem: 1320M
[11/13 01:07:56] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 01:07:57] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 01:07:57] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 01:07:57] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 01:07:57] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 01:07:57] d2.utils.env INFO: Using a generated random seed 58344095
[11/13 01:08:13] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.86 seconds.
[11/13 01:08:14] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 01:08:22] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 01:08:22] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 01:08:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 01:08:24] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 01:08:24] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 01:08:24] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 01:08:24] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 01:08:24] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 01:08:24] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 01:08:24] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 01:08:25] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 01:08:25] d2.utils.events INFO:  iter: 3  total_loss: 0.14  loss_cls: 0.01731  loss_box_reg: 0.0411  loss_mask: 0.07373  loss_rpn_cls: 0.002235  loss_rpn_loc: 0.005634  data_time: 0.0764  lr: 2e-05  max_mem: 1320M
[11/13 01:15:50] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 01:15:50] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 01:15:50] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[11/13 01:15:50] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 01:15:50] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 01:15:50] d2.utils.env INFO: Using a generated random seed 51690958
[11/13 01:16:06] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.82 seconds.
[11/13 01:16:07] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 01:16:15] d2.data.build INFO: Removed 0 images with no usable annotations. 1 images left.
[11/13 01:16:15] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 01:16:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[11/13 01:16:17] d2.data.build INFO: Using training sampler TrainingSampler
[11/13 01:16:17] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 01:16:17] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 01:16:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 01:16:17] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[11/13 01:16:17] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/13 01:16:17] d2.engine.train_loop INFO: Starting training from iteration 1
[11/13 01:16:18] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/13 01:16:18] d2.utils.events INFO:  iter: 2  total_loss: 0.1411  loss_cls: 0.01915  loss_box_reg: 0.04221  loss_mask: 0.07363  loss_rpn_cls: 0.0004649  loss_rpn_loc: 0.005638  data_time: 0.1652  lr: N/A  max_mem: 1269M
[11/13 02:11:40] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 02:11:41] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 02:11:41] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/13 02:11:41] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 02:11:41] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 02:11:41] d2.utils.env INFO: Using a generated random seed 41869666
[11/13 02:11:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 02:11:56] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.75 seconds.
[11/13 02:11:57] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 02:12:05] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 02:12:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/13 02:12:07] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 02:12:07] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 02:12:20] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/13 02:12:21] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3732 s/iter. Eval: 0.0049 s/iter. Total: 0.3782 s/iter. ETA=0:00:00
[11/13 02:12:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.464577 (0.464577 s / iter per device, on 1 devices)
[11/13 02:12:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.373238 s / iter per device, on 1 devices)
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 02:12:21] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 02:12:21] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/13 02:12:21] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: Task: segm
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 02:12:21] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/13 16:43:20] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 16:43:21] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 16:43:21] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/13 16:43:21] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 16:43:21] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 16:43:21] d2.utils.env INFO: Using a generated random seed 21899423
[11/13 16:43:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 16:43:36] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 14.80 seconds.
[11/13 16:43:37] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 16:43:45] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 16:43:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/13 16:43:47] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 16:43:47] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 16:44:00] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/13 16:44:01] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3853 s/iter. Eval: 0.0049 s/iter. Total: 0.3902 s/iter. ETA=0:00:00
[11/13 16:44:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.454427 (0.454427 s / iter per device, on 1 devices)
[11/13 16:44:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.385287 s / iter per device, on 1 devices)
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50   |  AP75   |  APs   |   APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:-------:|:-----:|
| 95.260 | 100.000 | 100.000 | 95.000 | 100.000 |  nan  |
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 94.975 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 95.545 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 16:44:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 16:44:01] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/13 16:44:01] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: 95.2599,100.0000,100.0000,95.0000,100.0000,nan
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: Task: segm
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 16:44:01] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[11/13 16:44:32] detectron2 INFO: Rank of current process: 0. World size: 1
[11/13 16:44:33] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.23.5
detectron2              0.6 @/ssd1/chaolu225/pytorch/detectron2/detectron2
Compiler                GCC 11.3
CUDA compiler           CUDA 11.8
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.0.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100S-PCIE-32GB (arch=7.0)
Driver version          535.129.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.4.0
torchvision             0.15.0 @/home/chaolu225/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 16:44:33] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50154', opts=['OUTPUT_DIR', './output_300/'])
[11/13 16:44:33] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m

[11/13 16:44:33] detectron2 INFO: Full config saved to ./output_300/config.yaml
[11/13 16:44:33] d2.utils.env INFO: Using a generated random seed 34312585
[11/13 16:44:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[11/13 16:44:49] d2.data.datasets.coco INFO: Loading /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json takes 15.01 seconds.
[11/13 16:44:50] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /ssd1/chaolu225/pytorch/dataset/coco/annotations/instances_train2017.json
[11/13 16:44:58] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 9            |   bicycle    | 0            |      car      | 0            |
|  motorcycle   | 0            |   airplane   | 0            |      bus      | 0            |
|     train     | 0            |    truck     | 0            |     boat      | 0            |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 0            |
|      cat      | 0            |     dog      | 0            |     horse     | 0            |
|     sheep     | 0            |     cow      | 0            |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 3            | tennis racket | 0            |
|    bottle     | 0            |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 0            |
|     couch     | 0            | potted plant | 0            |      bed      | 0            |
| dining table  | 0            |    toilet    | 0            |      tv       | 0            |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 12           |              |              |               |              |[0m
[11/13 16:45:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[11/13 16:45:00] d2.data.common INFO: Serializing 1 elements to byte tensors and concatenating them all ...
[11/13 16:45:00] d2.data.common INFO: Serialized dataset takes 0.01 MiB
[11/13 16:45:13] d2.evaluation.evaluator INFO: Start inference on 1 batches
[11/13 16:45:14] d2.evaluation.evaluator INFO: Inference done 1/1. Dataloading: 0.0000 s/iter. Inference: 0.3923 s/iter. Eval: 0.0049 s/iter. Total: 0.3973 s/iter. ETA=0:00:00
[11/13 16:45:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.461685 (0.461685 s / iter per device, on 1 devices)
[11/13 16:45:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.392315 s / iter per device, on 1 devices)
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.17 seconds.
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP    |  AP50   |  AP75   |   APs   |   APm   |  APl  |
|:-------:|:-------:|:-------:|:-------:|:-------:|:-----:|
| 100.000 | 100.000 | 100.000 | 100.000 | 100.000 |  nan  |
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP      | category     | AP      | category       | AP   |
|:--------------|:--------|:-------------|:--------|:---------------|:-----|
| person        | 100.000 | bicycle      | nan     | car            | nan  |
| motorcycle    | nan     | airplane     | nan     | bus            | nan  |
| train         | nan     | truck        | nan     | boat           | nan  |
| traffic light | nan     | fire hydrant | nan     | stop sign      | nan  |
| parking meter | nan     | bench        | nan     | bird           | nan  |
| cat           | nan     | dog          | nan     | horse          | nan  |
| sheep         | nan     | cow          | nan     | elephant       | nan  |
| bear          | nan     | zebra        | nan     | giraffe        | nan  |
| backpack      | nan     | umbrella     | nan     | handbag        | nan  |
| tie           | nan     | suitcase     | nan     | frisbee        | nan  |
| skis          | nan     | snowboard    | nan     | sports ball    | nan  |
| kite          | nan     | baseball bat | nan     | baseball glove | nan  |
| skateboard    | nan     | surfboard    | 100.000 | tennis racket  | nan  |
| bottle        | nan     | wine glass   | nan     | cup            | nan  |
| fork          | nan     | knife        | nan     | spoon          | nan  |
| bowl          | nan     | banana       | nan     | apple          | nan  |
| sandwich      | nan     | orange       | nan     | broccoli       | nan  |
| carrot        | nan     | hot dog      | nan     | pizza          | nan  |
| donut         | nan     | cake         | nan     | chair          | nan  |
| couch         | nan     | potted plant | nan     | bed            | nan  |
| dining table  | nan     | toilet       | nan     | tv             | nan  |
| laptop        | nan     | mouse        | nan     | remote         | nan  |
| keyboard      | nan     | cell phone   | nan     | microwave      | nan  |
| oven          | nan     | toaster      | nan     | sink           | nan  |
| refrigerator  | nan     | book         | nan     | clock          | nan  |
| vase          | nan     | scissors     | nan     | teddy bear     | nan  |
| hair drier    | nan     | toothbrush   | nan     |                |      |
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.01 seconds.
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/13 16:45:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.16 seconds.
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm   |  APl  |
|:------:|:-------:|:-------:|:------:|:------:|:-----:|
| 87.442 | 100.000 | 100.000 | 88.414 | 80.000 |  nan  |
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[11/13 16:45:14] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP   |
|:--------------|:-------|:-------------|:-------|:---------------|:-----|
| person        | 88.218 | bicycle      | nan    | car            | nan  |
| motorcycle    | nan    | airplane     | nan    | bus            | nan  |
| train         | nan    | truck        | nan    | boat           | nan  |
| traffic light | nan    | fire hydrant | nan    | stop sign      | nan  |
| parking meter | nan    | bench        | nan    | bird           | nan  |
| cat           | nan    | dog          | nan    | horse          | nan  |
| sheep         | nan    | cow          | nan    | elephant       | nan  |
| bear          | nan    | zebra        | nan    | giraffe        | nan  |
| backpack      | nan    | umbrella     | nan    | handbag        | nan  |
| tie           | nan    | suitcase     | nan    | frisbee        | nan  |
| skis          | nan    | snowboard    | nan    | sports ball    | nan  |
| kite          | nan    | baseball bat | nan    | baseball glove | nan  |
| skateboard    | nan    | surfboard    | 86.667 | tennis racket  | nan  |
| bottle        | nan    | wine glass   | nan    | cup            | nan  |
| fork          | nan    | knife        | nan    | spoon          | nan  |
| bowl          | nan    | banana       | nan    | apple          | nan  |
| sandwich      | nan    | orange       | nan    | broccoli       | nan  |
| carrot        | nan    | hot dog      | nan    | pizza          | nan  |
| donut         | nan    | cake         | nan    | chair          | nan  |
| couch         | nan    | potted plant | nan    | bed            | nan  |
| dining table  | nan    | toilet       | nan    | tv             | nan  |
| laptop        | nan    | mouse        | nan    | remote         | nan  |
| keyboard      | nan    | cell phone   | nan    | microwave      | nan  |
| oven          | nan    | toaster      | nan    | sink           | nan  |
| refrigerator  | nan    | book         | nan    | clock          | nan  |
| vase          | nan    | scissors     | nan    | teddy bear     | nan  |
| hair drier    | nan    | toothbrush   | nan    |                |      |
[11/13 16:45:14] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: 100.0000,100.0000,100.0000,100.0000,100.0000,nan
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: Task: segm
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/13 16:45:14] d2.evaluation.testing INFO: copypaste: 87.4422,100.0000,100.0000,88.4138,80.0000,nan
[04/09 22:47:16] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:47:17] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:47:17] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:47:17] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:47:17] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:47:17] d2.utils.env INFO: Using a generated random seed 17919682
[04/09 22:47:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:47:31] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 12.64 seconds.
[04/09 22:47:32] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 22:47:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 22:47:46] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 22:47:46] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 22:47:58] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 22:47:59] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.106384 (0.000369 s / iter per device, on 1 devices)
[04/09 22:47:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000280 s / iter per device, on 1 devices)
[04/09 22:47:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 22:47:59] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 22:47:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 22:47:59] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 22:48:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.20 seconds.
[04/09 22:48:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:48:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.27 seconds.
[04/09 22:48:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 22:48:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:48:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 22:48:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.97 seconds.
[04/09 22:48:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:48:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.30 seconds.
[04/09 22:48:08] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.028 | 0.037  | 0.037  | 0.000 | 0.020 | 0.038 |
[04/09 22:48:08] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.277 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:48:08] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: 0.0340,0.0371,0.0371,0.0000,0.0223,0.0476
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: Task: segm
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:48:08] d2.evaluation.testing INFO: copypaste: 0.0285,0.0371,0.0371,0.0000,0.0198,0.0376
[04/09 22:50:19] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:50:19] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:50:19] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:50:19] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:50:19] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:50:19] d2.utils.env INFO: Using a generated random seed 20071674
[04/09 22:50:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:50:32] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.93 seconds.
[04/09 22:50:33] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 22:50:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 22:50:47] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 22:50:47] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 22:50:59] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 22:51:00] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.914310 (0.000305 s / iter per device, on 1 devices)
[04/09 22:51:00] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000219 s / iter per device, on 1 devices)
[04/09 22:51:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 22:51:00] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 22:51:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 22:51:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 22:51:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.19 seconds.
[04/09 22:51:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:51:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.27 seconds.
[04/09 22:51:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 22:51:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:51:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 22:51:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 4.41 seconds.
[04/09 22:51:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:51:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.37 seconds.
[04/09 22:51:09] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.028 | 0.037  | 0.037  | 0.000 | 0.020 | 0.038 |
[04/09 22:51:09] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.277 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:51:09] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: Task: bbox
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: 0.0340,0.0371,0.0371,0.0000,0.0223,0.0476
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: Task: segm
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:51:09] d2.evaluation.testing INFO: copypaste: 0.0285,0.0371,0.0371,0.0000,0.0198,0.0376
[04/09 22:54:18] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:54:19] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:54:19] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:54:19] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:54:19] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:54:19] d2.utils.env INFO: Using a generated random seed 19498549
[04/09 22:54:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:54:31] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.98 seconds.
[04/09 22:54:32] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 22:54:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 22:54:46] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 22:54:46] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 22:55:45] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:55:46] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:55:46] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:55:46] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:55:46] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:55:46] d2.utils.env INFO: Using a generated random seed 46428683
[04/09 22:55:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:55:58] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.98 seconds.
[04/09 22:55:59] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 22:56:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 22:56:13] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 22:56:13] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 22:56:25] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 22:56:26] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.853917 (0.000285 s / iter per device, on 1 devices)
[04/09 22:56:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000192 s / iter per device, on 1 devices)
[04/09 22:56:26] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 22:56:26] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 22:56:26] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 22:56:26] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 22:56:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.21 seconds.
[04/09 22:56:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:56:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.27 seconds.
[04/09 22:56:30] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 22:56:30] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:56:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 22:56:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.94 seconds.
[04/09 22:56:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:56:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.30 seconds.
[04/09 22:56:34] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.028 | 0.037  | 0.037  | 0.000 | 0.020 | 0.038 |
[04/09 22:56:34] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.277 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:56:35] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: 0.0340,0.0371,0.0371,0.0000,0.0223,0.0476
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: Task: segm
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:56:35] d2.evaluation.testing INFO: copypaste: 0.0285,0.0371,0.0371,0.0000,0.0198,0.0376
[04/09 22:57:16] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:57:17] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:57:17] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:57:17] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:57:17] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:57:17] d2.utils.env INFO: Using a generated random seed 17575250
[04/09 22:57:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:57:29] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.84 seconds.
[04/09 22:57:30] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 22:57:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 22:57:44] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 22:57:45] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 22:57:58] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 22:57:59] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.884235 (0.000295 s / iter per device, on 1 devices)
[04/09 22:57:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000202 s / iter per device, on 1 devices)
[04/09 22:57:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 22:57:59] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 22:57:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 22:57:59] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 22:58:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.23 seconds.
[04/09 22:58:02] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:58:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.29 seconds.
[04/09 22:58:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 22:58:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:58:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 22:58:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 4.28 seconds.
[04/09 22:58:07] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 22:58:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.31 seconds.
[04/09 22:58:08] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.028 | 0.037  | 0.037  | 0.000 | 0.020 | 0.038 |
[04/09 22:58:08] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.277 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 22:58:08] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: 0.0340,0.0371,0.0371,0.0000,0.0223,0.0476
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: Task: segm
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 22:58:08] d2.evaluation.testing INFO: copypaste: 0.0285,0.0371,0.0371,0.0000,0.0198,0.0376
[04/09 22:59:33] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 22:59:34] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 22:59:34] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 22:59:34] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 22:59:34] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 22:59:34] d2.utils.env INFO: Using a generated random seed 35013612
[04/09 22:59:35] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 22:59:47] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.94 seconds.
[04/09 22:59:48] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:00:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:00:02] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:00:02] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 23:00:14] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 23:00:15] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.856417 (0.000286 s / iter per device, on 1 devices)
[04/09 23:00:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000192 s / iter per device, on 1 devices)
[04/09 23:00:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 23:00:15] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 23:00:15] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 23:00:15] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 23:00:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.21 seconds.
[04/09 23:00:18] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 23:00:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.28 seconds.
[04/09 23:00:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 23:00:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 23:00:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 23:00:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.97 seconds.
[04/09 23:00:22] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 23:00:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.30 seconds.
[04/09 23:00:23] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.028 | 0.037  | 0.037  | 0.000 | 0.020 | 0.038 |
[04/09 23:00:23] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.277 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 23:00:23] d2.engine.defaults INFO: Evaluation results for coco_2017_train in csv format:
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: Task: bbox
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: 0.0340,0.0371,0.0371,0.0000,0.0223,0.0476
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: Task: segm
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[04/09 23:00:23] d2.evaluation.testing INFO: copypaste: 0.0285,0.0371,0.0371,0.0000,0.0198,0.0376
[04/09 23:17:32] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:17:33] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:17:33] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:17:33] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:17:33] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:17:33] d2.utils.env INFO: Using a generated random seed 33671066
[04/09 23:17:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:17:46] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.86 seconds.
[04/09 23:17:46] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:18:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:18:00] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:18:00] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 23:19:46] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:19:47] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:19:47] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:19:47] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:19:47] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:19:47] d2.utils.env INFO: Using a generated random seed 47786769
[04/09 23:19:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:20:00] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.94 seconds.
[04/09 23:20:01] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:20:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:20:14] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:20:14] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 23:20:27] d2.evaluation.evaluator INFO: Start inference on 3000 batches
[04/09 23:20:27] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.831103 (0.000277 s / iter per device, on 1 devices)
[04/09 23:20:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.000188 s / iter per device, on 1 devices)
[04/09 23:20:27] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[04/09 23:20:27] d2.evaluation.coco_evaluation INFO: Saving results to ./output_300/inference/coco_instances_results.json
[04/09 23:20:27] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[04/09 23:20:28] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[04/09 23:20:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 3.21 seconds.
[04/09 23:20:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[04/09 23:20:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.28 seconds.
[04/09 23:20:31] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.034 | 0.037  | 0.037  | 0.000 | 0.022 | 0.048 |
[04/09 23:20:31] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.000 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 2.723 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.000 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.000 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
[04/09 23:20:31] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[04/09 23:28:08] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:28:08] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:28:08] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:28:08] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:28:08] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:28:09] d2.utils.env INFO: Using a generated random seed 9343124
[04/09 23:28:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:28:21] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.99 seconds.
[04/09 23:28:22] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:28:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:28:36] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:28:36] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 23:34:27] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:34:27] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:34:27] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:34:27] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:34:27] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:34:27] d2.utils.env INFO: Using a generated random seed 28201471
[04/09 23:34:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:34:40] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.98 seconds.
[04/09 23:34:41] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:35:16] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:35:17] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:35:17] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:35:17] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:35:17] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:35:17] d2.utils.env INFO: Using a generated random seed 17494030
[04/09 23:35:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:35:29] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.94 seconds.
[04/09 23:35:30] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:35:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:35:44] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:35:44] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/09 23:56:45] detectron2 INFO: Rank of current process: 0. World size: 1
[04/09 23:56:46] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.161.07
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/09 23:56:46] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['OUTPUT_DIR', './output_300/'])
[04/09 23:56:46] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/09 23:56:46] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/09 23:56:46] d2.utils.env INFO: Using a generated random seed 46396655
[04/09 23:56:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/09 23:56:58] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 11.92 seconds.
[04/09 23:56:59] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/09 23:57:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[04/09 23:57:13] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/09 23:57:13] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/18 23:51:36] detectron2 INFO: Rank of current process: 0. World size: 1
[04/18 23:51:37] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.171.04
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/18 23:51:37] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[04/18 23:51:37] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/18 23:51:37] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/18 23:51:37] d2.utils.env INFO: Using a generated random seed 37701134
[04/18 23:51:38] d2.engine.defaults INFO: | name                                             | #elements or shape   |
|:-------------------------------------------------|:---------------------|
| model                                            | 44.3M                |
|  backbone                                        |  26.8M               |
|   backbone.fpn_lateral2                          |   65.8K              |
|    backbone.fpn_lateral2.weight                  |    (256, 256, 1, 1)  |
|    backbone.fpn_lateral2.bias                    |    (256,)            |
|   backbone.fpn_output2                           |   0.6M               |
|    backbone.fpn_output2.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output2.bias                     |    (256,)            |
|   backbone.fpn_lateral3                          |   0.1M               |
|    backbone.fpn_lateral3.weight                  |    (256, 512, 1, 1)  |
|    backbone.fpn_lateral3.bias                    |    (256,)            |
|   backbone.fpn_output3                           |   0.6M               |
|    backbone.fpn_output3.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output3.bias                     |    (256,)            |
|   backbone.fpn_lateral4                          |   0.3M               |
|    backbone.fpn_lateral4.weight                  |    (256, 1024, 1, 1) |
|    backbone.fpn_lateral4.bias                    |    (256,)            |
|   backbone.fpn_output4                           |   0.6M               |
|    backbone.fpn_output4.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output4.bias                     |    (256,)            |
|   backbone.fpn_lateral5                          |   0.5M               |
|    backbone.fpn_lateral5.weight                  |    (256, 2048, 1, 1) |
|    backbone.fpn_lateral5.bias                    |    (256,)            |
|   backbone.fpn_output5                           |   0.6M               |
|    backbone.fpn_output5.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output5.bias                     |    (256,)            |
|   backbone.bottom_up                             |   23.5M              |
|    backbone.bottom_up.stem                       |    9.4K              |
|    backbone.bottom_up.res2                       |    0.2M              |
|    backbone.bottom_up.res3                       |    1.2M              |
|    backbone.bottom_up.res4                       |    7.1M              |
|    backbone.bottom_up.res5                       |    14.9M             |
|  proposal_generator                              |  0.6M                |
|   proposal_generator.rpn_head                    |   0.6M               |
|    proposal_generator.rpn_head.conv              |    0.6M              |
|    proposal_generator.rpn_head.objectness_logits |    0.8K              |
|    proposal_generator.rpn_head.anchor_deltas     |    3.1K              |
|  roi_heads                                       |  16.9M               |
|   roi_heads.box_head                             |   13.9M              |
|    roi_heads.box_head.fc1                        |    12.8M             |
|    roi_heads.box_head.fc2                        |    1.0M              |
|   roi_heads.box_predictor                        |   0.4M               |
|    roi_heads.box_predictor.cls_score             |    83.0K             |
|    roi_heads.box_predictor.bbox_pred             |    0.3M              |
|   roi_heads.mask_head                            |   2.6M               |
|    roi_heads.mask_head.mask_fcn1                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn2                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn3                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn4                 |    0.6M              |
|    roi_heads.mask_head.deconv                    |    0.3M              |
|    roi_heads.mask_head.predictor                 |    20.6K             |
[04/18 23:51:51] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 12.74 seconds.
[04/18 23:51:51] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/18 23:52:04] d2.data.build INFO: Removed 0 images with no usable annotations. 3000 images left.
[04/18 23:52:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[04/18 23:52:05] d2.data.build INFO: Using training sampler TrainingSampler
[04/18 23:52:05] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/18 23:52:05] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/18 23:52:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/18 23:52:06] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[04/18 23:52:06] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[04/18 23:52:06] d2.engine.train_loop INFO: Starting training from iteration 1
[04/18 23:52:08] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[04/18 23:52:08] d2.utils.events INFO:  iter: 2  total_loss: 4.32  loss_cls: 1.029  loss_box_reg: 0.5582  loss_mask: 0.6223  loss_rpn_cls: 1.646  loss_rpn_loc: 0.465  data_time: 0.1263  lr: N/A  max_mem: 1165M
[04/19 11:18:12] detectron2 INFO: Rank of current process: 0. World size: 1
[04/19 11:18:13] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]
numpy                   1.24.3
detectron2              0.6 @/mnt/ssd1/rujie/pytorch/detectron2/detectron2
Compiler                GCC 10.5
CUDA compiler           CUDA 12.0
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 2.1.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA TITAN Xp (arch=6.1)
Driver version          535.171.04
CUDA_HOME               /usr/local/cuda
Pillow                  10.0.1
torchvision             0.16.1 @/home/rujie/anaconda3/envs/torch/lib/python3.10/site-packages/torchvision
torchvision arch flags  5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.1
----------------------  ---------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/19 11:18:13] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50155', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.0025', 'MODEL.WEIGHTS', 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl', 'OUTPUT_DIR', './output_300'])
[04/19 11:18:13] detectron2 INFO: Contents of args.config_file=../configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50

[04/19 11:18:13] detectron2 INFO: Full config saved to ./output_300/config.yaml
[04/19 11:18:13] d2.utils.env INFO: Using a generated random seed 13752494
[04/19 11:18:14] d2.engine.defaults INFO: | name                                             | #elements or shape   |
|:-------------------------------------------------|:---------------------|
| model                                            | 44.3M                |
|  backbone                                        |  26.8M               |
|   backbone.fpn_lateral2                          |   65.8K              |
|    backbone.fpn_lateral2.weight                  |    (256, 256, 1, 1)  |
|    backbone.fpn_lateral2.bias                    |    (256,)            |
|   backbone.fpn_output2                           |   0.6M               |
|    backbone.fpn_output2.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output2.bias                     |    (256,)            |
|   backbone.fpn_lateral3                          |   0.1M               |
|    backbone.fpn_lateral3.weight                  |    (256, 512, 1, 1)  |
|    backbone.fpn_lateral3.bias                    |    (256,)            |
|   backbone.fpn_output3                           |   0.6M               |
|    backbone.fpn_output3.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output3.bias                     |    (256,)            |
|   backbone.fpn_lateral4                          |   0.3M               |
|    backbone.fpn_lateral4.weight                  |    (256, 1024, 1, 1) |
|    backbone.fpn_lateral4.bias                    |    (256,)            |
|   backbone.fpn_output4                           |   0.6M               |
|    backbone.fpn_output4.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output4.bias                     |    (256,)            |
|   backbone.fpn_lateral5                          |   0.5M               |
|    backbone.fpn_lateral5.weight                  |    (256, 2048, 1, 1) |
|    backbone.fpn_lateral5.bias                    |    (256,)            |
|   backbone.fpn_output5                           |   0.6M               |
|    backbone.fpn_output5.weight                   |    (256, 256, 3, 3)  |
|    backbone.fpn_output5.bias                     |    (256,)            |
|   backbone.bottom_up                             |   23.5M              |
|    backbone.bottom_up.stem                       |    9.4K              |
|    backbone.bottom_up.res2                       |    0.2M              |
|    backbone.bottom_up.res3                       |    1.2M              |
|    backbone.bottom_up.res4                       |    7.1M              |
|    backbone.bottom_up.res5                       |    14.9M             |
|  proposal_generator                              |  0.6M                |
|   proposal_generator.rpn_head                    |   0.6M               |
|    proposal_generator.rpn_head.conv              |    0.6M              |
|    proposal_generator.rpn_head.objectness_logits |    0.8K              |
|    proposal_generator.rpn_head.anchor_deltas     |    3.1K              |
|  roi_heads                                       |  16.9M               |
|   roi_heads.box_head                             |   13.9M              |
|    roi_heads.box_head.fc1                        |    12.8M             |
|    roi_heads.box_head.fc2                        |    1.0M              |
|   roi_heads.box_predictor                        |   0.4M               |
|    roi_heads.box_predictor.cls_score             |    83.0K             |
|    roi_heads.box_predictor.bbox_pred             |    0.3M              |
|   roi_heads.mask_head                            |   2.6M               |
|    roi_heads.mask_head.mask_fcn1                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn2                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn3                 |    0.6M              |
|    roi_heads.mask_head.mask_fcn4                 |    0.6M              |
|    roi_heads.mask_head.deconv                    |    0.3M              |
|    roi_heads.mask_head.predictor                 |    20.6K             |
[04/19 11:18:26] d2.data.datasets.coco INFO: Loading /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json takes 12.11 seconds.
[04/19 11:18:27] d2.data.datasets.coco INFO: Loaded 118287 images in COCO format from /mnt/ssd1/rujie/pytorch/dataset/coco/annotations/instances_train2017.json
[04/19 11:18:40] d2.data.build INFO: Removed 0 images with no usable annotations. 3000 images left.
[04/19 11:18:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=1333, sample_style='choice')]
[04/19 11:18:41] d2.data.build INFO: Using training sampler TrainingSampler
[04/19 11:18:41] d2.data.common INFO: Serializing 3000 elements to byte tensors and concatenating them all ...
[04/19 11:18:41] d2.data.common INFO: Serialized dataset takes 11.60 MiB
[04/19 11:18:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output_300/model_final.pth ...
[04/19 11:18:42] fvcore.common.checkpoint INFO: Loading trainer from ./output_300/model_final.pth ...
[04/19 11:18:42] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[04/19 11:18:42] d2.engine.train_loop INFO: Starting training from iteration 1
[04/19 11:18:43] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[04/19 11:18:43] d2.utils.events INFO:  iter: 2  total_loss: 2.183  loss_cls: 1.094  loss_box_reg: 0.3049  loss_mask: 0.4605  loss_rpn_cls: 0.2816  loss_rpn_loc: 0.04171  data_time: 0.1167  lr: N/A  max_mem: 1107M
